# WebSum - Web Scraping Tool

## üìã Table of Contents
- [‚ú® Features](#-features)
- [üöÄ Installation Guide](#-installation-guide)
- [üõ†Ô∏è Basic Usage](#Ô∏è-basic-usage)
- [üìÇ Output Structure](#-output-structure)
- [‚ùì FAQ](#-faq)
- [‚ö†Ô∏è Troubleshooting](#Ô∏è-troubleshooting)

## ‚ú® Features
- Extract clean markdown from web pages
- Follow up to 3 links automatically
- Save results in organized folders
- Remove headers/footers automatically

## üöÄ Installation Guide

### Prerequisites
1. Install [Python 3.10+](https://www.python.org/downloads/)
   - Check installation: `python --version`
2. (Recommended) Create virtual environment:
   ```bash
   python -m venv venv
   venv\Scripts\activate  # Windows
   source venv/bin/activate  # Mac/Linux
   ```

### Installation Steps
1. Clone repository:
   ```bash
   git clone https://github.com/yourusername/websum.git
   cd websum
   ```
2. Install requirements:
   ```bash
   pip install crawl4ai
   ```

## üõ†Ô∏è Basic Usage
```bash
python websum.py [URL] [MAX_LINKS]
```

### Examples
1. Basic usage (3 links):
   ```bash
   python websum.py https://example.com
   ```
2. Get 5 links:
   ```bash
   python websum.py https://example.com 5
   ```
3. Save to custom location:
   ```bash
   python websum.py https://example.com
   # Output saved to 'scraped_data/[timestamp]'
   ```

## üìÇ Output Structure
```
scraped_data/
‚îî‚îÄ‚îÄ 20240205_141543/          # Timestamp
    ‚îú‚îÄ‚îÄ base_page.md         # Main page content
    ‚îú‚îÄ‚îÄ link_1.md           # First linked page
    ‚îî‚îÄ‚îÄ link_2.md           # Second linked page
```

## ‚ùì FAQ
**Q:** How do I know if Python is installed correctly?
> Run `python --version` in your terminal. You should see 3.10 or higher.

**Q:** What if I get permission errors?
> Try running as administrator: Right-click Command Prompt > "Run as administrator"

**Q:** Where can I learn more about web scraping?
> - [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
> - [Scrapy Tutorial](https://docs.scrapy.org/en/latest/intro/tutorial.html)

## ‚ö†Ô∏è Troubleshooting
| Error | Solution |
|-------|----------|
| ModuleNotFoundError | Run `pip install -r requirements.txt` |
| Invalid URL | Add http:// prefix (e.g. `http://example.com`) |
| Empty output | Check if website blocks scrapers |

## ü§ù Support
For additional help:
- [Python Virtual Environments Guide](https://docs.python.org/3/tutorial/venv.html)
- [crawl4ai Documentation](https://pypi.org/project/crawl4ai/)

---
üìù License: MIT | ‚ö†Ô∏è Use responsibly | üïµÔ∏è Respect robots.txt
