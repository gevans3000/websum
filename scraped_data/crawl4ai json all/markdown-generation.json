{
  "url": "https://docs.crawl4ai.com/core/markdown-generation",
  "timestamp": "2025-02-06T13:23:45.310043",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"üöÄü§ñ Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/markdown-generation/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Markdown Generation - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Markdown Generation</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#markdown-generation-basics\">Markdown Generation Basics</a></li>\n        <li><a href=\"#1-quick-example\">1. Quick Example</a></li><li><a href=\"#2-how-markdown-generation-works\">2. How Markdown Generation Works</a></li><li><a href=\"#3-configuring-the-default-markdown-generator\">3. Configuring the Default Markdown Generator</a></li><li><a href=\"#4-content-filters\">4. Content Filters</a></li><li><a href=\"#5-using-fit-markdown\">5. Using Fit Markdown</a></li><li><a href=\"#6-the-markdowngenerationresult-object\">6. The MarkdownGenerationResult Object</a></li><li><a href=\"#7-combining-filters-bm25-pruning-in-two-passes\">7. Combining Filters (BM25 + Pruning) in Two Passes</a></li><li><a href=\"#8-common-pitfalls-tips\">8. Common Pitfalls &amp; Tips</a></li><li><a href=\"#9-summary-next-steps\">9. Summary &amp; Next Steps</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"markdown-generation-basics\">Markdown Generation Basics</h1>\n<p>One of Crawl4AI‚Äôs core features is generating <strong>clean, structured markdown</strong> from web pages. Originally built to solve the problem of extracting only the ‚Äúactual‚Äù content and discarding boilerplate or noise, Crawl4AI‚Äôs markdown system remains one of its biggest draws for AI workflows.</p>\n<p>In this tutorial, you‚Äôll learn:</p>\n<ol>\n<li>How to configure the <strong>Default Markdown Generator</strong>  </li>\n<li>How <strong>content filters</strong> (BM25 or Pruning) help you refine markdown and discard junk  </li>\n<li>The difference between raw markdown (<code>result.markdown</code>) and filtered markdown (<code>fit_markdown</code>)  </li>\n</ol>\n<blockquote>\n<p><strong>Prerequisites</strong><br>\n- You‚Äôve completed or read <a href=\"../simple-crawling/\">AsyncWebCrawler Basics</a> to understand how to run a simple crawl.<br>\n- You know how to configure <code>CrawlerRunConfig</code>.</p>\n</blockquote>\n<hr>\n<h2 id=\"1-quick-example\">1. Quick Example</h2>\n<p>Here‚Äôs a minimal code snippet that uses the <strong>DefaultMarkdownGenerator</strong> with no additional filtering:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        markdown_generator=DefaultMarkdownGenerator()\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown Output:\\n\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)  <span class=\"hljs-comment\"># The unfiltered markdown from the page</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>What‚Äôs happening?</strong><br>\n- <code>CrawlerRunConfig( markdown_generator = DefaultMarkdownGenerator() )</code> instructs Crawl4AI to convert the final HTML into markdown at the end of each crawl.<br>\n- The resulting markdown is accessible via <code>result.markdown</code>.</p>\n<hr>\n<h2 id=\"2-how-markdown-generation-works\">2. How Markdown Generation Works</h2>\n<h3 id=\"21-html-to-text-conversion-forked-modified\">2.1 HTML-to-Text Conversion (Forked &amp; Modified)</h3>\n<p>Under the hood, <strong>DefaultMarkdownGenerator</strong> uses a specialized HTML-to-text approach that:</p>\n<ul>\n<li>Preserves headings, code blocks, bullet points, etc.  </li>\n<li>Removes extraneous tags (scripts, styles) that don‚Äôt add meaningful content.  </li>\n<li>Can optionally generate references for links or skip them altogether.</li>\n</ul>\n<p>A set of <strong>options</strong> (passed as a dict) allows you to customize precisely how HTML converts to markdown. These map to standard html2text-like configuration plus your own enhancements (e.g., ignoring internal links, preserving certain tags verbatim, or adjusting line widths).</p>\n<h3 id=\"22-link-citations-references\">2.2 Link Citations &amp; References</h3>\n<p>By default, the generator can convert <code>&lt;a href=\"...\"&gt;</code> elements into <code>[text][1]</code> citations, then place the actual links at the bottom of the document. This is handy for research workflows that demand references in a structured manner.</p>\n<h3 id=\"23-optional-content-filters\">2.3 Optional Content Filters</h3>\n<p>Before or after the HTML-to-Markdown step, you can apply a <strong>content filter</strong> (like BM25 or Pruning) to reduce noise and produce a ‚Äúfit_markdown‚Äù‚Äîa heavily pruned version focusing on the page‚Äôs main text. We‚Äôll cover these filters shortly.</p>\n<hr>\n<h2 id=\"3-configuring-the-default-markdown-generator\">3. Configuring the Default Markdown Generator</h2>\n<p>You can tweak the output by passing an <code>options</code> dict to <code>DefaultMarkdownGenerator</code>. For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Example: ignore all links, don't escape HTML, and wrap text at 80 characters</span>\n    md_generator = DefaultMarkdownGenerator(\n        options={\n            <span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>,\n            <span class=\"hljs-string\">\"escape_html\"</span>: <span class=\"hljs-literal\">False</span>,\n            <span class=\"hljs-string\">\"body_width\"</span>: <span class=\"hljs-number\">80</span>\n        }\n    )\n\n    config = CrawlerRunConfig(\n        markdown_generator=md_generator\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/docs\"</span>, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown:\\n\"</span>, result.markdown[:<span class=\"hljs-number\">500</span>])  <span class=\"hljs-comment\"># Just a snippet</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    <span class=\"hljs-keyword\">import</span> asyncio\n    asyncio.run(main())\n</code></pre></div>\n<p>Some commonly used <code>options</code>:</p>\n<ul>\n<li><strong><code>ignore_links</code></strong> (bool): Whether to remove all hyperlinks in the final markdown.  </li>\n<li><strong><code>ignore_images</code></strong> (bool): Remove all <code>![image]()</code> references.  </li>\n<li><strong><code>escape_html</code></strong> (bool): Turn HTML entities into text (default is often <code>True</code>).  </li>\n<li><strong><code>body_width</code></strong> (int): Wrap text at N characters. <code>0</code> or <code>None</code> means no wrapping.  </li>\n<li><strong><code>skip_internal_links</code></strong> (bool): If <code>True</code>, omit <code>#localAnchors</code> or internal links referencing the same page.  </li>\n<li><strong><code>include_sup_sub</code></strong> (bool): Attempt to handle <code>&lt;sup&gt;</code> / <code>&lt;sub&gt;</code> in a more readable way.</li>\n</ul>\n<hr>\n<h2 id=\"4-content-filters\">4. Content Filters</h2>\n<p><strong>Content filters</strong> selectively remove or rank sections of text before turning them into Markdown. This is especially helpful if your page has ads, nav bars, or other clutter you don‚Äôt want.</p>\n<h3 id=\"41-bm25contentfilter\">4.1 BM25ContentFilter</h3>\n<p>If you have a <strong>search query</strong>, BM25 is a good choice:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> BM25ContentFilter\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\nbm25_filter = BM25ContentFilter(\n    user_query=<span class=\"hljs-string\">\"machine learning\"</span>,\n    bm25_threshold=<span class=\"hljs-number\">1.2</span>,\n    use_stemming=<span class=\"hljs-literal\">True</span>\n)\n\nmd_generator = DefaultMarkdownGenerator(\n    content_filter=bm25_filter,\n    options={<span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>}\n)\n\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n</code></pre></div>\n<ul>\n<li><strong><code>user_query</code></strong>: The term you want to focus on. BM25 tries to keep only content blocks relevant to that query.  </li>\n<li><strong><code>bm25_threshold</code></strong>: Raise it to keep fewer blocks; lower it to keep more.  </li>\n<li><strong><code>use_stemming</code></strong>: If <code>True</code>, variations of words match (e.g., ‚Äúlearn,‚Äù ‚Äúlearning,‚Äù ‚Äúlearnt‚Äù).</li>\n</ul>\n<p><strong>No query provided?</strong> BM25 tries to glean a context from page metadata, or you can simply treat it as a scorched-earth approach that discards text with low generic score. Realistically, you want to supply a query for best results.</p>\n<h3 id=\"42-pruningcontentfilter\">4.2 PruningContentFilter</h3>\n<p>If you <strong>don‚Äôt</strong> have a specific query, or if you just want a robust ‚Äújunk remover,‚Äù use <code>PruningContentFilter</code>. It analyzes text density, link density, HTML structure, and known patterns (like ‚Äúnav,‚Äù ‚Äúfooter‚Äù) to systematically prune extraneous or repetitive sections.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-cpp\">from crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n\nprune_filter = <span class=\"hljs-built_in\">PruningContentFilter</span>(\n    threshold=<span class=\"hljs-number\">0.5</span>,\n    threshold_type=<span class=\"hljs-string\">\"fixed\"</span>,  <span class=\"hljs-meta\"># or <span class=\"hljs-string\">\"dynamic\"</span></span>\n    min_word_threshold=<span class=\"hljs-number\">50</span>\n)\n</code></pre></div>\n<ul>\n<li><strong><code>threshold</code></strong>: Score boundary. Blocks below this score get removed.  </li>\n<li><strong><code>threshold_type</code></strong>:  <ul>\n<li><code>\"fixed\"</code>: Straight comparison (<code>score &gt;= threshold</code> keeps the block).  </li>\n<li><code>\"dynamic\"</code>: The filter adjusts threshold in a data-driven manner.  </li>\n</ul>\n</li>\n<li><strong><code>min_word_threshold</code></strong>: Discard blocks under N words as likely too short or unhelpful.</li>\n</ul>\n<p><strong>When to Use PruningContentFilter</strong><br>\n- You want a broad cleanup without a user query.<br>\n- The page has lots of repeated sidebars, footers, or disclaimers that hamper text extraction.</p>\n<h3 id=\"43-llmcontentfilter\">4.3 LLMContentFilter</h3>\n<p>For intelligent content filtering and high-quality markdown generation, you can use the <strong>LLMContentFilter</strong>. This filter leverages LLMs to generate relevant markdown while preserving the original content's meaning and structure:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> LLMContentFilter\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Initialize LLM filter with specific instruction</span>\n    <span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n        provider=<span class=\"hljs-string\">\"openai/gpt-4o\"</span>,  <span class=\"hljs-comment\"># or your preferred provider</span>\n        api_token=<span class=\"hljs-string\">\"your-api-token\"</span>,  <span class=\"hljs-comment\"># or use environment variable</span>\n        instruction=<span class=\"hljs-string\">\"\"\"\n        Focus on extracting the core educational content.\n        Include:\n        - Key concepts and explanations\n        - Important code examples\n        - Essential technical details\n        Exclude:\n        - Navigation elements\n        - Sidebars\n        - Footer content\n        Format the output as clean markdown with proper code blocks and headers.\n        \"\"\"</span>,\n        chunk_token_threshold=<span class=\"hljs-number\">4096</span>,  <span class=\"hljs-comment\"># Adjust based on your needs</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    config = CrawlerRunConfig(\n        content_filter=<span class=\"hljs-built_in\">filter</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n        <span class=\"hljs-built_in\">print</span>(result.fit_markdown)  <span class=\"hljs-comment\"># Filtered markdown content</span>\n</code></pre></div>\n<p><strong>Key Features:</strong>\n- <strong>Intelligent Filtering</strong>: Uses LLMs to understand and extract relevant content while maintaining context\n- <strong>Customizable Instructions</strong>: Tailor the filtering process with specific instructions\n- <strong>Chunk Processing</strong>: Handles large documents by processing them in chunks (controlled by <code>chunk_token_threshold</code>)\n- <strong>Parallel Processing</strong>: For better performance, use smaller <code>chunk_token_threshold</code> (e.g., 2048 or 4096) to enable parallel processing of content chunks</p>\n<p><strong>Two Common Use Cases:</strong></p>\n<ol>\n<li>\n<p><strong>Exact Content Preservation</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n    instruction=<span class=\"hljs-string\">\"\"\"\n    Extract the main educational content while preserving its original wording and substance completely.\n    1. Maintain the exact language and terminology\n    2. Keep all technical explanations and examples intact\n    3. Preserve the original flow and structure\n    4. Remove only clearly irrelevant elements like navigation menus and ads\n    \"\"\"</span>,\n    chunk_token_threshold=<span class=\"hljs-number\">4096</span>\n)\n</code></pre></div><p></p>\n</li>\n<li>\n<p><strong>Focused Content Extraction</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n    instruction=<span class=\"hljs-string\">\"\"\"\n    Focus on extracting specific types of content:\n    - Technical documentation\n    - Code examples\n    - API references\n    Reformat the content into clear, well-structured markdown\n    \"\"\"</span>,\n    chunk_token_threshold=<span class=\"hljs-number\">4096</span>\n)\n</code></pre></div><p></p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Performance Tip</strong>: Set a smaller <code>chunk_token_threshold</code> (e.g., 2048 or 4096) to enable parallel processing of content chunks. The default value is infinity, which processes the entire content as a single chunk.</p>\n</blockquote>\n<hr>\n<h2 id=\"5-using-fit-markdown\">5. Using Fit Markdown</h2>\n<p>When a content filter is active, the library produces two forms of markdown inside <code>result.markdown_v2</code> or (if using the simplified field) <code>result.markdown</code>:</p>\n<p>1.‚ÄÄ<strong><code>raw_markdown</code></strong>: The full unfiltered markdown.<br>\n2.‚ÄÄ<strong><code>fit_markdown</code></strong>: A ‚Äúfit‚Äù version where the filter has removed or trimmed noisy segments.</p>\n<p><strong>Note</strong>:  </p>\n<blockquote>\n<p>In earlier examples, you may see references to <code>result.markdown_v2</code>. Depending on your library version, you might access <code>result.markdown</code>, <code>result.markdown_v2</code>, or an object named <code>MarkdownGenerationResult</code>. The idea is the same: you‚Äôll have a raw version and a filtered (‚Äúfit‚Äù) version if a filter is used.</p>\n</blockquote>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        markdown_generator=DefaultMarkdownGenerator(\n            content_filter=PruningContentFilter(threshold=<span class=\"hljs-number\">0.6</span>),\n            options={<span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>}\n        )\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://news.example.com/tech\"</span>, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw markdown:\\n\"</span>, result.markdown)\n\n            <span class=\"hljs-comment\"># If a filter is used, we also have .fit_markdown:</span>\n            md_object = result.markdown_v2  <span class=\"hljs-comment\"># or your equivalent</span>\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Filtered markdown:\\n\"</span>, md_object.fit_markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"6-the-markdowngenerationresult-object\">6. The <code>MarkdownGenerationResult</code> Object</h2>\n<p>If your library stores detailed markdown output in an object like <code>MarkdownGenerationResult</code>, you‚Äôll see fields such as:</p>\n<ul>\n<li><strong><code>raw_markdown</code></strong>: The direct HTML-to-markdown transformation (no filtering).  </li>\n<li><strong><code>markdown_with_citations</code></strong>: A version that moves links to reference-style footnotes.  </li>\n<li><strong><code>references_markdown</code></strong>: A separate string or section containing the gathered references.  </li>\n<li><strong><code>fit_markdown</code></strong>: The filtered markdown if you used a content filter.  </li>\n<li><strong><code>fit_html</code></strong>: The corresponding HTML snippet used to generate <code>fit_markdown</code> (helpful for debugging or advanced usage).</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-swift\">md_obj <span class=\"hljs-operator\">=</span> result.markdown_v2  # your library‚Äôs naming may vary\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"RAW:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.raw_markdown)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"CITED:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.markdown_with_citations)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"REFERENCES:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.references_markdown)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"FIT:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.fit_markdown)\n</code></pre></div>\n<p><strong>Why Does This Matter?</strong><br>\n- You can supply <code>raw_markdown</code> to an LLM if you want the entire text.<br>\n- Or feed <code>fit_markdown</code> into a vector database to reduce token usage.<br>\n- <code>references_markdown</code> can help you keep track of link provenance.</p>\n<hr>\n<p>Below is a <strong>revised section</strong> under ‚ÄúCombining Filters (BM25 + Pruning)‚Äù that demonstrates how you can run <strong>two</strong> passes of content filtering without re-crawling, by taking the HTML (or text) from a first pass and feeding it into the second filter. It uses real code patterns from the snippet you provided for <strong>BM25ContentFilter</strong>, which directly accepts <strong>HTML</strong> strings (and can also handle plain text with minimal adaptation).</p>\n<hr>\n<h2 id=\"7-combining-filters-bm25-pruning-in-two-passes\">7. Combining Filters (BM25 + Pruning) in Two Passes</h2>\n<p>You might want to <strong>prune out</strong> noisy boilerplate first (with <code>PruningContentFilter</code>), and then <strong>rank what‚Äôs left</strong> against a user query (with <code>BM25ContentFilter</code>). You don‚Äôt have to crawl the page twice. Instead:</p>\n<p>1.‚ÄÄ<strong>First pass</strong>: Apply <code>PruningContentFilter</code> directly to the raw HTML from <code>result.html</code> (the crawler‚Äôs downloaded HTML).<br>\n2.‚ÄÄ<strong>Second pass</strong>: Take the pruned HTML (or text) from step 1, and feed it into <code>BM25ContentFilter</code>, focusing on a user query.</p>\n<h3 id=\"two-pass-example\">Two-Pass Example</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter, BM25ContentFilter\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> BeautifulSoup\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1. Crawl with minimal or no markdown generator, just get raw HTML</span>\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># If you only want raw HTML, you can skip passing a markdown_generator</span>\n        <span class=\"hljs-comment\"># or provide one but focus on .html in this example</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/tech-article\"</span>, config=config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success <span class=\"hljs-keyword\">or</span> <span class=\"hljs-keyword\">not</span> result.html:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed or no HTML content.\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        raw_html = result.html\n\n        <span class=\"hljs-comment\"># 2. First pass: PruningContentFilter on raw HTML</span>\n        pruning_filter = PruningContentFilter(threshold=<span class=\"hljs-number\">0.5</span>, min_word_threshold=<span class=\"hljs-number\">50</span>)\n\n        <span class=\"hljs-comment\"># filter_content returns a list of \"text chunks\" or cleaned HTML sections</span>\n        pruned_chunks = pruning_filter.filter_content(raw_html)\n        <span class=\"hljs-comment\"># This list is basically pruned content blocks, presumably in HTML or text form</span>\n\n        <span class=\"hljs-comment\"># For demonstration, let's combine these chunks back into a single HTML-like string</span>\n        <span class=\"hljs-comment\"># or you could do further processing. It's up to your pipeline design.</span>\n        pruned_html = <span class=\"hljs-string\">\"\\n\"</span>.join(pruned_chunks)\n\n        <span class=\"hljs-comment\"># 3. Second pass: BM25ContentFilter with a user query</span>\n        bm25_filter = BM25ContentFilter(\n            user_query=<span class=\"hljs-string\">\"machine learning\"</span>,\n            bm25_threshold=<span class=\"hljs-number\">1.2</span>,\n            language=<span class=\"hljs-string\">\"english\"</span>\n        )\n\n        <span class=\"hljs-comment\"># returns a list of text chunks</span>\n        bm25_chunks = bm25_filter.filter_content(pruned_html)  \n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> bm25_chunks:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Nothing matched the BM25 query after pruning.\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-comment\"># 4. Combine or display final results</span>\n        final_text = <span class=\"hljs-string\">\"\\n---\\n\"</span>.join(bm25_chunks)\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"==== PRUNED OUTPUT (first pass) ====\"</span>)\n        <span class=\"hljs-built_in\">print</span>(pruned_html[:<span class=\"hljs-number\">500</span>], <span class=\"hljs-string\">\"... (truncated)\"</span>)  <span class=\"hljs-comment\"># preview</span>\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n==== BM25 OUTPUT (second pass) ====\"</span>)\n        <span class=\"hljs-built_in\">print</span>(final_text[:<span class=\"hljs-number\">500</span>], <span class=\"hljs-string\">\"... (truncated)\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"whats-happening\">What‚Äôs Happening?</h3>\n<p>1.‚ÄÄ<strong>Raw HTML</strong>: We crawl once and store the raw HTML in <code>result.html</code>.<br>\n2.‚ÄÄ<strong>PruningContentFilter</strong>: Takes HTML + optional parameters. It extracts blocks of text or partial HTML, removing headings/sections deemed ‚Äúnoise.‚Äù It returns a <strong>list of text chunks</strong>.<br>\n3.‚ÄÄ<strong>Combine or Transform</strong>: We join these pruned chunks back into a single HTML-like string. (Alternatively, you could store them in a list for further logic‚Äîwhatever suits your pipeline.)<br>\n4.‚ÄÄ<strong>BM25ContentFilter</strong>: We feed the pruned string into <code>BM25ContentFilter</code> with a user query. This second pass further narrows the content to chunks relevant to ‚Äúmachine learning.‚Äù</p>\n<p><strong>No Re-Crawling</strong>: We used <code>raw_html</code> from the first pass, so there‚Äôs no need to run <code>arun()</code> again‚Äî<strong>no second network request</strong>.</p>\n<h3 id=\"tips-variations\">Tips &amp; Variations</h3>\n<ul>\n<li><strong>Plain Text vs. HTML</strong>: If your pruned output is mostly text, BM25 can still handle it; just keep in mind it expects a valid string input. If you supply partial HTML (like <code>\"&lt;p&gt;some text&lt;/p&gt;\"</code>), it will parse it as HTML.  </li>\n<li><strong>Chaining in a Single Pipeline</strong>: If your code supports it, you can chain multiple filters automatically. Otherwise, manual two-pass filtering (as shown) is straightforward.  </li>\n<li><strong>Adjust Thresholds</strong>: If you see too much or too little text in step one, tweak <code>threshold=0.5</code> or <code>min_word_threshold=50</code>. Similarly, <code>bm25_threshold=1.2</code> can be raised/lowered for more or fewer chunks in step two.</li>\n</ul>\n<h3 id=\"one-pass-combination\">One-Pass Combination?</h3>\n<p>If your codebase or pipeline design allows applying multiple filters in one pass, you could do so. But often it‚Äôs simpler‚Äîand more transparent‚Äîto run them sequentially, analyzing each step‚Äôs result.</p>\n<p><strong>Bottom Line</strong>: By <strong>manually chaining</strong> your filtering logic in two passes, you get powerful incremental control over the final content. First, remove ‚Äúglobal‚Äù clutter with Pruning, then refine further with BM25-based query relevance‚Äîwithout incurring a second network crawl.</p>\n<hr>\n<h2 id=\"8-common-pitfalls-tips\">8. Common Pitfalls &amp; Tips</h2>\n<p>1.‚ÄÄ<strong>No Markdown Output?</strong><br>\n   - Make sure the crawler actually retrieved HTML. If the site is heavily JS-based, you may need to enable dynamic rendering or wait for elements.<br>\n   - Check if your content filter is too aggressive. Lower thresholds or disable the filter to see if content reappears.</p>\n<p>2.‚ÄÄ<strong>Performance Considerations</strong><br>\n   - Very large pages with multiple filters can be slower. Consider <code>cache_mode</code> to avoid re-downloading.<br>\n   - If your final use case is LLM ingestion, consider summarizing further or chunking big texts.</p>\n<p>3.‚ÄÄ<strong>Take Advantage of <code>fit_markdown</code></strong><br>\n   - Great for RAG pipelines, semantic search, or any scenario where extraneous boilerplate is unwanted.<br>\n   - Still verify the textual quality‚Äîsome sites have crucial data in footers or sidebars.</p>\n<p>4.‚ÄÄ<strong>Adjusting <code>html2text</code> Options</strong><br>\n   - If you see lots of raw HTML slipping into the text, turn on <code>escape_html</code>.<br>\n   - If code blocks look messy, experiment with <code>mark_code</code> or <code>handle_code_in_pre</code>.</p>\n<hr>\n<h2 id=\"9-summary-next-steps\">9. Summary &amp; Next Steps</h2>\n<p>In this <strong>Markdown Generation Basics</strong> tutorial, you learned to:</p>\n<ul>\n<li>Configure the <strong>DefaultMarkdownGenerator</strong> with HTML-to-text options.  </li>\n<li>Use <strong>BM25ContentFilter</strong> for query-specific extraction or <strong>PruningContentFilter</strong> for general noise removal.  </li>\n<li>Distinguish between raw and filtered markdown (<code>fit_markdown</code>).  </li>\n<li>Leverage the <code>MarkdownGenerationResult</code> object to handle different forms of output (citations, references, etc.).</li>\n</ul>\n<p>Now you can produce high-quality Markdown from any website, focusing on exactly the content you need‚Äîan essential step for powering AI models, summarization pipelines, or knowledge-base queries.</p>\n<p><strong>Last Updated</strong>: 2025-01-01</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Markdown Generation Basics\nOne of Crawl4AI‚Äôs core features is generating **clean, structured markdown** from web pages. Originally built to solve the problem of extracting only the ‚Äúactual‚Äù content and discarding boilerplate or noise, Crawl4AI‚Äôs markdown system remains one of its biggest draws for AI workflows.\nIn this tutorial, you‚Äôll learn:\n  1. How to configure the **Default Markdown Generator**\n  2. How **content filters** (BM25 or Pruning) help you refine markdown and discard junk \n  3. The difference between raw markdown (`result.markdown`) and filtered markdown (`fit_markdown`) \n\n\n> **Prerequisites** - You‚Äôve completed or read [AsyncWebCrawler Basics](https://docs.crawl4ai.com/core/<../simple-crawling/>) to understand how to run a simple crawl. - You know how to configure `CrawlerRunConfig`.\n## 1. Quick Example\nHere‚Äôs a minimal code snippet that uses the **DefaultMarkdownGenerator** with no additional filtering:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nasync def main():\n  config = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator()\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\", config=config)\n    if result.success:\n      print(\"Raw Markdown Output:\\n\")\n      print(result.markdown) # The unfiltered markdown from the page\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**What‚Äôs happening?** - `CrawlerRunConfig( markdown_generator = DefaultMarkdownGenerator() )` instructs Crawl4AI to convert the final HTML into markdown at the end of each crawl. - The resulting markdown is accessible via `result.markdown`.\n## 2. How Markdown Generation Works\n### 2.1 HTML-to-Text Conversion (Forked & Modified)\nUnder the hood, **DefaultMarkdownGenerator** uses a specialized HTML-to-text approach that:\n  * Preserves headings, code blocks, bullet points, etc. \n  * Removes extraneous tags (scripts, styles) that don‚Äôt add meaningful content. \n  * Can optionally generate references for links or skip them altogether.\n\n\nA set of **options** (passed as a dict) allows you to customize precisely how HTML converts to markdown. These map to standard html2text-like configuration plus your own enhancements (e.g., ignoring internal links, preserving certain tags verbatim, or adjusting line widths).\n### 2.2 Link Citations & References\nBy default, the generator can convert `<a href=\"...\">` elements into `[text][1]` citations, then place the actual links at the bottom of the document. This is handy for research workflows that demand references in a structured manner.\n### 2.3 Optional Content Filters\nBefore or after the HTML-to-Markdown step, you can apply a **content filter** (like BM25 or Pruning) to reduce noise and produce a ‚Äúfit_markdown‚Äù‚Äîa heavily pruned version focusing on the page‚Äôs main text. We‚Äôll cover these filters shortly.\n## 3. Configuring the Default Markdown Generator\nYou can tweak the output by passing an `options` dict to `DefaultMarkdownGenerator`. For example:\n```\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Example: ignore all links, don't escape HTML, and wrap text at 80 characters\n  md_generator = DefaultMarkdownGenerator(\n    options={\n      \"ignore_links\": True,\n      \"escape_html\": False,\n      \"body_width\": 80\n    }\n  )\n  config = CrawlerRunConfig(\n    markdown_generator=md_generator\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com/docs\", config=config)\n    if result.success:\n      print(\"Markdown:\\n\", result.markdown[:500]) # Just a snippet\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  import asyncio\n  asyncio.run(main())\n\n```\n\nSome commonly used `options`:\n  * **`ignore_links`**(bool): Whether to remove all hyperlinks in the final markdown.\n  * **`ignore_images`**(bool): Remove all`![image]()` references. \n  * **`escape_html`**(bool): Turn HTML entities into text (default is often`True`). \n  * **`body_width`**(int): Wrap text at N characters.`0` or `None` means no wrapping. \n  * **`skip_internal_links`**(bool): If`True` , omit `#localAnchors` or internal links referencing the same page. \n  * **`include_sup_sub`**(bool): Attempt to handle`<sup>` / `<sub>` in a more readable way.\n\n\n## 4. Content Filters\n**Content filters** selectively remove or rank sections of text before turning them into Markdown. This is especially helpful if your page has ads, nav bars, or other clutter you don‚Äôt want.\n### 4.1 BM25ContentFilter\nIf you have a **search query** , BM25 is a good choice:\n```\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai.content_filter_strategy import BM25ContentFilter\nfrom crawl4ai import CrawlerRunConfig\nbm25_filter = BM25ContentFilter(\n  user_query=\"machine learning\",\n  bm25_threshold=1.2,\n  use_stemming=True\n)\nmd_generator = DefaultMarkdownGenerator(\n  content_filter=bm25_filter,\n  options={\"ignore_links\": True}\n)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n\n```\n\n  * **`user_query`**: The term you want to focus on. BM25 tries to keep only content blocks relevant to that query.\n  * **`bm25_threshold`**: Raise it to keep fewer blocks; lower it to keep more.\n  * **`use_stemming`**: If`True` , variations of words match (e.g., ‚Äúlearn,‚Äù ‚Äúlearning,‚Äù ‚Äúlearnt‚Äù).\n\n\n**No query provided?** BM25 tries to glean a context from page metadata, or you can simply treat it as a scorched-earth approach that discards text with low generic score. Realistically, you want to supply a query for best results.\n### 4.2 PruningContentFilter\nIf you **don‚Äôt** have a specific query, or if you just want a robust ‚Äújunk remover,‚Äù use `PruningContentFilter`. It analyzes text density, link density, HTML structure, and known patterns (like ‚Äúnav,‚Äù ‚Äúfooter‚Äù) to systematically prune extraneous or repetitive sections.\n```\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nprune_filter = PruningContentFilter(\n  threshold=0.5,\n  threshold_type=\"fixed\", # or \"dynamic\"\n  min_word_threshold=50\n)\n\n```\n\n  * **`threshold`**: Score boundary. Blocks below this score get removed.\n  * **`threshold_type`**:\n    * `\"fixed\"`: Straight comparison (`score >= threshold` keeps the block). \n    * `\"dynamic\"`: The filter adjusts threshold in a data-driven manner. \n  * **`min_word_threshold`**: Discard blocks under N words as likely too short or unhelpful.\n\n\n**When to Use PruningContentFilter** - You want a broad cleanup without a user query. - The page has lots of repeated sidebars, footers, or disclaimers that hamper text extraction.\n### 4.3 LLMContentFilter\nFor intelligent content filtering and high-quality markdown generation, you can use the **LLMContentFilter**. This filter leverages LLMs to generate relevant markdown while preserving the original content's meaning and structure:\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import LLMContentFilter\nasync def main():\n  # Initialize LLM filter with specific instruction\n  filter = LLMContentFilter(\n    provider=\"openai/gpt-4o\", # or your preferred provider\n    api_token=\"your-api-token\", # or use environment variable\n    instruction=\"\"\"\n    Focus on extracting the core educational content.\n    Include:\n    - Key concepts and explanations\n    - Important code examples\n    - Essential technical details\n    Exclude:\n    - Navigation elements\n    - Sidebars\n    - Footer content\n    Format the output as clean markdown with proper code blocks and headers.\n    \"\"\",\n    chunk_token_threshold=4096, # Adjust based on your needs\n    verbose=True\n  )\n  config = CrawlerRunConfig(\n    content_filter=filter\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\", config=config)\n    print(result.fit_markdown) # Filtered markdown content\n\n```\n\n**Key Features:** - **Intelligent Filtering** : Uses LLMs to understand and extract relevant content while maintaining context - **Customizable Instructions** : Tailor the filtering process with specific instructions - **Chunk Processing** : Handles large documents by processing them in chunks (controlled by `chunk_token_threshold`) - **Parallel Processing** : For better performance, use smaller `chunk_token_threshold` (e.g., 2048 or 4096) to enable parallel processing of content chunks\n**Two Common Use Cases:**\n  1. **Exact Content Preservation** : \n```\nfilter = LLMContentFilter(\n  instruction=\"\"\"\n  Extract the main educational content while preserving its original wording and substance completely.\n  1. Maintain the exact language and terminology\n  2. Keep all technical explanations and examples intact\n  3. Preserve the original flow and structure\n  4. Remove only clearly irrelevant elements like navigation menus and ads\n  \"\"\",\n  chunk_token_threshold=4096\n)\n\n```\n\n  2. **Focused Content Extraction** : \n```\nfilter = LLMContentFilter(\n  instruction=\"\"\"\n  Focus on extracting specific types of content:\n  - Technical documentation\n  - Code examples\n  - API references\n  Reformat the content into clear, well-structured markdown\n  \"\"\",\n  chunk_token_threshold=4096\n)\n\n```\n\n\n\n> **Performance Tip** : Set a smaller `chunk_token_threshold` (e.g., 2048 or 4096) to enable parallel processing of content chunks. The default value is infinity, which processes the entire content as a single chunk.\n## 5. Using Fit Markdown\nWhen a content filter is active, the library produces two forms of markdown inside `result.markdown_v2` or (if using the simplified field) `result.markdown`:\n1. **`raw_markdown`**: The full unfiltered markdown. 2.**`fit_markdown`**: A ‚Äúfit‚Äù version where the filter has removed or trimmed noisy segments.\n**Note** : \n> In earlier examples, you may see references to `result.markdown_v2`. Depending on your library version, you might access `result.markdown`, `result.markdown_v2`, or an object named `MarkdownGenerationResult`. The idea is the same: you‚Äôll have a raw version and a filtered (‚Äúfit‚Äù) version if a filter is used.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nasync def main():\n  config = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator(\n      content_filter=PruningContentFilter(threshold=0.6),\n      options={\"ignore_links\": True}\n    )\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://news.example.com/tech\", config=config)\n    if result.success:\n      print(\"Raw markdown:\\n\", result.markdown)\n      # If a filter is used, we also have .fit_markdown:\n      md_object = result.markdown_v2 # or your equivalent\n      print(\"Filtered markdown:\\n\", md_object.fit_markdown)\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 6. The `MarkdownGenerationResult` Object\nIf your library stores detailed markdown output in an object like `MarkdownGenerationResult`, you‚Äôll see fields such as:\n  * **`raw_markdown`**: The direct HTML-to-markdown transformation (no filtering).\n  * **`markdown_with_citations`**: A version that moves links to reference-style footnotes.\n  * **`references_markdown`**: A separate string or section containing the gathered references.\n  * **`fit_markdown`**: The filtered markdown if you used a content filter.\n  * **`fit_html`**: The corresponding HTML snippet used to generate`fit_markdown` (helpful for debugging or advanced usage).\n\n\n**Example** :\n```\nmd_obj = result.markdown_v2 # your library‚Äôs naming may vary\nprint(\"RAW:\\n\", md_obj.raw_markdown)\nprint(\"CITED:\\n\", md_obj.markdown_with_citations)\nprint(\"REFERENCES:\\n\", md_obj.references_markdown)\nprint(\"FIT:\\n\", md_obj.fit_markdown)\n\n```\n\n**Why Does This Matter?** - You can supply `raw_markdown` to an LLM if you want the entire text. - Or feed `fit_markdown` into a vector database to reduce token usage. - `references_markdown` can help you keep track of link provenance.\nBelow is a **revised section** under ‚ÄúCombining Filters (BM25 + Pruning)‚Äù that demonstrates how you can run **two** passes of content filtering without re-crawling, by taking the HTML (or text) from a first pass and feeding it into the second filter. It uses real code patterns from the snippet you provided for **BM25ContentFilter** , which directly accepts **HTML** strings (and can also handle plain text with minimal adaptation).\n## 7. Combining Filters (BM25 + Pruning) in Two Passes\nYou might want to **prune out** noisy boilerplate first (with `PruningContentFilter`), and then **rank what‚Äôs left** against a user query (with `BM25ContentFilter`). You don‚Äôt have to crawl the page twice. Instead:\n1. **First pass** : Apply `PruningContentFilter` directly to the raw HTML from `result.html` (the crawler‚Äôs downloaded HTML). 2. **Second pass** : Take the pruned HTML (or text) from step 1, and feed it into `BM25ContentFilter`, focusing on a user query.\n### Two-Pass Example\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter\nfrom bs4 import BeautifulSoup\nasync def main():\n  # 1. Crawl with minimal or no markdown generator, just get raw HTML\n  config = CrawlerRunConfig(\n    # If you only want raw HTML, you can skip passing a markdown_generator\n    # or provide one but focus on .html in this example\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com/tech-article\", config=config)\n    if not result.success or not result.html:\n      print(\"Crawl failed or no HTML content.\")\n      return\n    raw_html = result.html\n    # 2. First pass: PruningContentFilter on raw HTML\n    pruning_filter = PruningContentFilter(threshold=0.5, min_word_threshold=50)\n    # filter_content returns a list of \"text chunks\" or cleaned HTML sections\n    pruned_chunks = pruning_filter.filter_content(raw_html)\n    # This list is basically pruned content blocks, presumably in HTML or text form\n    # For demonstration, let's combine these chunks back into a single HTML-like string\n    # or you could do further processing. It's up to your pipeline design.\n    pruned_html = \"\\n\".join(pruned_chunks)\n    # 3. Second pass: BM25ContentFilter with a user query\n    bm25_filter = BM25ContentFilter(\n      user_query=\"machine learning\",\n      bm25_threshold=1.2,\n      language=\"english\"\n    )\n    # returns a list of text chunks\n    bm25_chunks = bm25_filter.filter_content(pruned_html) \n    if not bm25_chunks:\n      print(\"Nothing matched the BM25 query after pruning.\")\n      return\n    # 4. Combine or display final results\n    final_text = \"\\n---\\n\".join(bm25_chunks)\n    print(\"==== PRUNED OUTPUT (first pass) ====\")\n    print(pruned_html[:500], \"... (truncated)\") # preview\n    print(\"\\n==== BM25 OUTPUT (second pass) ====\")\n    print(final_text[:500], \"... (truncated)\")\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### What‚Äôs Happening?\n1. **Raw HTML** : We crawl once and store the raw HTML in `result.html`. 2. **PruningContentFilter** : Takes HTML + optional parameters. It extracts blocks of text or partial HTML, removing headings/sections deemed ‚Äúnoise.‚Äù It returns a **list of text chunks**. 3. **Combine or Transform** : We join these pruned chunks back into a single HTML-like string. (Alternatively, you could store them in a list for further logic‚Äîwhatever suits your pipeline.) 4. **BM25ContentFilter** : We feed the pruned string into `BM25ContentFilter` with a user query. This second pass further narrows the content to chunks relevant to ‚Äúmachine learning.‚Äù\n**No Re-Crawling** : We used `raw_html` from the first pass, so there‚Äôs no need to run `arun()` again‚Äî**no second network request**.\n### Tips & Variations\n  * **Plain Text vs. HTML** : If your pruned output is mostly text, BM25 can still handle it; just keep in mind it expects a valid string input. If you supply partial HTML (like `\"<p>some text</p>\"`), it will parse it as HTML. \n  * **Chaining in a Single Pipeline** : If your code supports it, you can chain multiple filters automatically. Otherwise, manual two-pass filtering (as shown) is straightforward. \n  * **Adjust Thresholds** : If you see too much or too little text in step one, tweak `threshold=0.5` or `min_word_threshold=50`. Similarly, `bm25_threshold=1.2` can be raised/lowered for more or fewer chunks in step two.\n\n\n### One-Pass Combination?\nIf your codebase or pipeline design allows applying multiple filters in one pass, you could do so. But often it‚Äôs simpler‚Äîand more transparent‚Äîto run them sequentially, analyzing each step‚Äôs result.\n**Bottom Line** : By **manually chaining** your filtering logic in two passes, you get powerful incremental control over the final content. First, remove ‚Äúglobal‚Äù clutter with Pruning, then refine further with BM25-based query relevance‚Äîwithout incurring a second network crawl.\n## 8. Common Pitfalls & Tips\n1. **No Markdown Output?** - Make sure the crawler actually retrieved HTML. If the site is heavily JS-based, you may need to enable dynamic rendering or wait for elements. - Check if your content filter is too aggressive. Lower thresholds or disable the filter to see if content reappears.\n2. **Performance Considerations** - Very large pages with multiple filters can be slower. Consider `cache_mode` to avoid re-downloading. - If your final use case is LLM ingestion, consider summarizing further or chunking big texts.\n3. **Take Advantage of`fit_markdown`** - Great for RAG pipelines, semantic search, or any scenario where extraneous boilerplate is unwanted. - Still verify the textual quality‚Äîsome sites have crucial data in footers or sidebars.\n4. **Adjusting`html2text` Options** - If you see lots of raw HTML slipping into the text, turn on `escape_html`. - If code blocks look messy, experiment with `mark_code` or `handle_code_in_pre`.\n## 9. Summary & Next Steps\nIn this **Markdown Generation Basics** tutorial, you learned to:\n  * Configure the **DefaultMarkdownGenerator** with HTML-to-text options. \n  * Use **BM25ContentFilter** for query-specific extraction or **PruningContentFilter** for general noise removal. \n  * Distinguish between raw and filtered markdown (`fit_markdown`). \n  * Leverage the `MarkdownGenerationResult` object to handle different forms of output (citations, references, etc.).\n\n\nNow you can produce high-quality Markdown from any website, focusing on exactly the content you need‚Äîan essential step for powering AI models, summarization pipelines, or knowledge-base queries.\n**Last Updated** : 2025-01-01\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/browser-crawler-config",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/crawler-result",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/link-media",
    "https://docs.crawl4ai.com/local-files",
    "https://docs.crawl4ai.com/page-interaction",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 23,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:29",
    "page_limit": 34
  }
}