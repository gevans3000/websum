[
  {
    "source_file": "arun.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/arun",
      "timestamp": "2025-02-06T13:23:25.908734",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/arun/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>arun() - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">arun()</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#arun-parameter-guide-new-approach\">arun() Parameter Guide (New Approach)</a></li>\n        <li><a href=\"#1-core-usage\">1. Core Usage</a></li><li><a href=\"#2-cache-control\">2. Cache Control</a></li><li><a href=\"#3-content-processing-selection\">3. Content Processing &amp; Selection</a></li><li><a href=\"#4-page-navigation-timing\">4. Page Navigation &amp; Timing</a></li><li><a href=\"#5-session-management\">5. Session Management</a></li><li><a href=\"#6-screenshot-pdf-media-options\">6. Screenshot, PDF &amp; Media Options</a></li><li><a href=\"#7-extraction-strategy\">7. Extraction Strategy</a></li><li><a href=\"#8-comprehensive-example\">8. Comprehensive Example</a></li><li><a href=\"#9-best-practices\">9. Best Practices</a></li><li><a href=\"#10-conclusion\">10. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"arun-parameter-guide-new-approach\"><code>arun()</code> Parameter Guide (New Approach)</h1>\n<p>In Crawl4AI\u2019s <strong>latest</strong> configuration model, nearly all parameters that once went directly to <code>arun()</code> are now part of <strong><code>CrawlerRunConfig</code></strong>.\u2000When calling <code>arun()</code>, you provide:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">await</span> crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com\"</span>,  \n    config=my_run_config\n)\n</code></pre></div>\n<p>Below is an organized look at the parameters that can go inside <code>CrawlerRunConfig</code>, divided by their functional areas.\u2000For <strong>Browser</strong> settings (e.g., <code>headless</code>, <code>browser_type</code>), see <a href=\"../parameters/\">BrowserConfig</a>.</p>\n<hr>\n<h2 id=\"1-core-usage\">1.\u2000Core Usage</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    run_config = CrawlerRunConfig(\n        verbose=<span class=\"hljs-literal\">True</span>,            <span class=\"hljs-comment\"># Detailed logging</span>\n        cache_mode=CacheMode.ENABLED,  <span class=\"hljs-comment\"># Use normal read/write cache</span>\n        check_robots_txt=<span class=\"hljs-literal\">True</span>,   <span class=\"hljs-comment\"># Respect robots.txt rules</span>\n        <span class=\"hljs-comment\"># ...\u2000other parameters</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n            config=run_config\n        )\n\n        <span class=\"hljs-comment\"># Check if blocked by robots.txt</span>\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success <span class=\"hljs-keyword\">and</span> result.status_code == <span class=\"hljs-number\">403</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Error: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n</code></pre></div>\n<p><strong>Key Fields</strong>:\n- <code>verbose=True</code> logs each crawl step.\u2000 \n- <code>cache_mode</code> decides how to read/write the local crawl cache.</p>\n<hr>\n<h2 id=\"2-cache-control\">2.\u2000Cache Control</h2>\n<p><strong><code>cache_mode</code></strong> (default: <code>CacheMode.ENABLED</code>)<br>\nUse a built-in enum from <code>CacheMode</code>:</p>\n<ul>\n<li><code>ENABLED</code>: Normal caching\u2014reads if available, writes if missing.</li>\n<li><code>DISABLED</code>: No caching\u2014always refetch pages.</li>\n<li><code>READ_ONLY</code>: Reads from cache only; no new writes.</li>\n<li><code>WRITE_ONLY</code>: Writes to cache but doesn\u2019t read existing data.</li>\n<li><code>BYPASS</code>: Skips reading cache for this crawl (though it might still write if set up that way).</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">run_config = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS\n)\n</code></pre></div>\n<p><strong>Additional flags</strong>:</p>\n<ul>\n<li><code>bypass_cache=True</code> acts like <code>CacheMode.BYPASS</code>.</li>\n<li><code>disable_cache=True</code> acts like <code>CacheMode.DISABLED</code>.</li>\n<li><code>no_cache_read=True</code> acts like <code>CacheMode.WRITE_ONLY</code>.</li>\n<li><code>no_cache_write=True</code> acts like <code>CacheMode.READ_ONLY</code>.</li>\n</ul>\n<hr>\n<h2 id=\"3-content-processing-selection\">3.\u2000Content Processing &amp; Selection</h2>\n<h3 id=\"31-text-processing\">3.1 Text Processing</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    word_count_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">10</span>,   <span class=\"hljs-comment\"># Ignore text blocks &lt;10 words</span>\n    only_text<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">False</span>,           <span class=\"hljs-comment\"># If True, tries to remove non-text elements</span>\n    keep_data_attributes<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">False</span> <span class=\"hljs-comment\"># Keep or discard data-* attributes</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<h3 id=\"32-content-selection\">3.2 Content Selection</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    css_selector<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\".main-content\"</span>,  <span class=\"hljs-comment\"># Focus on .main-content region only</span>\n    excluded_tags<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"form\"</span>, <span class=\"hljs-string\">\"nav\"</span><span class=\"hljs-punctuation\">]</span>, <span class=\"hljs-comment\"># Remove entire tag blocks</span>\n    remove_forms<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># Specifically strip &lt;form&gt; elements</span>\n    remove_overlay_elements<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Attempt to remove modals/popups</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<h3 id=\"33-link-handling\">3.3 Link Handling</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    exclude_external_links<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,         <span class=\"hljs-comment\"># Remove external links from final content</span>\n    exclude_social_media_links<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,     <span class=\"hljs-comment\"># Remove links to known social sites</span>\n    exclude_domains<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"ads.example.com\"</span><span class=\"hljs-punctuation\">]</span>, <span class=\"hljs-comment\"># Exclude links to these domains</span>\n    exclude_social_media_domains<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"facebook.com\"</span>,<span class=\"hljs-string\">\"twitter.com\"</span><span class=\"hljs-punctuation\">]</span>, <span class=\"hljs-comment\"># Extend the default list</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<h3 id=\"34-media-filtering\">3.4 Media Filtering</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    exclude_external_images<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Strip images from other domains</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<hr>\n<h2 id=\"4-page-navigation-timing\">4.\u2000Page Navigation &amp; Timing</h2>\n<h3 id=\"41-basic-browser-flow\">4.1 Basic Browser Flow</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">run_config = CrawlerRunConfig(\n    wait_for=<span class=\"hljs-string\">\"css:.dynamic-content\"</span>, <span class=\"hljs-comment\"># Wait for .dynamic-content</span>\n    delay_before_return_html=2.0,    <span class=\"hljs-comment\"># Wait 2s before capturing final HTML</span>\n    page_timeout=60000,             <span class=\"hljs-comment\"># Navigation &amp; script timeout (ms)</span>\n)\n</code></pre></div>\n<p><strong>Key Fields</strong>:</p>\n<ul>\n<li><code>wait_for</code>:  </li>\n<li><code>\"css:selector\"</code> or  </li>\n<li>\n<p><code>\"js:() =&gt; boolean\"</code><br>\n  e.g.\u2000<code>js:() =&gt; document.querySelectorAll('.item').length &gt; 10</code>.</p>\n</li>\n<li>\n<p><code>mean_delay</code> &amp; <code>max_range</code>: define random delays for <code>arun_many()</code> calls.\u2000 </p>\n</li>\n<li><code>semaphore_count</code>: concurrency limit when crawling multiple URLs.</li>\n</ul>\n<h3 id=\"42-javascript-execution\">4.2 JavaScript Execution</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    js_code<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n        <span class=\"hljs-string\">\"document.querySelector('.load-more')?.click();\"</span>\n    <span class=\"hljs-punctuation\">]</span>,\n    js_only<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">False</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<ul>\n<li><code>js_code</code> can be a single string or a list of strings.\u2000 </li>\n<li><code>js_only=True</code> means \u201cI\u2019m continuing in the same session with new JS steps, no new full navigation.\u201d</li>\n</ul>\n<h3 id=\"43-anti-bot\">4.3 Anti-Bot</h3>\n<p></p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    magic<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    simulate_user<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    override_navigator<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n- <code>magic=True</code> tries multiple stealth features.\u2000 \n- <code>simulate_user=True</code> mimics mouse movements or random delays.\u2000 \n- <code>override_navigator=True</code> fakes some navigator properties (like user agent checks).<p></p>\n<hr>\n<h2 id=\"5-session-management\">5.\u2000Session Management</h2>\n<p><strong><code>session_id</code></strong>: \n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">run_config = CrawlerRunConfig(\n    session_id=<span class=\"hljs-string\">\"my_session123\"</span>\n)\n</code></pre></div>\nIf re-used in subsequent <code>arun()</code> calls, the same tab/page context is continued (helpful for multi-step tasks or stateful browsing).<p></p>\n<hr>\n<h2 id=\"6-screenshot-pdf-media-options\">6.\u2000Screenshot, PDF &amp; Media Options</h2>\n<p></p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">run_config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    screenshot<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># Grab a screenshot as base64</span>\n    screenshot_wait_for<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">1.0</span>,     <span class=\"hljs-comment\"># Wait 1s before capturing</span>\n    pdf<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,                    <span class=\"hljs-comment\"># Also produce a PDF</span>\n    image_description_min_word_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">5</span>,  <span class=\"hljs-comment\"># If analyzing alt text</span>\n    image_score_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">3</span>,                <span class=\"hljs-comment\"># Filter out low-score images</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<strong>Where they appear</strong>:\n- <code>result.screenshot</code> \u2192 Base64 screenshot string.\n- <code>result.pdf</code> \u2192 Byte array with PDF data.<p></p>\n<hr>\n<h2 id=\"7-extraction-strategy\">7.\u2000Extraction Strategy</h2>\n<p><strong>For advanced data extraction</strong> (CSS/LLM-based), set <code>extraction_strategy</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">run_config = CrawlerRunConfig(\n    extraction_strategy=my_css_or_llm_strategy\n)\n</code></pre></div>\n<p>The extracted data will appear in <code>result.extracted_content</code>.</p>\n<hr>\n<h2 id=\"8-comprehensive-example\">8.\u2000Comprehensive Example</h2>\n<p>Below is a snippet combining many parameters:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Example schema</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Articles\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"article.post\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>,  <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>,  <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n\n    run_config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Core</span>\n        verbose=<span class=\"hljs-literal\">True</span>,\n        cache_mode=CacheMode.ENABLED,\n        check_robots_txt=<span class=\"hljs-literal\">True</span>,   <span class=\"hljs-comment\"># Respect robots.txt rules</span>\n\n        <span class=\"hljs-comment\"># Content</span>\n        word_count_threshold=<span class=\"hljs-number\">10</span>,\n        css_selector=<span class=\"hljs-string\">\"main.content\"</span>,\n        excluded_tags=[<span class=\"hljs-string\">\"nav\"</span>, <span class=\"hljs-string\">\"footer\"</span>],\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Page &amp; JS</span>\n        js_code=<span class=\"hljs-string\">\"document.querySelector('.show-more')?.click();\"</span>,\n        wait_for=<span class=\"hljs-string\">\"css:.loaded-block\"</span>,\n        page_timeout=<span class=\"hljs-number\">30000</span>,\n\n        <span class=\"hljs-comment\"># Extraction</span>\n        extraction_strategy=JsonCssExtractionStrategy(schema),\n\n        <span class=\"hljs-comment\"># Session</span>\n        session_id=<span class=\"hljs-string\">\"persistent_session\"</span>,\n\n        <span class=\"hljs-comment\"># Media</span>\n        screenshot=<span class=\"hljs-literal\">True</span>,\n        pdf=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Anti-bot</span>\n        simulate_user=<span class=\"hljs-literal\">True</span>,\n        magic=<span class=\"hljs-literal\">True</span>,\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/posts\"</span>, config=run_config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extraction JSON:\"</span>, result.extracted_content)\n            <span class=\"hljs-keyword\">if</span> result.screenshot:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Screenshot length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.screenshot))\n            <span class=\"hljs-keyword\">if</span> result.pdf:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"PDF bytes length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.pdf))\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>What we covered</strong>:</p>\n<p>1.\u2000<strong>Crawling</strong> the main content region, ignoring external links.\u2000 \n2.\u2000Running <strong>JavaScript</strong> to click \u201c.show-more\u201d.\u2000 \n3.\u2000<strong>Waiting</strong> for \u201c.loaded-block\u201d to appear.\u2000 \n4.\u2000Generating a <strong>screenshot</strong> &amp; <strong>PDF</strong> of the final page.\u2000 \n5.\u2000Extracting repeated \u201carticle.post\u201d elements with a <strong>CSS-based</strong> extraction strategy.</p>\n<hr>\n<h2 id=\"9-best-practices\">9.\u2000Best Practices</h2>\n<p>1.\u2000<strong>Use <code>BrowserConfig</code> for global browser</strong> settings (headless, user agent).\u2000 \n2.\u2000<strong>Use <code>CrawlerRunConfig</code></strong> to handle the <strong>specific</strong> crawl needs: content filtering, caching, JS, screenshot, extraction, etc.\u2000 \n3.\u2000Keep your <strong>parameters consistent</strong> in run configs\u2014especially if you\u2019re part of a large codebase with multiple crawls.\u2000 \n4.\u2000<strong>Limit</strong> large concurrency (<code>semaphore_count</code>) if the site or your system can\u2019t handle it.\u2000 \n5.\u2000For dynamic pages, set <code>js_code</code> or <code>scan_full_page</code> so you load all content.</p>\n<hr>\n<h2 id=\"10-conclusion\">10.\u2000Conclusion</h2>\n<p>All parameters that used to be direct arguments to <code>arun()</code> now belong in <strong><code>CrawlerRunConfig</code></strong>.\u2000This approach:</p>\n<ul>\n<li>Makes code <strong>clearer</strong> and <strong>more maintainable</strong>.\u2000 </li>\n<li>Minimizes confusion about which arguments affect global vs.\u2000per-crawl behavior.\u2000 </li>\n<li>Allows you to create <strong>reusable</strong> config objects for different pages or tasks.</li>\n</ul>\n<p>For a <strong>full</strong> reference, check out the <a href=\"../parameters/\">CrawlerRunConfig Docs</a>.\u2000</p>\n<p>Happy crawling with your <strong>structured, flexible</strong> config approach!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# `arun()` Parameter Guide (New Approach)\nIn Crawl4AI\u2019s **latest** configuration model, nearly all parameters that once went directly to `arun()` are now part of **`CrawlerRunConfig`**. When calling`arun()` , you provide:\n```\nawait crawler.arun(\n  url=\"https://example.com\", \n  config=my_run_config\n)\n\n```\n\nBelow is an organized look at the parameters that can go inside `CrawlerRunConfig`, divided by their functional areas. For **Browser** settings (e.g., `headless`, `browser_type`), see [BrowserConfig](https://docs.crawl4ai.com/api/<../parameters/>).\n## 1. Core Usage\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nasync def main():\n  run_config = CrawlerRunConfig(\n    verbose=True,      # Detailed logging\n    cache_mode=CacheMode.ENABLED, # Use normal read/write cache\n    check_robots_txt=True,  # Respect robots.txt rules\n    # ...\u2000other parameters\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com\",\n      config=run_config\n    )\n    # Check if blocked by robots.txt\n    if not result.success and result.status_code == 403:\n      print(f\"Error: {result.error_message}\")\n\n```\n\n**Key Fields** : - `verbose=True` logs each crawl step. - `cache_mode` decides how to read/write the local crawl cache.\n## 2. Cache Control\n**`cache_mode`**(default:`CacheMode.ENABLED`) Use a built-in enum from `CacheMode`:\n  * `ENABLED`: Normal caching\u2014reads if available, writes if missing.\n  * `DISABLED`: No caching\u2014always refetch pages.\n  * `READ_ONLY`: Reads from cache only; no new writes.\n  * `WRITE_ONLY`: Writes to cache but doesn\u2019t read existing data.\n  * `BYPASS`: Skips reading cache for this crawl (though it might still write if set up that way).\n\n\n```\nrun_config = CrawlerRunConfig(\n  cache_mode=CacheMode.BYPASS\n)\n\n```\n\n**Additional flags** :\n  * `bypass_cache=True` acts like `CacheMode.BYPASS`.\n  * `disable_cache=True` acts like `CacheMode.DISABLED`.\n  * `no_cache_read=True` acts like `CacheMode.WRITE_ONLY`.\n  * `no_cache_write=True` acts like `CacheMode.READ_ONLY`.\n\n\n## 3. Content Processing & Selection\n### 3.1 Text Processing\n```\nrun_config = CrawlerRunConfig(\n  word_count_threshold=10,  # Ignore text blocks <10 words\n  only_text=False,      # If True, tries to remove non-text elements\n  keep_data_attributes=False # Keep or discard data-* attributes\n)\n\n```\n\n### 3.2 Content Selection\n```\nrun_config = CrawlerRunConfig(\n  css_selector=\".main-content\", # Focus on .main-content region only\n  excluded_tags=[\"form\", \"nav\"], # Remove entire tag blocks\n  remove_forms=True,       # Specifically strip <form> elements\n  remove_overlay_elements=True, # Attempt to remove modals/popups\n)\n\n```\n\n### 3.3 Link Handling\n```\nrun_config = CrawlerRunConfig(\n  exclude_external_links=True,     # Remove external links from final content\n  exclude_social_media_links=True,   # Remove links to known social sites\n  exclude_domains=[\"ads.example.com\"], # Exclude links to these domains\n  exclude_social_media_domains=[\"facebook.com\",\"twitter.com\"], # Extend the default list\n)\n\n```\n\n### 3.4 Media Filtering\n```\nrun_config = CrawlerRunConfig(\n  exclude_external_images=True # Strip images from other domains\n)\n\n```\n\n## 4. Page Navigation & Timing\n### 4.1 Basic Browser Flow\n```\nrun_config = CrawlerRunConfig(\n  wait_for=\"css:.dynamic-content\", # Wait for .dynamic-content\n  delay_before_return_html=2.0,  # Wait 2s before capturing final HTML\n  page_timeout=60000,       # Navigation & script timeout (ms)\n)\n\n```\n\n**Key Fields** :\n  * `wait_for`: \n  * `\"css:selector\"` or \n  * `\"js:() => boolean\"` e.g. `js:() => document.querySelectorAll('.item').length > 10`.\n  * `mean_delay` & `max_range`: define random delays for `arun_many()` calls. \n  * `semaphore_count`: concurrency limit when crawling multiple URLs.\n\n\n### 4.2 JavaScript Execution\n```\nrun_config = CrawlerRunConfig(\n  js_code=[\n    \"window.scrollTo(0, document.body.scrollHeight);\",\n    \"document.querySelector('.load-more')?.click();\"\n  ],\n  js_only=False\n)\n\n```\n\n  * `js_code` can be a single string or a list of strings. \n  * `js_only=True` means \u201cI\u2019m continuing in the same session with new JS steps, no new full navigation.\u201d\n\n\n### 4.3 Anti-Bot\n```\nrun_config = CrawlerRunConfig(\n  magic=True,\n  simulate_user=True,\n  override_navigator=True\n)\n\n```\n\n- `magic=True` tries multiple stealth features. - `simulate_user=True` mimics mouse movements or random delays. - `override_navigator=True` fakes some navigator properties (like user agent checks). \n## 5. Session Management\n**`session_id`**:\n```\nrun_config = CrawlerRunConfig(\n  session_id=\"my_session123\"\n)\n\n```\n\nIf re-used in subsequent `arun()` calls, the same tab/page context is continued (helpful for multi-step tasks or stateful browsing). \n## 6. Screenshot, PDF & Media Options\n```\nrun_config = CrawlerRunConfig(\n  screenshot=True,       # Grab a screenshot as base64\n  screenshot_wait_for=1.0,   # Wait 1s before capturing\n  pdf=True,          # Also produce a PDF\n  image_description_min_word_threshold=5, # If analyzing alt text\n  image_score_threshold=3,        # Filter out low-score images\n)\n\n```\n\n**Where they appear** : - `result.screenshot` \u2192 Base64 screenshot string. - `result.pdf` \u2192 Byte array with PDF data. \n## 7. Extraction Strategy\n**For advanced data extraction** (CSS/LLM-based), set `extraction_strategy`:\n```\nrun_config = CrawlerRunConfig(\n  extraction_strategy=my_css_or_llm_strategy\n)\n\n```\n\nThe extracted data will appear in `result.extracted_content`.\n## 8. Comprehensive Example\nBelow is a snippet combining many parameters:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  # Example schema\n  schema = {\n    \"name\": \"Articles\",\n    \"baseSelector\": \"article.post\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  run_config = CrawlerRunConfig(\n    # Core\n    verbose=True,\n    cache_mode=CacheMode.ENABLED,\n    check_robots_txt=True,  # Respect robots.txt rules\n    # Content\n    word_count_threshold=10,\n    css_selector=\"main.content\",\n    excluded_tags=[\"nav\", \"footer\"],\n    exclude_external_links=True,\n    # Page & JS\n    js_code=\"document.querySelector('.show-more')?.click();\",\n    wait_for=\"css:.loaded-block\",\n    page_timeout=30000,\n    # Extraction\n    extraction_strategy=JsonCssExtractionStrategy(schema),\n    # Session\n    session_id=\"persistent_session\",\n    # Media\n    screenshot=True,\n    pdf=True,\n    # Anti-bot\n    simulate_user=True,\n    magic=True,\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com/posts\", config=run_config)\n    if result.success:\n      print(\"HTML length:\", len(result.cleaned_html))\n      print(\"Extraction JSON:\", result.extracted_content)\n      if result.screenshot:\n        print(\"Screenshot length:\", len(result.screenshot))\n      if result.pdf:\n        print(\"PDF bytes length:\", len(result.pdf))\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**What we covered** :\n1. **Crawling** the main content region, ignoring external links. 2. Running **JavaScript** to click \u201c.show-more\u201d. 3. **Waiting** for \u201c.loaded-block\u201d to appear. 4. Generating a **screenshot** & **PDF** of the final page. 5. Extracting repeated \u201carticle.post\u201d elements with a **CSS-based** extraction strategy.\n## 9. Best Practices\n1. **Use`BrowserConfig` for global browser** settings (headless, user agent). 2. **Use`CrawlerRunConfig`** to handle the **specific** crawl needs: content filtering, caching, JS, screenshot, extraction, etc. 3. Keep your **parameters consistent** in run configs\u2014especially if you\u2019re part of a large codebase with multiple crawls. 4. **Limit** large concurrency (`semaphore_count`) if the site or your system can\u2019t handle it. 5. For dynamic pages, set `js_code` or `scan_full_page` so you load all content.\n## 10. Conclusion\nAll parameters that used to be direct arguments to `arun()` now belong in **`CrawlerRunConfig`**. This approach:\n  * Makes code **clearer** and **more maintainable**. \n  * Minimizes confusion about which arguments affect global vs. per-crawl behavior. \n  * Allows you to create **reusable** config objects for different pages or tasks.\n\n\nFor a **full** reference, check out the [CrawlerRunConfig Docs](https://docs.crawl4ai.com/api/<../parameters/>). \nHappy crawling with your **structured, flexible** config approach!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun_many",
        "https://docs.crawl4ai.com/async-webcrawler",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/parameters",
        "https://docs.crawl4ai.com/strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 7,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:09",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "arun_many.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/arun_many",
      "timestamp": "2025-02-06T13:23:27.086174",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/arun_many/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>arun_many() - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">arun_many()</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#arun_many-reference\">arun_many(...) Reference</a></li>\n        <li><a href=\"#function-signature\">Function Signature</a></li><li><a href=\"#differences-from-arun\">Differences from arun()</a></li><li><a href=\"#dispatcher-reference\">Dispatcher Reference</a></li><li><a href=\"#common-pitfalls\">Common Pitfalls</a></li><li><a href=\"#conclusion\">Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"arun_many-reference\"><code>arun_many(...)</code> Reference</h1>\n<blockquote>\n<p><strong>Note</strong>: This function is very similar to <a href=\"../arun/\"><code>arun()</code></a> but focused on <strong>concurrent</strong> or <strong>batch</strong> crawling.\u2000If you\u2019re unfamiliar with <code>arun()</code> usage, please read that doc first, then review this for differences.</p>\n</blockquote>\n<h2 id=\"function-signature\">Function Signature</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">arun_many</span>(<span class=\"hljs-params\">\n    urls: <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>], <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Any</span>]],\n    config: <span class=\"hljs-type\">Optional</span>[CrawlerRunConfig] = <span class=\"hljs-literal\">None</span>,\n    dispatcher: <span class=\"hljs-type\">Optional</span>[BaseDispatcher] = <span class=\"hljs-literal\">None</span>,\n    ...\n</span>) -&gt; <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">List</span>[CrawlResult], AsyncGenerator[CrawlResult, <span class=\"hljs-literal\">None</span>]]:\n    <span class=\"hljs-string\">\"\"\"\n    Crawl multiple URLs concurrently or in batches.\n\n    :param urls: A list of URLs (or tasks) to crawl.\n    :param config: (Optional) A default `CrawlerRunConfig` applying to each crawl.\n    :param dispatcher: (Optional) A concurrency controller (e.g.\u2000MemoryAdaptiveDispatcher).\n    ...\n    :return: Either a list of `CrawlResult` objects, or an async generator if streaming is enabled.\n    \"\"\"</span>\n</code></pre></div>\n<h2 id=\"differences-from-arun\">Differences from <code>arun()</code></h2>\n<p>1.\u2000<strong>Multiple URLs</strong>:  </p>\n<ul>\n<li>Instead of crawling a single URL, you pass a list of them (strings or tasks).\u2000 </li>\n<li>The function returns either a <strong>list</strong> of <code>CrawlResult</code> or an <strong>async generator</strong> if streaming is enabled.</li>\n</ul>\n<p>2.\u2000<strong>Concurrency &amp; Dispatchers</strong>:  </p>\n<ul>\n<li><strong><code>dispatcher</code></strong> param allows advanced concurrency control.\u2000 </li>\n<li>If omitted, a default dispatcher (like <code>MemoryAdaptiveDispatcher</code>) is used internally.\u2000 </li>\n<li>Dispatchers handle concurrency, rate limiting, and memory-based adaptive throttling (see <a href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>).</li>\n</ul>\n<p>3.\u2000<strong>Streaming Support</strong>:  </p>\n<ul>\n<li>Enable streaming by setting <code>stream=True</code> in your <code>CrawlerRunConfig</code>.</li>\n<li>When streaming, use <code>async for</code> to process results as they become available.</li>\n<li>Ideal for processing large numbers of URLs without waiting for all to complete.</li>\n</ul>\n<p>4.\u2000<strong>Parallel</strong> Execution**:  </p>\n<ul>\n<li><code>arun_many()</code> can run multiple requests concurrently under the hood.\u2000 </li>\n<li>Each <code>CrawlResult</code> might also include a <strong><code>dispatch_result</code></strong> with concurrency details (like memory usage, start/end times).</li>\n</ul>\n<h3 id=\"basic-example-batch-mode\">Basic Example (Batch Mode)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-comment\"># Minimal usage: The default dispatcher will be used</span>\nresults = <span class=\"hljs-keyword\">await</span> crawler.arun_many(\n    urls=[<span class=\"hljs-string\">\"https://site1.com\"</span>, <span class=\"hljs-string\">\"https://site2.com\"</span>],\n    config=CrawlerRunConfig(stream=<span class=\"hljs-literal\">False</span>)  <span class=\"hljs-comment\"># Default behavior</span>\n)\n\n<span class=\"hljs-keyword\">for</span> res <span class=\"hljs-keyword\">in</span> results:\n    <span class=\"hljs-keyword\">if</span> res.success:\n        <span class=\"hljs-built_in\">print</span>(res.url, <span class=\"hljs-string\">\"crawled OK!\"</span>)\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Failed:\"</span>, res.url, <span class=\"hljs-string\">\"-\"</span>, res.error_message)\n</code></pre></div>\n<h3 id=\"streaming-example\">Streaming Example</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">config = CrawlerRunConfig(\n    stream=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Enable streaming mode</span>\n    cache_mode=CacheMode.BYPASS\n)\n\n<span class=\"hljs-comment\"># Process results as they complete</span>\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">await</span> crawler.arun_many(\n    urls=[<span class=\"hljs-string\">\"https://site1.com\"</span>, <span class=\"hljs-string\">\"https://site2.com\"</span>, <span class=\"hljs-string\">\"https://site3.com\"</span>],\n    config=config\n):\n    <span class=\"hljs-keyword\">if</span> result.success:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Just completed: <span class=\"hljs-subst\">{result.url}</span>\"</span>)\n        <span class=\"hljs-comment\"># Process each result immediately</span>\n        process_result(result)\n</code></pre></div>\n<h3 id=\"with-a-custom-dispatcher\">With a Custom Dispatcher</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">dispatcher = MemoryAdaptiveDispatcher(\n    memory_threshold_percent=70.0,\n    max_session_permit=10\n)\nresults = await crawler.arun_many(\n    urls=[<span class=\"hljs-string\">\"https://site1.com\"</span>, <span class=\"hljs-string\">\"https://site2.com\"</span>, <span class=\"hljs-string\">\"https://site3.com\"</span>],\n    config=my_run_config,\n    dispatcher=dispatcher\n)\n</code></pre></div>\n<p><strong>Key Points</strong>:\n- Each URL is processed by the same or separate sessions, depending on the dispatcher\u2019s strategy.\n- <code>dispatch_result</code> in each <code>CrawlResult</code> (if using concurrency) can hold memory and timing info.\u2000 \n- If you need to handle authentication or session IDs, pass them in each individual task or within your run config.</p>\n<h3 id=\"return-value\">Return Value</h3>\n<p>Either a <strong>list</strong> of <a href=\"../crawl-result/\"><code>CrawlResult</code></a> objects, or an <strong>async generator</strong> if streaming is enabled.\u2000You can iterate to check <code>result.success</code> or read each item\u2019s <code>extracted_content</code>, <code>markdown</code>, or <code>dispatch_result</code>.</p>\n<hr>\n<h2 id=\"dispatcher-reference\">Dispatcher Reference</h2>\n<ul>\n<li><strong><code>MemoryAdaptiveDispatcher</code></strong>: Dynamically manages concurrency based on system memory usage.\u2000 </li>\n<li><strong><code>SemaphoreDispatcher</code></strong>: Fixed concurrency limit, simpler but less adaptive.\u2000 </li>\n</ul>\n<p>For advanced usage or custom settings, see <a href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling with Dispatchers</a>.</p>\n<hr>\n<h2 id=\"common-pitfalls\">Common Pitfalls</h2>\n<p>1.\u2000<strong>Large Lists</strong>: If you pass thousands of URLs, be mindful of memory or rate-limits.\u2000A dispatcher can help.\u2000 </p>\n<p>2.\u2000<strong>Session Reuse</strong>: If you need specialized logins or persistent contexts, ensure your dispatcher or tasks handle sessions accordingly.\u2000 </p>\n<p>3.\u2000<strong>Error Handling</strong>: Each <code>CrawlResult</code> might fail for different reasons\u2014always check <code>result.success</code> or the <code>error_message</code> before proceeding.</p>\n<hr>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Use <code>arun_many()</code> when you want to <strong>crawl multiple URLs</strong> simultaneously or in controlled parallel tasks.\u2000If you need advanced concurrency features (like memory-based adaptive throttling or complex rate-limiting), provide a <strong>dispatcher</strong>.\u2000Each result is a standard <code>CrawlResult</code>, possibly augmented with concurrency stats (<code>dispatch_result</code>) for deeper inspection.\u2000For more details on concurrency logic and dispatchers, see the <a href=\"../../advanced/multi-url-crawling/\">Advanced Multi-URL Crawling</a> docs.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# `arun_many(...)` Reference\n> **Note** : This function is very similar to `arun()`[](https://docs.crawl4ai.com/api/<../arun/>) but focused on **concurrent** or **batch** crawling. If you\u2019re unfamiliar with `arun()` usage, please read that doc first, then review this for differences.\n## Function Signature\n```\nasync def arun_many(\n  urls: Union[List[str], List[Any]],\n  config: Optional[CrawlerRunConfig] = None,\n  dispatcher: Optional[BaseDispatcher] = None,\n  ...\n) -> Union[List[CrawlResult], AsyncGenerator[CrawlResult, None]]:\n  \"\"\"\n  Crawl multiple URLs concurrently or in batches.\n  :param urls: A list of URLs (or tasks) to crawl.\n  :param config: (Optional) A default `CrawlerRunConfig` applying to each crawl.\n  :param dispatcher: (Optional) A concurrency controller (e.g.\u2000MemoryAdaptiveDispatcher).\n  ...\n  :return: Either a list of `CrawlResult` objects, or an async generator if streaming is enabled.\n  \"\"\"\n\n```\n\n## Differences from `arun()`\n1. **Multiple URLs** : \n  * Instead of crawling a single URL, you pass a list of them (strings or tasks). \n  * The function returns either a **list** of `CrawlResult` or an **async generator** if streaming is enabled.\n\n\n2. **Concurrency & Dispatchers**: \n  * **`dispatcher`**param allows advanced concurrency control.\n  * If omitted, a default dispatcher (like `MemoryAdaptiveDispatcher`) is used internally. \n  * Dispatchers handle concurrency, rate limiting, and memory-based adaptive throttling (see [Multi-URL Crawling](https://docs.crawl4ai.com/api/advanced/multi-url-crawling/>)).\n\n\n3. **Streaming Support** : \n  * Enable streaming by setting `stream=True` in your `CrawlerRunConfig`.\n  * When streaming, use `async for` to process results as they become available.\n  * Ideal for processing large numbers of URLs without waiting for all to complete.\n\n\n4. **Parallel** Execution**: \n  * `arun_many()` can run multiple requests concurrently under the hood. \n  * Each `CrawlResult` might also include a **`dispatch_result`**with concurrency details (like memory usage, start/end times).\n\n\n### Basic Example (Batch Mode)\n```\n# Minimal usage: The default dispatcher will be used\nresults = await crawler.arun_many(\n  urls=[\"https://site1.com\", \"https://site2.com\"],\n  config=CrawlerRunConfig(stream=False) # Default behavior\n)\nfor res in results:\n  if res.success:\n    print(res.url, \"crawled OK!\")\n  else:\n    print(\"Failed:\", res.url, \"-\", res.error_message)\n\n```\n\n### Streaming Example\n```\nconfig = CrawlerRunConfig(\n  stream=True, # Enable streaming mode\n  cache_mode=CacheMode.BYPASS\n)\n# Process results as they complete\nasync for result in await crawler.arun_many(\n  urls=[\"https://site1.com\", \"https://site2.com\", \"https://site3.com\"],\n  config=config\n):\n  if result.success:\n    print(f\"Just completed: {result.url}\")\n    # Process each result immediately\n    process_result(result)\n\n```\n\n### With a Custom Dispatcher\n```\ndispatcher = MemoryAdaptiveDispatcher(\n  memory_threshold_percent=70.0,\n  max_session_permit=10\n)\nresults = await crawler.arun_many(\n  urls=[\"https://site1.com\", \"https://site2.com\", \"https://site3.com\"],\n  config=my_run_config,\n  dispatcher=dispatcher\n)\n\n```\n\n**Key Points** : - Each URL is processed by the same or separate sessions, depending on the dispatcher\u2019s strategy. - `dispatch_result` in each `CrawlResult` (if using concurrency) can hold memory and timing info. - If you need to handle authentication or session IDs, pass them in each individual task or within your run config.\n### Return Value\nEither a **list** of `CrawlResult`[](https://docs.crawl4ai.com/api/<../crawl-result/>) objects, or an **async generator** if streaming is enabled. You can iterate to check `result.success` or read each item\u2019s `extracted_content`, `markdown`, or `dispatch_result`.\n## Dispatcher Reference\n  * **`MemoryAdaptiveDispatcher`**: Dynamically manages concurrency based on system memory usage.\n  * **`SemaphoreDispatcher`**: Fixed concurrency limit, simpler but less adaptive.\n\n\nFor advanced usage or custom settings, see [Multi-URL Crawling with Dispatchers](https://docs.crawl4ai.com/api/advanced/multi-url-crawling/>).\n## Common Pitfalls\n1. **Large Lists** : If you pass thousands of URLs, be mindful of memory or rate-limits. A dispatcher can help. \n2. **Session Reuse** : If you need specialized logins or persistent contexts, ensure your dispatcher or tasks handle sessions accordingly. \n3. **Error Handling** : Each `CrawlResult` might fail for different reasons\u2014always check `result.success` or the `error_message` before proceeding.\n## Conclusion\nUse `arun_many()` when you want to **crawl multiple URLs** simultaneously or in controlled parallel tasks. If you need advanced concurrency features (like memory-based adaptive throttling or complex rate-limiting), provide a **dispatcher**. Each result is a standard `CrawlResult`, possibly augmented with concurrency stats (`dispatch_result`) for deeper inspection. For more details on concurrency logic and dispatchers, see the [Advanced Multi-URL Crawling](https://docs.crawl4ai.com/api/advanced/multi-url-crawling/>) docs.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun",
        "https://docs.crawl4ai.com/async-webcrawler",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/parameters",
        "https://docs.crawl4ai.com/strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 8,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:10",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "async-webcrawler.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/async-webcrawler",
      "timestamp": "2025-02-06T13:23:28.275614",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/async-webcrawler/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>AsyncWebCrawler - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">AsyncWebCrawler</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#asyncwebcrawler\">AsyncWebCrawler</a></li>\n        <li><a href=\"#1-constructor-overview\">1. Constructor Overview</a></li><li><a href=\"#2-lifecycle-startclose-or-context-manager\">2. Lifecycle: Start/Close or Context Manager</a></li><li><a href=\"#3-primary-method-arun\">3. Primary Method: arun()</a></li><li><a href=\"#4-batch-processing-arun_many\">4. Batch Processing: arun_many()</a></li><li><a href=\"#5-crawlresult-output\">5. CrawlResult Output</a></li><li><a href=\"#6-quick-example\">6. Quick Example</a></li><li><a href=\"#7-best-practices-migration-notes\">7. Best Practices &amp; Migration Notes</a></li><li><a href=\"#8-summary\">8. Summary</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"asyncwebcrawler\">AsyncWebCrawler</h1>\n<p>The <strong><code>AsyncWebCrawler</code></strong> is the core class for asynchronous web crawling in Crawl4AI.\u2000You typically create it <strong>once</strong>, optionally customize it with a <strong><code>BrowserConfig</code></strong> (e.g., headless, user agent), then <strong>run</strong> multiple <strong><code>arun()</code></strong> calls with different <strong><code>CrawlerRunConfig</code></strong> objects.</p>\n<p><strong>Recommended usage</strong>:</p>\n<p>1.\u2000<strong>Create</strong> a <code>BrowserConfig</code> for global browser settings.\u2000 </p>\n<p>2.\u2000<strong>Instantiate</strong> <code>AsyncWebCrawler(config=browser_config)</code>.\u2000 </p>\n<p>3.\u2000<strong>Use</strong> the crawler in an async context manager (<code>async with</code>) or manage start/close manually.\u2000 </p>\n<p>4.\u2000<strong>Call</strong> <code>arun(url, config=crawler_run_config)</code> for each page you want.</p>\n<hr>\n<h2 id=\"1-constructor-overview\">1.\u2000Constructor Overview</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">AsyncWebCrawler</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        self,\n        crawler_strategy: <span class=\"hljs-type\">Optional</span>[AsyncCrawlerStrategy] = <span class=\"hljs-literal\">None</span>,\n        config: <span class=\"hljs-type\">Optional</span>[BrowserConfig] = <span class=\"hljs-literal\">None</span>,\n        always_bypass_cache: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,           <span class=\"hljs-comment\"># deprecated</span>\n        always_by_pass_cache: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">bool</span>] = <span class=\"hljs-literal\">None</span>, <span class=\"hljs-comment\"># also deprecated</span>\n        base_directory: <span class=\"hljs-built_in\">str</span> = ...,\n        thread_safe: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,\n        **kwargs,\n    </span>):\n        <span class=\"hljs-string\">\"\"\"\n        Create an AsyncWebCrawler instance.\n\n        Args:\n            crawler_strategy: \n                (Advanced) Provide a custom crawler strategy if needed.\n            config: \n                A BrowserConfig object specifying how the browser is set up.\n            always_bypass_cache: \n                (Deprecated) Use CrawlerRunConfig.cache_mode instead.\n            base_directory:     \n                Folder for storing caches/logs (if relevant).\n            thread_safe: \n                If True, attempts some concurrency safeguards.\u2000Usually False.\n            **kwargs: \n                Additional legacy or debugging parameters.\n        \"\"\"</span>\n    )\n\n<span class=\"hljs-comment\">### Typical Initialization</span>\n\n```python\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig\n\nbrowser_cfg = BrowserConfig(\n    browser_type=<span class=\"hljs-string\">\"chromium\"</span>,\n    headless=<span class=\"hljs-literal\">True</span>,\n    verbose=<span class=\"hljs-literal\">True</span>\n)\n\ncrawler = AsyncWebCrawler(config=browser_cfg)\n</code></pre></div>\n<p><strong>Notes</strong>:</p>\n<ul>\n<li><strong>Legacy</strong> parameters like <code>always_bypass_cache</code> remain for backward compatibility, but prefer to set <strong>caching</strong> in <code>CrawlerRunConfig</code>.</li>\n</ul>\n<hr>\n<h2 id=\"2-lifecycle-startclose-or-context-manager\">2.\u2000Lifecycle: Start/Close or Context Manager</h2>\n<h3 id=\"21-context-manager-recommended\">2.1 Context Manager (Recommended)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>(<span class=\"hljs-params\">config=browser_cfg</span>) <span class=\"hljs-keyword\">as</span> crawler:\n    result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>)\n    <span class=\"hljs-meta\"># The crawler automatically starts/closes resources</span>\n</code></pre></div>\n<p>When the <code>async with</code> block ends, the crawler cleans up (closes the browser, etc.).</p>\n<h3 id=\"22-manual-start-close\">2.2 Manual Start &amp; Close</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\">crawler = AsyncWebCrawler(config=browser_cfg)\n<span class=\"hljs-keyword\">await</span> crawler.start()\n\nresult1 = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>)\nresult2 = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://another.com\"</span>)\n\n<span class=\"hljs-keyword\">await</span> crawler.close()\n</code></pre></div>\n<p>Use this style if you have a <strong>long-running</strong> application or need full control of the crawler\u2019s lifecycle.</p>\n<hr>\n<h2 id=\"3-primary-method-arun\">3.\u2000Primary Method: <code>arun()</code></h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">arun</span>(<span class=\"hljs-params\">\n    self,\n    url: <span class=\"hljs-built_in\">str</span>,\n    config: <span class=\"hljs-type\">Optional</span>[CrawlerRunConfig] = <span class=\"hljs-literal\">None</span>,\n    <span class=\"hljs-comment\"># Legacy parameters for backward compatibility...</span>\n</span>) -&gt; CrawlResult:\n    ...\n</code></pre></div>\n<h3 id=\"31-new-approach\">3.1 New Approach</h3>\n<p>You pass a <code>CrawlerRunConfig</code> object that sets up everything about a crawl\u2014content filtering, caching, session reuse, JS code, screenshots, etc.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> CrawlerRunConfig, CacheMode\n\nrun_cfg = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    css_selector=<span class=\"hljs-string\">\"main.article\"</span>,\n    word_count_threshold=<span class=\"hljs-number\">10</span>,\n    screenshot=<span class=\"hljs-literal\">True</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/news\"</span>, config=run_cfg)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawled HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n    <span class=\"hljs-keyword\">if</span> result.screenshot:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Screenshot base64 length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.screenshot))\n</code></pre></div>\n<h3 id=\"32-legacy-parameters-still-accepted\">3.2 Legacy Parameters Still Accepted</h3>\n<p>For <strong>backward</strong> compatibility, <code>arun()</code> can still accept direct arguments like <code>css_selector=...</code>, <code>word_count_threshold=...</code>, etc., but we strongly advise migrating them into a <strong><code>CrawlerRunConfig</code></strong>.</p>\n<hr>\n<h2 id=\"4-batch-processing-arun_many\">4.\u2000Batch Processing: <code>arun_many()</code></h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">arun_many</span>(<span class=\"hljs-params\">\n    self,\n    urls: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>],\n    config: <span class=\"hljs-type\">Optional</span>[CrawlerRunConfig] = <span class=\"hljs-literal\">None</span>,\n    <span class=\"hljs-comment\"># Legacy parameters maintained for backwards compatibility...</span>\n</span>) -&gt; <span class=\"hljs-type\">List</span>[CrawlResult]:\n    <span class=\"hljs-string\">\"\"\"\n    Process multiple URLs with intelligent rate limiting and resource monitoring.\n    \"\"\"</span>\n</code></pre></div>\n<h3 id=\"41-resource-aware-crawling\">4.1 Resource-Aware Crawling</h3>\n<p>The <code>arun_many()</code> method now uses an intelligent dispatcher that:</p>\n<ul>\n<li>Monitors system memory usage</li>\n<li>Implements adaptive rate limiting</li>\n<li>Provides detailed progress monitoring</li>\n<li>Manages concurrent crawls efficiently</li>\n</ul>\n<h3 id=\"42-example-usage\">4.2 Example Usage</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, RateLimitConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.dispatcher <span class=\"hljs-keyword\">import</span> DisplayMode\n\n<span class=\"hljs-comment\"># Configure browser</span>\nbrowser_cfg = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)\n\n<span class=\"hljs-comment\"># Configure crawler with rate limiting</span>\nrun_cfg = CrawlerRunConfig(\n    <span class=\"hljs-comment\"># Enable rate limiting</span>\n    enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n    rate_limit_config=RateLimitConfig(\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>),  <span class=\"hljs-comment\"># Random delay between 1-2 seconds</span>\n        max_delay=<span class=\"hljs-number\">30.0</span>,         <span class=\"hljs-comment\"># Maximum delay after rate limit hits</span>\n        max_retries=<span class=\"hljs-number\">2</span>,          <span class=\"hljs-comment\"># Number of retries before giving up</span>\n        rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]  <span class=\"hljs-comment\"># Status codes that trigger rate limiting</span>\n    ),\n    <span class=\"hljs-comment\"># Resource monitoring</span>\n    memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,  <span class=\"hljs-comment\"># Pause if memory exceeds this</span>\n    check_interval=<span class=\"hljs-number\">0.5</span>,            <span class=\"hljs-comment\"># How often to check resources</span>\n    max_session_permit=<span class=\"hljs-number\">3</span>,          <span class=\"hljs-comment\"># Maximum concurrent crawls</span>\n    display_mode=DisplayMode.DETAILED.value  <span class=\"hljs-comment\"># Show detailed progress</span>\n)\n\nurls = [\n    <span class=\"hljs-string\">\"https://example.com/page1\"</span>,\n    <span class=\"hljs-string\">\"https://example.com/page2\"</span>,\n    <span class=\"hljs-string\">\"https://example.com/page3\"</span>\n]\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n    results = <span class=\"hljs-keyword\">await</span> crawler.arun_many(urls, config=run_cfg)\n    <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"URL: <span class=\"hljs-subst\">{result.url}</span>, Success: <span class=\"hljs-subst\">{result.success}</span>\"</span>)\n</code></pre></div>\n<h3 id=\"43-key-features\">4.3 Key Features</h3>\n<p>1.\u2000<strong>Rate Limiting</strong></p>\n<ul>\n<li>Automatic delay between requests</li>\n<li>Exponential backoff on rate limit detection</li>\n<li>Domain-specific rate limiting</li>\n<li>Configurable retry strategy</li>\n</ul>\n<p>2.\u2000<strong>Resource Monitoring</strong></p>\n<ul>\n<li>Memory usage tracking</li>\n<li>Adaptive concurrency based on system load</li>\n<li>Automatic pausing when resources are constrained</li>\n</ul>\n<p>3.\u2000<strong>Progress Monitoring</strong></p>\n<ul>\n<li>Detailed or aggregated progress display</li>\n<li>Real-time status updates</li>\n<li>Memory usage statistics</li>\n</ul>\n<p>4.\u2000<strong>Error Handling</strong></p>\n<ul>\n<li>Graceful handling of rate limits</li>\n<li>Automatic retries with backoff</li>\n<li>Detailed error reporting</li>\n</ul>\n<hr>\n<h2 id=\"5-crawlresult-output\">5.\u2000<code>CrawlResult</code> Output</h2>\n<p>Each <code>arun()</code> returns a <strong><code>CrawlResult</code></strong> containing:</p>\n<ul>\n<li><code>url</code>: Final URL (if redirected).</li>\n<li><code>html</code>: Original HTML.</li>\n<li><code>cleaned_html</code>: Sanitized HTML.</li>\n<li><code>markdown_v2</code> (or future <code>markdown</code>): Markdown outputs (raw, fit, etc.).</li>\n<li><code>extracted_content</code>: If an extraction strategy was used (JSON for CSS/LLM strategies).</li>\n<li><code>screenshot</code>, <code>pdf</code>: If screenshots/PDF requested.</li>\n<li><code>media</code>, <code>links</code>: Information about discovered images/links.</li>\n<li><code>success</code>, <code>error_message</code>: Status info.</li>\n</ul>\n<p>For details, see <a href=\"../crawl-result/\">CrawlResult doc</a>.</p>\n<hr>\n<h2 id=\"6-quick-example\">6.\u2000Quick Example</h2>\n<p>Below is an example hooking it all together:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n<span class=\"hljs-keyword\">import</span> json\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1.\u2000Browser config</span>\n    browser_cfg = BrowserConfig(\n        browser_type=<span class=\"hljs-string\">\"firefox\"</span>,\n        headless=<span class=\"hljs-literal\">False</span>,\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-comment\"># 2.\u2000Run config</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Articles\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"article.post\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, \n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, \n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"url\"</span>, \n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, \n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, \n                <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>\n            }\n        ]\n    }\n\n    run_cfg = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        extraction_strategy=JsonCssExtractionStrategy(schema),\n        word_count_threshold=<span class=\"hljs-number\">15</span>,\n        remove_overlay_elements=<span class=\"hljs-literal\">True</span>,\n        wait_for=<span class=\"hljs-string\">\"css:.post\"</span>  <span class=\"hljs-comment\"># Wait for posts to appear</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com/blog\"</span>,\n            config=run_cfg\n        )\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Cleaned HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n            <span class=\"hljs-keyword\">if</span> result.extracted_content:\n                articles = json.loads(result.extracted_content)\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extracted articles:\"</span>, articles[:<span class=\"hljs-number\">2</span>])\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\nasyncio.run(main())\n</code></pre></div>\n<p><strong>Explanation</strong>:</p>\n<ul>\n<li>We define a <strong><code>BrowserConfig</code></strong> with Firefox, no headless, and <code>verbose=True</code>.\u2000 </li>\n<li>We define a <strong><code>CrawlerRunConfig</code></strong> that <strong>bypasses cache</strong>, uses a <strong>CSS</strong> extraction schema, has a <code>word_count_threshold=15</code>, etc.\u2000 </li>\n<li>We pass them to <code>AsyncWebCrawler(config=...)</code> and <code>arun(url=..., config=...)</code>.</li>\n</ul>\n<hr>\n<h2 id=\"7-best-practices-migration-notes\">7.\u2000Best Practices &amp; Migration Notes</h2>\n<p>1.\u2000<strong>Use</strong> <code>BrowserConfig</code> for <strong>global</strong> settings about the browser\u2019s environment.\u2000 \n2.\u2000<strong>Use</strong> <code>CrawlerRunConfig</code> for <strong>per-crawl</strong> logic (caching, content filtering, extraction strategies, wait conditions).\u2000 \n3.\u2000<strong>Avoid</strong> legacy parameters like <code>css_selector</code> or <code>word_count_threshold</code> directly in <code>arun()</code>.\u2000Instead:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">run_cfg</span> = CrawlerRunConfig(css_selector=<span class=\"hljs-string\">\".main-content\"</span>, word_count_threshold=<span class=\"hljs-number\">20</span>)\n<span class=\"hljs-attr\">result</span> = await crawler.arun(url=<span class=\"hljs-string\">\"...\"</span>, config=run_cfg)\n</code></pre></div>\n<p>4.\u2000<strong>Context Manager</strong> usage is simplest unless you want a persistent crawler across many calls.</p>\n<hr>\n<h2 id=\"8-summary\">8.\u2000Summary</h2>\n<p><strong>AsyncWebCrawler</strong> is your entry point to asynchronous crawling:</p>\n<ul>\n<li><strong>Constructor</strong> accepts <strong><code>BrowserConfig</code></strong> (or defaults).\u2000 </li>\n<li><strong><code>arun(url, config=CrawlerRunConfig)</code></strong> is the main method for single-page crawls.\u2000 </li>\n<li><strong><code>arun_many(urls, config=CrawlerRunConfig)</code></strong> handles concurrency across multiple URLs.\u2000 </li>\n<li>For advanced lifecycle control, use <code>start()</code> and <code>close()</code> explicitly.\u2000 </li>\n</ul>\n<p><strong>Migration</strong>:  </p>\n<ul>\n<li>If you used <code>AsyncWebCrawler(browser_type=\"chromium\", css_selector=\"...\")</code>, move browser settings to <code>BrowserConfig(...)</code> and content/crawl logic to <code>CrawlerRunConfig(...)</code>.</li>\n</ul>\n<p>This modular approach ensures your code is <strong>clean</strong>, <strong>scalable</strong>, and <strong>easy to maintain</strong>.\u2000For any advanced or rarely used parameters, see the <a href=\"../parameters/\">BrowserConfig docs</a>.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# AsyncWebCrawler\nThe **`AsyncWebCrawler`**is the core class for asynchronous web crawling in Crawl4AI. You typically create it**once** , optionally customize it with a **`BrowserConfig`**(e.g., headless, user agent), then**run** multiple **`arun()`**calls with different**`CrawlerRunConfig`**objects.\n**Recommended usage** :\n1. **Create** a `BrowserConfig` for global browser settings. \n2. **Instantiate** `AsyncWebCrawler(config=browser_config)`. \n3. **Use** the crawler in an async context manager (`async with`) or manage start/close manually. \n4. **Call** `arun(url, config=crawler_run_config)` for each page you want.\n## 1. Constructor Overview\n```\nclass AsyncWebCrawler:\n  def __init__(\n    self,\n    crawler_strategy: Optional[AsyncCrawlerStrategy] = None,\n    config: Optional[BrowserConfig] = None,\n    always_bypass_cache: bool = False,      # deprecated\n    always_by_pass_cache: Optional[bool] = None, # also deprecated\n    base_directory: str = ...,\n    thread_safe: bool = False,\n    **kwargs,\n  ):\n    \"\"\"\n    Create an AsyncWebCrawler instance.\n    Args:\n      crawler_strategy: \n        (Advanced) Provide a custom crawler strategy if needed.\n      config: \n        A BrowserConfig object specifying how the browser is set up.\n      always_bypass_cache: \n        (Deprecated) Use CrawlerRunConfig.cache_mode instead.\n      base_directory:   \n        Folder for storing caches/logs (if relevant).\n      thread_safe: \n        If True, attempts some concurrency safeguards.\u2000Usually False.\n      **kwargs: \n        Additional legacy or debugging parameters.\n    \"\"\"\n  )\n### Typical Initialization\n```python\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig\nbrowser_cfg = BrowserConfig(\n  browser_type=\"chromium\",\n  headless=True,\n  verbose=True\n)\ncrawler = AsyncWebCrawler(config=browser_cfg)\n\n```\n\n**Notes** :\n  * **Legacy** parameters like `always_bypass_cache` remain for backward compatibility, but prefer to set **caching** in `CrawlerRunConfig`.\n\n\n## 2. Lifecycle: Start/Close or Context Manager\n### 2.1 Context Manager (Recommended)\n```\nasync with AsyncWebCrawler(config=browser_cfg) as crawler:\n  result = await crawler.arun(\"https://example.com\")\n  # The crawler automatically starts/closes resources\n\n```\n\nWhen the `async with` block ends, the crawler cleans up (closes the browser, etc.).\n### 2.2 Manual Start & Close\n```\ncrawler = AsyncWebCrawler(config=browser_cfg)\nawait crawler.start()\nresult1 = await crawler.arun(\"https://example.com\")\nresult2 = await crawler.arun(\"https://another.com\")\nawait crawler.close()\n\n```\n\nUse this style if you have a **long-running** application or need full control of the crawler\u2019s lifecycle.\n## 3. Primary Method: `arun()`\n```\nasync def arun(\n  self,\n  url: str,\n  config: Optional[CrawlerRunConfig] = None,\n  # Legacy parameters for backward compatibility...\n) -> CrawlResult:\n  ...\n\n```\n\n### 3.1 New Approach\nYou pass a `CrawlerRunConfig` object that sets up everything about a crawl\u2014content filtering, caching, session reuse, JS code, screenshots, etc.\n```\nimport asyncio\nfrom crawl4ai import CrawlerRunConfig, CacheMode\nrun_cfg = CrawlerRunConfig(\n  cache_mode=CacheMode.BYPASS,\n  css_selector=\"main.article\",\n  word_count_threshold=10,\n  screenshot=True\n)\nasync with AsyncWebCrawler(config=browser_cfg) as crawler:\n  result = await crawler.arun(\"https://example.com/news\", config=run_cfg)\n  print(\"Crawled HTML length:\", len(result.cleaned_html))\n  if result.screenshot:\n    print(\"Screenshot base64 length:\", len(result.screenshot))\n\n```\n\n### 3.2 Legacy Parameters Still Accepted\nFor **backward** compatibility, `arun()` can still accept direct arguments like `css_selector=...`, `word_count_threshold=...`, etc., but we strongly advise migrating them into a **`CrawlerRunConfig`**.\n## 4. Batch Processing: `arun_many()`\n```\nasync def arun_many(\n  self,\n  urls: List[str],\n  config: Optional[CrawlerRunConfig] = None,\n  # Legacy parameters maintained for backwards compatibility...\n) -> List[CrawlResult]:\n  \"\"\"\n  Process multiple URLs with intelligent rate limiting and resource monitoring.\n  \"\"\"\n\n```\n\n### 4.1 Resource-Aware Crawling\nThe `arun_many()` method now uses an intelligent dispatcher that:\n  * Monitors system memory usage\n  * Implements adaptive rate limiting\n  * Provides detailed progress monitoring\n  * Manages concurrent crawls efficiently\n\n\n### 4.2 Example Usage\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, RateLimitConfig\nfrom crawl4ai.dispatcher import DisplayMode\n# Configure browser\nbrowser_cfg = BrowserConfig(headless=True)\n# Configure crawler with rate limiting\nrun_cfg = CrawlerRunConfig(\n  # Enable rate limiting\n  enable_rate_limiting=True,\n  rate_limit_config=RateLimitConfig(\n    base_delay=(1.0, 2.0), # Random delay between 1-2 seconds\n    max_delay=30.0,     # Maximum delay after rate limit hits\n    max_retries=2,     # Number of retries before giving up\n    rate_limit_codes=[429, 503] # Status codes that trigger rate limiting\n  ),\n  # Resource monitoring\n  memory_threshold_percent=70.0, # Pause if memory exceeds this\n  check_interval=0.5,      # How often to check resources\n  max_session_permit=3,     # Maximum concurrent crawls\n  display_mode=DisplayMode.DETAILED.value # Show detailed progress\n)\nurls = [\n  \"https://example.com/page1\",\n  \"https://example.com/page2\",\n  \"https://example.com/page3\"\n]\nasync with AsyncWebCrawler(config=browser_cfg) as crawler:\n  results = await crawler.arun_many(urls, config=run_cfg)\n  for result in results:\n    print(f\"URL: {result.url}, Success: {result.success}\")\n\n```\n\n### 4.3 Key Features\n1. **Rate Limiting**\n  * Automatic delay between requests\n  * Exponential backoff on rate limit detection\n  * Domain-specific rate limiting\n  * Configurable retry strategy\n\n\n2. **Resource Monitoring**\n  * Memory usage tracking\n  * Adaptive concurrency based on system load\n  * Automatic pausing when resources are constrained\n\n\n3. **Progress Monitoring**\n  * Detailed or aggregated progress display\n  * Real-time status updates\n  * Memory usage statistics\n\n\n4. **Error Handling**\n  * Graceful handling of rate limits\n  * Automatic retries with backoff\n  * Detailed error reporting\n\n\n## 5. `CrawlResult` Output\nEach `arun()` returns a **`CrawlResult`**containing:\n  * `url`: Final URL (if redirected).\n  * `html`: Original HTML.\n  * `cleaned_html`: Sanitized HTML.\n  * `markdown_v2` (or future `markdown`): Markdown outputs (raw, fit, etc.).\n  * `extracted_content`: If an extraction strategy was used (JSON for CSS/LLM strategies).\n  * `screenshot`, `pdf`: If screenshots/PDF requested.\n  * `media`, `links`: Information about discovered images/links.\n  * `success`, `error_message`: Status info.\n\n\nFor details, see [CrawlResult doc](https://docs.crawl4ai.com/api/<../crawl-result/>).\n## 6. Quick Example\nBelow is an example hooking it all together:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nimport json\nasync def main():\n  # 1.\u2000Browser config\n  browser_cfg = BrowserConfig(\n    browser_type=\"firefox\",\n    headless=False,\n    verbose=True\n  )\n  # 2.\u2000Run config\n  schema = {\n    \"name\": \"Articles\",\n    \"baseSelector\": \"article.post\",\n    \"fields\": [\n      {\n        \"name\": \"title\", \n        \"selector\": \"h2\", \n        \"type\": \"text\"\n      },\n      {\n        \"name\": \"url\", \n        \"selector\": \"a\", \n        \"type\": \"attribute\", \n        \"attribute\": \"href\"\n      }\n    ]\n  }\n  run_cfg = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    extraction_strategy=JsonCssExtractionStrategy(schema),\n    word_count_threshold=15,\n    remove_overlay_elements=True,\n    wait_for=\"css:.post\" # Wait for posts to appear\n  )\n  async with AsyncWebCrawler(config=browser_cfg) as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com/blog\",\n      config=run_cfg\n    )\n    if result.success:\n      print(\"Cleaned HTML length:\", len(result.cleaned_html))\n      if result.extracted_content:\n        articles = json.loads(result.extracted_content)\n        print(\"Extracted articles:\", articles[:2])\n    else:\n      print(\"Error:\", result.error_message)\nasyncio.run(main())\n\n```\n\n**Explanation** :\n  * We define a **`BrowserConfig`**with Firefox, no headless, and`verbose=True`. \n  * We define a **`CrawlerRunConfig`**that**bypasses cache** , uses a **CSS** extraction schema, has a `word_count_threshold=15`, etc. \n  * We pass them to `AsyncWebCrawler(config=...)` and `arun(url=..., config=...)`.\n\n\n## 7. Best Practices & Migration Notes\n1. **Use** `BrowserConfig` for **global** settings about the browser\u2019s environment. 2. **Use** `CrawlerRunConfig` for **per-crawl** logic (caching, content filtering, extraction strategies, wait conditions). 3. **Avoid** legacy parameters like `css_selector` or `word_count_threshold` directly in `arun()`. Instead:\n```\nrun_cfg = CrawlerRunConfig(css_selector=\".main-content\", word_count_threshold=20)\nresult = await crawler.arun(url=\"...\", config=run_cfg)\n\n```\n\n4. **Context Manager** usage is simplest unless you want a persistent crawler across many calls.\n## 8. Summary\n**AsyncWebCrawler** is your entry point to asynchronous crawling:\n  * **Constructor** accepts **`BrowserConfig`**(or defaults).\n  * **`arun(url, config=CrawlerRunConfig)`**is the main method for single-page crawls.\n  * **`arun_many(urls, config=CrawlerRunConfig)`**handles concurrency across multiple URLs.\n  * For advanced lifecycle control, use `start()` and `close()` explicitly. \n\n\n**Migration** : \n  * If you used `AsyncWebCrawler(browser_type=\"chromium\", css_selector=\"...\")`, move browser settings to `BrowserConfig(...)` and content/crawl logic to `CrawlerRunConfig(...)`.\n\n\nThis modular approach ensures your code is **clean** , **scalable** , and **easy to maintain**. For any advanced or rarely used parameters, see the [BrowserConfig docs](https://docs.crawl4ai.com/api/<../parameters/>).\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun",
        "https://docs.crawl4ai.com/arun_many",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/parameters",
        "https://docs.crawl4ai.com/strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 9,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:12",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "blog.json",
    "content": {
      "url": "https://docs.crawl4ai.com/blog",
      "timestamp": "2025-02-06T13:23:32.966073",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/blog/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../img/favicon-32x32.png\">\n\n\n    \n \n<title>Blog Home - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../assets/highlight.min.js\"></script>\n    \n    <script src=\"../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Blog Home</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawl4ai-blog\">Crawl4AI Blog</a></li>\n        <li><a href=\"#latest-release\">Latest Release</a></li><li><a href=\"#project-history\">Project History</a></li><li><a href=\"#stay-updated\">Stay Updated</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawl4ai-blog\">Crawl4AI Blog</h1>\n<p>Welcome to the Crawl4AI blog! Here you'll find detailed release notes, technical insights, and updates about the project. Whether you're looking for the latest improvements or want to dive deep into web crawling techniques, this is the place.</p>\n<h2 id=\"latest-release\">Latest Release</h2>\n<h3 id=\"042-configurable-crawlers-session-management-and-smarter-screenshots\"><a href=\"releases/0.4.2/\">0.4.2 - Configurable Crawlers, Session Management, and Smarter Screenshots</a></h3>\n<p><em>December 12, 2024</em></p>\n<p>The 0.4.2 update brings massive improvements to configuration, making crawlers and browsers easier to manage with dedicated objects. You can now import/export local storage for seamless session management. Plus, long-page screenshots are faster and cleaner, and full-page PDF exports are now possible. Check out all the new features to make your crawling experience even smoother.</p>\n<p><a href=\"releases/0.4.2/\">Read full release notes \u2192</a></p>\n<hr>\n<h3 id=\"041-smarter-crawling-with-lazy-load-handling-text-only-mode-and-more\"><a href=\"releases/0.4.1/\">0.4.1 - Smarter Crawling with Lazy-Load Handling, Text-Only Mode, and More</a></h3>\n<p><em>December 8, 2024</em></p>\n<p>This release brings major improvements to handling lazy-loaded images, a blazing-fast Text-Only Mode, full-page scanning for infinite scrolls, dynamic viewport adjustments, and session reuse for efficient crawling. If you're looking to improve speed, reliability, or handle dynamic content with ease, this update has you covered.</p>\n<p><a href=\"releases/0.4.1/\">Read full release notes \u2192</a></p>\n<hr>\n<h3 id=\"040-major-content-filtering-update\"><a href=\"releases/0.4.0/\">0.4.0 - Major Content Filtering Update</a></h3>\n<p><em>December 1, 2024</em></p>\n<p>Introduced significant improvements to content filtering, multi-threaded environment handling, and user-agent generation. This release features the new PruningContentFilter, enhanced thread safety, and improved test coverage.</p>\n<p><a href=\"releases/0.4.0/\">Read full release notes \u2192</a></p>\n<h2 id=\"project-history\">Project History</h2>\n<p>Curious about how Crawl4AI has evolved? Check out our <a href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">complete changelog</a> for a detailed history of all versions and updates.</p>\n<h2 id=\"stay-updated\">Stay Updated</h2>\n<ul>\n<li>Star us on <a href=\"https://github.com/unclecode/crawl4ai\">GitHub</a></li>\n<li>Follow <a href=\"https://twitter.com/unclecode\">@unclecode</a> on Twitter</li>\n<li>Join our community discussions on GitHub</li>\n</ul>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Crawl4AI Blog\nWelcome to the Crawl4AI blog! Here you'll find detailed release notes, technical insights, and updates about the project. Whether you're looking for the latest improvements or want to dive deep into web crawling techniques, this is the place.\n## Latest Release\n### [0.4.2 - Configurable Crawlers, Session Management, and Smarter Screenshots](https://docs.crawl4ai.com/<releases/0.4.2/>)\n_December 12, 2024_\nThe 0.4.2 update brings massive improvements to configuration, making crawlers and browsers easier to manage with dedicated objects. You can now import/export local storage for seamless session management. Plus, long-page screenshots are faster and cleaner, and full-page PDF exports are now possible. Check out all the new features to make your crawling experience even smoother.\n[Read full release notes \u2192](https://docs.crawl4ai.com/<releases/0.4.2/>)\n### [0.4.1 - Smarter Crawling with Lazy-Load Handling, Text-Only Mode, and More](https://docs.crawl4ai.com/<releases/0.4.1/>)\n_December 8, 2024_\nThis release brings major improvements to handling lazy-loaded images, a blazing-fast Text-Only Mode, full-page scanning for infinite scrolls, dynamic viewport adjustments, and session reuse for efficient crawling. If you're looking to improve speed, reliability, or handle dynamic content with ease, this update has you covered.\n[Read full release notes \u2192](https://docs.crawl4ai.com/<releases/0.4.1/>)\n### [0.4.0 - Major Content Filtering Update](https://docs.crawl4ai.com/<releases/0.4.0/>)\n_December 1, 2024_\nIntroduced significant improvements to content filtering, multi-threaded environment handling, and user-agent generation. This release features the new PruningContentFilter, enhanced thread safety, and improved test coverage.\n[Read full release notes \u2192](https://docs.crawl4ai.com/<releases/0.4.0/>)\n## Project History\nCurious about how Crawl4AI has evolved? Check out our for a detailed history of all versions and updates.\n## Stay Updated\n  * Star us on \n  * Follow on Twitter\n  * Join our community discussions on GitHub\n\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/releases/0.4.0",
        "https://docs.crawl4ai.com/releases/0.4.1",
        "https://docs.crawl4ai.com/releases/0.4.2"
      ],
      "depth": 1,
      "stats": {
        "processed": 13,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:16",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "browser-crawler-config.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/browser-crawler-config",
      "timestamp": "2025-02-06T13:23:34.161632",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/browser-crawler-config/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Browser &amp; Crawler Config - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Browser &amp; Crawler Config</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#browser-crawler-configuration-quick-overview\">Browser &amp; Crawler Configuration (Quick Overview)</a></li>\n        <li><a href=\"#1-browserconfig-essentials\">1. BrowserConfig Essentials</a></li><li><a href=\"#2-crawlerrunconfig-essentials\">2. CrawlerRunConfig Essentials</a></li><li><a href=\"#3-putting-it-all-together\">3. Putting It All Together</a></li><li><a href=\"#4-next-steps\">4. Next Steps</a></li><li><a href=\"#5-conclusion\">5. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"browser-crawler-configuration-quick-overview\">Browser &amp; Crawler Configuration (Quick Overview)</h1>\n<p>Crawl4AI\u2019s flexibility stems from two key classes:</p>\n<p>1.\u2000<strong><code>BrowserConfig</code></strong> \u2013 Dictates <strong>how</strong> the browser is launched and behaves (e.g., headless or visible, proxy, user agent).<br>\n2.\u2000<strong><code>CrawlerRunConfig</code></strong> \u2013 Dictates <strong>how</strong> each <strong>crawl</strong> operates (e.g., caching, extraction, timeouts, JavaScript code to run, etc.).</p>\n<p>In most examples, you create <strong>one</strong> <code>BrowserConfig</code> for the entire crawler session, then pass a <strong>fresh</strong> or re-used <code>CrawlerRunConfig</code> whenever you call <code>arun()</code>. This tutorial shows the most commonly used parameters. If you need advanced or rarely used fields, see the <a href=\"../../api/parameters/\">Configuration Parameters</a>.</p>\n<hr>\n<h2 id=\"1-browserconfig-essentials\">1. BrowserConfig Essentials</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BrowserConfig</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        browser_type=<span class=\"hljs-string\">\"chromium\"</span>,\n        headless=<span class=\"hljs-literal\">True</span>,\n        proxy_config=<span class=\"hljs-literal\">None</span>,\n        viewport_width=<span class=\"hljs-number\">1080</span>,\n        viewport_height=<span class=\"hljs-number\">600</span>,\n        verbose=<span class=\"hljs-literal\">True</span>,\n        use_persistent_context=<span class=\"hljs-literal\">False</span>,\n        user_data_dir=<span class=\"hljs-literal\">None</span>,\n        cookies=<span class=\"hljs-literal\">None</span>,\n        headers=<span class=\"hljs-literal\">None</span>,\n        user_agent=<span class=\"hljs-literal\">None</span>,\n        text_mode=<span class=\"hljs-literal\">False</span>,\n        light_mode=<span class=\"hljs-literal\">False</span>,\n        extra_args=<span class=\"hljs-literal\">None</span>,\n        <span class=\"hljs-comment\"># ... other advanced parameters omitted here</span>\n    </span>):\n        ...\n</code></pre></div>\n<h3 id=\"key-fields-to-note\">Key Fields to Note</h3>\n<p>1.\u2000<strong><code>browser_type</code></strong><br>\n- Options: <code>\"chromium\"</code>, <code>\"firefox\"</code>, or <code>\"webkit\"</code>.<br>\n- Defaults to <code>\"chromium\"</code>.<br>\n- If you need a different engine, specify it here.</p>\n<p>2.\u2000<strong><code>headless</code></strong><br>\n   - <code>True</code>: Runs the browser in headless mode (invisible browser).<br>\n   - <code>False</code>: Runs the browser in visible mode, which helps with debugging.</p>\n<p>3.\u2000<strong><code>proxy_config</code></strong><br>\n   - A dictionary with fields like:<br>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-json\"><span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-attr\">\"server\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"http://proxy.example.com:8080\"</span><span class=\"hljs-punctuation\">,</span> \n    <span class=\"hljs-attr\">\"username\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"...\"</span><span class=\"hljs-punctuation\">,</span> \n    <span class=\"hljs-attr\">\"password\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"...\"</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n   - Leave as <code>None</code> if a proxy is not required.<p></p>\n<p>4.\u2000<strong><code>viewport_width</code> &amp; <code>viewport_height</code></strong>:<br>\n   - The initial window size.<br>\n   - Some sites behave differently with smaller or bigger viewports.</p>\n<p>5.\u2000<strong><code>verbose</code></strong>:<br>\n   - If <code>True</code>, prints extra logs.<br>\n   - Handy for debugging.</p>\n<p>6.\u2000<strong><code>use_persistent_context</code></strong>:<br>\n   - If <code>True</code>, uses a <strong>persistent</strong> browser profile, storing cookies/local storage across runs.<br>\n   - Typically also set <code>user_data_dir</code> to point to a folder.</p>\n<p>7.\u2000<strong><code>cookies</code></strong> &amp; <strong><code>headers</code></strong>:<br>\n   - If you want to start with specific cookies or add universal HTTP headers, set them here.<br>\n   - E.g. <code>cookies=[{\"name\": \"session\", \"value\": \"abc123\", \"domain\": \"example.com\"}]</code>.</p>\n<p>8.\u2000<strong><code>user_agent</code></strong>:<br>\n   - Custom User-Agent string. If <code>None</code>, a default is used.<br>\n   - You can also set <code>user_agent_mode=\"random\"</code> for randomization (if you want to fight bot detection).</p>\n<p>9.\u2000<strong><code>text_mode</code></strong> &amp; <strong><code>light_mode</code></strong>:<br>\n   - <code>text_mode=True</code> disables images, possibly speeding up text-only crawls.<br>\n   - <code>light_mode=True</code> turns off certain background features for performance.  </p>\n<p>10.\u2000<strong><code>extra_args</code></strong>:<br>\n    - Additional flags for the underlying browser.<br>\n    - E.g. <code>[\"--disable-extensions\"]</code>.</p>\n<h3 id=\"helper-methods\">Helper Methods</h3>\n<p>Both configuration classes provide a <code>clone()</code> method to create modified copies:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\"><span class=\"hljs-comment\"># Create a base browser config</span>\nbase_browser <span class=\"hljs-punctuation\">=</span> BrowserConfig<span class=\"hljs-punctuation\">(</span>\n    browser_type<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"chromium\"</span>,\n    headless<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    text_mode<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n\n<span class=\"hljs-comment\"># Create a visible browser config for debugging</span>\ndebug_browser <span class=\"hljs-punctuation\">=</span> base_browser.clone<span class=\"hljs-punctuation\">(</span>\n    headless<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">False</span>,\n    verbose<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p><strong>Minimal Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig\n\nbrowser_conf = BrowserConfig(\n    browser_type=<span class=\"hljs-string\">\"firefox\"</span>,\n    headless=<span class=\"hljs-literal\">False</span>,\n    text_mode=<span class=\"hljs-literal\">True</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_conf) <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>)\n    <span class=\"hljs-built_in\">print</span>(result.markdown[:<span class=\"hljs-number\">300</span>])\n</code></pre></div>\n<hr>\n<h2 id=\"2-crawlerrunconfig-essentials\">2. CrawlerRunConfig Essentials</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CrawlerRunConfig</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        word_count_threshold=<span class=\"hljs-number\">200</span>,\n        extraction_strategy=<span class=\"hljs-literal\">None</span>,\n        markdown_generator=<span class=\"hljs-literal\">None</span>,\n        cache_mode=<span class=\"hljs-literal\">None</span>,\n        js_code=<span class=\"hljs-literal\">None</span>,\n        wait_for=<span class=\"hljs-literal\">None</span>,\n        screenshot=<span class=\"hljs-literal\">False</span>,\n        pdf=<span class=\"hljs-literal\">False</span>,\n        enable_rate_limiting=<span class=\"hljs-literal\">False</span>,\n        rate_limit_config=<span class=\"hljs-literal\">None</span>,\n        memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,\n        check_interval=<span class=\"hljs-number\">1.0</span>,\n        max_session_permit=<span class=\"hljs-number\">20</span>,\n        display_mode=<span class=\"hljs-literal\">None</span>,\n        verbose=<span class=\"hljs-literal\">True</span>,\n        stream=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Enable streaming for arun_many()</span>\n        <span class=\"hljs-comment\"># ... other advanced parameters omitted</span>\n    </span>):\n        ...\n</code></pre></div>\n<h3 id=\"key-fields-to-note_1\">Key Fields to Note</h3>\n<p>1.\u2000<strong><code>word_count_threshold</code></strong>:<br>\n   - The minimum word count before a block is considered.<br>\n   - If your site has lots of short paragraphs or items, you can lower it.</p>\n<p>2.\u2000<strong><code>extraction_strategy</code></strong>:<br>\n   - Where you plug in JSON-based extraction (CSS, LLM, etc.).<br>\n   - If <code>None</code>, no structured extraction is done (only raw/cleaned HTML + markdown).</p>\n<p>3.\u2000<strong><code>markdown_generator</code></strong>:<br>\n   - E.g., <code>DefaultMarkdownGenerator(...)</code>, controlling how HTML\u2192Markdown conversion is done.<br>\n   - If <code>None</code>, a default approach is used.</p>\n<p>4.\u2000<strong><code>cache_mode</code></strong>:<br>\n   - Controls caching behavior (<code>ENABLED</code>, <code>BYPASS</code>, <code>DISABLED</code>, etc.).<br>\n   - If <code>None</code>, defaults to some level of caching or you can specify <code>CacheMode.ENABLED</code>.</p>\n<p>5.\u2000<strong><code>js_code</code></strong>:<br>\n   - A string or list of JS strings to execute.<br>\n   - Great for \u201cLoad More\u201d buttons or user interactions.  </p>\n<p>6.\u2000<strong><code>wait_for</code></strong>:<br>\n   - A CSS or JS expression to wait for before extracting content.<br>\n   - Common usage: <code>wait_for=\"css:.main-loaded\"</code> or <code>wait_for=\"js:() =&gt; window.loaded === true\"</code>.</p>\n<p>7.\u2000<strong><code>screenshot</code></strong> &amp; <strong><code>pdf</code></strong>:<br>\n   - If <code>True</code>, captures a screenshot or PDF after the page is fully loaded.<br>\n   - The results go to <code>result.screenshot</code> (base64) or <code>result.pdf</code> (bytes).</p>\n<p>8.\u2000<strong><code>verbose</code></strong>:<br>\n   - Logs additional runtime details.<br>\n   - Overlaps with the browser\u2019s verbosity if also set to <code>True</code> in <code>BrowserConfig</code>.</p>\n<p>9.\u2000<strong><code>enable_rate_limiting</code></strong>:<br>\n   - If <code>True</code>, enables rate limiting for batch processing.<br>\n   - Requires <code>rate_limit_config</code> to be set.</p>\n<p>10.\u2000<strong><code>rate_limit_config</code></strong>:<br>\n    - A <code>RateLimitConfig</code> object controlling rate limiting behavior.<br>\n    - See below for details.</p>\n<p>11.\u2000<strong><code>memory_threshold_percent</code></strong>:<br>\n    - The memory threshold (as a percentage) to monitor.<br>\n    - If exceeded, the crawler will pause or slow down.</p>\n<p>12.\u2000<strong><code>check_interval</code></strong>:<br>\n    - The interval (in seconds) to check system resources.<br>\n    - Affects how often memory and CPU usage are monitored.</p>\n<p>13.\u2000<strong><code>max_session_permit</code></strong>:<br>\n    - The maximum number of concurrent crawl sessions.<br>\n    - Helps prevent overwhelming the system.</p>\n<p>14.\u2000<strong><code>display_mode</code></strong>:<br>\n    - The display mode for progress information (<code>DETAILED</code>, <code>BRIEF</code>, etc.).<br>\n    - Affects how much information is printed during the crawl.</p>\n<h3 id=\"helper-methods_1\">Helper Methods</h3>\n<p>The <code>clone()</code> method is particularly useful for creating variations of your crawler configuration:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\"><span class=\"hljs-comment\"># Create a base configuration</span>\nbase_config = CrawlerRunConfig(\n    cache_mode=CacheMode.ENABLED,\n    word_count_threshold=200,\n    wait_until=<span class=\"hljs-string\">\"networkidle\"</span>\n)\n\n<span class=\"hljs-comment\"># Create variations for different use cases</span>\nstream_config = base_config.clone(\n    stream=True,  <span class=\"hljs-comment\"># Enable streaming mode</span>\n    cache_mode=CacheMode.BYPASS\n)\n\ndebug_config = base_config.clone(\n    page_timeout=120000,  <span class=\"hljs-comment\"># Longer timeout for debugging</span>\n    verbose=True\n)\n</code></pre></div>\n<p>The <code>clone()</code> method:\n- Creates a new instance with all the same settings\n- Updates only the specified parameters\n- Leaves the original configuration unchanged\n- Perfect for creating variations without repeating all parameters</p>\n<h3 id=\"rate-limiting-resource-management\">Rate Limiting &amp; Resource Management</h3>\n<p>For batch processing with <code>arun_many()</code>, you can enable intelligent rate limiting:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> RateLimitConfig\n\nconfig = CrawlerRunConfig(\n    enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n    rate_limit_config=RateLimitConfig(\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),    <span class=\"hljs-comment\"># Random delay range</span>\n        max_delay=<span class=\"hljs-number\">60.0</span>,           <span class=\"hljs-comment\"># Max delay after rate limits</span>\n        max_retries=<span class=\"hljs-number\">3</span>,            <span class=\"hljs-comment\"># Retries before giving up</span>\n        rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]  <span class=\"hljs-comment\"># Status codes to watch</span>\n    ),\n    memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,  <span class=\"hljs-comment\"># Memory threshold</span>\n    check_interval=<span class=\"hljs-number\">1.0</span>,            <span class=\"hljs-comment\"># Resource check interval</span>\n    max_session_permit=<span class=\"hljs-number\">20</span>,         <span class=\"hljs-comment\"># Max concurrent crawls</span>\n    display_mode=<span class=\"hljs-string\">\"DETAILED\"</span>        <span class=\"hljs-comment\"># Progress display mode</span>\n)\n</code></pre></div>\n<p>This configuration:\n- Implements intelligent rate limiting per domain\n- Monitors system resources\n- Provides detailed progress information\n- Manages concurrent crawls efficiently</p>\n<p><strong>Minimal Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\ncrawl_conf = CrawlerRunConfig(\n    js_code=<span class=\"hljs-string\">\"document.querySelector('button#loadMore')?.click()\"</span>,\n    wait_for=<span class=\"hljs-string\">\"css:.loaded-content\"</span>,\n    screenshot=<span class=\"hljs-literal\">True</span>,\n    enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n    rate_limit_config=RateLimitConfig(\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),\n        max_delay=<span class=\"hljs-number\">60.0</span>,\n        max_retries=<span class=\"hljs-number\">3</span>,\n        rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]\n    ),\n    stream=<span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Enable streaming</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=crawl_conf)\n    <span class=\"hljs-built_in\">print</span>(result.screenshot[:<span class=\"hljs-number\">100</span>])  <span class=\"hljs-comment\"># Base64-encoded PNG snippet</span>\n</code></pre></div>\n<hr>\n<h2 id=\"3-putting-it-all-together\">3. Putting It All Together</h2>\n<p>In a typical scenario, you define <strong>one</strong> <code>BrowserConfig</code> for your crawler session, then create <strong>one or more</strong> <code>CrawlerRunConfig</code> depending on each call\u2019s needs:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1) Browser config: headless, bigger viewport, no proxy</span>\n    browser_conf = BrowserConfig(\n        headless=<span class=\"hljs-literal\">True</span>,\n        viewport_width=<span class=\"hljs-number\">1280</span>,\n        viewport_height=<span class=\"hljs-number\">720</span>\n    )\n\n    <span class=\"hljs-comment\"># 2) Example extraction strategy</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Articles\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.article\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n    extraction = JsonCssExtractionStrategy(schema)\n\n    <span class=\"hljs-comment\"># 3) Crawler run config: skip cache, use extraction</span>\n    run_conf = CrawlerRunConfig(\n        extraction_strategy=extraction,\n        cache_mode=CacheMode.BYPASS,\n        enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n        rate_limit_config=RateLimitConfig(\n            base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),\n            max_delay=<span class=\"hljs-number\">60.0</span>,\n            max_retries=<span class=\"hljs-number\">3</span>,\n            rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]\n        )\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_conf) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># 4) Execute the crawl</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com/news\"</span>, config=run_conf)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extracted content:\"</span>, result.extracted_content)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"4-next-steps\">4. Next Steps</h2>\n<p>For a <strong>detailed list</strong> of available parameters (including advanced ones), see:</p>\n<ul>\n<li><a href=\"../../api/parameters/\">BrowserConfig and CrawlerRunConfig Reference</a>  </li>\n</ul>\n<p>You can explore topics like:</p>\n<ul>\n<li><strong>Custom Hooks &amp; Auth</strong> (Inject JavaScript or handle login forms).  </li>\n<li><strong>Session Management</strong> (Re-use pages, preserve state across multiple calls).  </li>\n<li><strong>Magic Mode</strong> or <strong>Identity-based Crawling</strong> (Fight bot detection by simulating user behavior).  </li>\n<li><strong>Advanced Caching</strong> (Fine-tune read/write cache modes).  </li>\n</ul>\n<hr>\n<h2 id=\"5-conclusion\">5. Conclusion</h2>\n<p><strong>BrowserConfig</strong> and <strong>CrawlerRunConfig</strong> give you straightforward ways to define:</p>\n<ul>\n<li><strong>Which</strong> browser to launch, how it should run, and any proxy or user agent needs.  </li>\n<li><strong>How</strong> each crawl should behave\u2014caching, timeouts, JavaScript code, extraction strategies, etc.</li>\n</ul>\n<p>Use them together for <strong>clear, maintainable</strong> code, and when you need more specialized behavior, check out the advanced parameters in the <a href=\"../../api/parameters/\">reference docs</a>. Happy crawling!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Browser & Crawler Configuration (Quick Overview)\nCrawl4AI\u2019s flexibility stems from two key classes:\n1. **`BrowserConfig`**\u2013 Dictates**how** the browser is launched and behaves (e.g., headless or visible, proxy, user agent). 2. **`CrawlerRunConfig`**\u2013 Dictates**how** each **crawl** operates (e.g., caching, extraction, timeouts, JavaScript code to run, etc.).\nIn most examples, you create **one** `BrowserConfig` for the entire crawler session, then pass a **fresh** or re-used `CrawlerRunConfig` whenever you call `arun()`. This tutorial shows the most commonly used parameters. If you need advanced or rarely used fields, see the [Configuration Parameters](https://docs.crawl4ai.com/core/api/parameters/>).\n## 1. BrowserConfig Essentials\n```\nclass BrowserConfig:\n  def __init__(\n    browser_type=\"chromium\",\n    headless=True,\n    proxy_config=None,\n    viewport_width=1080,\n    viewport_height=600,\n    verbose=True,\n    use_persistent_context=False,\n    user_data_dir=None,\n    cookies=None,\n    headers=None,\n    user_agent=None,\n    text_mode=False,\n    light_mode=False,\n    extra_args=None,\n    # ... other advanced parameters omitted here\n  ):\n    ...\n\n```\n\n### Key Fields to Note\n1. **`browser_type`**- Options:`\"chromium\"` , `\"firefox\"`, or `\"webkit\"`. - Defaults to `\"chromium\"`. - If you need a different engine, specify it here.\n2. **`headless`**-`True` : Runs the browser in headless mode (invisible browser). - `False`: Runs the browser in visible mode, which helps with debugging.\n3. **`proxy_config`**- A dictionary with fields like:\n```\n{\n  \"server\": \"http://proxy.example.com:8080\", \n  \"username\": \"...\", \n  \"password\": \"...\"\n}\n\n```\n\n- Leave as `None` if a proxy is not required. \n4. **`viewport_width` & `viewport_height`**: - The initial window size. - Some sites behave differently with smaller or bigger viewports.\n5. **`verbose`**: - If`True` , prints extra logs. - Handy for debugging.\n6. **`use_persistent_context`**: - If`True` , uses a **persistent** browser profile, storing cookies/local storage across runs. - Typically also set `user_data_dir` to point to a folder.\n7. **`cookies`** & **`headers`**: - If you want to start with specific cookies or add universal HTTP headers, set them here. - E.g.`cookies=[{\"name\": \"session\", \"value\": \"abc123\", \"domain\": \"example.com\"}]`.\n8. **`user_agent`**: - Custom User-Agent string. If`None` , a default is used. - You can also set `user_agent_mode=\"random\"` for randomization (if you want to fight bot detection).\n9. **`text_mode`** & **`light_mode`**: -`text_mode=True` disables images, possibly speeding up text-only crawls. - `light_mode=True` turns off certain background features for performance. \n10. **`extra_args`**: - Additional flags for the underlying browser. - E.g.`[\"--disable-extensions\"]`.\n### Helper Methods\nBoth configuration classes provide a `clone()` method to create modified copies:\n```\n# Create a base browser config\nbase_browser = BrowserConfig(\n  browser_type=\"chromium\",\n  headless=True,\n  text_mode=True\n)\n# Create a visible browser config for debugging\ndebug_browser = base_browser.clone(\n  headless=False,\n  verbose=True\n)\n\n```\n\n**Minimal Example** :\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig\nbrowser_conf = BrowserConfig(\n  browser_type=\"firefox\",\n  headless=False,\n  text_mode=True\n)\nasync with AsyncWebCrawler(config=browser_conf) as crawler:\n  result = await crawler.arun(\"https://example.com\")\n  print(result.markdown[:300])\n\n```\n\n## 2. CrawlerRunConfig Essentials\n```\nclass CrawlerRunConfig:\n  def __init__(\n    word_count_threshold=200,\n    extraction_strategy=None,\n    markdown_generator=None,\n    cache_mode=None,\n    js_code=None,\n    wait_for=None,\n    screenshot=False,\n    pdf=False,\n    enable_rate_limiting=False,\n    rate_limit_config=None,\n    memory_threshold_percent=70.0,\n    check_interval=1.0,\n    max_session_permit=20,\n    display_mode=None,\n    verbose=True,\n    stream=False, # Enable streaming for arun_many()\n    # ... other advanced parameters omitted\n  ):\n    ...\n\n```\n\n### Key Fields to Note\n1. **`word_count_threshold`**: - The minimum word count before a block is considered. - If your site has lots of short paragraphs or items, you can lower it.\n2. **`extraction_strategy`**: - Where you plug in JSON-based extraction (CSS, LLM, etc.). - If`None` , no structured extraction is done (only raw/cleaned HTML + markdown).\n3. **`markdown_generator`**: - E.g.,`DefaultMarkdownGenerator(...)` , controlling how HTML\u2192Markdown conversion is done. - If `None`, a default approach is used.\n4. **`cache_mode`**: - Controls caching behavior (`ENABLED` , `BYPASS`, `DISABLED`, etc.). - If `None`, defaults to some level of caching or you can specify `CacheMode.ENABLED`.\n5. **`js_code`**: - A string or list of JS strings to execute. - Great for \u201cLoad More\u201d buttons or user interactions.\n6. **`wait_for`**: - A CSS or JS expression to wait for before extracting content. - Common usage:`wait_for=\"css:.main-loaded\"` or `wait_for=\"js:() => window.loaded === true\"`.\n7. **`screenshot`** & **`pdf`**: - If`True` , captures a screenshot or PDF after the page is fully loaded. - The results go to `result.screenshot` (base64) or `result.pdf` (bytes).\n8. **`verbose`**: - Logs additional runtime details. - Overlaps with the browser\u2019s verbosity if also set to`True` in `BrowserConfig`.\n9. **`enable_rate_limiting`**: - If`True` , enables rate limiting for batch processing. - Requires `rate_limit_config` to be set.\n10. **`rate_limit_config`**: - A`RateLimitConfig` object controlling rate limiting behavior. - See below for details.\n11. **`memory_threshold_percent`**: - The memory threshold (as a percentage) to monitor. - If exceeded, the crawler will pause or slow down.\n12. **`check_interval`**: - The interval (in seconds) to check system resources. - Affects how often memory and CPU usage are monitored.\n13. **`max_session_permit`**: - The maximum number of concurrent crawl sessions. - Helps prevent overwhelming the system.\n14. **`display_mode`**: - The display mode for progress information (`DETAILED` , `BRIEF`, etc.). - Affects how much information is printed during the crawl.\n### Helper Methods\nThe `clone()` method is particularly useful for creating variations of your crawler configuration:\n```\n# Create a base configuration\nbase_config = CrawlerRunConfig(\n  cache_mode=CacheMode.ENABLED,\n  word_count_threshold=200,\n  wait_until=\"networkidle\"\n)\n# Create variations for different use cases\nstream_config = base_config.clone(\n  stream=True, # Enable streaming mode\n  cache_mode=CacheMode.BYPASS\n)\ndebug_config = base_config.clone(\n  page_timeout=120000, # Longer timeout for debugging\n  verbose=True\n)\n\n```\n\nThe `clone()` method: - Creates a new instance with all the same settings - Updates only the specified parameters - Leaves the original configuration unchanged - Perfect for creating variations without repeating all parameters\n### Rate Limiting & Resource Management\nFor batch processing with `arun_many()`, you can enable intelligent rate limiting:\n```\nfrom crawl4ai import RateLimitConfig\nconfig = CrawlerRunConfig(\n  enable_rate_limiting=True,\n  rate_limit_config=RateLimitConfig(\n    base_delay=(1.0, 3.0),  # Random delay range\n    max_delay=60.0,      # Max delay after rate limits\n    max_retries=3,      # Retries before giving up\n    rate_limit_codes=[429, 503] # Status codes to watch\n  ),\n  memory_threshold_percent=70.0, # Memory threshold\n  check_interval=1.0,      # Resource check interval\n  max_session_permit=20,     # Max concurrent crawls\n  display_mode=\"DETAILED\"    # Progress display mode\n)\n\n```\n\nThis configuration: - Implements intelligent rate limiting per domain - Monitors system resources - Provides detailed progress information - Manages concurrent crawls efficiently\n**Minimal Example** :\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\ncrawl_conf = CrawlerRunConfig(\n  js_code=\"document.querySelector('button#loadMore')?.click()\",\n  wait_for=\"css:.loaded-content\",\n  screenshot=True,\n  enable_rate_limiting=True,\n  rate_limit_config=RateLimitConfig(\n    base_delay=(1.0, 3.0),\n    max_delay=60.0,\n    max_retries=3,\n    rate_limit_codes=[429, 503]\n  ),\n  stream=True # Enable streaming\n)\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(url=\"https://example.com\", config=crawl_conf)\n  print(result.screenshot[:100]) # Base64-encoded PNG snippet\n\n```\n\n## 3. Putting It All Together\nIn a typical scenario, you define **one** `BrowserConfig` for your crawler session, then create **one or more** `CrawlerRunConfig` depending on each call\u2019s needs:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  # 1) Browser config: headless, bigger viewport, no proxy\n  browser_conf = BrowserConfig(\n    headless=True,\n    viewport_width=1280,\n    viewport_height=720\n  )\n  # 2) Example extraction strategy\n  schema = {\n    \"name\": \"Articles\",\n    \"baseSelector\": \"div.article\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  extraction = JsonCssExtractionStrategy(schema)\n  # 3) Crawler run config: skip cache, use extraction\n  run_conf = CrawlerRunConfig(\n    extraction_strategy=extraction,\n    cache_mode=CacheMode.BYPASS,\n    enable_rate_limiting=True,\n    rate_limit_config=RateLimitConfig(\n      base_delay=(1.0, 3.0),\n      max_delay=60.0,\n      max_retries=3,\n      rate_limit_codes=[429, 503]\n    )\n  )\n  async with AsyncWebCrawler(config=browser_conf) as crawler:\n    # 4) Execute the crawl\n    result = await crawler.arun(url=\"https://example.com/news\", config=run_conf)\n    if result.success:\n      print(\"Extracted content:\", result.extracted_content)\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 4. Next Steps\nFor a **detailed list** of available parameters (including advanced ones), see:\n  * [BrowserConfig and CrawlerRunConfig Reference](https://docs.crawl4ai.com/core/api/parameters/>)\n\n\nYou can explore topics like:\n  * **Custom Hooks & Auth** (Inject JavaScript or handle login forms). \n  * **Session Management** (Re-use pages, preserve state across multiple calls). \n  * **Magic Mode** or **Identity-based Crawling** (Fight bot detection by simulating user behavior). \n  * **Advanced Caching** (Fine-tune read/write cache modes). \n\n\n## 5. Conclusion\n**BrowserConfig** and **CrawlerRunConfig** give you straightforward ways to define:\n  * **Which** browser to launch, how it should run, and any proxy or user agent needs. \n  * **How** each crawl should behave\u2014caching, timeouts, JavaScript code, extraction strategies, etc.\n\n\nUse them together for **clear, maintainable** code, and when you need more specialized behavior, check out the advanced parameters in the [reference docs](https://docs.crawl4ai.com/core/api/parameters/>). Happy crawling!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 14,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:17",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "cache-modes.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/cache-modes",
      "timestamp": "2025-02-06T13:23:35.290756",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/cache-modes/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Cache Modes - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Cache Modes</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawl4ai-cache-system-and-migration-guide\">Crawl4AI Cache System and Migration Guide</a></li>\n        <li><a href=\"#overview\">Overview</a></li><li><a href=\"#old-vs-new-approach\">Old vs New Approach</a></li><li><a href=\"#migration-example\">Migration Example</a></li><li><a href=\"#common-migration-patterns\">Common Migration Patterns</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawl4ai-cache-system-and-migration-guide\">Crawl4AI Cache System and Migration Guide</h1>\n<h2 id=\"overview\">Overview</h2>\n<p>Starting from version 0.5.0, Crawl4AI introduces a new caching system that replaces the old boolean flags with a more intuitive <code>CacheMode</code> enum. This change simplifies cache control and makes the behavior more predictable.</p>\n<h2 id=\"old-vs-new-approach\">Old vs New Approach</h2>\n<h3 id=\"old-way-deprecated\">Old Way (Deprecated)</h3>\n<p>The old system used multiple boolean flags:\n- <code>bypass_cache</code>: Skip cache entirely\n- <code>disable_cache</code>: Disable all caching\n- <code>no_cache_read</code>: Don't read from cache\n- <code>no_cache_write</code>: Don't write to cache</p>\n<h3 id=\"new-way-recommended\">New Way (Recommended)</h3>\n<p>The new system uses a single <code>CacheMode</code> enum:\n- <code>CacheMode.ENABLED</code>: Normal caching (read/write)\n- <code>CacheMode.DISABLED</code>: No caching at all\n- <code>CacheMode.READ_ONLY</code>: Only read from cache\n- <code>CacheMode.WRITE_ONLY</code>: Only write to cache\n- <code>CacheMode.BYPASS</code>: Skip cache for this operation</p>\n<h2 id=\"migration-example\">Migration Example</h2>\n<h3 id=\"old-code-deprecated\">Old Code (Deprecated)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">use_proxy</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(verbose=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n            bypass_cache=<span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Old way</span>\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-built_in\">len</span>(result.markdown))\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">await</span> use_proxy()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"new-code-recommended\">New Code (Recommended)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">use_proxy</span>():\n    <span class=\"hljs-comment\"># Use CacheMode in CrawlerRunConfig</span>\n    config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)  \n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(verbose=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n            config=config  <span class=\"hljs-comment\"># Pass the configuration object</span>\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-built_in\">len</span>(result.markdown))\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">await</span> use_proxy()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h2 id=\"common-migration-patterns\">Common Migration Patterns</h2>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Old Flag</th>\n<th>New Mode</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>bypass_cache=True</code></td>\n<td><code>cache_mode=CacheMode.BYPASS</code></td>\n</tr>\n<tr>\n<td><code>disable_cache=True</code></td>\n<td><code>cache_mode=CacheMode.DISABLED</code></td>\n</tr>\n<tr>\n<td><code>no_cache_read=True</code></td>\n<td><code>cache_mode=CacheMode.WRITE_ONLY</code></td>\n</tr>\n<tr>\n<td><code>no_cache_write=True</code></td>\n<td><code>cache_mode=CacheMode.READ_ONLY</code></td>\n</tr>\n</tbody>\n</table>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Crawl4AI Cache System and Migration Guide\n## Overview\nStarting from version 0.5.0, Crawl4AI introduces a new caching system that replaces the old boolean flags with a more intuitive `CacheMode` enum. This change simplifies cache control and makes the behavior more predictable.\n## Old vs New Approach\n### Old Way (Deprecated)\nThe old system used multiple boolean flags: - `bypass_cache`: Skip cache entirely - `disable_cache`: Disable all caching - `no_cache_read`: Don't read from cache - `no_cache_write`: Don't write to cache\n### New Way (Recommended)\nThe new system uses a single `CacheMode` enum: - `CacheMode.ENABLED`: Normal caching (read/write) - `CacheMode.DISABLED`: No caching at all - `CacheMode.READ_ONLY`: Only read from cache - `CacheMode.WRITE_ONLY`: Only write to cache - `CacheMode.BYPASS`: Skip cache for this operation\n## Migration Example\n### Old Code (Deprecated)\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nasync def use_proxy():\n  async with AsyncWebCrawler(verbose=True) as crawler:\n    result = await crawler.arun(\n      url=\"https://www.nbcnews.com/business\",\n      bypass_cache=True # Old way\n    )\n    print(len(result.markdown))\nasync def main():\n  await use_proxy()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### New Code (Recommended)\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CacheMode\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def use_proxy():\n  # Use CacheMode in CrawlerRunConfig\n  config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS) \n  async with AsyncWebCrawler(verbose=True) as crawler:\n    result = await crawler.arun(\n      url=\"https://www.nbcnews.com/business\",\n      config=config # Pass the configuration object\n    )\n    print(len(result.markdown))\nasync def main():\n  await use_proxy()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## Common Migration Patterns\nOld Flag | New Mode  \n---|---  \n`bypass_cache=True` | `cache_mode=CacheMode.BYPASS`  \n`disable_cache=True` | `cache_mode=CacheMode.DISABLED`  \n`no_cache_read=True` | `cache_mode=CacheMode.WRITE_ONLY`  \n`no_cache_write=True` | `cache_mode=CacheMode.READ_ONLY`  \n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 15,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:19",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "chunking.json",
    "content": {
      "url": "https://docs.crawl4ai.com/extraction/chunking",
      "timestamp": "2025-02-06T13:23:50.127040",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/extraction/chunking/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Chunking - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Chunking</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#chunking-strategies\">Chunking Strategies</a></li>\n        <li><a href=\"#why-use-chunking\">Why Use Chunking?</a></li><li><a href=\"#methods-of-chunking\">Methods of Chunking</a></li><li><a href=\"#combining-chunking-with-cosine-similarity\">Combining Chunking with Cosine Similarity</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"chunking-strategies\">Chunking Strategies</h1>\n<p>Chunking strategies are critical for dividing large texts into manageable parts, enabling effective content processing and extraction. These strategies are foundational in cosine similarity-based extraction techniques, which allow users to retrieve only the most relevant chunks of content for a given query. Additionally, they facilitate direct integration into RAG (Retrieval-Augmented Generation) systems for structured and scalable workflows.</p>\n<h3 id=\"why-use-chunking\">Why Use Chunking?</h3>\n<p>1.\u2000<strong>Cosine Similarity and Query Relevance</strong>: Prepares chunks for semantic similarity analysis.\n2.\u2000<strong>RAG System Integration</strong>: Seamlessly processes and stores chunks for retrieval.\n3.\u2000<strong>Structured Processing</strong>: Allows for diverse segmentation methods, such as sentence-based, topic-based, or windowed approaches.</p>\n<h3 id=\"methods-of-chunking\">Methods of Chunking</h3>\n<h4 id=\"1-regex-based-chunking\">1. Regex-Based Chunking</h4>\n<p>Splits text based on regular expression patterns, useful for coarse segmentation.</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RegexChunking</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, patterns=<span class=\"hljs-literal\">None</span></span>):\n        self.patterns = patterns <span class=\"hljs-keyword\">or</span> [<span class=\"hljs-string\">r'\\n\\n'</span>]  <span class=\"hljs-comment\"># Default pattern for paragraphs</span>\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">chunk</span>(<span class=\"hljs-params\">self, text</span>):\n        paragraphs = [text]\n        <span class=\"hljs-keyword\">for</span> pattern <span class=\"hljs-keyword\">in</span> self.patterns:\n            paragraphs = [seg <span class=\"hljs-keyword\">for</span> p <span class=\"hljs-keyword\">in</span> paragraphs <span class=\"hljs-keyword\">for</span> seg <span class=\"hljs-keyword\">in</span> re.split(pattern, p)]\n        <span class=\"hljs-keyword\">return</span> paragraphs\n\n<span class=\"hljs-comment\"># Example Usage</span>\ntext = <span class=\"hljs-string\">\"\"\"This is the first paragraph.\n\nThis is the second paragraph.\"\"\"</span>\nchunker = RegexChunking()\n<span class=\"hljs-built_in\">print</span>(chunker.chunk(text))\n</code></pre></div><p></p>\n<h4 id=\"2-sentence-based-chunking\">2. Sentence-Based Chunking</h4>\n<p>Divides text into sentences using NLP tools, ideal for extracting meaningful statements.</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> sent_tokenize\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">NlpSentenceChunking</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">chunk</span>(<span class=\"hljs-params\">self, text</span>):\n        sentences = sent_tokenize(text)\n        <span class=\"hljs-keyword\">return</span> [sentence.strip() <span class=\"hljs-keyword\">for</span> sentence <span class=\"hljs-keyword\">in</span> sentences]\n\n<span class=\"hljs-comment\"># Example Usage</span>\ntext = <span class=\"hljs-string\">\"This is sentence one. This is sentence two.\"</span>\nchunker = NlpSentenceChunking()\n<span class=\"hljs-built_in\">print</span>(chunker.chunk(text))\n</code></pre></div><p></p>\n<h4 id=\"3-topic-based-segmentation\">3. Topic-Based Segmentation</h4>\n<p>Uses algorithms like TextTiling to create topic-coherent chunks.</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> nltk.tokenize <span class=\"hljs-keyword\">import</span> TextTilingTokenizer\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">TopicSegmentationChunking</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):\n        self.tokenizer = TextTilingTokenizer()\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">chunk</span>(<span class=\"hljs-params\">self, text</span>):\n        <span class=\"hljs-keyword\">return</span> self.tokenizer.tokenize(text)\n\n<span class=\"hljs-comment\"># Example Usage</span>\ntext = <span class=\"hljs-string\">\"\"\"This is an introduction.\nThis is a detailed discussion on the topic.\"\"\"</span>\nchunker = TopicSegmentationChunking()\n<span class=\"hljs-built_in\">print</span>(chunker.chunk(text))\n</code></pre></div><p></p>\n<h4 id=\"4-fixed-length-word-chunking\">4. Fixed-Length Word Chunking</h4>\n<p>Segments text into chunks of a fixed word count.</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">FixedLengthWordChunking</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, chunk_size=<span class=\"hljs-number\">100</span></span>):\n        self.chunk_size = chunk_size\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">chunk</span>(<span class=\"hljs-params\">self, text</span>):\n        words = text.split()\n        <span class=\"hljs-keyword\">return</span> [<span class=\"hljs-string\">' '</span>.join(words[i:i + self.chunk_size]) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(words), self.chunk_size)]\n\n<span class=\"hljs-comment\"># Example Usage</span>\ntext = <span class=\"hljs-string\">\"This is a long text with many words to be chunked into fixed sizes.\"</span>\nchunker = FixedLengthWordChunking(chunk_size=<span class=\"hljs-number\">5</span>)\n<span class=\"hljs-built_in\">print</span>(chunker.chunk(text))\n</code></pre></div><p></p>\n<h4 id=\"5-sliding-window-chunking\">5. Sliding Window Chunking</h4>\n<p>Generates overlapping chunks for better contextual coherence.</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SlidingWindowChunking</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, window_size=<span class=\"hljs-number\">100</span>, step=<span class=\"hljs-number\">50</span></span>):\n        self.window_size = window_size\n        self.step = step\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">chunk</span>(<span class=\"hljs-params\">self, text</span>):\n        words = text.split()\n        chunks = []\n        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(words) - self.window_size + <span class=\"hljs-number\">1</span>, self.step):\n            chunks.append(<span class=\"hljs-string\">' '</span>.join(words[i:i + self.window_size]))\n        <span class=\"hljs-keyword\">return</span> chunks\n\n<span class=\"hljs-comment\"># Example Usage</span>\ntext = <span class=\"hljs-string\">\"This is a long text to demonstrate sliding window chunking.\"</span>\nchunker = SlidingWindowChunking(window_size=<span class=\"hljs-number\">5</span>, step=<span class=\"hljs-number\">2</span>)\n<span class=\"hljs-built_in\">print</span>(chunker.chunk(text))\n</code></pre></div><p></p>\n<h3 id=\"combining-chunking-with-cosine-similarity\">Combining Chunking with Cosine Similarity</h3>\n<p>To enhance the relevance of extracted content, chunking strategies can be paired with cosine similarity techniques. Here\u2019s an example workflow:</p>\n<p><strong>Code Example</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> sklearn.feature_extraction.text <span class=\"hljs-keyword\">import</span> TfidfVectorizer\n<span class=\"hljs-keyword\">from</span> sklearn.metrics.pairwise <span class=\"hljs-keyword\">import</span> cosine_similarity\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CosineSimilarityExtractor</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, query</span>):\n        self.query = query\n        self.vectorizer = TfidfVectorizer()\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">find_relevant_chunks</span>(<span class=\"hljs-params\">self, chunks</span>):\n        vectors = self.vectorizer.fit_transform([self.query] + chunks)\n        similarities = cosine_similarity(vectors[<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">1</span>], vectors[<span class=\"hljs-number\">1</span>:]).flatten()\n        <span class=\"hljs-keyword\">return</span> [(chunks[i], similarities[i]) <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(chunks))]\n\n<span class=\"hljs-comment\"># Example Workflow</span>\ntext = <span class=\"hljs-string\">\"\"\"This is a sample document. It has multiple sentences. \nWe are testing chunking and similarity.\"\"\"</span>\n\nchunker = SlidingWindowChunking(window_size=<span class=\"hljs-number\">5</span>, step=<span class=\"hljs-number\">3</span>)\nchunks = chunker.chunk(text)\nquery = <span class=\"hljs-string\">\"testing chunking\"</span>\nextractor = CosineSimilarityExtractor(query)\nrelevant_chunks = extractor.find_relevant_chunks(chunks)\n\n<span class=\"hljs-built_in\">print</span>(relevant_chunks)\n</code></pre></div><p></p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Chunking Strategies\nChunking strategies are critical for dividing large texts into manageable parts, enabling effective content processing and extraction. These strategies are foundational in cosine similarity-based extraction techniques, which allow users to retrieve only the most relevant chunks of content for a given query. Additionally, they facilitate direct integration into RAG (Retrieval-Augmented Generation) systems for structured and scalable workflows.\n### Why Use Chunking?\n1. **Cosine Similarity and Query Relevance** : Prepares chunks for semantic similarity analysis. 2. **RAG System Integration** : Seamlessly processes and stores chunks for retrieval. 3. **Structured Processing** : Allows for diverse segmentation methods, such as sentence-based, topic-based, or windowed approaches.\n### Methods of Chunking\n#### 1. Regex-Based Chunking\nSplits text based on regular expression patterns, useful for coarse segmentation.\n**Code Example** : \n```\nclass RegexChunking:\n  def __init__(self, patterns=None):\n    self.patterns = patterns or [r'\\n\\n'] # Default pattern for paragraphs\n  def chunk(self, text):\n    paragraphs = [text]\n    for pattern in self.patterns:\n      paragraphs = [seg for p in paragraphs for seg in re.split(pattern, p)]\n    return paragraphs\n# Example Usage\ntext = \"\"\"This is the first paragraph.\nThis is the second paragraph.\"\"\"\nchunker = RegexChunking()\nprint(chunker.chunk(text))\n\n```\n\n#### 2. Sentence-Based Chunking\nDivides text into sentences using NLP tools, ideal for extracting meaningful statements.\n**Code Example** : \n```\nfrom nltk.tokenize import sent_tokenize\nclass NlpSentenceChunking:\n  def chunk(self, text):\n    sentences = sent_tokenize(text)\n    return [sentence.strip() for sentence in sentences]\n# Example Usage\ntext = \"This is sentence one. This is sentence two.\"\nchunker = NlpSentenceChunking()\nprint(chunker.chunk(text))\n\n```\n\n#### 3. Topic-Based Segmentation\nUses algorithms like TextTiling to create topic-coherent chunks.\n**Code Example** : \n```\nfrom nltk.tokenize import TextTilingTokenizer\nclass TopicSegmentationChunking:\n  def __init__(self):\n    self.tokenizer = TextTilingTokenizer()\n  def chunk(self, text):\n    return self.tokenizer.tokenize(text)\n# Example Usage\ntext = \"\"\"This is an introduction.\nThis is a detailed discussion on the topic.\"\"\"\nchunker = TopicSegmentationChunking()\nprint(chunker.chunk(text))\n\n```\n\n#### 4. Fixed-Length Word Chunking\nSegments text into chunks of a fixed word count.\n**Code Example** : \n```\nclass FixedLengthWordChunking:\n  def __init__(self, chunk_size=100):\n    self.chunk_size = chunk_size\n  def chunk(self, text):\n    words = text.split()\n    return [' '.join(words[i:i + self.chunk_size]) for i in range(0, len(words), self.chunk_size)]\n# Example Usage\ntext = \"This is a long text with many words to be chunked into fixed sizes.\"\nchunker = FixedLengthWordChunking(chunk_size=5)\nprint(chunker.chunk(text))\n\n```\n\n#### 5. Sliding Window Chunking\nGenerates overlapping chunks for better contextual coherence.\n**Code Example** : \n```\nclass SlidingWindowChunking:\n  def __init__(self, window_size=100, step=50):\n    self.window_size = window_size\n    self.step = step\n  def chunk(self, text):\n    words = text.split()\n    chunks = []\n    for i in range(0, len(words) - self.window_size + 1, self.step):\n      chunks.append(' '.join(words[i:i + self.window_size]))\n    return chunks\n# Example Usage\ntext = \"This is a long text to demonstrate sliding window chunking.\"\nchunker = SlidingWindowChunking(window_size=5, step=2)\nprint(chunker.chunk(text))\n\n```\n\n### Combining Chunking with Cosine Similarity\nTo enhance the relevance of extracted content, chunking strategies can be paired with cosine similarity techniques. Here\u2019s an example workflow:\n**Code Example** : \n```\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nclass CosineSimilarityExtractor:\n  def __init__(self, query):\n    self.query = query\n    self.vectorizer = TfidfVectorizer()\n  def find_relevant_chunks(self, chunks):\n    vectors = self.vectorizer.fit_transform([self.query] + chunks)\n    similarities = cosine_similarity(vectors[0:1], vectors[1:]).flatten()\n    return [(chunks[i], similarities[i]) for i in range(len(chunks))]\n# Example Workflow\ntext = \"\"\"This is a sample document. It has multiple sentences. \nWe are testing chunking and similarity.\"\"\"\nchunker = SlidingWindowChunking(window_size=5, step=3)\nchunks = chunker.chunk(text)\nquery = \"testing chunking\"\nextractor = CosineSimilarityExtractor(query)\nrelevant_chunks = extractor.find_relevant_chunks(chunks)\nprint(relevant_chunks)\n\n```\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/clustring-strategies",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/llm-strategies",
        "https://docs.crawl4ai.com/no-llm-strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 27,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:33",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "clustring-strategies.json",
    "content": {
      "url": "https://docs.crawl4ai.com/extraction/clustring-strategies",
      "timestamp": "2025-02-06T13:23:51.301875",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/extraction/clustring-strategies/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Clustering Strategies - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Clustering Strategies</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#cosine-strategy\">Cosine Strategy</a></li>\n        <li><a href=\"#how-it-works\">How It Works</a></li><li><a href=\"#basic-usage\">Basic Usage</a></li><li><a href=\"#configuration-options\">Configuration Options</a></li><li><a href=\"#use-cases\">Use Cases</a></li><li><a href=\"#advanced-features\">Advanced Features</a></li><li><a href=\"#best-practices\">Best Practices</a></li><li><a href=\"#error-handling\">Error Handling</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"cosine-strategy\">Cosine Strategy</h1>\n<p>The Cosine Strategy in Crawl4AI uses similarity-based clustering to identify and extract relevant content sections from web pages. This strategy is particularly useful when you need to find and extract content based on semantic similarity rather than structural patterns.</p>\n<h2 id=\"how-it-works\">How It Works</h2>\n<p>The Cosine Strategy:\n1. Breaks down page content into meaningful chunks\n2. Converts text into vector representations\n3. Calculates similarity between chunks\n4. Clusters similar content together\n5. Ranks and filters content based on relevance</p>\n<h2 id=\"basic-usage\">Basic Usage</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy import CosineStrategy\n\nstrategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"product reviews\"</span>,    <span class=\"hljs-meta\"># Target content type</span>\n    word_count_threshold=<span class=\"hljs-number\">10</span>,             <span class=\"hljs-meta\"># Minimum words per cluster</span>\n    sim_threshold=<span class=\"hljs-number\">0.3</span>                    <span class=\"hljs-meta\"># Similarity threshold</span>\n)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>() <span class=\"hljs-keyword\">as</span> crawler:\n    result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(\n        url=<span class=\"hljs-string\">\"https://example.com/reviews\"</span>,\n        extraction_strategy=strategy\n    )\n\n    content = result.extracted_content\n</code></pre></div>\n<h2 id=\"configuration-options\">Configuration Options</h2>\n<h3 id=\"core-parameters\">Core Parameters</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">CosineStrategy(\n    <span class=\"hljs-comment\"># Content Filtering</span>\n    semantic_filter: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-literal\">None</span>,       <span class=\"hljs-comment\"># Keywords/topic for content filtering</span>\n    word_count_threshold: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">10</span>,    <span class=\"hljs-comment\"># Minimum words per cluster</span>\n    sim_threshold: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.3</span>,        <span class=\"hljs-comment\"># Similarity threshold (0.0 to 1.0)</span>\n\n    <span class=\"hljs-comment\"># Clustering Parameters</span>\n    max_dist: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.2</span>,            <span class=\"hljs-comment\"># Maximum distance for clustering</span>\n    linkage_method: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">'ward'</span>,      <span class=\"hljs-comment\"># Clustering linkage method</span>\n    top_k: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">3</span>,                   <span class=\"hljs-comment\"># Number of top categories to extract</span>\n\n    <span class=\"hljs-comment\"># Model Configuration</span>\n    model_name: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">'sentence-transformers/all-MiniLM-L6-v2'</span>,  <span class=\"hljs-comment\"># Embedding model</span>\n\n    verbose: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>             <span class=\"hljs-comment\"># Enable logging</span>\n)\n</code></pre></div>\n<h3 id=\"parameter-details\">Parameter Details</h3>\n<p>1.\u2000<strong>semantic_filter</strong>\n   - Sets the target topic or content type\n   - Use keywords relevant to your desired content\n   - Example: \"technical specifications\", \"user reviews\", \"pricing information\"</p>\n<p>2.\u2000<strong>sim_threshold</strong>\n   - Controls how similar content must be to be grouped together\n   - Higher values (e.g., 0.8) mean stricter matching\n   - Lower values (e.g., 0.3) allow more variation\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-comment\"># Strict matching</span>\n<span class=\"hljs-attr\">strategy</span> = CosineStrategy(sim_threshold=<span class=\"hljs-number\">0.8</span>)\n\n<span class=\"hljs-comment\"># Loose matching</span>\n<span class=\"hljs-attr\">strategy</span> = CosineStrategy(sim_threshold=<span class=\"hljs-number\">0.3</span>)\n</code></pre></div><p></p>\n<p>3.\u2000<strong>word_count_threshold</strong>\n   - Filters out short content blocks\n   - Helps eliminate noise and irrelevant content\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-comment\"># Only consider substantial paragraphs</span>\n<span class=\"hljs-attr\">strategy</span> = CosineStrategy(word_count_threshold=<span class=\"hljs-number\">50</span>)\n</code></pre></div><p></p>\n<p>4.\u2000<strong>top_k</strong>\n   - Number of top content clusters to return\n   - Higher values return more diverse content\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-comment\"># Get top 5 most relevant content clusters</span>\n<span class=\"hljs-attr\">strategy</span> = CosineStrategy(top_k=<span class=\"hljs-number\">5</span>)\n</code></pre></div><p></p>\n<h2 id=\"use-cases\">Use Cases</h2>\n<h3 id=\"1-article-content-extraction\">1. Article Content Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">strategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"main article content\"</span>,\n    word_count_threshold=100,  <span class=\"hljs-comment\"># Longer blocks for articles</span>\n    top_k=1                   <span class=\"hljs-comment\"># Usually want single main content</span>\n)\n\nresult = await crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com/blog/post\"</span>,\n    extraction_strategy=strategy\n)\n</code></pre></div>\n<h3 id=\"2-product-review-analysis\">2. Product Review Analysis</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">strategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"customer reviews and ratings\"</span>,\n    word_count_threshold=20,   <span class=\"hljs-comment\"># Reviews can be shorter</span>\n    top_k=10,                 <span class=\"hljs-comment\"># Get multiple reviews</span>\n    sim_threshold=0.4         <span class=\"hljs-comment\"># Allow variety in review content</span>\n)\n</code></pre></div>\n<h3 id=\"3-technical-documentation\">3. Technical Documentation</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">strategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"technical specifications documentation\"</span>,\n    word_count_threshold=30,\n    sim_threshold=0.6,        <span class=\"hljs-comment\"># Stricter matching for technical content</span>\n    max_dist=0.3             <span class=\"hljs-comment\"># Allow related technical sections</span>\n)\n</code></pre></div>\n<h2 id=\"advanced-features\">Advanced Features</h2>\n<h3 id=\"custom-clustering\">Custom Clustering</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">strategy = CosineStrategy(\n    linkage_method=<span class=\"hljs-string\">'complete'</span>,  <span class=\"hljs-comment\"># Alternative clustering method</span>\n    max_dist=0.4,              <span class=\"hljs-comment\"># Larger clusters</span>\n    model_name=<span class=\"hljs-string\">'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'</span>  <span class=\"hljs-comment\"># Multilingual support</span>\n)\n</code></pre></div>\n<h3 id=\"content-filtering-pipeline\">Content Filtering Pipeline</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">strategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"pricing plans features\"</span>,\n    word_count_threshold=<span class=\"hljs-number\">15</span>,\n    sim_threshold=<span class=\"hljs-number\">0.5</span>,\n    top_k=<span class=\"hljs-number\">3</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_pricing_features</span>(<span class=\"hljs-params\">url: <span class=\"hljs-built_in\">str</span></span>):\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=url,\n            extraction_strategy=strategy\n        )\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            content = json.loads(result.extracted_content)\n            <span class=\"hljs-keyword\">return</span> {\n                <span class=\"hljs-string\">'pricing_features'</span>: content,\n                <span class=\"hljs-string\">'clusters'</span>: <span class=\"hljs-built_in\">len</span>(content),\n                <span class=\"hljs-string\">'similarity_scores'</span>: [item[<span class=\"hljs-string\">'score'</span>] <span class=\"hljs-keyword\">for</span> item <span class=\"hljs-keyword\">in</span> content]\n            }\n</code></pre></div>\n<h2 id=\"best-practices\">Best Practices</h2>\n<p>1.\u2000<strong>Adjust Thresholds Iteratively</strong>\n   - Start with default values\n   - Adjust based on results\n   - Monitor clustering quality</p>\n<p>2.\u2000<strong>Choose Appropriate Word Count Thresholds</strong>\n   - Higher for articles (100+)\n   - Lower for reviews/comments (20+)\n   - Medium for product descriptions (50+)</p>\n<p>3.\u2000<strong>Optimize Performance</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">strategy <span class=\"hljs-punctuation\">=</span> CosineStrategy<span class=\"hljs-punctuation\">(</span>\n    word_count_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">10</span>,  <span class=\"hljs-comment\"># Filter early</span>\n    top_k<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">5</span>,                 <span class=\"hljs-comment\"># Limit results</span>\n    verbose<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>             <span class=\"hljs-comment\"># Monitor performance</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div><p></p>\n<p>4.\u2000<strong>Handle Different Content Types</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\"><span class=\"hljs-comment\"># For mixed content pages</span>\nstrategy = CosineStrategy(\n    semantic_filter=<span class=\"hljs-string\">\"product features\"</span>,\n    sim_threshold=0.4,      <span class=\"hljs-comment\"># More flexible matching</span>\n    max_dist=0.3,          <span class=\"hljs-comment\"># Larger clusters</span>\n    top_k=3                <span class=\"hljs-comment\"># Multiple relevant sections</span>\n)\n</code></pre></div><p></p>\n<h2 id=\"error-handling\">Error Handling</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">try</span>:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n        url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n        extraction_strategy=strategy\n    )\n\n    <span class=\"hljs-keyword\">if</span> result.success:\n        content = json.loads(result.extracted_content)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> content:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"No relevant content found\"</span>)\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Extraction failed: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\n<span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Error during extraction: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">str</span>(e)}</span>\"</span>)\n</code></pre></div>\n<p>The Cosine Strategy is particularly effective when:\n- Content structure is inconsistent\n- You need semantic understanding\n- You want to find similar content blocks\n- Structure-based extraction (CSS/XPath) isn't reliable</p>\n<p>It works well with other strategies and can be used as a pre-processing step for LLM-based extraction.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Cosine Strategy\nThe Cosine Strategy in Crawl4AI uses similarity-based clustering to identify and extract relevant content sections from web pages. This strategy is particularly useful when you need to find and extract content based on semantic similarity rather than structural patterns.\n## How It Works\nThe Cosine Strategy: 1. Breaks down page content into meaningful chunks 2. Converts text into vector representations 3. Calculates similarity between chunks 4. Clusters similar content together 5. Ranks and filters content based on relevance\n## Basic Usage\n```\nfrom crawl4ai.extraction_strategy import CosineStrategy\nstrategy = CosineStrategy(\n  semantic_filter=\"product reviews\",  # Target content type\n  word_count_threshold=10,       # Minimum words per cluster\n  sim_threshold=0.3          # Similarity threshold\n)\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(\n    url=\"https://example.com/reviews\",\n    extraction_strategy=strategy\n  )\n  content = result.extracted_content\n\n```\n\n## Configuration Options\n### Core Parameters\n```\nCosineStrategy(\n  # Content Filtering\n  semantic_filter: str = None,    # Keywords/topic for content filtering\n  word_count_threshold: int = 10,  # Minimum words per cluster\n  sim_threshold: float = 0.3,    # Similarity threshold (0.0 to 1.0)\n  # Clustering Parameters\n  max_dist: float = 0.2,      # Maximum distance for clustering\n  linkage_method: str = 'ward',   # Clustering linkage method\n  top_k: int = 3,          # Number of top categories to extract\n  # Model Configuration\n  model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', # Embedding model\n  verbose: bool = False       # Enable logging\n)\n\n```\n\n### Parameter Details\n1. **semantic_filter** - Sets the target topic or content type - Use keywords relevant to your desired content - Example: \"technical specifications\", \"user reviews\", \"pricing information\"\n2. **sim_threshold** - Controls how similar content must be to be grouped together - Higher values (e.g., 0.8) mean stricter matching - Lower values (e.g., 0.3) allow more variation \n```\n# Strict matching\nstrategy = CosineStrategy(sim_threshold=0.8)\n# Loose matching\nstrategy = CosineStrategy(sim_threshold=0.3)\n\n```\n\n3. **word_count_threshold** - Filters out short content blocks - Helps eliminate noise and irrelevant content \n```\n# Only consider substantial paragraphs\nstrategy = CosineStrategy(word_count_threshold=50)\n\n```\n\n4. **top_k** - Number of top content clusters to return - Higher values return more diverse content \n```\n# Get top 5 most relevant content clusters\nstrategy = CosineStrategy(top_k=5)\n\n```\n\n## Use Cases\n### 1. Article Content Extraction\n```\nstrategy = CosineStrategy(\n  semantic_filter=\"main article content\",\n  word_count_threshold=100, # Longer blocks for articles\n  top_k=1          # Usually want single main content\n)\nresult = await crawler.arun(\n  url=\"https://example.com/blog/post\",\n  extraction_strategy=strategy\n)\n\n```\n\n### 2. Product Review Analysis\n```\nstrategy = CosineStrategy(\n  semantic_filter=\"customer reviews and ratings\",\n  word_count_threshold=20,  # Reviews can be shorter\n  top_k=10,         # Get multiple reviews\n  sim_threshold=0.4     # Allow variety in review content\n)\n\n```\n\n### 3. Technical Documentation\n```\nstrategy = CosineStrategy(\n  semantic_filter=\"technical specifications documentation\",\n  word_count_threshold=30,\n  sim_threshold=0.6,    # Stricter matching for technical content\n  max_dist=0.3       # Allow related technical sections\n)\n\n```\n\n## Advanced Features\n### Custom Clustering\n```\nstrategy = CosineStrategy(\n  linkage_method='complete', # Alternative clustering method\n  max_dist=0.4,       # Larger clusters\n  model_name='sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2' # Multilingual support\n)\n\n```\n\n### Content Filtering Pipeline\n```\nstrategy = CosineStrategy(\n  semantic_filter=\"pricing plans features\",\n  word_count_threshold=15,\n  sim_threshold=0.5,\n  top_k=3\n)\nasync def extract_pricing_features(url: str):\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=url,\n      extraction_strategy=strategy\n    )\n    if result.success:\n      content = json.loads(result.extracted_content)\n      return {\n        'pricing_features': content,\n        'clusters': len(content),\n        'similarity_scores': [item['score'] for item in content]\n      }\n\n```\n\n## Best Practices\n1. **Adjust Thresholds Iteratively** - Start with default values - Adjust based on results - Monitor clustering quality\n2. **Choose Appropriate Word Count Thresholds** - Higher for articles (100+) - Lower for reviews/comments (20+) - Medium for product descriptions (50+)\n3. **Optimize Performance**\n```\nstrategy = CosineStrategy(\n  word_count_threshold=10, # Filter early\n  top_k=5,         # Limit results\n  verbose=True       # Monitor performance\n)\n\n```\n\n4. **Handle Different Content Types**\n```\n# For mixed content pages\nstrategy = CosineStrategy(\n  semantic_filter=\"product features\",\n  sim_threshold=0.4,   # More flexible matching\n  max_dist=0.3,     # Larger clusters\n  top_k=3        # Multiple relevant sections\n)\n\n```\n\n## Error Handling\n```\ntry:\n  result = await crawler.arun(\n    url=\"https://example.com\",\n    extraction_strategy=strategy\n  )\n  if result.success:\n    content = json.loads(result.extracted_content)\n    if not content:\n      print(\"No relevant content found\")\n  else:\n    print(f\"Extraction failed: {result.error_message}\")\nexcept Exception as e:\n  print(f\"Error during extraction: {str(e)}\")\n\n```\n\nThe Cosine Strategy is particularly effective when: - Content structure is inconsistent - You need semantic understanding - You want to find similar content blocks - Structure-based extraction (CSS/XPath) isn't reliable\nIt works well with other strategies and can be used as a pre-processing step for LLM-based extraction.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/chunking",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/llm-strategies",
        "https://docs.crawl4ai.com/no-llm-strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 28,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:35",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "content-selection.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/content-selection",
      "timestamp": "2025-02-06T13:23:36.609656",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/content-selection/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Content Selection - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Content Selection</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#content-selection\">Content Selection</a></li>\n        <li><a href=\"#1-css-based-selection\">1. CSS-Based Selection</a></li><li><a href=\"#2-content-filtering-exclusions\">2. Content Filtering &amp; Exclusions</a></li><li><a href=\"#3-handling-iframes\">3. Handling Iframes</a></li><li><a href=\"#4-structured-extraction-examples\">4. Structured Extraction Examples</a></li><li><a href=\"#5-comprehensive-example\">5. Comprehensive Example</a></li><li><a href=\"#6-scraping-modes\">6. Scraping Modes</a></li><li><a href=\"#7-conclusion\">7. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"content-selection\">Content Selection</h1>\n<p>Crawl4AI provides multiple ways to <strong>select</strong>, <strong>filter</strong>, and <strong>refine</strong> the content from your crawls. Whether you need to target a specific CSS region, exclude entire tags, filter out external links, or remove certain domains and images, <strong><code>CrawlerRunConfig</code></strong> offers a wide range of parameters.</p>\n<p>Below, we show how to configure these parameters and combine them for precise control.</p>\n<hr>\n<h2 id=\"1-css-based-selection\">1. CSS-Based Selection</h2>\n<p>A straightforward way to <strong>limit</strong> your crawl results to a certain region of the page is <strong><code>css_selector</code></strong> in <strong><code>CrawlerRunConfig</code></strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># e.g., first 30 items from Hacker News</span>\n        css_selector=<span class=\"hljs-string\">\".athing:nth-child(-n+30)\"</span>  \n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com/newest\"</span>, \n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Partial HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Result</strong>: Only elements matching that selector remain in <code>result.cleaned_html</code>.</p>\n<hr>\n<h2 id=\"2-content-filtering-exclusions\">2. Content Filtering &amp; Exclusions</h2>\n<h3 id=\"21-basic-overview\">2.1 Basic Overview</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">config = CrawlerRunConfig(\n    <span class=\"hljs-comment\"># Content thresholds</span>\n    word_count_threshold=<span class=\"hljs-number\">10</span>,        <span class=\"hljs-comment\"># Minimum words per block</span>\n\n    <span class=\"hljs-comment\"># Tag exclusions</span>\n    excluded_tags=[<span class=\"hljs-string\">'form'</span>, <span class=\"hljs-string\">'header'</span>, <span class=\"hljs-string\">'footer'</span>, <span class=\"hljs-string\">'nav'</span>],\n\n    <span class=\"hljs-comment\"># Link filtering</span>\n    exclude_external_links=<span class=\"hljs-literal\">True</span>,    \n    exclude_social_media_links=<span class=\"hljs-literal\">True</span>,\n    <span class=\"hljs-comment\"># Block entire domains</span>\n    exclude_domains=[<span class=\"hljs-string\">\"adtrackers.com\"</span>, <span class=\"hljs-string\">\"spammynews.org\"</span>],    \n    exclude_social_media_domains=[<span class=\"hljs-string\">\"facebook.com\"</span>, <span class=\"hljs-string\">\"twitter.com\"</span>],\n\n    <span class=\"hljs-comment\"># Media filtering</span>\n    exclude_external_images=<span class=\"hljs-literal\">True</span>\n)\n</code></pre></div>\n<p><strong>Explanation</strong>:</p>\n<ul>\n<li><strong><code>word_count_threshold</code></strong>: Ignores text blocks under X words. Helps skip trivial blocks like short nav or disclaimers.  </li>\n<li><strong><code>excluded_tags</code></strong>: Removes entire tags (<code>&lt;form&gt;</code>, <code>&lt;header&gt;</code>, <code>&lt;footer&gt;</code>, etc.).  </li>\n<li><strong>Link Filtering</strong>:  </li>\n<li><code>exclude_external_links</code>: Strips out external links and may remove them from <code>result.links</code>.  </li>\n<li><code>exclude_social_media_links</code>: Removes links pointing to known social media domains.  </li>\n<li><code>exclude_domains</code>: A custom list of domains to block if discovered in links.  </li>\n<li><code>exclude_social_media_domains</code>: A curated list (override or add to it) for social media sites.  </li>\n<li><strong>Media Filtering</strong>:  </li>\n<li><code>exclude_external_images</code>: Discards images not hosted on the same domain as the main page (or its subdomains).</li>\n</ul>\n<p>By default in case you set <code>exclude_social_media_links=True</code>, the following social media domains are excluded:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">[\n    <span class=\"hljs-string\">'facebook.com'</span>,\n    <span class=\"hljs-string\">'twitter.com'</span>,\n    <span class=\"hljs-string\">'x.com'</span>,\n    <span class=\"hljs-string\">'linkedin.com'</span>,\n    <span class=\"hljs-string\">'instagram.com'</span>,\n    <span class=\"hljs-string\">'pinterest.com'</span>,\n    <span class=\"hljs-string\">'tiktok.com'</span>,\n    <span class=\"hljs-string\">'snapchat.com'</span>,\n    <span class=\"hljs-string\">'reddit.com'</span>,\n]\n</code></pre></div><p></p>\n<h3 id=\"22-example-usage\">2.2 Example Usage</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        css_selector=<span class=\"hljs-string\">\"main.content\"</span>, \n        word_count_threshold=<span class=\"hljs-number\">10</span>,\n        excluded_tags=[<span class=\"hljs-string\">\"nav\"</span>, <span class=\"hljs-string\">\"footer\"</span>],\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        exclude_social_media_links=<span class=\"hljs-literal\">True</span>,\n        exclude_domains=[<span class=\"hljs-string\">\"ads.com\"</span>, <span class=\"hljs-string\">\"spammytrackers.net\"</span>],\n        exclude_external_images=<span class=\"hljs-literal\">True</span>,\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>, config=config)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Cleaned HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Note</strong>: If these parameters remove too much, reduce or disable them accordingly.</p>\n<hr>\n<h2 id=\"3-handling-iframes\">3. Handling Iframes</h2>\n<p>Some sites embed content in <code>&lt;iframe&gt;</code> tags. If you want that inline:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-sql\">config <span class=\"hljs-operator\">=</span> CrawlerRunConfig(\n    # <span class=\"hljs-keyword\">Merge</span> iframe content <span class=\"hljs-keyword\">into</span> the <span class=\"hljs-keyword\">final</span> output\n    process_iframes<span class=\"hljs-operator\">=</span><span class=\"hljs-literal\">True</span>,    \n    remove_overlay_elements<span class=\"hljs-operator\">=</span><span class=\"hljs-literal\">True</span>\n)\n</code></pre></div><p></p>\n<p><strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        process_iframes=<span class=\"hljs-literal\">True</span>,\n        remove_overlay_elements=<span class=\"hljs-literal\">True</span>\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.org/iframe-demo\"</span>, \n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Iframe-merged length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div><p></p>\n<hr>\n<h2 id=\"4-structured-extraction-examples\">4. Structured Extraction Examples</h2>\n<p>You can combine content selection with a more advanced extraction strategy. For instance, a <strong>CSS-based</strong> or <strong>LLM-based</strong> extraction strategy can run on the filtered HTML.</p>\n<h3 id=\"41-pattern-based-with-jsoncssextractionstrategy\">4.1 Pattern-Based with <code>JsonCssExtractionStrategy</code></h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Minimal schema for repeated items</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"News Items\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"tr.athing\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a.storylink\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, \n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a.storylink\"</span>, \n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, \n                <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>\n            }\n        ]\n    }\n\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Content filtering</span>\n        excluded_tags=[<span class=\"hljs-string\">\"form\"</span>, <span class=\"hljs-string\">\"header\"</span>],\n        exclude_domains=[<span class=\"hljs-string\">\"adsite.com\"</span>],\n\n        <span class=\"hljs-comment\"># CSS selection or entire page</span>\n        css_selector=<span class=\"hljs-string\">\"table.itemlist\"</span>,\n\n        <span class=\"hljs-comment\"># No caching for demonstration</span>\n        cache_mode=CacheMode.BYPASS,\n\n        <span class=\"hljs-comment\"># Extraction strategy</span>\n        extraction_strategy=JsonCssExtractionStrategy(schema)\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com/newest\"</span>, \n            config=config\n        )\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Sample extracted item:\"</span>, data[:<span class=\"hljs-number\">1</span>])  <span class=\"hljs-comment\"># Show first item</span>\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"42-llm-based-extraction\">4.2 LLM-Based Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> pydantic <span class=\"hljs-keyword\">import</span> BaseModel, Field\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> LLMExtractionStrategy\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ArticleData</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    headline: <span class=\"hljs-built_in\">str</span>\n    summary: <span class=\"hljs-built_in\">str</span>\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    llm_strategy = LLMExtractionStrategy(\n        provider=<span class=\"hljs-string\">\"openai/gpt-4\"</span>,\n        api_token=<span class=\"hljs-string\">\"sk-YOUR_API_KEY\"</span>,\n        schema=ArticleData.schema(),\n        extraction_type=<span class=\"hljs-string\">\"schema\"</span>,\n        instruction=<span class=\"hljs-string\">\"Extract 'headline' and a short 'summary' from the content.\"</span>\n    )\n\n    config = CrawlerRunConfig(\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        word_count_threshold=<span class=\"hljs-number\">20</span>,\n        extraction_strategy=llm_strategy\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>, config=config)\n        article = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(article)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p>Here, the crawler:</p>\n<ul>\n<li>Filters out external links (<code>exclude_external_links=True</code>).  </li>\n<li>Ignores very short text blocks (<code>word_count_threshold=20</code>).  </li>\n<li>Passes the final HTML to your LLM strategy for an AI-driven parse.</li>\n</ul>\n<hr>\n<h2 id=\"5-comprehensive-example\">5. Comprehensive Example</h2>\n<p>Below is a short function that unifies <strong>CSS selection</strong>, <strong>exclusion</strong> logic, and a pattern-based extraction, demonstrating how you can fine-tune your final data:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_main_articles</span>(<span class=\"hljs-params\">url: <span class=\"hljs-built_in\">str</span></span>):\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"ArticleBlock\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.article-block\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"headline\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"summary\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".summary\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"metadata\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"nested\"</span>,\n                <span class=\"hljs-string\">\"fields\"</span>: [\n                    {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"author\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".author\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n                    {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"date\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".date\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>}\n                ]\n            }\n        ]\n    }\n\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Keep only #main-content</span>\n        css_selector=<span class=\"hljs-string\">\"#main-content\"</span>,\n\n        <span class=\"hljs-comment\"># Filtering</span>\n        word_count_threshold=<span class=\"hljs-number\">10</span>,\n        excluded_tags=[<span class=\"hljs-string\">\"nav\"</span>, <span class=\"hljs-string\">\"footer\"</span>],  \n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        exclude_domains=[<span class=\"hljs-string\">\"somebadsite.com\"</span>],\n        exclude_external_images=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Extraction</span>\n        extraction_strategy=JsonCssExtractionStrategy(schema),\n\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=url, config=config)\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Error: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-literal\">None</span>\n        <span class=\"hljs-keyword\">return</span> json.loads(result.extracted_content)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    articles = <span class=\"hljs-keyword\">await</span> extract_main_articles(<span class=\"hljs-string\">\"https://news.ycombinator.com/newest\"</span>)\n    <span class=\"hljs-keyword\">if</span> articles:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extracted Articles:\"</span>, articles[:<span class=\"hljs-number\">2</span>])  <span class=\"hljs-comment\"># Show first 2</span>\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Why This Works</strong>:\n- <strong>CSS</strong> scoping with <code>#main-content</code>.<br>\n- Multiple <strong>exclude_</strong> parameters to remove domains, external images, etc.<br>\n- A <strong>JsonCssExtractionStrategy</strong> to parse repeated article blocks.</p>\n<hr>\n<h2 id=\"6-scraping-modes\">6. Scraping Modes</h2>\n<p>Crawl4AI provides two different scraping strategies for HTML content processing: <code>WebScrapingStrategy</code> (BeautifulSoup-based, default) and <code>LXMLWebScrapingStrategy</code> (LXML-based). The LXML strategy offers significantly better performance, especially for large HTML documents.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai import AsyncWebCrawler, CrawlerRunConfig, <span class=\"hljs-function\">LXMLWebScrapingStrategy\n\n<span class=\"hljs-keyword\">async</span> def <span class=\"hljs-title\">main</span>():\n    config</span> = CrawlerRunConfig(\n        scraping_strategy=LXMLWebScrapingStrategy()  <span class=\"hljs-meta\"># Faster alternative to default BeautifulSoup</span>\n    )\n    <span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>() <span class=\"hljs-keyword\">as</span> crawler:\n        result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com\"</span>, \n            config=config\n        )\n</code></pre></div>\n<p>You can also create your own custom scraping strategy by inheriting from <code>ContentScrapingStrategy</code>. The strategy must return a <code>ScrapingResult</code> object with the following structure:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> ContentScrapingStrategy, ScrapingResult, MediaItem, Media, Link, Links\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CustomScrapingStrategy</span>(<span class=\"hljs-title class_ inherited__\">ContentScrapingStrategy</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">scrap</span>(<span class=\"hljs-params\">self, url: <span class=\"hljs-built_in\">str</span>, html: <span class=\"hljs-built_in\">str</span>, **kwargs</span>) -&gt; ScrapingResult:\n        <span class=\"hljs-comment\"># Implement your custom scraping logic here</span>\n        <span class=\"hljs-keyword\">return</span> ScrapingResult(\n            cleaned_html=<span class=\"hljs-string\">\"&lt;html&gt;...&lt;/html&gt;\"</span>,  <span class=\"hljs-comment\"># Cleaned HTML content</span>\n            success=<span class=\"hljs-literal\">True</span>,                     <span class=\"hljs-comment\"># Whether scraping was successful</span>\n            media=Media(\n                images=[                      <span class=\"hljs-comment\"># List of images found</span>\n                    MediaItem(\n                        src=<span class=\"hljs-string\">\"https://example.com/image.jpg\"</span>,\n                        alt=<span class=\"hljs-string\">\"Image description\"</span>,\n                        desc=<span class=\"hljs-string\">\"Surrounding text\"</span>,\n                        score=<span class=\"hljs-number\">1</span>,\n                        <span class=\"hljs-built_in\">type</span>=<span class=\"hljs-string\">\"image\"</span>,\n                        group_id=<span class=\"hljs-number\">1</span>,\n                        <span class=\"hljs-built_in\">format</span>=<span class=\"hljs-string\">\"jpg\"</span>,\n                        width=<span class=\"hljs-number\">800</span>\n                    )\n                ],\n                videos=[],                    <span class=\"hljs-comment\"># List of videos (same structure as images)</span>\n                audios=[]                     <span class=\"hljs-comment\"># List of audio files (same structure as images)</span>\n            ),\n            links=Links(\n                internal=[                    <span class=\"hljs-comment\"># List of internal links</span>\n                    Link(\n                        href=<span class=\"hljs-string\">\"https://example.com/page\"</span>,\n                        text=<span class=\"hljs-string\">\"Link text\"</span>,\n                        title=<span class=\"hljs-string\">\"Link title\"</span>,\n                        base_domain=<span class=\"hljs-string\">\"example.com\"</span>\n                    )\n                ],\n                external=[]                   <span class=\"hljs-comment\"># List of external links (same structure)</span>\n            ),\n            metadata={                        <span class=\"hljs-comment\"># Additional metadata</span>\n                <span class=\"hljs-string\">\"title\"</span>: <span class=\"hljs-string\">\"Page Title\"</span>,\n                <span class=\"hljs-string\">\"description\"</span>: <span class=\"hljs-string\">\"Page description\"</span>\n            }\n        )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">ascrap</span>(<span class=\"hljs-params\">self, url: <span class=\"hljs-built_in\">str</span>, html: <span class=\"hljs-built_in\">str</span>, **kwargs</span>) -&gt; ScrapingResult:\n        <span class=\"hljs-comment\"># For simple cases, you can use the sync version</span>\n        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">await</span> asyncio.to_thread(self.scrap, url, html, **kwargs)\n</code></pre></div>\n<h3 id=\"performance-considerations\">Performance Considerations</h3>\n<p>The LXML strategy can be up to 10-20x faster than BeautifulSoup strategy, particularly when processing large HTML documents. However, please note:</p>\n<ol>\n<li>LXML strategy is currently experimental</li>\n<li>In some edge cases, the parsing results might differ slightly from BeautifulSoup</li>\n<li>If you encounter any inconsistencies between LXML and BeautifulSoup results, please <a href=\"https://github.com/codeium/crawl4ai/issues\">raise an issue</a> with a reproducible example</li>\n</ol>\n<p>Choose LXML strategy when:\n- Processing large HTML documents (recommended for &gt;100KB)\n- Performance is critical\n- Working with well-formed HTML</p>\n<p>Stick to BeautifulSoup strategy (default) when:\n- Maximum compatibility is needed\n- Working with malformed HTML\n- Exact parsing behavior is critical</p>\n<hr>\n<h2 id=\"7-conclusion\">7. Conclusion</h2>\n<p>By mixing <strong>css_selector</strong> scoping, <strong>content filtering</strong> parameters, and advanced <strong>extraction strategies</strong>, you can precisely <strong>choose</strong> which data to keep. Key parameters in <strong><code>CrawlerRunConfig</code></strong> for content selection include:</p>\n<p>1.\u2000<strong><code>css_selector</code></strong> \u2013 Basic scoping to an element or region.<br>\n2.\u2000<strong><code>word_count_threshold</code></strong> \u2013 Skip short blocks.<br>\n3.\u2000<strong><code>excluded_tags</code></strong> \u2013 Remove entire HTML tags.<br>\n4.\u2000<strong><code>exclude_external_links</code></strong>, <strong><code>exclude_social_media_links</code></strong>, <strong><code>exclude_domains</code></strong> \u2013 Filter out unwanted links or domains.<br>\n5.\u2000<strong><code>exclude_external_images</code></strong> \u2013 Remove images from external sources.<br>\n6.\u2000<strong><code>process_iframes</code></strong> \u2013 Merge iframe content if needed.  </p>\n<p>Combine these with structured extraction (CSS, LLM-based, or others) to build powerful crawls that yield exactly the content you want, from raw or cleaned HTML up to sophisticated JSON structures. For more detail, see <a href=\"../../api/parameters/\">Configuration Reference</a>. Enjoy curating your data to the max!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Content Selection\nCrawl4AI provides multiple ways to **select** , **filter** , and **refine** the content from your crawls. Whether you need to target a specific CSS region, exclude entire tags, filter out external links, or remove certain domains and images, **`CrawlerRunConfig`**offers a wide range of parameters.\nBelow, we show how to configure these parameters and combine them for precise control.\n## 1. CSS-Based Selection\nA straightforward way to **limit** your crawl results to a certain region of the page is **`css_selector`**in**`CrawlerRunConfig`**:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  config = CrawlerRunConfig(\n    # e.g., first 30 items from Hacker News\n    css_selector=\".athing:nth-child(-n+30)\" \n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com/newest\", \n      config=config\n    )\n    print(\"Partial HTML length:\", len(result.cleaned_html))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Result** : Only elements matching that selector remain in `result.cleaned_html`.\n## 2. Content Filtering & Exclusions\n### 2.1 Basic Overview\n```\nconfig = CrawlerRunConfig(\n  # Content thresholds\n  word_count_threshold=10,    # Minimum words per block\n  # Tag exclusions\n  excluded_tags=['form', 'header', 'footer', 'nav'],\n  # Link filtering\n  exclude_external_links=True,  \n  exclude_social_media_links=True,\n  # Block entire domains\n  exclude_domains=[\"adtrackers.com\", \"spammynews.org\"],  \n  exclude_social_media_domains=[\"facebook.com\", \"twitter.com\"],\n  # Media filtering\n  exclude_external_images=True\n)\n\n```\n\n**Explanation** :\n  * **`word_count_threshold`**: Ignores text blocks under X words. Helps skip trivial blocks like short nav or disclaimers.\n  * **`excluded_tags`**: Removes entire tags (`<form>` , `<header>`, `<footer>`, etc.). \n  * **Link Filtering** : \n  * `exclude_external_links`: Strips out external links and may remove them from `result.links`. \n  * `exclude_social_media_links`: Removes links pointing to known social media domains. \n  * `exclude_domains`: A custom list of domains to block if discovered in links. \n  * `exclude_social_media_domains`: A curated list (override or add to it) for social media sites. \n  * **Media Filtering** : \n  * `exclude_external_images`: Discards images not hosted on the same domain as the main page (or its subdomains).\n\n\nBy default in case you set `exclude_social_media_links=True`, the following social media domains are excluded: \n```\n[\n  'facebook.com',\n  'twitter.com',\n  'x.com',\n  'linkedin.com',\n  'instagram.com',\n  'pinterest.com',\n  'tiktok.com',\n  'snapchat.com',\n  'reddit.com',\n]\n\n```\n\n### 2.2 Example Usage\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nasync def main():\n  config = CrawlerRunConfig(\n    css_selector=\"main.content\", \n    word_count_threshold=10,\n    excluded_tags=[\"nav\", \"footer\"],\n    exclude_external_links=True,\n    exclude_social_media_links=True,\n    exclude_domains=[\"ads.com\", \"spammytrackers.net\"],\n    exclude_external_images=True,\n    cache_mode=CacheMode.BYPASS\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=\"https://news.ycombinator.com\", config=config)\n    print(\"Cleaned HTML length:\", len(result.cleaned_html))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Note** : If these parameters remove too much, reduce or disable them accordingly.\n## 3. Handling Iframes\nSome sites embed content in `<iframe>` tags. If you want that inline: \n```\nconfig = CrawlerRunConfig(\n  # Merge iframe content into the final output\n  process_iframes=True,  \n  remove_overlay_elements=True\n)\n\n```\n\n**Usage** : \n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  config = CrawlerRunConfig(\n    process_iframes=True,\n    remove_overlay_elements=True\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://example.org/iframe-demo\", \n      config=config\n    )\n    print(\"Iframe-merged length:\", len(result.cleaned_html))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 4. Structured Extraction Examples\nYou can combine content selection with a more advanced extraction strategy. For instance, a **CSS-based** or **LLM-based** extraction strategy can run on the filtered HTML.\n### 4.1 Pattern-Based with `JsonCssExtractionStrategy`\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  # Minimal schema for repeated items\n  schema = {\n    \"name\": \"News Items\",\n    \"baseSelector\": \"tr.athing\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"a.storylink\", \"type\": \"text\"},\n      {\n        \"name\": \"link\", \n        \"selector\": \"a.storylink\", \n        \"type\": \"attribute\", \n        \"attribute\": \"href\"\n      }\n    ]\n  }\n  config = CrawlerRunConfig(\n    # Content filtering\n    excluded_tags=[\"form\", \"header\"],\n    exclude_domains=[\"adsite.com\"],\n    # CSS selection or entire page\n    css_selector=\"table.itemlist\",\n    # No caching for demonstration\n    cache_mode=CacheMode.BYPASS,\n    # Extraction strategy\n    extraction_strategy=JsonCssExtractionStrategy(schema)\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com/newest\", \n      config=config\n    )\n    data = json.loads(result.extracted_content)\n    print(\"Sample extracted item:\", data[:1]) # Show first item\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### 4.2 LLM-Based Extraction\n```\nimport asyncio\nimport json\nfrom pydantic import BaseModel, Field\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\nclass ArticleData(BaseModel):\n  headline: str\n  summary: str\nasync def main():\n  llm_strategy = LLMExtractionStrategy(\n    provider=\"openai/gpt-4\",\n    api_token=\"sk-YOUR_API_KEY\",\n    schema=ArticleData.schema(),\n    extraction_type=\"schema\",\n    instruction=\"Extract 'headline' and a short 'summary' from the content.\"\n  )\n  config = CrawlerRunConfig(\n    exclude_external_links=True,\n    word_count_threshold=20,\n    extraction_strategy=llm_strategy\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=\"https://news.ycombinator.com\", config=config)\n    article = json.loads(result.extracted_content)\n    print(article)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\nHere, the crawler:\n  * Filters out external links (`exclude_external_links=True`). \n  * Ignores very short text blocks (`word_count_threshold=20`). \n  * Passes the final HTML to your LLM strategy for an AI-driven parse.\n\n\n## 5. Comprehensive Example\nBelow is a short function that unifies **CSS selection** , **exclusion** logic, and a pattern-based extraction, demonstrating how you can fine-tune your final data:\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def extract_main_articles(url: str):\n  schema = {\n    \"name\": \"ArticleBlock\",\n    \"baseSelector\": \"div.article-block\",\n    \"fields\": [\n      {\"name\": \"headline\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"summary\", \"selector\": \".summary\", \"type\": \"text\"},\n      {\n        \"name\": \"metadata\",\n        \"type\": \"nested\",\n        \"fields\": [\n          {\"name\": \"author\", \"selector\": \".author\", \"type\": \"text\"},\n          {\"name\": \"date\", \"selector\": \".date\", \"type\": \"text\"}\n        ]\n      }\n    ]\n  }\n  config = CrawlerRunConfig(\n    # Keep only #main-content\n    css_selector=\"#main-content\",\n    # Filtering\n    word_count_threshold=10,\n    excluded_tags=[\"nav\", \"footer\"], \n    exclude_external_links=True,\n    exclude_domains=[\"somebadsite.com\"],\n    exclude_external_images=True,\n    # Extraction\n    extraction_strategy=JsonCssExtractionStrategy(schema),\n    cache_mode=CacheMode.BYPASS\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=url, config=config)\n    if not result.success:\n      print(f\"Error: {result.error_message}\")\n      return None\n    return json.loads(result.extracted_content)\nasync def main():\n  articles = await extract_main_articles(\"https://news.ycombinator.com/newest\")\n  if articles:\n    print(\"Extracted Articles:\", articles[:2]) # Show first 2\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Why This Works** : - **CSS** scoping with `#main-content`. - Multiple **exclude_** parameters to remove domains, external images, etc. - A **JsonCssExtractionStrategy** to parse repeated article blocks.\n## 6. Scraping Modes\nCrawl4AI provides two different scraping strategies for HTML content processing: `WebScrapingStrategy` (BeautifulSoup-based, default) and `LXMLWebScrapingStrategy` (LXML-based). The LXML strategy offers significantly better performance, especially for large HTML documents.\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, LXMLWebScrapingStrategy\nasync def main():\n  config = CrawlerRunConfig(\n    scraping_strategy=LXMLWebScrapingStrategy() # Faster alternative to default BeautifulSoup\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com\", \n      config=config\n    )\n\n```\n\nYou can also create your own custom scraping strategy by inheriting from `ContentScrapingStrategy`. The strategy must return a `ScrapingResult` object with the following structure:\n```\nfrom crawl4ai import ContentScrapingStrategy, ScrapingResult, MediaItem, Media, Link, Links\nclass CustomScrapingStrategy(ContentScrapingStrategy):\n  def scrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n    # Implement your custom scraping logic here\n    return ScrapingResult(\n      cleaned_html=\"<html>...</html>\", # Cleaned HTML content\n      success=True,           # Whether scraping was successful\n      media=Media(\n        images=[           # List of images found\n          MediaItem(\n            src=\"https://example.com/image.jpg\",\n            alt=\"Image description\",\n            desc=\"Surrounding text\",\n            score=1,\n            type=\"image\",\n            group_id=1,\n            format=\"jpg\",\n            width=800\n          )\n        ],\n        videos=[],          # List of videos (same structure as images)\n        audios=[]           # List of audio files (same structure as images)\n      ),\n      links=Links(\n        internal=[          # List of internal links\n          Link(\n            href=\"https://example.com/page\",\n            text=\"Link text\",\n            title=\"Link title\",\n            base_domain=\"example.com\"\n          )\n        ],\n        external=[]          # List of external links (same structure)\n      ),\n      metadata={            # Additional metadata\n        \"title\": \"Page Title\",\n        \"description\": \"Page description\"\n      }\n    )\n  async def ascrap(self, url: str, html: str, **kwargs) -> ScrapingResult:\n    # For simple cases, you can use the sync version\n    return await asyncio.to_thread(self.scrap, url, html, **kwargs)\n\n```\n\n### Performance Considerations\nThe LXML strategy can be up to 10-20x faster than BeautifulSoup strategy, particularly when processing large HTML documents. However, please note:\n  1. LXML strategy is currently experimental\n  2. In some edge cases, the parsing results might differ slightly from BeautifulSoup\n  3. If you encounter any inconsistencies between LXML and BeautifulSoup results, please with a reproducible example\n\n\nChoose LXML strategy when: - Processing large HTML documents (recommended for >100KB) - Performance is critical - Working with well-formed HTML\nStick to BeautifulSoup strategy (default) when: - Maximum compatibility is needed - Working with malformed HTML - Exact parsing behavior is critical\n## 7. Conclusion\nBy mixing **css_selector** scoping, **content filtering** parameters, and advanced **extraction strategies** , you can precisely **choose** which data to keep. Key parameters in **`CrawlerRunConfig`**for content selection include:\n1. **`css_selector`**\u2013 Basic scoping to an element or region. 2.**`word_count_threshold`**\u2013 Skip short blocks. 3.**`excluded_tags`**\u2013 Remove entire HTML tags. 4.**`exclude_external_links`**,**`exclude_social_media_links`**,**`exclude_domains`**\u2013 Filter out unwanted links or domains. 5.**`exclude_external_images`**\u2013 Remove images from external sources. 6.**`process_iframes`**\u2013 Merge iframe content if needed.\nCombine these with structured extraction (CSS, LLM-based, or others) to build powerful crawls that yield exactly the content you want, from raw or cleaned HTML up to sophisticated JSON structures. For more detail, see [Configuration Reference](https://docs.crawl4ai.com/core/api/parameters/>). Enjoy curating your data to the max!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 16,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:20",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "content.json",
    "content": {
      "url": "https://docs.crawl4ai.com/",
      "timestamp": "2025-02-06T13:23:18.784531",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"img/favicon-32x32.png\">\n\n\n    \n \n<title>Home - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"css/normalize.css\" rel=\"stylesheet\">\n<link href=\"css/terminal.css\" rel=\"stylesheet\">\n<link href=\"css/theme.css\" rel=\"stylesheet\">\n<link href=\"css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \".\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"assets/highlight.min.js\"></script>\n    \n    <script src=\"assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\".\" class=\"menu-item active\" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Home</span>\n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawl4ai-open-source-llm-friendly-web-crawler-scraper\">\ud83d\ude80\ud83e\udd16 Crawl4AI: Open-Source LLM-Friendly Web Crawler &amp; Scraper</a></li>\n        <li><a href=\"#quick-start\">Quick Start</a></li><li><a href=\"#what-does-crawl4ai-do\">What Does Crawl4AI Do?</a></li><li><a href=\"#documentation-structure\">Documentation Structure</a></li><li><a href=\"#how-you-can-support\">How You Can Support</a></li><li><a href=\"#quick-links\">Quick Links</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawl4ai-open-source-llm-friendly-web-crawler-scraper\">\ud83d\ude80\ud83e\udd16 Crawl4AI: Open-Source LLM-Friendly Web Crawler &amp; Scraper</h1>\n<div class=\"badges\" align=\"center\">\n\n  <p>\n    <a href=\"https://trendshift.io/repositories/11716\" target=\"_blank\">\n      <img src=\"https://trendshift.io/api/badge/repositories/11716\" alt=\"unclecode%2Fcrawl4ai | Trendshift\" style=\"width: 250px; height: 55px;\" width=\"250\" height=\"55\">\n    </a>\n\n  </p>\n\n  <p>\n    <a href=\"https://github.com/unclecode/crawl4ai/stargazers\">\n      <img src=\"https://img.shields.io/github/stars/unclecode/crawl4ai?style=social\" alt=\"GitHub Stars\">\n    </a>\n    <a href=\"https://github.com/unclecode/crawl4ai/network/members\">\n      <img src=\"https://img.shields.io/github/forks/unclecode/crawl4ai?style=social\" alt=\"GitHub Forks\">\n    </a>\n    <a href=\"https://badge.fury.io/py/crawl4ai\">\n      <img src=\"https://badge.fury.io/py/crawl4ai.svg\" alt=\"PyPI version\" width=\"139\" height=\"20\">\n    </a>\n  </p>\n\n  <p>\n    <a href=\"https://pypi.org/project/crawl4ai/\">\n      <img src=\"https://img.shields.io/pypi/pyversions/crawl4ai\" alt=\"Python Version\" width=\"228\" height=\"20\">\n    </a>\n    <a href=\"https://pepy.tech/project/crawl4ai\">\n      <img src=\"https://static.pepy.tech/badge/crawl4ai/month\" alt=\"Downloads\" width=\"148\" height=\"20\">\n    </a>\n    <a href=\"https://github.com/unclecode/crawl4ai/blob/main/LICENSE\">\n      <img src=\"https://img.shields.io/github/license/unclecode/crawl4ai\" alt=\"License\" width=\"120\" height=\"20\">\n    </a>\n  </p>\n\n</div>\n\n<p>Crawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for large language models, AI agents, and data pipelines. Fully open source, flexible, and built for real-time performance, <strong>Crawl4AI</strong> empowers developers with unmatched speed, precision, and deployment ease.</p>\n<blockquote>\n<p><strong>Note</strong>: If you're looking for the old documentation, you can access it <a href=\"https://old.docs.crawl4ai.com\">here</a>.</p>\n</blockquote>\n<h2 id=\"quick-start\">Quick Start</h2>\n<p>Here's a quick example to show you how easy it is to use Crawl4AI with its asynchronous capabilities:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Create an instance of AsyncWebCrawler</span>\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Run the crawler on a URL</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://crawl4ai.com\"</span>)\n\n        <span class=\"hljs-comment\"># Print the extracted content</span>\n        <span class=\"hljs-built_in\">print</span>(result.markdown)\n\n<span class=\"hljs-comment\"># Run the async main function</span>\nasyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"what-does-crawl4ai-do\">What Does Crawl4AI Do?</h2>\n<p>Crawl4AI is a feature-rich crawler and scraper that aims to:</p>\n<p>1.\u2000<strong>Generate Clean Markdown</strong>: Perfect for RAG pipelines or direct ingestion into LLMs.<br>\n2.\u2000<strong>Structured Extraction</strong>: Parse repeated patterns with CSS, XPath, or LLM-based extraction.<br>\n3.\u2000<strong>Advanced Browser Control</strong>: Hooks, proxies, stealth modes, session re-use\u2014fine-grained control.<br>\n4.\u2000<strong>High Performance</strong>: Parallel crawling, chunk-based extraction, real-time use cases.<br>\n5.\u2000<strong>Open Source</strong>: No forced API keys, no paywalls\u2014everyone can access their data.  </p>\n<p><strong>Core Philosophies</strong>:\n- <strong>Democratize Data</strong>: Free to use, transparent, and highly configurable.<br>\n- <strong>LLM Friendly</strong>: Minimally processed, well-structured text, images, and metadata, so AI models can easily consume it.</p>\n<hr>\n<h2 id=\"documentation-structure\">Documentation Structure</h2>\n<p>To help you get started, we\u2019ve organized our docs into clear sections:</p>\n<ul>\n<li><strong>Setup &amp; Installation</strong><br>\n  Basic instructions to install Crawl4AI via pip or Docker.  </li>\n<li><strong>Quick Start</strong><br>\n  A hands-on introduction showing how to do your first crawl, generate Markdown, and do a simple extraction.  </li>\n<li><strong>Core</strong><br>\n  Deeper guides on single-page crawling, advanced browser/crawler parameters, content filtering, and caching.  </li>\n<li><strong>Advanced</strong><br>\n  Explore link &amp; media handling, lazy loading, hooking &amp; authentication, proxies, session management, and more.  </li>\n<li><strong>Extraction</strong><br>\n  Detailed references for no-LLM (CSS, XPath) vs. LLM-based strategies, chunking, and clustering approaches.  </li>\n<li><strong>API Reference</strong><br>\n  Find the technical specifics of each class and method, including <code>AsyncWebCrawler</code>, <code>arun()</code>, and <code>CrawlResult</code>.</li>\n</ul>\n<p>Throughout these sections, you\u2019ll find code samples you can <strong>copy-paste</strong> into your environment. If something is missing or unclear, raise an issue or PR.</p>\n<hr>\n<h2 id=\"how-you-can-support\">How You Can Support</h2>\n<ul>\n<li><strong>Star &amp; Fork</strong>: If you find Crawl4AI helpful, star the repo on GitHub or fork it to add your own features.  </li>\n<li><strong>File Issues</strong>: Encounter a bug or missing feature? Let us know by filing an issue, so we can improve.  </li>\n<li><strong>Pull Requests</strong>: Whether it\u2019s a small fix, a big feature, or better docs\u2014contributions are always welcome.  </li>\n<li><strong>Join Discord</strong>: Come chat about web scraping, crawling tips, or AI workflows with the community.  </li>\n<li><strong>Spread the Word</strong>: Mention Crawl4AI in your blog posts, talks, or on social media.  </li>\n</ul>\n<p><strong>Our mission</strong>: to empower everyone\u2014students, researchers, entrepreneurs, data scientists\u2014to access, parse, and shape the world\u2019s data with speed, cost-efficiency, and creative freedom.</p>\n<hr>\n<h2 id=\"quick-links\">Quick Links</h2>\n<ul>\n<li><strong><a href=\"https://github.com/unclecode/crawl4ai\">GitHub Repo</a></strong>  </li>\n<li><strong><a href=\"core/installation/\">Installation Guide</a></strong>  </li>\n<li><strong><a href=\"core/quickstart/\">Quick Start</a></strong>  </li>\n<li><strong><a href=\"api/async-webcrawler/\">API Reference</a></strong>  </li>\n<li><strong><a href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a></strong>  </li>\n</ul>\n<p>Thank you for joining me on this journey. Let\u2019s keep building an <strong>open, democratic</strong> approach to data extraction and AI together.</p>\n<p>Happy Crawling!<br>\n\u2014 <em>Unclecode, Founder &amp; Maintainer of Crawl4AI</em>  </p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# \ud83d\ude80\ud83e\udd16 Crawl4AI: Open-Source LLM-Friendly Web Crawler & Scraper\nCrawl4AI is the #1 trending GitHub repository, actively maintained by a vibrant community. It delivers blazing-fast, AI-ready web crawling tailored for large language models, AI agents, and data pipelines. Fully open source, flexible, and built for real-time performance, **Crawl4AI** empowers developers with unmatched speed, precision, and deployment ease.\n> **Note** : If you're looking for the old documentation, you can access it [here](https://docs.crawl4ai.com/<https:/old.docs.crawl4ai.com>).\n## Quick Start\nHere's a quick example to show you how easy it is to use Crawl4AI with its asynchronous capabilities:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nasync def main():\n  # Create an instance of AsyncWebCrawler\n  async with AsyncWebCrawler() as crawler:\n    # Run the crawler on a URL\n    result = await crawler.arun(url=\"https://crawl4ai.com\")\n    # Print the extracted content\n    print(result.markdown)\n# Run the async main function\nasyncio.run(main())\n\n```\n\n## What Does Crawl4AI Do?\nCrawl4AI is a feature-rich crawler and scraper that aims to:\n1. **Generate Clean Markdown** : Perfect for RAG pipelines or direct ingestion into LLMs. 2. **Structured Extraction** : Parse repeated patterns with CSS, XPath, or LLM-based extraction. 3. **Advanced Browser Control** : Hooks, proxies, stealth modes, session re-use\u2014fine-grained control. 4. **High Performance** : Parallel crawling, chunk-based extraction, real-time use cases. 5. **Open Source** : No forced API keys, no paywalls\u2014everyone can access their data. \n**Core Philosophies** : - **Democratize Data** : Free to use, transparent, and highly configurable. - **LLM Friendly** : Minimally processed, well-structured text, images, and metadata, so AI models can easily consume it.\n## Documentation Structure\nTo help you get started, we\u2019ve organized our docs into clear sections:\n  * **Setup & Installation** Basic instructions to install Crawl4AI via pip or Docker. \n  * **Quick Start** A hands-on introduction showing how to do your first crawl, generate Markdown, and do a simple extraction. \n  * **Core** Deeper guides on single-page crawling, advanced browser/crawler parameters, content filtering, and caching. \n  * **Advanced** Explore link & media handling, lazy loading, hooking & authentication, proxies, session management, and more. \n  * **Extraction** Detailed references for no-LLM (CSS, XPath) vs. LLM-based strategies, chunking, and clustering approaches. \n  * **API Reference** Find the technical specifics of each class and method, including `AsyncWebCrawler`, `arun()`, and `CrawlResult`.\n\n\nThroughout these sections, you\u2019ll find code samples you can **copy-paste** into your environment. If something is missing or unclear, raise an issue or PR.\n## How You Can Support\n  * **Star & Fork**: If you find Crawl4AI helpful, star the repo on GitHub or fork it to add your own features. \n  * **File Issues** : Encounter a bug or missing feature? Let us know by filing an issue, so we can improve. \n  * **Pull Requests** : Whether it\u2019s a small fix, a big feature, or better docs\u2014contributions are always welcome. \n  * **Join Discord** : Come chat about web scraping, crawling tips, or AI workflows with the community. \n  * **Spread the Word** : Mention Crawl4AI in your blog posts, talks, or on social media. \n\n\n**Our mission** : to empower everyone\u2014students, researchers, entrepreneurs, data scientists\u2014to access, parse, and shape the world\u2019s data with speed, cost-efficiency, and creative freedom.\n## Quick Links\n  * **[Installation Guide](https://docs.crawl4ai.com/<core/installation/>)**\n  * **[Quick Start](https://docs.crawl4ai.com/<core/quickstart/>)**\n  * **[API Reference](https://docs.crawl4ai.com/<api/async-webcrawler/>)**\n\n\nThank you for joining me on this journey. Let\u2019s keep building an **open, democratic** approach to data extraction and AI together.\nHappy Crawling! \u2014 _Unclecode, Founder & Maintainer of Crawl4AI_\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies"
      ],
      "stats": {
        "processed": 1,
        "total": 0,
        "depth": 0,
        "elapsed": "0:00:02",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "crawl-result.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/crawl-result",
      "timestamp": "2025-02-06T13:23:29.528540",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/crawl-result/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>CrawlResult - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">CrawlResult</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawlresult-reference\">CrawlResult Reference</a></li>\n        <li><a href=\"#1-basic-crawl-info\">1. Basic Crawl Info</a></li><li><a href=\"#2-raw-cleaned-content\">2. Raw / Cleaned Content</a></li><li><a href=\"#3-markdown-fields\">3. Markdown Fields</a></li><li><a href=\"#4-media-links\">4. Media &amp; Links</a></li><li><a href=\"#5-additional-fields\">5. Additional Fields</a></li><li><a href=\"#6-dispatch_result-optional\">6. dispatch_result (optional)</a></li><li><a href=\"#7-example-accessing-everything\">7. Example: Accessing Everything</a></li><li><a href=\"#8-key-points-future\">8. Key Points &amp; Future</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawlresult-reference\"><code>CrawlResult</code> Reference</h1>\n<p>The <strong><code>CrawlResult</code></strong> class encapsulates everything returned after a single crawl operation. It provides the <strong>raw or processed content</strong>, details on links and media, plus optional metadata (like screenshots, PDFs, or extracted JSON).</p>\n<p><strong>Location</strong>: <code>crawl4ai/crawler/models.py</code> (for reference)</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CrawlResult</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    url: <span class=\"hljs-built_in\">str</span>\n    html: <span class=\"hljs-built_in\">str</span>\n    success: <span class=\"hljs-built_in\">bool</span>\n    cleaned_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    media: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    links: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    downloaded_files: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>]] = <span class=\"hljs-literal\">None</span>\n    screenshot: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    pdf : <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">bytes</span>] = <span class=\"hljs-literal\">None</span>\n    markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">Union</span>[<span class=\"hljs-built_in\">str</span>, MarkdownGenerationResult]] = <span class=\"hljs-literal\">None</span>\n    markdown_v2: <span class=\"hljs-type\">Optional</span>[MarkdownGenerationResult] = <span class=\"hljs-literal\">None</span>\n    fit_markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    fit_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    extracted_content: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    metadata: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    error_message: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    session_id: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    response_headers: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    status_code: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>\n    ssl_certificate: <span class=\"hljs-type\">Optional</span>[SSLCertificate] = <span class=\"hljs-literal\">None</span>\n    dispatch_result: <span class=\"hljs-type\">Optional</span>[DispatchResult] = <span class=\"hljs-literal\">None</span>\n    ...\n</code></pre></div>\n<p>Below is a <strong>field-by-field</strong> explanation and possible usage patterns.</p>\n<hr>\n<h2 id=\"1-basic-crawl-info\">1. Basic Crawl Info</h2>\n<h3 id=\"11-url-str\">1.1 <strong><code>url</code></strong> <em>(str)</em></h3>\n<p><strong>What</strong>: The final crawled URL (after any redirects).<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-built_in\">print</span>(result.url)  <span class=\"hljs-comment\"># e.g., \"https://example.com/\"</span>\n</code></pre></div><p></p>\n<h3 id=\"12-success-bool\">1.2 <strong><code>success</code></strong> <em>(bool)</em></h3>\n<p><strong>What</strong>: <code>True</code> if the crawl pipeline ended without major errors; <code>False</code> otherwise.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Crawl failed: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n</code></pre></div><p></p>\n<h3 id=\"13-status_code-optionalint\">1.3 <strong><code>status_code</code></strong> <em>(Optional[int])</em></h3>\n<p><strong>What</strong>: The page\u2019s HTTP status code (e.g., 200, 404).<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> result.status_code == 404:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Page not found!\"</span>)\n</code></pre></div><p></p>\n<h3 id=\"14-error_message-optionalstr\">1.4 <strong><code>error_message</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: If <code>success=False</code>, a textual description of the failure.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> not result.success:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n</code></pre></div><p></p>\n<h3 id=\"15-session_id-optionalstr\">1.5 <strong><code>session_id</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: The ID used for reusing a browser context across multiple calls.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># If you used session_id=\"login_session\" in CrawlerRunConfig, see it here:</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Session:\"</span>, result.session_id)\n</code></pre></div><p></p>\n<h3 id=\"16-response_headers-optionaldict\">1.6 <strong><code>response_headers</code></strong> <em>(Optional[dict])</em></h3>\n<p><strong>What</strong>: Final HTTP response headers.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">if result<span class=\"hljs-selector-class\">.response_headers</span>:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Server:\"</span>, result.response_headers.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"Server\"</span>, <span class=\"hljs-string\">\"Unknown\"</span>))\n</code></pre></div><p></p>\n<h3 id=\"17-ssl_certificate-optionalsslcertificate\">1.7 <strong><code>ssl_certificate</code></strong> <em>(Optional[SSLCertificate])</em></h3>\n<p><strong>What</strong>: If <code>fetch_ssl_certificate=True</code> in your CrawlerRunConfig, <strong><code>result.ssl_certificate</code></strong> contains a  <a href=\"../../advanced/ssl-certificate/\"><strong><code>SSLCertificate</code></strong></a> object describing the site\u2019s certificate. You can export the cert in multiple formats (PEM/DER/JSON) or access its properties like <code>issuer</code>, \n <code>subject</code>, <code>valid_from</code>, <code>valid_until</code>, etc. \n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> result.ssl_certificate:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Issuer:\"</span>, result.ssl_certificate.issuer)\n</code></pre></div><p></p>\n<hr>\n<h2 id=\"2-raw-cleaned-content\">2. Raw / Cleaned Content</h2>\n<h3 id=\"21-html-str\">2.1 <strong><code>html</code></strong> <em>(str)</em></h3>\n<p><strong>What</strong>: The <strong>original</strong> unmodified HTML from the final page load.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-comment\"># Possibly large</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-built_in\">len</span>(result.html))\n</code></pre></div><p></p>\n<h3 id=\"22-cleaned_html-optionalstr\">2.2 <strong><code>cleaned_html</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: A sanitized HTML version\u2014scripts, styles, or excluded tags are removed based on your <code>CrawlerRunConfig</code>.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-built_in\">print</span>(result.cleaned_html[:500])  <span class=\"hljs-comment\"># Show a snippet</span>\n</code></pre></div><p></p>\n<h3 id=\"23-fit_html-optionalstr\">2.3 <strong><code>fit_html</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: If a <strong>content filter</strong> or heuristic (e.g., Pruning/BM25) modifies the HTML, the \u201cfit\u201d or post-filter version.<br>\n<strong>When</strong>: This is <strong>only</strong> present if your <code>markdown_generator</code> or <code>content_filter</code> produces it.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> result.fit_html:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"High-value HTML content:\"</span>, result.fit_html[:300])\n</code></pre></div><p></p>\n<hr>\n<h2 id=\"3-markdown-fields\">3. Markdown Fields</h2>\n<h3 id=\"31-the-markdown-generation-approach\">3.1 The Markdown Generation Approach</h3>\n<p>Crawl4AI can convert HTML\u2192Markdown, optionally including:</p>\n<ul>\n<li><strong>Raw</strong> markdown  </li>\n<li><strong>Links as citations</strong> (with a references section)  </li>\n<li><strong>Fit</strong> markdown if a <strong>content filter</strong> is used (like Pruning or BM25)</li>\n</ul>\n<h3 id=\"32-markdown_v2-optionalmarkdowngenerationresult\">3.2 <strong><code>markdown_v2</code></strong> <em>(Optional[MarkdownGenerationResult])</em></h3>\n<p><strong>What</strong>: The <strong>structured</strong> object holding multiple markdown variants. Soon to be consolidated into <code>markdown</code>.  </p>\n<p><strong><code>MarkdownGenerationResult</code></strong> includes:\n- <strong><code>raw_markdown</code></strong> <em>(str)</em>: The full HTML\u2192Markdown conversion.<br>\n- <strong><code>markdown_with_citations</code></strong> <em>(str)</em>: Same markdown, but with link references as academic-style citations.<br>\n- <strong><code>references_markdown</code></strong> <em>(str)</em>: The reference list or footnotes at the end.<br>\n- <strong><code>fit_markdown</code></strong> <em>(Optional[str])</em>: If content filtering (Pruning/BM25) was applied, the filtered \u201cfit\u201d text.<br>\n- <strong><code>fit_html</code></strong> <em>(Optional[str])</em>: The HTML that led to <code>fit_markdown</code>.</p>\n<p><strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> result.markdown_v2:\n    md_res = result.markdown_v2\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw MD:\"</span>, md_res.raw_markdown[:300])\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Citations MD:\"</span>, md_res.markdown_with_citations[:300])\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"References:\"</span>, md_res.references_markdown)\n    <span class=\"hljs-keyword\">if</span> md_res.fit_markdown:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Pruned text:\"</span>, md_res.fit_markdown[:300])\n</code></pre></div><p></p>\n<h3 id=\"33-markdown-optionalunionstr-markdowngenerationresult\">3.3 <strong><code>markdown</code></strong> <em>(Optional[Union[str, MarkdownGenerationResult]])</em></h3>\n<p><strong>What</strong>: In future versions, <code>markdown</code> will fully replace <code>markdown_v2</code>. Right now, it might be a <code>str</code> or a <code>MarkdownGenerationResult</code>.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-comment\"># Soon, you might see:</span>\n<span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(result.markdown, MarkdownGenerationResult):\n    <span class=\"hljs-built_in\">print</span>(result.markdown.raw_markdown[:<span class=\"hljs-number\">200</span>])\n<span class=\"hljs-keyword\">else</span>:\n    <span class=\"hljs-built_in\">print</span>(result.markdown)\n</code></pre></div><p></p>\n<h3 id=\"34-fit_markdown-optionalstr\">3.4 <strong><code>fit_markdown</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: A direct reference to the final filtered markdown (legacy approach).<br>\n<strong>When</strong>: This is set if a filter or content strategy explicitly writes there. Usually overshadowed by <code>markdown_v2.fit_markdown</code>.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-built_in\">print</span>(result.fit_markdown)  <span class=\"hljs-comment\"># Legacy field, prefer result.markdown_v2.fit_markdown</span>\n</code></pre></div><p></p>\n<p><strong>Important</strong>: \u201cFit\u201d content (in <code>fit_markdown</code>/<code>fit_html</code>) only exists if you used a <strong>filter</strong> (like <strong>PruningContentFilter</strong> or <strong>BM25ContentFilter</strong>) within a <code>MarkdownGenerationStrategy</code>.</p>\n<hr>\n<h2 id=\"4-media-links\">4. Media &amp; Links</h2>\n<h3 id=\"41-media-dictstr-listdict\">4.1 <strong><code>media</code></strong> <em>(Dict[str, List[Dict]])</em></h3>\n<p><strong>What</strong>: Contains info about discovered images, videos, or audio. Typically keys: <code>\"images\"</code>, <code>\"videos\"</code>, <code>\"audios\"</code>.<br>\n<strong>Common Fields</strong> in each item:</p>\n<ul>\n<li><code>src</code> <em>(str)</em>: Media URL  </li>\n<li><code>alt</code> or <code>title</code> <em>(str)</em>: Descriptive text  </li>\n<li><code>score</code> <em>(float)</em>: Relevance score if the crawler\u2019s heuristic found it \u201cimportant\u201d  </li>\n<li><code>desc</code> or <code>description</code> <em>(Optional[str])</em>: Additional context extracted from surrounding text  </li>\n</ul>\n<p><strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\">images = result.media.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"images\"</span>, [])\n<span class=\"hljs-keyword\">for</span> img <span class=\"hljs-keyword\">in</span> images:\n    <span class=\"hljs-keyword\">if</span> img.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"score\"</span>, <span class=\"hljs-number\">0</span>) &gt; <span class=\"hljs-number\">5</span>:\n        print(<span class=\"hljs-string\">\"High-value image:\"</span>, img[<span class=\"hljs-string\">\"src\"</span>])\n</code></pre></div><p></p>\n<h3 id=\"42-links-dictstr-listdict\">4.2 <strong><code>links</code></strong> <em>(Dict[str, List[Dict]])</em></h3>\n<p><strong>What</strong>: Holds internal and external link data. Usually two keys: <code>\"internal\"</code> and <code>\"external\"</code>.<br>\n<strong>Common Fields</strong>:</p>\n<ul>\n<li><code>href</code> <em>(str)</em>: The link target  </li>\n<li><code>text</code> <em>(str)</em>: Link text  </li>\n<li><code>title</code> <em>(str)</em>: Title attribute  </li>\n<li><code>context</code> <em>(str)</em>: Surrounding text snippet  </li>\n<li><code>domain</code> <em>(str)</em>: If external, the domain</li>\n</ul>\n<p><strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">for</span> link <span class=\"hljs-keyword\">in</span> result.links[<span class=\"hljs-string\">\"internal\"</span>]:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Internal link to <span class=\"hljs-subst\">{link[<span class=\"hljs-string\">'href'</span>]}</span> with text <span class=\"hljs-subst\">{link[<span class=\"hljs-string\">'text'</span>]}</span>\"</span>)\n</code></pre></div><p></p>\n<hr>\n<h2 id=\"5-additional-fields\">5. Additional Fields</h2>\n<h3 id=\"51-extracted_content-optionalstr\">5.1 <strong><code>extracted_content</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: If you used <strong><code>extraction_strategy</code></strong> (CSS, LLM, etc.), the structured output (JSON).<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">if result<span class=\"hljs-selector-class\">.extracted_content</span>:\n    data = json.<span class=\"hljs-built_in\">loads</span>(result.extracted_content)\n    <span class=\"hljs-built_in\">print</span>(data)\n</code></pre></div><p></p>\n<h3 id=\"52-downloaded_files-optionalliststr\">5.2 <strong><code>downloaded_files</code></strong> <em>(Optional[List[str]])</em></h3>\n<p><strong>What</strong>: If <code>accept_downloads=True</code> in your <code>BrowserConfig</code> + <code>downloads_path</code>, lists local file paths for downloaded items.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-keyword\">if</span> result.downloaded_files:\n    <span class=\"hljs-keyword\">for</span> file_path <span class=\"hljs-keyword\">in</span> result.downloaded_files:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Downloaded:\"</span>, file_path)\n</code></pre></div><p></p>\n<h3 id=\"53-screenshot-optionalstr\">5.3 <strong><code>screenshot</code></strong> <em>(Optional[str])</em></h3>\n<p><strong>What</strong>: Base64-encoded screenshot if <code>screenshot=True</code> in <code>CrawlerRunConfig</code>.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> base64\n<span class=\"hljs-keyword\">if</span> result.screenshot:\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"page.png\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n        f.write(base64.b64decode(result.screenshot))\n</code></pre></div><p></p>\n<h3 id=\"54-pdf-optionalbytes\">5.4 <strong><code>pdf</code></strong> <em>(Optional[bytes])</em></h3>\n<p><strong>What</strong>: Raw PDF bytes if <code>pdf=True</code> in <code>CrawlerRunConfig</code>.<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">if</span> result.pdf:\n    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"page.pdf\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n        f.write(result.pdf)\n</code></pre></div><p></p>\n<h3 id=\"55-metadata-optionaldict\">5.5 <strong><code>metadata</code></strong> <em>(Optional[dict])</em></h3>\n<p><strong>What</strong>: Page-level metadata if discovered (title, description, OG data, etc.).<br>\n<strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">if result<span class=\"hljs-selector-class\">.metadata</span>:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Title:\"</span>, result.metadata.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"title\"</span>))\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Author:\"</span>, result.metadata.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"author\"</span>))\n</code></pre></div><p></p>\n<hr>\n<h2 id=\"6-dispatch_result-optional\">6. <code>dispatch_result</code> (optional)</h2>\n<p>A <code>DispatchResult</code> object providing additional concurrency and resource usage information when crawling URLs in parallel (e.g., via <code>arun_many()</code> with custom dispatchers). It contains:</p>\n<ul>\n<li><strong><code>task_id</code></strong>: A unique identifier for the parallel task.</li>\n<li><strong><code>memory_usage</code></strong> (float): The memory (in MB) used at the time of completion.</li>\n<li><strong><code>peak_memory</code></strong> (float): The peak memory usage (in MB) recorded during the task\u2019s execution.</li>\n<li><strong><code>start_time</code></strong> / <strong><code>end_time</code></strong> (datetime): Time range for this crawling task.</li>\n<li><strong><code>error_message</code></strong> (str): Any dispatcher- or concurrency-related error encountered.</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-comment\"># Example usage:</span>\n<span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:\n    <span class=\"hljs-keyword\">if</span> result.success <span class=\"hljs-keyword\">and</span> result.dispatch_result:\n        dr = result.dispatch_result\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"URL: <span class=\"hljs-subst\">{result.url}</span>, Task ID: <span class=\"hljs-subst\">{dr.task_id}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Memory: <span class=\"hljs-subst\">{dr.memory_usage:<span class=\"hljs-number\">.1</span>f}</span> MB (Peak: <span class=\"hljs-subst\">{dr.peak_memory:<span class=\"hljs-number\">.1</span>f}</span> MB)\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Duration: <span class=\"hljs-subst\">{dr.end_time - dr.start_time}</span>\"</span>)\n</code></pre></div>\n<blockquote>\n<p><strong>Note</strong>: This field is typically populated when using <code>arun_many(...)</code> alongside a <strong>dispatcher</strong> (e.g., <code>MemoryAdaptiveDispatcher</code> or <code>SemaphoreDispatcher</code>). If no concurrency or dispatcher is used, <code>dispatch_result</code> may remain <code>None</code>. </p>\n</blockquote>\n<hr>\n<h2 id=\"7-example-accessing-everything\">7. Example: Accessing Everything</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">handle_result</span>(<span class=\"hljs-params\">result: CrawlResult</span>):\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl error:\"</span>, result.error_message)\n        <span class=\"hljs-keyword\">return</span>\n\n    <span class=\"hljs-comment\"># Basic info</span>\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawled URL:\"</span>, result.url)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Status code:\"</span>, result.status_code)\n\n    <span class=\"hljs-comment\"># HTML</span>\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Original HTML size:\"</span>, <span class=\"hljs-built_in\">len</span>(result.html))\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Cleaned HTML size:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html <span class=\"hljs-keyword\">or</span> <span class=\"hljs-string\">\"\"</span>))\n\n    <span class=\"hljs-comment\"># Markdown output</span>\n    <span class=\"hljs-keyword\">if</span> result.markdown_v2:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown:\"</span>, result.markdown_v2.raw_markdown[:<span class=\"hljs-number\">300</span>])\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Citations Markdown:\"</span>, result.markdown_v2.markdown_with_citations[:<span class=\"hljs-number\">300</span>])\n        <span class=\"hljs-keyword\">if</span> result.markdown_v2.fit_markdown:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fit Markdown:\"</span>, result.markdown_v2.fit_markdown[:<span class=\"hljs-number\">200</span>])\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown (legacy):\"</span>, result.markdown[:<span class=\"hljs-number\">200</span>] <span class=\"hljs-keyword\">if</span> result.markdown <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"N/A\"</span>)\n\n    <span class=\"hljs-comment\"># Media &amp; Links</span>\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"images\"</span> <span class=\"hljs-keyword\">in</span> result.media:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Image count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.media[<span class=\"hljs-string\">\"images\"</span>]))\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-string\">\"internal\"</span> <span class=\"hljs-keyword\">in</span> result.links:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Internal link count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links[<span class=\"hljs-string\">\"internal\"</span>]))\n\n    <span class=\"hljs-comment\"># Extraction strategy result</span>\n    <span class=\"hljs-keyword\">if</span> result.extracted_content:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Structured data:\"</span>, result.extracted_content)\n\n    <span class=\"hljs-comment\"># Screenshot/PDF</span>\n    <span class=\"hljs-keyword\">if</span> result.screenshot:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Screenshot length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.screenshot))\n    <span class=\"hljs-keyword\">if</span> result.pdf:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"PDF bytes length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.pdf))\n</code></pre></div>\n<hr>\n<h2 id=\"8-key-points-future\">8. Key Points &amp; Future</h2>\n<p>1.\u2000<strong><code>markdown_v2</code> vs <code>markdown</code></strong><br>\n   - Right now, <code>markdown_v2</code> is the more robust container (<code>MarkdownGenerationResult</code>), providing <strong>raw_markdown</strong>, <strong>markdown_with_citations</strong>, references, plus possible <strong>fit_markdown</strong>.<br>\n   - In future versions, everything will unify under <strong><code>markdown</code></strong>. If you rely on advanced features (citations, fit content), check <code>markdown_v2</code>.</p>\n<p>2.\u2000<strong>Fit Content</strong><br>\n   - <strong><code>fit_markdown</code></strong> and <strong><code>fit_html</code></strong> appear only if you used a content filter (like <strong>PruningContentFilter</strong> or <strong>BM25ContentFilter</strong>) inside your <strong>MarkdownGenerationStrategy</strong> or set them directly.<br>\n   - If no filter is used, they remain <code>None</code>.</p>\n<p>3.\u2000<strong>References &amp; Citations</strong><br>\n   - If you enable link citations in your <code>DefaultMarkdownGenerator</code> (<code>options={\"citations\": True}</code>), you\u2019ll see <code>markdown_with_citations</code> plus a <strong><code>references_markdown</code></strong> block. This helps large language models or academic-like referencing.</p>\n<p>4.\u2000<strong>Links &amp; Media</strong><br>\n   - <code>links[\"internal\"]</code> and <code>links[\"external\"]</code> group discovered anchors by domain.<br>\n   - <code>media[\"images\"]</code> / <code>[\"videos\"]</code> / <code>[\"audios\"]</code> store extracted media elements with optional scoring or context.</p>\n<p>5.\u2000<strong>Error Cases</strong><br>\n   - If <code>success=False</code>, check <code>error_message</code> (e.g., timeouts, invalid URLs).<br>\n   - <code>status_code</code> might be <code>None</code> if we failed before an HTTP response.</p>\n<p>Use <strong><code>CrawlResult</code></strong> to glean all final outputs and feed them into your data pipelines, AI models, or archives. With the synergy of a properly configured <strong>BrowserConfig</strong> and <strong>CrawlerRunConfig</strong>, the crawler can produce robust, structured results here in <strong><code>CrawlResult</code></strong>.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# `CrawlResult` Reference\nThe **`CrawlResult`**class encapsulates everything returned after a single crawl operation. It provides the**raw or processed content** , details on links and media, plus optional metadata (like screenshots, PDFs, or extracted JSON).\n**Location** : `crawl4ai/crawler/models.py` (for reference)\n```\nclass CrawlResult(BaseModel):\n  url: str\n  html: str\n  success: bool\n  cleaned_html: Optional[str] = None\n  media: Dict[str, List[Dict]] = {}\n  links: Dict[str, List[Dict]] = {}\n  downloaded_files: Optional[List[str]] = None\n  screenshot: Optional[str] = None\n  pdf : Optional[bytes] = None\n  markdown: Optional[Union[str, MarkdownGenerationResult]] = None\n  markdown_v2: Optional[MarkdownGenerationResult] = None\n  fit_markdown: Optional[str] = None\n  fit_html: Optional[str] = None\n  extracted_content: Optional[str] = None\n  metadata: Optional[dict] = None\n  error_message: Optional[str] = None\n  session_id: Optional[str] = None\n  response_headers: Optional[dict] = None\n  status_code: Optional[int] = None\n  ssl_certificate: Optional[SSLCertificate] = None\n  dispatch_result: Optional[DispatchResult] = None\n  ...\n\n```\n\nBelow is a **field-by-field** explanation and possible usage patterns.\n## 1. Basic Crawl Info\n### 1.1 **`url`**_(str)_\n**What** : The final crawled URL (after any redirects). **Usage** : \n```\nprint(result.url) # e.g., \"https://example.com/\"\n\n```\n\n### 1.2 **`success`**_(bool)_\n**What** : `True` if the crawl pipeline ended without major errors; `False` otherwise. **Usage** : \n```\nif not result.success:\n  print(f\"Crawl failed: {result.error_message}\")\n\n```\n\n### 1.3 **`status_code`**_(Optional[int])_\n**What** : The page\u2019s HTTP status code (e.g., 200, 404). **Usage** : \n```\nif result.status_code == 404:\n  print(\"Page not found!\")\n\n```\n\n### 1.4 **`error_message`**_(Optional[str])_\n**What** : If `success=False`, a textual description of the failure. **Usage** : \n```\nif not result.success:\n  print(\"Error:\", result.error_message)\n\n```\n\n### 1.5 **`session_id`**_(Optional[str])_\n**What** : The ID used for reusing a browser context across multiple calls. **Usage** : \n```\n# If you used session_id=\"login_session\" in CrawlerRunConfig, see it here:\nprint(\"Session:\", result.session_id)\n\n```\n\n### 1.6 **`response_headers`**_(Optional[dict])_\n**What** : Final HTTP response headers. **Usage** : \n```\nif result.response_headers:\n  print(\"Server:\", result.response_headers.get(\"Server\", \"Unknown\"))\n\n```\n\n### 1.7 **`ssl_certificate`**_(Optional[SSLCertificate])_\n**What** : If `fetch_ssl_certificate=True` in your CrawlerRunConfig, **`result.ssl_certificate`**contains a[**`SSLCertificate`**](https://docs.crawl4ai.com/api/advanced/ssl-certificate/>)object describing the site\u2019s certificate. You can export the cert in multiple formats (PEM/DER/JSON) or access its properties like`issuer`, `subject`, `valid_from`, `valid_until`, etc. **Usage** : \n```\nif result.ssl_certificate:\n  print(\"Issuer:\", result.ssl_certificate.issuer)\n\n```\n\n## 2. Raw / Cleaned Content\n### 2.1 **`html`**_(str)_\n**What** : The **original** unmodified HTML from the final page load. **Usage** : \n```\n# Possibly large\nprint(len(result.html))\n\n```\n\n### 2.2 **`cleaned_html`**_(Optional[str])_\n**What** : A sanitized HTML version\u2014scripts, styles, or excluded tags are removed based on your `CrawlerRunConfig`. **Usage** : \n```\nprint(result.cleaned_html[:500]) # Show a snippet\n\n```\n\n### 2.3 **`fit_html`**_(Optional[str])_\n**What** : If a **content filter** or heuristic (e.g., Pruning/BM25) modifies the HTML, the \u201cfit\u201d or post-filter version. **When** : This is **only** present if your `markdown_generator` or `content_filter` produces it. **Usage** : \n```\nif result.fit_html:\n  print(\"High-value HTML content:\", result.fit_html[:300])\n\n```\n\n## 3. Markdown Fields\n### 3.1 The Markdown Generation Approach\nCrawl4AI can convert HTML\u2192Markdown, optionally including:\n  * **Raw** markdown \n  * **Links as citations** (with a references section) \n  * **Fit** markdown if a **content filter** is used (like Pruning or BM25)\n\n\n### 3.2 **`markdown_v2`**_(Optional[MarkdownGenerationResult])_\n**What** : The **structured** object holding multiple markdown variants. Soon to be consolidated into `markdown`. \n**`MarkdownGenerationResult`**includes: -**`raw_markdown`**_(str)_ : The full HTML\u2192Markdown conversion. - **`markdown_with_citations`**_(str)_ : Same markdown, but with link references as academic-style citations. - **`references_markdown`**_(str)_ : The reference list or footnotes at the end. - **`fit_markdown`**_(Optional[str])_ : If content filtering (Pruning/BM25) was applied, the filtered \u201cfit\u201d text. - **`fit_html`**_(Optional[str])_ : The HTML that led to `fit_markdown`.\n**Usage** : \n```\nif result.markdown_v2:\n  md_res = result.markdown_v2\n  print(\"Raw MD:\", md_res.raw_markdown[:300])\n  print(\"Citations MD:\", md_res.markdown_with_citations[:300])\n  print(\"References:\", md_res.references_markdown)\n  if md_res.fit_markdown:\n    print(\"Pruned text:\", md_res.fit_markdown[:300])\n\n```\n\n### 3.3 **`markdown`**_(Optional[Union[str, MarkdownGenerationResult]])_\n**What** : In future versions, `markdown` will fully replace `markdown_v2`. Right now, it might be a `str` or a `MarkdownGenerationResult`. **Usage** : \n```\n# Soon, you might see:\nif isinstance(result.markdown, MarkdownGenerationResult):\n  print(result.markdown.raw_markdown[:200])\nelse:\n  print(result.markdown)\n\n```\n\n### 3.4 **`fit_markdown`**_(Optional[str])_\n**What** : A direct reference to the final filtered markdown (legacy approach). **When** : This is set if a filter or content strategy explicitly writes there. Usually overshadowed by `markdown_v2.fit_markdown`. **Usage** : \n```\nprint(result.fit_markdown) # Legacy field, prefer result.markdown_v2.fit_markdown\n\n```\n\n**Important** : \u201cFit\u201d content (in `fit_markdown`/`fit_html`) only exists if you used a **filter** (like **PruningContentFilter** or **BM25ContentFilter**) within a `MarkdownGenerationStrategy`.\n## 4. Media & Links\n### 4.1 **`media`**_(Dict[str, List[Dict]])_\n**What** : Contains info about discovered images, videos, or audio. Typically keys: `\"images\"`, `\"videos\"`, `\"audios\"`. **Common Fields** in each item:\n  * `src` _(str)_ : Media URL \n  * `alt` or `title` _(str)_ : Descriptive text \n  * `score` _(float)_ : Relevance score if the crawler\u2019s heuristic found it \u201cimportant\u201d \n  * `desc` or `description` _(Optional[str])_ : Additional context extracted from surrounding text \n\n\n**Usage** : \n```\nimages = result.media.get(\"images\", [])\nfor img in images:\n  if img.get(\"score\", 0) > 5:\n    print(\"High-value image:\", img[\"src\"])\n\n```\n\n### 4.2 **`links`**_(Dict[str, List[Dict]])_\n**What** : Holds internal and external link data. Usually two keys: `\"internal\"` and `\"external\"`. **Common Fields** :\n  * `href` _(str)_ : The link target \n  * `text` _(str)_ : Link text \n  * `title` _(str)_ : Title attribute \n  * `context` _(str)_ : Surrounding text snippet \n  * `domain` _(str)_ : If external, the domain\n\n\n**Usage** : \n```\nfor link in result.links[\"internal\"]:\n  print(f\"Internal link to {link['href']} with text {link['text']}\")\n\n```\n\n## 5. Additional Fields\n### 5.1 **`extracted_content`**_(Optional[str])_\n**What** : If you used **`extraction_strategy`**(CSS, LLM, etc.), the structured output (JSON).**Usage** : \n```\nif result.extracted_content:\n  data = json.loads(result.extracted_content)\n  print(data)\n\n```\n\n### 5.2 **`downloaded_files`**_(Optional[List[str]])_\n**What** : If `accept_downloads=True` in your `BrowserConfig` + `downloads_path`, lists local file paths for downloaded items. **Usage** : \n```\nif result.downloaded_files:\n  for file_path in result.downloaded_files:\n    print(\"Downloaded:\", file_path)\n\n```\n\n### 5.3 **`screenshot`**_(Optional[str])_\n**What** : Base64-encoded screenshot if `screenshot=True` in `CrawlerRunConfig`. **Usage** : \n```\nimport base64\nif result.screenshot:\n  with open(\"page.png\", \"wb\") as f:\n    f.write(base64.b64decode(result.screenshot))\n\n```\n\n### 5.4 **`pdf`**_(Optional[bytes])_\n**What** : Raw PDF bytes if `pdf=True` in `CrawlerRunConfig`. **Usage** : \n```\nif result.pdf:\n  with open(\"page.pdf\", \"wb\") as f:\n    f.write(result.pdf)\n\n```\n\n### 5.5 **`metadata`**_(Optional[dict])_\n**What** : Page-level metadata if discovered (title, description, OG data, etc.). **Usage** : \n```\nif result.metadata:\n  print(\"Title:\", result.metadata.get(\"title\"))\n  print(\"Author:\", result.metadata.get(\"author\"))\n\n```\n\n## 6. `dispatch_result` (optional)\nA `DispatchResult` object providing additional concurrency and resource usage information when crawling URLs in parallel (e.g., via `arun_many()` with custom dispatchers). It contains:\n  * **`task_id`**: A unique identifier for the parallel task.\n  * **`memory_usage`**(float): The memory (in MB) used at the time of completion.\n  * **`peak_memory`**(float): The peak memory usage (in MB) recorded during the task\u2019s execution.\n  * **`start_time`**/**`end_time`**(datetime): Time range for this crawling task.\n  * **`error_message`**(str): Any dispatcher- or concurrency-related error encountered.\n\n\n```\n# Example usage:\nfor result in results:\n  if result.success and result.dispatch_result:\n    dr = result.dispatch_result\n    print(f\"URL: {result.url}, Task ID: {dr.task_id}\")\n    print(f\"Memory: {dr.memory_usage:.1f} MB (Peak: {dr.peak_memory:.1f} MB)\")\n    print(f\"Duration: {dr.end_time - dr.start_time}\")\n\n```\n\n> **Note** : This field is typically populated when using `arun_many(...)` alongside a **dispatcher** (e.g., `MemoryAdaptiveDispatcher` or `SemaphoreDispatcher`). If no concurrency or dispatcher is used, `dispatch_result` may remain `None`. \n## 7. Example: Accessing Everything\n```\nasync def handle_result(result: CrawlResult):\n  if not result.success:\n    print(\"Crawl error:\", result.error_message)\n    return\n  # Basic info\n  print(\"Crawled URL:\", result.url)\n  print(\"Status code:\", result.status_code)\n  # HTML\n  print(\"Original HTML size:\", len(result.html))\n  print(\"Cleaned HTML size:\", len(result.cleaned_html or \"\"))\n  # Markdown output\n  if result.markdown_v2:\n    print(\"Raw Markdown:\", result.markdown_v2.raw_markdown[:300])\n    print(\"Citations Markdown:\", result.markdown_v2.markdown_with_citations[:300])\n    if result.markdown_v2.fit_markdown:\n      print(\"Fit Markdown:\", result.markdown_v2.fit_markdown[:200])\n  else:\n    print(\"Raw Markdown (legacy):\", result.markdown[:200] if result.markdown else \"N/A\")\n  # Media & Links\n  if \"images\" in result.media:\n    print(\"Image count:\", len(result.media[\"images\"]))\n  if \"internal\" in result.links:\n    print(\"Internal link count:\", len(result.links[\"internal\"]))\n  # Extraction strategy result\n  if result.extracted_content:\n    print(\"Structured data:\", result.extracted_content)\n  # Screenshot/PDF\n  if result.screenshot:\n    print(\"Screenshot length:\", len(result.screenshot))\n  if result.pdf:\n    print(\"PDF bytes length:\", len(result.pdf))\n\n```\n\n## 8. Key Points & Future\n1. **`markdown_v2`vs`markdown`** - Right now, `markdown_v2` is the more robust container (`MarkdownGenerationResult`), providing **raw_markdown** , **markdown_with_citations** , references, plus possible **fit_markdown**. - In future versions, everything will unify under **`markdown`**. If you rely on advanced features (citations, fit content), check`markdown_v2`.\n2. **Fit Content** - **`fit_markdown`**and**`fit_html`**appear only if you used a content filter (like**PruningContentFilter** or **BM25ContentFilter**) inside your **MarkdownGenerationStrategy** or set them directly. - If no filter is used, they remain `None`.\n3. **References & Citations** - If you enable link citations in your `DefaultMarkdownGenerator` (`options={\"citations\": True}`), you\u2019ll see `markdown_with_citations` plus a **`references_markdown`**block. This helps large language models or academic-like referencing.\n4. **Links & Media** - `links[\"internal\"]` and `links[\"external\"]` group discovered anchors by domain. - `media[\"images\"]` / `[\"videos\"]` / `[\"audios\"]` store extracted media elements with optional scoring or context.\n5. **Error Cases** - If `success=False`, check `error_message` (e.g., timeouts, invalid URLs). - `status_code` might be `None` if we failed before an HTTP response.\nUse **`CrawlResult`**to glean all final outputs and feed them into your data pipelines, AI models, or archives. With the synergy of a properly configured**BrowserConfig** and **CrawlerRunConfig** , the crawler can produce robust, structured results here in **`CrawlResult`**.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun",
        "https://docs.crawl4ai.com/arun_many",
        "https://docs.crawl4ai.com/async-webcrawler",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/parameters",
        "https://docs.crawl4ai.com/strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 10,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:13",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "crawler-result.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/crawler-result",
      "timestamp": "2025-02-06T13:23:37.802018",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/crawler-result/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Crawler Result - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Crawler Result</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawl-result-and-output\">Crawl Result and Output</a></li>\n        <li><a href=\"#1-the-crawlresult-model\">1. The CrawlResult Model</a></li><li><a href=\"#2-html-variants\">2. HTML Variants</a></li><li><a href=\"#3-markdown-generation\">3. Markdown Generation</a></li><li><a href=\"#4-structured-extraction-extracted_content\">4. Structured Extraction: extracted_content</a></li><li><a href=\"#5-more-fields-links-media-and-more\">5. More Fields: Links, Media, and More</a></li><li><a href=\"#6-accessing-these-fields\">6. Accessing These Fields</a></li><li><a href=\"#7-next-steps\">7. Next Steps</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawl-result-and-output\">Crawl Result and Output</h1>\n<p>When you call <code>arun()</code> on a page, Crawl4AI returns a <strong><code>CrawlResult</code></strong> object containing everything you might need\u2014raw HTML, a cleaned version, optional screenshots or PDFs, structured extraction results, and more. This document explains those fields and how they map to different output types.  </p>\n<hr>\n<h2 id=\"1-the-crawlresult-model\">1. The <code>CrawlResult</code> Model</h2>\n<p>Below is the core schema. Each field captures a different aspect of the crawl\u2019s result:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MarkdownGenerationResult</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    raw_markdown: <span class=\"hljs-built_in\">str</span>\n    markdown_with_citations: <span class=\"hljs-built_in\">str</span>\n    references_markdown: <span class=\"hljs-built_in\">str</span>\n    fit_markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    fit_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CrawlResult</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    url: <span class=\"hljs-built_in\">str</span>\n    html: <span class=\"hljs-built_in\">str</span>\n    success: <span class=\"hljs-built_in\">bool</span>\n    cleaned_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    media: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    links: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    downloaded_files: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>]] = <span class=\"hljs-literal\">None</span>\n    screenshot: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    pdf : <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">bytes</span>] = <span class=\"hljs-literal\">None</span>\n    markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">Union</span>[<span class=\"hljs-built_in\">str</span>, MarkdownGenerationResult]] = <span class=\"hljs-literal\">None</span>\n    markdown_v2: <span class=\"hljs-type\">Optional</span>[MarkdownGenerationResult] = <span class=\"hljs-literal\">None</span>\n    extracted_content: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    metadata: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    error_message: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    session_id: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    response_headers: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    status_code: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>\n    ssl_certificate: <span class=\"hljs-type\">Optional</span>[SSLCertificate] = <span class=\"hljs-literal\">None</span>\n    <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Config</span>:\n        arbitrary_types_allowed = <span class=\"hljs-literal\">True</span>\n</code></pre></div>\n<h3 id=\"table-key-fields-in-crawlresult\">Table: Key Fields in <code>CrawlResult</code></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Field (Name &amp; Type)</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>url (<code>str</code>)</strong></td>\n<td>The final or actual URL crawled (in case of redirects).</td>\n</tr>\n<tr>\n<td><strong>html (<code>str</code>)</strong></td>\n<td>Original, unmodified page HTML. Good for debugging or custom processing.</td>\n</tr>\n<tr>\n<td><strong>success (<code>bool</code>)</strong></td>\n<td><code>True</code> if the crawl completed without major errors, else <code>False</code>.</td>\n</tr>\n<tr>\n<td><strong>cleaned_html (<code>Optional[str]</code>)</strong></td>\n<td>Sanitized HTML with scripts/styles removed; can exclude tags if configured via <code>excluded_tags</code> etc.</td>\n</tr>\n<tr>\n<td><strong>media (<code>Dict[str, List[Dict]]</code>)</strong></td>\n<td>Extracted media info (images, audio, etc.), each with attributes like <code>src</code>, <code>alt</code>, <code>score</code>, etc.</td>\n</tr>\n<tr>\n<td><strong>links (<code>Dict[str, List[Dict]]</code>)</strong></td>\n<td>Extracted link data, split by <code>internal</code> and <code>external</code>. Each link usually has <code>href</code>, <code>text</code>, etc.</td>\n</tr>\n<tr>\n<td><strong>downloaded_files (<code>Optional[List[str]]</code>)</strong></td>\n<td>If <code>accept_downloads=True</code> in <code>BrowserConfig</code>, this lists the filepaths of saved downloads.</td>\n</tr>\n<tr>\n<td><strong>screenshot (<code>Optional[str]</code>)</strong></td>\n<td>Screenshot of the page (base64-encoded) if <code>screenshot=True</code>.</td>\n</tr>\n<tr>\n<td><strong>pdf (<code>Optional[bytes]</code>)</strong></td>\n<td>PDF of the page if <code>pdf=True</code>.</td>\n</tr>\n<tr>\n<td><strong>markdown (<code>Optional[str or MarkdownGenerationResult]</code>)</strong></td>\n<td>For now, <code>markdown_v2</code> holds a <code>MarkdownGenerationResult</code>. Over time, this will be consolidated into <code>markdown</code>. The generator can provide raw markdown, citations, references, and optionally <code>fit_markdown</code>.</td>\n</tr>\n<tr>\n<td><strong>markdown_v2 (<code>Optional[MarkdownGenerationResult]</code>)</strong></td>\n<td>Legacy field for detailed markdown output. This will be replaced by <code>markdown</code> soon.</td>\n</tr>\n<tr>\n<td><strong>extracted_content (<code>Optional[str]</code>)</strong></td>\n<td>The output of a structured extraction (CSS/LLM-based) stored as JSON string or other text.</td>\n</tr>\n<tr>\n<td><strong>metadata (<code>Optional[dict]</code>)</strong></td>\n<td>Additional info about the crawl or extracted data.</td>\n</tr>\n<tr>\n<td><strong>error_message (<code>Optional[str]</code>)</strong></td>\n<td>If <code>success=False</code>, contains a short description of what went wrong.</td>\n</tr>\n<tr>\n<td><strong>session_id (<code>Optional[str]</code>)</strong></td>\n<td>The ID of the session used for multi-page or persistent crawling.</td>\n</tr>\n<tr>\n<td><strong>response_headers (<code>Optional[dict]</code>)</strong></td>\n<td>HTTP response headers, if captured.</td>\n</tr>\n<tr>\n<td><strong>status_code (<code>Optional[int]</code>)</strong></td>\n<td>HTTP status code (e.g., 200 for OK).</td>\n</tr>\n<tr>\n<td><strong>ssl_certificate (<code>Optional[SSLCertificate]</code>)</strong></td>\n<td>SSL certificate info if <code>fetch_ssl_certificate=True</code>.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"2-html-variants\">2. HTML Variants</h2>\n<h3 id=\"html-raw-html\"><code>html</code>: Raw HTML</h3>\n<p>Crawl4AI preserves the exact HTML as <code>result.html</code>. Useful for:</p>\n<ul>\n<li>Debugging page issues or checking the original content.</li>\n<li>Performing your own specialized parse if needed.</li>\n</ul>\n<h3 id=\"cleaned_html-sanitized\"><code>cleaned_html</code>: Sanitized</h3>\n<p>If you specify any cleanup or exclusion parameters in <code>CrawlerRunConfig</code> (like <code>excluded_tags</code>, <code>remove_forms</code>, etc.), you\u2019ll see the result here:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-lua\"><span class=\"hljs-built_in\">config</span> = CrawlerRunConfig(\n    excluded_tags=[<span class=\"hljs-string\">\"form\"</span>, <span class=\"hljs-string\">\"header\"</span>, <span class=\"hljs-string\">\"footer\"</span>],\n    keep_data_attributes=False\n)\nresult = await crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, <span class=\"hljs-built_in\">config</span>=<span class=\"hljs-built_in\">config</span>)\n<span class=\"hljs-built_in\">print</span>(result.cleaned_html)  # Freed of forms, header, footer, data-* attributes\n</code></pre></div>\n<hr>\n<h2 id=\"3-markdown-generation\">3. Markdown Generation</h2>\n<h3 id=\"31-markdown_v2-legacy-vs-markdown\">3.1 <code>markdown_v2</code> (Legacy) vs <code>markdown</code></h3>\n<ul>\n<li><strong><code>markdown_v2</code></strong>: The current location for detailed markdown output, returning a <strong><code>MarkdownGenerationResult</code></strong> object.  </li>\n<li><strong><code>markdown</code></strong>: Eventually, we\u2019re merging these fields. For now, you might see <code>result.markdown_v2</code> used widely in code examples.</li>\n</ul>\n<p><strong><code>MarkdownGenerationResult</code></strong> Fields:</p>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Field</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>raw_markdown</strong></td>\n<td>The basic HTML\u2192Markdown conversion.</td>\n</tr>\n<tr>\n<td><strong>markdown_with_citations</strong></td>\n<td>Markdown including inline citations that reference links at the end.</td>\n</tr>\n<tr>\n<td><strong>references_markdown</strong></td>\n<td>The references/citations themselves (if <code>citations=True</code>).</td>\n</tr>\n<tr>\n<td><strong>fit_markdown</strong></td>\n<td>The filtered/\u201cfit\u201d markdown if a content filter was used.</td>\n</tr>\n<tr>\n<td><strong>fit_html</strong></td>\n<td>The filtered HTML that generated <code>fit_markdown</code>.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"32-basic-example-with-a-markdown-generator\">3.2 Basic Example with a Markdown Generator</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\nconfig = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator(\n        options={<span class=\"hljs-string\">\"citations\"</span>: <span class=\"hljs-literal\">True</span>, <span class=\"hljs-string\">\"body_width\"</span>: <span class=\"hljs-number\">80</span>}  <span class=\"hljs-comment\"># e.g. pass html2text style options</span>\n    )\n)\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n\nmd_res = result.markdown_v2  <span class=\"hljs-comment\"># or eventually 'result.markdown'</span>\n<span class=\"hljs-built_in\">print</span>(md_res.raw_markdown[:<span class=\"hljs-number\">500</span>])\n<span class=\"hljs-built_in\">print</span>(md_res.markdown_with_citations)\n<span class=\"hljs-built_in\">print</span>(md_res.references_markdown)\n</code></pre></div>\n<p><strong>Note</strong>: If you use a filter like <code>PruningContentFilter</code>, you\u2019ll get <code>fit_markdown</code> and <code>fit_html</code> as well.</p>\n<hr>\n<h2 id=\"4-structured-extraction-extracted_content\">4. Structured Extraction: <code>extracted_content</code></h2>\n<p>If you run a JSON-based extraction strategy (CSS, XPath, LLM, etc.), the structured data is <strong>not</strong> stored in <code>markdown</code>\u2014it\u2019s placed in <strong><code>result.extracted_content</code></strong> as a JSON string (or sometimes plain text).</p>\n<h3 id=\"example-css-extraction-with-raw-html\">Example: CSS Extraction with <code>raw://</code> HTML</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Example Items\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.item\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n    raw_html = <span class=\"hljs-string\">\"&lt;div class='item'&gt;&lt;h2&gt;Item 1&lt;/h2&gt;&lt;a href='https://example.com/item1'&gt;Link 1&lt;/a&gt;&lt;/div&gt;\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"raw://\"</span> + raw_html,\n            config=CrawlerRunConfig(\n                cache_mode=CacheMode.BYPASS,\n                extraction_strategy=JsonCssExtractionStrategy(schema)\n            )\n        )\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(data)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p>Here:\n- <code>url=\"raw://...\"</code> passes the HTML content directly, no network requests.<br>\n- The <strong>CSS</strong> extraction strategy populates <code>result.extracted_content</code> with the JSON array <code>[{\"title\": \"...\", \"link\": \"...\"}]</code>.</p>\n<hr>\n<h2 id=\"5-more-fields-links-media-and-more\">5. More Fields: Links, Media, and More</h2>\n<h3 id=\"51-links\">5.1 <code>links</code></h3>\n<p>A dictionary, typically with <code>\"internal\"</code> and <code>\"external\"</code> lists. Each entry might have <code>href</code>, <code>text</code>, <code>title</code>, etc. This is automatically captured if you haven\u2019t disabled link extraction.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-built_in\">print</span>(result.links[<span class=\"hljs-string\">\"internal\"</span>][:3])  <span class=\"hljs-comment\"># Show first 3 internal links</span>\n</code></pre></div>\n<h3 id=\"52-media\">5.2 <code>media</code></h3>\n<p>Similarly, a dictionary with <code>\"images\"</code>, <code>\"audio\"</code>, <code>\"video\"</code>, etc. Each item could include <code>src</code>, <code>alt</code>, <code>score</code>, and more, if your crawler is set to gather them.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\">images = result.media.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"images\"</span>, [])\n<span class=\"hljs-keyword\">for</span> img <span class=\"hljs-keyword\">in</span> images:\n    print(<span class=\"hljs-string\">\"Image URL:\"</span>, img[<span class=\"hljs-string\">\"src\"</span>], <span class=\"hljs-string\">\"Alt:\"</span>, img.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"alt\"</span>))\n</code></pre></div>\n<h3 id=\"53-screenshot-and-pdf\">5.3 <code>screenshot</code> and <code>pdf</code></h3>\n<p>If you set <code>screenshot=True</code> or <code>pdf=True</code> in <strong><code>CrawlerRunConfig</code></strong>, then:</p>\n<ul>\n<li><code>result.screenshot</code> contains a base64-encoded PNG string.  </li>\n<li><code>result.pdf</code> contains raw PDF bytes (you can write them to a file).</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"page.pdf\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n    f.write(result.pdf)\n</code></pre></div>\n<h3 id=\"54-ssl_certificate\">5.4 <code>ssl_certificate</code></h3>\n<p>If <code>fetch_ssl_certificate=True</code>, <code>result.ssl_certificate</code> holds details about the site\u2019s SSL cert, such as issuer, validity dates, etc.</p>\n<hr>\n<h2 id=\"6-accessing-these-fields\">6. Accessing These Fields</h2>\n<p>After you run:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">result</span> = await crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=some_config)\n</code></pre></div>\n<p>Check any field:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">if result<span class=\"hljs-selector-class\">.success</span>:\n    <span class=\"hljs-built_in\">print</span>(result.status_code, result.response_headers)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Links found:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"internal\"</span>, [])))\n    if result.markdown_v2:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown snippet:\"</span>, result.markdown_v2.raw_markdown[:<span class=\"hljs-number\">200</span>])\n    if result.extracted_content:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Structured JSON:\"</span>, result.extracted_content)\nelse:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n</code></pre></div>\n<p><strong>Remember</strong>: Use <code>result.markdown_v2</code> for now. It will eventually become <code>result.markdown</code>.</p>\n<hr>\n<h2 id=\"7-next-steps\">7. Next Steps</h2>\n<ul>\n<li><strong>Markdown Generation</strong>: Dive deeper into how to configure <code>DefaultMarkdownGenerator</code> and various filters.  </li>\n<li><strong>Content Filtering</strong>: Learn how to use <code>BM25ContentFilter</code> and <code>PruningContentFilter</code>.</li>\n<li><strong>Session &amp; Hooks</strong>: If you want to manipulate the page or preserve state across multiple <code>arun()</code> calls, see the hooking or session docs.  </li>\n<li><strong>LLM Extraction</strong>: For complex or unstructured content requiring AI-driven parsing, check the LLM-based strategies doc.</li>\n</ul>\n<p><strong>Enjoy</strong> exploring all that <code>CrawlResult</code> offers\u2014whether you need raw HTML, sanitized output, markdown, or fully structured data, Crawl4AI has you covered!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Crawl Result and Output\nWhen you call `arun()` on a page, Crawl4AI returns a **`CrawlResult`**object containing everything you might need\u2014raw HTML, a cleaned version, optional screenshots or PDFs, structured extraction results, and more. This document explains those fields and how they map to different output types.\n## 1. The `CrawlResult` Model\nBelow is the core schema. Each field captures a different aspect of the crawl\u2019s result:\n```\nclass MarkdownGenerationResult(BaseModel):\n  raw_markdown: str\n  markdown_with_citations: str\n  references_markdown: str\n  fit_markdown: Optional[str] = None\n  fit_html: Optional[str] = None\nclass CrawlResult(BaseModel):\n  url: str\n  html: str\n  success: bool\n  cleaned_html: Optional[str] = None\n  media: Dict[str, List[Dict]] = {}\n  links: Dict[str, List[Dict]] = {}\n  downloaded_files: Optional[List[str]] = None\n  screenshot: Optional[str] = None\n  pdf : Optional[bytes] = None\n  markdown: Optional[Union[str, MarkdownGenerationResult]] = None\n  markdown_v2: Optional[MarkdownGenerationResult] = None\n  extracted_content: Optional[str] = None\n  metadata: Optional[dict] = None\n  error_message: Optional[str] = None\n  session_id: Optional[str] = None\n  response_headers: Optional[dict] = None\n  status_code: Optional[int] = None\n  ssl_certificate: Optional[SSLCertificate] = None\n  class Config:\n    arbitrary_types_allowed = True\n\n```\n\n### Table: Key Fields in `CrawlResult`\nField (Name & Type) | Description  \n---|---  \n**url (`str`)** | The final or actual URL crawled (in case of redirects).  \n**html (`str`)** | Original, unmodified page HTML. Good for debugging or custom processing.  \n**success (`bool`)** | `True` if the crawl completed without major errors, else `False`.  \n**cleaned_html (`Optional[str]`)** | Sanitized HTML with scripts/styles removed; can exclude tags if configured via `excluded_tags` etc.  \n**media (`Dict[str, List[Dict]]`)** | Extracted media info (images, audio, etc.), each with attributes like `src`, `alt`, `score`, etc.  \n**links (`Dict[str, List[Dict]]`)** | Extracted link data, split by `internal` and `external`. Each link usually has `href`, `text`, etc.  \n**downloaded_files (`Optional[List[str]]`)** | If `accept_downloads=True` in `BrowserConfig`, this lists the filepaths of saved downloads.  \n**screenshot (`Optional[str]`)** | Screenshot of the page (base64-encoded) if `screenshot=True`.  \n**pdf (`Optional[bytes]`)** | PDF of the page if `pdf=True`.  \n**markdown (`Optional[str or MarkdownGenerationResult]`)** | For now, `markdown_v2` holds a `MarkdownGenerationResult`. Over time, this will be consolidated into `markdown`. The generator can provide raw markdown, citations, references, and optionally `fit_markdown`.  \n**markdown_v2 (`Optional[MarkdownGenerationResult]`)** | Legacy field for detailed markdown output. This will be replaced by `markdown` soon.  \n**extracted_content (`Optional[str]`)** | The output of a structured extraction (CSS/LLM-based) stored as JSON string or other text.  \n**metadata (`Optional[dict]`)** | Additional info about the crawl or extracted data.  \n**error_message (`Optional[str]`)** | If `success=False`, contains a short description of what went wrong.  \n**session_id (`Optional[str]`)** | The ID of the session used for multi-page or persistent crawling.  \n**response_headers (`Optional[dict]`)** | HTTP response headers, if captured.  \n**status_code (`Optional[int]`)** | HTTP status code (e.g., 200 for OK).  \n**ssl_certificate (`Optional[SSLCertificate]`)** | SSL certificate info if `fetch_ssl_certificate=True`.  \n## 2. HTML Variants\n### `html`: Raw HTML\nCrawl4AI preserves the exact HTML as `result.html`. Useful for:\n  * Debugging page issues or checking the original content.\n  * Performing your own specialized parse if needed.\n\n\n### `cleaned_html`: Sanitized\nIf you specify any cleanup or exclusion parameters in `CrawlerRunConfig` (like `excluded_tags`, `remove_forms`, etc.), you\u2019ll see the result here:\n```\nconfig = CrawlerRunConfig(\n  excluded_tags=[\"form\", \"header\", \"footer\"],\n  keep_data_attributes=False\n)\nresult = await crawler.arun(\"https://example.com\", config=config)\nprint(result.cleaned_html) # Freed of forms, header, footer, data-* attributes\n\n```\n\n## 3. Markdown Generation\n### 3.1 `markdown_v2` (Legacy) vs `markdown`\n  * **`markdown_v2`**: The current location for detailed markdown output, returning a**`MarkdownGenerationResult`**object.\n  * **`markdown`**: Eventually, we\u2019re merging these fields. For now, you might see`result.markdown_v2` used widely in code examples.\n\n\n**`MarkdownGenerationResult`**Fields:\nField | Description  \n---|---  \n**raw_markdown** | The basic HTML\u2192Markdown conversion.  \n**markdown_with_citations** | Markdown including inline citations that reference links at the end.  \n**references_markdown** | The references/citations themselves (if `citations=True`).  \n**fit_markdown** | The filtered/\u201cfit\u201d markdown if a content filter was used.  \n**fit_html** | The filtered HTML that generated `fit_markdown`.  \n### 3.2 Basic Example with a Markdown Generator\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nconfig = CrawlerRunConfig(\n  markdown_generator=DefaultMarkdownGenerator(\n    options={\"citations\": True, \"body_width\": 80} # e.g. pass html2text style options\n  )\n)\nresult = await crawler.arun(url=\"https://example.com\", config=config)\nmd_res = result.markdown_v2 # or eventually 'result.markdown'\nprint(md_res.raw_markdown[:500])\nprint(md_res.markdown_with_citations)\nprint(md_res.references_markdown)\n\n```\n\n**Note** : If you use a filter like `PruningContentFilter`, you\u2019ll get `fit_markdown` and `fit_html` as well.\n## 4. Structured Extraction: `extracted_content`\nIf you run a JSON-based extraction strategy (CSS, XPath, LLM, etc.), the structured data is **not** stored in `markdown`\u2014it\u2019s placed in **`result.extracted_content`**as a JSON string (or sometimes plain text).\n### Example: CSS Extraction with `raw://` HTML\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  schema = {\n    \"name\": \"Example Items\",\n    \"baseSelector\": \"div.item\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  raw_html = \"<div class='item'><h2>Item 1</h2><a href='https://example.com/item1'>Link 1</a></div>\"\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"raw://\" + raw_html,\n      config=CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        extraction_strategy=JsonCssExtractionStrategy(schema)\n      )\n    )\n    data = json.loads(result.extracted_content)\n    print(data)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\nHere: - `url=\"raw://...\"` passes the HTML content directly, no network requests. - The **CSS** extraction strategy populates `result.extracted_content` with the JSON array `[{\"title\": \"...\", \"link\": \"...\"}]`.\n## 5. More Fields: Links, Media, and More\n### 5.1 `links`\nA dictionary, typically with `\"internal\"` and `\"external\"` lists. Each entry might have `href`, `text`, `title`, etc. This is automatically captured if you haven\u2019t disabled link extraction.\n```\nprint(result.links[\"internal\"][:3]) # Show first 3 internal links\n\n```\n\n### 5.2 `media`\nSimilarly, a dictionary with `\"images\"`, `\"audio\"`, `\"video\"`, etc. Each item could include `src`, `alt`, `score`, and more, if your crawler is set to gather them.\n```\nimages = result.media.get(\"images\", [])\nfor img in images:\n  print(\"Image URL:\", img[\"src\"], \"Alt:\", img.get(\"alt\"))\n\n```\n\n### 5.3 `screenshot` and `pdf`\nIf you set `screenshot=True` or `pdf=True` in **`CrawlerRunConfig`**, then:\n  * `result.screenshot` contains a base64-encoded PNG string. \n  * `result.pdf` contains raw PDF bytes (you can write them to a file).\n\n\n```\nwith open(\"page.pdf\", \"wb\") as f:\n  f.write(result.pdf)\n\n```\n\n### 5.4 `ssl_certificate`\nIf `fetch_ssl_certificate=True`, `result.ssl_certificate` holds details about the site\u2019s SSL cert, such as issuer, validity dates, etc.\n## 6. Accessing These Fields\nAfter you run:\n```\nresult = await crawler.arun(url=\"https://example.com\", config=some_config)\n\n```\n\nCheck any field:\n```\nif result.success:\n  print(result.status_code, result.response_headers)\n  print(\"Links found:\", len(result.links.get(\"internal\", [])))\n  if result.markdown_v2:\n    print(\"Markdown snippet:\", result.markdown_v2.raw_markdown[:200])\n  if result.extracted_content:\n    print(\"Structured JSON:\", result.extracted_content)\nelse:\n  print(\"Error:\", result.error_message)\n\n```\n\n**Remember** : Use `result.markdown_v2` for now. It will eventually become `result.markdown`.\n## 7. Next Steps\n  * **Markdown Generation** : Dive deeper into how to configure `DefaultMarkdownGenerator` and various filters. \n  * **Content Filtering** : Learn how to use `BM25ContentFilter` and `PruningContentFilter`.\n  * **Session & Hooks**: If you want to manipulate the page or preserve state across multiple `arun()` calls, see the hooking or session docs. \n  * **LLM Extraction** : For complex or unstructured content requiring AI-driven parsing, check the LLM-based strategies doc.\n\n\n**Enjoy** exploring all that `CrawlResult` offers\u2014whether you need raw HTML, sanitized output, markdown, or fully structured data, Crawl4AI has you covered!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 17,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:21",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "docker-deploymeny.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/docker-deploymeny",
      "timestamp": "2025-02-06T13:23:39.221168",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/docker-deploymeny/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Docker Deployment - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Docker Deployment</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#docker-deployment\">Docker Deployment</a></li>\n        <li><a href=\"#quick-start\">Quick Start \ud83d\ude80</a></li><li><a href=\"#running-with-docker-compose\">Running with Docker Compose \ud83d\udc33</a></li><li><a href=\"#api-security\">API Security \ud83d\udd12</a></li><li><a href=\"#configuration-options\">Configuration Options \ud83d\udd27</a></li><li><a href=\"#usage-examples\">Usage Examples \ud83d\udcdd</a></li><li><a href=\"#platform-specific-instructions\">Platform-Specific Instructions \ud83d\udcbb</a></li><li><a href=\"#testing\">Testing \ud83e\uddea</a></li><li><a href=\"#advanced-configuration\">Advanced Configuration \u2699\ufe0f</a></li><li><a href=\"#troubleshooting\">Troubleshooting \ud83d\udd0d</a></li><li><a href=\"#best-practices\">Best Practices \ud83c\udf1f</a></li><li><a href=\"#api-reference\">API Reference \ud83d\udcda</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"docker-deployment\">Docker Deployment</h1>\n<p>Crawl4AI provides official Docker images for easy deployment and scalability. This guide covers installation, configuration, and usage of Crawl4AI in Docker environments.</p>\n<h2 id=\"quick-start\">Quick Start \ud83d\ude80</h2>\n<p>Pull and run the basic version:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># Basic run without security</span>\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n\n<span class=\"hljs-comment\"># Run with API security enabled</span>\ndocker run -p 11235:11235 -e CRAWL4AI_API_TOKEN=your_secret_token unclecode/crawl4ai:basic\n</code></pre></div>\n<h2 id=\"running-with-docker-compose\">Running with Docker Compose \ud83d\udc33</h2>\n<h3 id=\"use-docker-compose-from-local-dockerfile-or-docker-hub\">Use Docker Compose (From Local Dockerfile or Docker Hub)</h3>\n<p>Crawl4AI provides flexibility to use Docker Compose for managing your containerized services. You can either build the image locally from the provided <code>Dockerfile</code> or use the pre-built image from Docker Hub.</p>\n<h3 id=\"option-1-using-docker-compose-to-build-locally\"><strong>Option 1: Using Docker Compose to Build Locally</strong></h3>\n<p>If you want to build the image locally, use the provided <code>docker-compose.local.yml</code> file.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-lua\">docker-compose -f docker-compose.<span class=\"hljs-keyword\">local</span>.yml up -d\n</code></pre></div>\n<p>This will:\n1. Build the Docker image from the provided <code>Dockerfile</code>.\n2. Start the container and expose it on <code>http://localhost:11235</code>.</p>\n<hr>\n<h3 id=\"option-2-using-docker-compose-with-pre-built-image-from-hub\"><strong>Option 2: Using Docker Compose with Pre-Built Image from Hub</strong></h3>\n<p>If you prefer using the pre-built image on Docker Hub, use the <code>docker-compose.hub.yml</code> file.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">docker-compose -f docker-compose.hub.yml up -d\n</code></pre></div>\n<p>This will:\n1. Pull the pre-built image <code>unclecode/crawl4ai:basic</code> (or <code>all</code>, depending on your configuration).\n2. Start the container and expose it on <code>http://localhost:11235</code>.</p>\n<hr>\n<h3 id=\"stopping-the-running-services\"><strong>Stopping the Running Services</strong></h3>\n<p>To stop the services started via Docker Compose, you can use:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker-compose -f docker-compose.local.yml down\n<span class=\"hljs-comment\"># OR</span>\ndocker-compose -f docker-compose.hub.yml down\n</code></pre></div>\n<p>If the containers don\u2019t stop and the application is still running, check the running containers:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">docker ps\n</code></pre></div>\n<p>Find the <code>CONTAINER ID</code> of the running service and stop it forcefully:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-php-template\"><span class=\"language-xml\">docker stop <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">CONTAINER_ID</span>&gt;</span>\n</span></code></pre></div>\n<hr>\n<h3 id=\"debugging-with-docker-compose\"><strong>Debugging with Docker Compose</strong></h3>\n<ul>\n<li>\n<p><strong>Check Logs</strong>: To view the container logs:\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-lua\">docker-compose -f docker-compose.<span class=\"hljs-keyword\">local</span>.yml logs -f\n</code></pre></div><p></p>\n</li>\n<li>\n<p><strong>Remove Orphaned Containers</strong>: If the service is still running unexpectedly:\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-lua\">docker-compose -f docker-compose.<span class=\"hljs-keyword\">local</span>.yml down <span class=\"hljs-comment\">--remove-orphans</span>\n</code></pre></div><p></p>\n</li>\n<li>\n<p><strong>Manually Remove Network</strong>: If the network is still in use:\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker network <span class=\"hljs-built_in\">ls</span>\ndocker network <span class=\"hljs-built_in\">rm</span> crawl4ai_default\n</code></pre></div><p></p>\n</li>\n</ul>\n<hr>\n<h3 id=\"why-use-docker-compose\">Why Use Docker Compose?</h3>\n<p>Docker Compose is the recommended way to deploy Crawl4AI because:\n1. It simplifies multi-container setups.\n2. Allows you to define environment variables, resources, and ports in a single file.\n3. Makes it easier to switch between local development and production-ready images.</p>\n<p>For example, your <code>docker-compose.yml</code> could include API keys, token settings, and memory limits, making deployment quick and consistent.</p>\n<h2 id=\"api-security\">API Security \ud83d\udd12</h2>\n<h3 id=\"understanding-crawl4ai_api_token\">Understanding CRAWL4AI_API_TOKEN</h3>\n<p>The <code>CRAWL4AI_API_TOKEN</code> provides optional security for your Crawl4AI instance:</p>\n<ul>\n<li>If <code>CRAWL4AI_API_TOKEN</code> is set: All API endpoints (except <code>/health</code>) require authentication</li>\n<li>If <code>CRAWL4AI_API_TOKEN</code> is not set: The API is publicly accessible</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># Secured Instance</span>\ndocker run -p 11235:11235 -e CRAWL4AI_API_TOKEN=your_secret_token unclecode/crawl4ai:all\n\n<span class=\"hljs-comment\"># Unsecured Instance</span>\ndocker run -p 11235:11235 unclecode/crawl4ai:all\n</code></pre></div>\n<h3 id=\"making-api-calls\">Making API Calls</h3>\n<p>For secured instances, include the token in all requests:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">import requests\n\n<span class=\"hljs-comment\"># Setup headers if token is being used</span>\napi_token = <span class=\"hljs-string\">\"your_secret_token\"</span>  <span class=\"hljs-comment\"># Same token set in CRAWL4AI_API_TOKEN</span>\nheaders = {<span class=\"hljs-string\">\"Authorization\"</span>: f<span class=\"hljs-string\">\"Bearer {api_token}\"</span>} if api_token <span class=\"hljs-keyword\">else</span> {}\n\n<span class=\"hljs-comment\"># Making authenticated requests</span>\nresponse = requests.post(\n    <span class=\"hljs-string\">\"http://localhost:11235/crawl\"</span>,\n    headers=headers,\n    json={\n        <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://example.com\"</span>,\n        <span class=\"hljs-string\">\"priority\"</span>: 10\n    }\n)\n\n<span class=\"hljs-comment\"># Checking task status</span>\ntask_id = response.json()[<span class=\"hljs-string\">\"task_id\"</span>]\nstatus = requests.get(\n    f<span class=\"hljs-string\">\"http://localhost:11235/task/{task_id}\"</span>,\n    headers=headers\n)\n</code></pre></div>\n<h3 id=\"using-with-docker-compose\">Using with Docker Compose</h3>\n<p>In your <code>docker-compose.yml</code>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-yaml\"><span class=\"hljs-attr\">services:</span>\n  <span class=\"hljs-attr\">crawl4ai:</span>\n    <span class=\"hljs-attr\">image:</span> <span class=\"hljs-string\">unclecode/crawl4ai:all</span>\n    <span class=\"hljs-attr\">environment:</span>\n      <span class=\"hljs-bullet\">-</span> <span class=\"hljs-string\">CRAWL4AI_API_TOKEN=${CRAWL4AI_API_TOKEN:-}</span>  <span class=\"hljs-comment\"># Optional</span>\n    <span class=\"hljs-comment\"># ... other configuration</span>\n</code></pre></div><p></p>\n<p>Then either:\n1. Set in <code>.env</code> file:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">CRAWL4AI_API_TOKEN</span>=your_secret_token\n</code></pre></div><p></p>\n<ol>\n<li>Or set via command line:\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">CRAWL4AI_API_TOKEN</span>=your_secret_token docker-compose up\n</code></pre></div></li>\n</ol>\n<blockquote>\n<p><strong>Security Note</strong>: If you enable the API token, make sure to keep it secure and never commit it to version control. The token will be required for all API endpoints except the health check endpoint (<code>/health</code>).</p>\n</blockquote>\n<h2 id=\"configuration-options\">Configuration Options \ud83d\udd27</h2>\n<h3 id=\"environment-variables\">Environment Variables</h3>\n<p>You can configure the service using environment variables:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># Basic configuration</span>\ndocker run -p 11235:11235 \\\n    -e MAX_CONCURRENT_TASKS=5 \\\n    unclecode/crawl4ai:all\n\n<span class=\"hljs-comment\"># With security and LLM support</span>\ndocker run -p 11235:11235 \\\n    -e CRAWL4AI_API_TOKEN=your_secret_token \\\n    -e OPENAI_API_KEY=sk-... \\\n    -e ANTHROPIC_API_KEY=sk-ant-... \\\n    unclecode/crawl4ai:all\n</code></pre></div>\n<h3 id=\"using-docker-compose-recommended\">Using Docker Compose (Recommended) \ud83d\udc33</h3>\n<p>Create a <code>docker-compose.yml</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ruby\"><span class=\"hljs-symbol\">version:</span> <span class=\"hljs-string\">'3.8'</span>\n\n<span class=\"hljs-symbol\">services:</span>\n  <span class=\"hljs-symbol\">crawl4ai:</span>\n    <span class=\"hljs-symbol\">image:</span> unclecode/<span class=\"hljs-symbol\">crawl4ai:</span>all\n    <span class=\"hljs-symbol\">ports:</span>\n      - <span class=\"hljs-string\">\"11235:11235\"</span>\n    <span class=\"hljs-symbol\">environment:</span>\n      - <span class=\"hljs-variable constant_\">CRAWL4AI_API_TOKEN</span>=<span class=\"hljs-variable\">${</span><span class=\"hljs-variable constant_\">CRAWL4AI_API_TOKEN</span><span class=\"hljs-symbol\">:-</span>}  <span class=\"hljs-comment\"># Optional API security</span>\n      - <span class=\"hljs-variable constant_\">MAX_CONCURRENT_TASKS</span>=<span class=\"hljs-number\">5</span>\n      <span class=\"hljs-comment\"># LLM Provider Keys</span>\n      - <span class=\"hljs-variable constant_\">OPENAI_API_KEY</span>=<span class=\"hljs-variable\">${</span><span class=\"hljs-variable constant_\">OPENAI_API_KEY</span><span class=\"hljs-symbol\">:-</span>}\n      - <span class=\"hljs-variable constant_\">ANTHROPIC_API_KEY</span>=<span class=\"hljs-variable\">${</span><span class=\"hljs-variable constant_\">ANTHROPIC_API_KEY</span><span class=\"hljs-symbol\">:-</span>}\n    <span class=\"hljs-symbol\">volumes:</span>\n      - <span class=\"hljs-regexp\">/dev/shm</span><span class=\"hljs-symbol\">:/dev/shm</span>\n    <span class=\"hljs-symbol\">deploy:</span>\n      <span class=\"hljs-symbol\">resources:</span>\n        <span class=\"hljs-symbol\">limits:</span>\n          <span class=\"hljs-symbol\">memory:</span> 4G\n        <span class=\"hljs-symbol\">reservations:</span>\n          <span class=\"hljs-symbol\">memory:</span> 1G\n</code></pre></div>\n<p>You can run it in two ways:</p>\n<ol>\n<li>\n<p>Using environment variables directly:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">CRAWL4AI_API_TOKEN</span>=secret123 OPENAI_API_KEY=sk-... docker-compose up\n</code></pre></div><p></p>\n</li>\n<li>\n<p>Using a <code>.env</code> file (recommended):\nCreate a <code>.env</code> file in the same directory:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-comment\"># API Security (optional)</span>\n<span class=\"hljs-attr\">CRAWL4AI_API_TOKEN</span>=your_secret_token\n\n<span class=\"hljs-comment\"># LLM Provider Keys</span>\n<span class=\"hljs-attr\">OPENAI_API_KEY</span>=sk-...\n<span class=\"hljs-attr\">ANTHROPIC_API_KEY</span>=sk-ant-...\n\n<span class=\"hljs-comment\"># Other Configuration</span>\n<span class=\"hljs-attr\">MAX_CONCURRENT_TASKS</span>=<span class=\"hljs-number\">5</span>\n</code></pre></div><p></p>\n</li>\n</ol>\n<p>Then simply run:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">docker-compose up\n</code></pre></div><p></p>\n<h3 id=\"testing-the-deployment\">Testing the Deployment \ud83e\uddea</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> requests\n\n<span class=\"hljs-comment\"># For unsecured instances</span>\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">test_unsecured</span>():\n    <span class=\"hljs-comment\"># Health check</span>\n    health = requests.get(<span class=\"hljs-string\">\"http://localhost:11235/health\"</span>)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Health check:\"</span>, health.json())\n\n    <span class=\"hljs-comment\"># Basic crawl</span>\n    response = requests.post(\n        <span class=\"hljs-string\">\"http://localhost:11235/crawl\"</span>,\n        json={\n            <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n            <span class=\"hljs-string\">\"priority\"</span>: <span class=\"hljs-number\">10</span>\n        }\n    )\n    task_id = response.json()[<span class=\"hljs-string\">\"task_id\"</span>]\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Task ID:\"</span>, task_id)\n\n<span class=\"hljs-comment\"># For secured instances</span>\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">test_secured</span>(<span class=\"hljs-params\">api_token</span>):\n    headers = {<span class=\"hljs-string\">\"Authorization\"</span>: <span class=\"hljs-string\">f\"Bearer <span class=\"hljs-subst\">{api_token}</span>\"</span>}\n\n    <span class=\"hljs-comment\"># Basic crawl with authentication</span>\n    response = requests.post(\n        <span class=\"hljs-string\">\"http://localhost:11235/crawl\"</span>,\n        headers=headers,\n        json={\n            <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n            <span class=\"hljs-string\">\"priority\"</span>: <span class=\"hljs-number\">10</span>\n        }\n    )\n    task_id = response.json()[<span class=\"hljs-string\">\"task_id\"</span>]\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Task ID:\"</span>, task_id)\n</code></pre></div>\n<h3 id=\"llm-extraction-example\">LLM Extraction Example \ud83e\udd16</h3>\n<p>When you've configured your LLM provider keys (via environment variables or <code>.env</code>), you can use LLM extraction:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">request = {\n    <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"extraction_config\"</span>: {\n        <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"llm\"</span>,\n        <span class=\"hljs-string\">\"params\"</span>: {\n            <span class=\"hljs-string\">\"provider\"</span>: <span class=\"hljs-string\">\"openai/gpt-4\"</span>,\n            <span class=\"hljs-string\">\"instruction\"</span>: <span class=\"hljs-string\">\"Extract main topics from the page\"</span>\n        }\n    }\n}\n\n<span class=\"hljs-comment\"># Make the request (add headers if using API security)</span>\nresponse = requests.post(<span class=\"hljs-string\">\"http://localhost:11235/crawl\"</span>, json=request)\n</code></pre></div>\n<blockquote>\n<p><strong>Note</strong>: Remember to add <code>.env</code> to your <code>.gitignore</code> to keep your API keys secure!</p>\n</blockquote>\n<h2 id=\"usage-examples\">Usage Examples \ud83d\udcdd</h2>\n<h3 id=\"basic-crawling\">Basic Crawling</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">request = {\n    <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n    <span class=\"hljs-string\">\"priority\"</span>: 10\n}\n\nresponse = requests.post(<span class=\"hljs-string\">\"http://localhost:11235/crawl\"</span>, json=request)\ntask_id = response.json()[<span class=\"hljs-string\">\"task_id\"</span>]\n\n<span class=\"hljs-comment\"># Get results</span>\nresult = requests.get(f<span class=\"hljs-string\">\"http://localhost:11235/task/{task_id}\"</span>)\n</code></pre></div>\n<h3 id=\"structured-data-extraction\">Structured Data Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\"><span class=\"hljs-keyword\">schema</span> <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Crypto Prices\"</span>,\n    <span class=\"hljs-string\">\"baseSelector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\".cds-tableRow-t45thuk\"</span>,\n    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"crypto\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"td:nth-child(1) h2\"</span>,\n            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>,\n        <span class=\"hljs-punctuation\">}</span>,\n        <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"price\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"td:nth-child(2)\"</span>,\n            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>,\n        <span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">]</span>,\n<span class=\"hljs-punctuation\">}</span>\n\nrequest <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://www.coinbase.com/explore\"</span>,\n    <span class=\"hljs-string\">\"extraction_config\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"json_css\"</span>,\n        <span class=\"hljs-string\">\"params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"schema\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-keyword\">schema</span><span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<h3 id=\"dynamic-content-handling\">Dynamic Content Handling</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">request = {\n    <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n    <span class=\"hljs-string\">\"js_code\"</span>: [\n        <span class=\"hljs-string\">\"const loadMoreButton = Array.from(document.querySelectorAll('button')).find(button =&gt; button.textContent.includes('Load More')); loadMoreButton &amp;&amp; loadMoreButton.click();\"</span>\n    ],\n    <span class=\"hljs-string\">\"wait_for\"</span>: <span class=\"hljs-string\">\"article.tease-card:nth-child(10)\"</span>\n}\n</code></pre></div>\n<h3 id=\"ai-powered-extraction-full-version\">AI-Powered Extraction (Full Version)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">request = {\n    <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n    <span class=\"hljs-string\">\"extraction_config\"</span>: {\n        <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"cosine\"</span>,\n        <span class=\"hljs-string\">\"params\"</span>: {\n            <span class=\"hljs-string\">\"semantic_filter\"</span>: <span class=\"hljs-string\">\"business finance economy\"</span>,\n            <span class=\"hljs-string\">\"word_count_threshold\"</span>: 10,\n            <span class=\"hljs-string\">\"max_dist\"</span>: 0.2,\n            <span class=\"hljs-string\">\"top_k\"</span>: 3\n        }\n    }\n}\n</code></pre></div>\n<h2 id=\"platform-specific-instructions\">Platform-Specific Instructions \ud83d\udcbb</h2>\n<h3 id=\"macos\">macOS</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n</code></pre></div>\n<h3 id=\"ubuntu\">Ubuntu</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># Basic version</span>\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n\n<span class=\"hljs-comment\"># With GPU support</span>\ndocker pull unclecode/crawl4ai:gpu\ndocker run --gpus all -p 11235:11235 unclecode/crawl4ai:gpu\n</code></pre></div>\n<h3 id=\"windows-powershell\">Windows (PowerShell)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n</code></pre></div>\n<h2 id=\"testing\">Testing \ud83e\uddea</h2>\n<p>Save this as <code>test_docker.py</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> requests\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> time\n<span class=\"hljs-keyword\">import</span> sys\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Crawl4AiTester</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, base_url: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">\"http://localhost:11235\"</span></span>):\n        self.base_url = base_url\n\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">submit_and_wait</span>(<span class=\"hljs-params\">self, request_data: <span class=\"hljs-built_in\">dict</span>, timeout: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">300</span></span>) -&gt; <span class=\"hljs-built_in\">dict</span>:\n        <span class=\"hljs-comment\"># Submit crawl job</span>\n        response = requests.post(<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.base_url}</span>/crawl\"</span>, json=request_data)\n        task_id = response.json()[<span class=\"hljs-string\">\"task_id\"</span>]\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Task ID: <span class=\"hljs-subst\">{task_id}</span>\"</span>)\n\n        <span class=\"hljs-comment\"># Poll for result</span>\n        start_time = time.time()\n        <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n            <span class=\"hljs-keyword\">if</span> time.time() - start_time &gt; timeout:\n                <span class=\"hljs-keyword\">raise</span> TimeoutError(<span class=\"hljs-string\">f\"Task <span class=\"hljs-subst\">{task_id}</span> timeout\"</span>)\n\n            result = requests.get(<span class=\"hljs-string\">f\"<span class=\"hljs-subst\">{self.base_url}</span>/task/<span class=\"hljs-subst\">{task_id}</span>\"</span>)\n            status = result.json()\n\n            <span class=\"hljs-keyword\">if</span> status[<span class=\"hljs-string\">\"status\"</span>] == <span class=\"hljs-string\">\"completed\"</span>:\n                <span class=\"hljs-keyword\">return</span> status\n\n            time.sleep(<span class=\"hljs-number\">2</span>)\n\n<span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">test_deployment</span>():\n    tester = Crawl4AiTester()\n\n    <span class=\"hljs-comment\"># Test basic crawl</span>\n    request = {\n        <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n        <span class=\"hljs-string\">\"priority\"</span>: <span class=\"hljs-number\">10</span>\n    }\n\n    result = tester.submit_and_wait(request)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Basic crawl successful!\"</span>)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Content length: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result[<span class=\"hljs-string\">'result'</span>][<span class=\"hljs-string\">'markdown'</span>])}</span>\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    test_deployment()\n</code></pre></div>\n<h2 id=\"advanced-configuration\">Advanced Configuration \u2699\ufe0f</h2>\n<h3 id=\"crawler-parameters\">Crawler Parameters</h3>\n<p>The <code>crawler_params</code> field allows you to configure the browser instance and crawling behavior. Here are key parameters you can use:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-comment\"># Browser Configuration</span>\n        <span class=\"hljs-string\">\"headless\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,                    <span class=\"hljs-comment\"># Run in headless mode</span>\n        <span class=\"hljs-string\">\"browser_type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"chromium\"</span>,          <span class=\"hljs-comment\"># chromium/firefox/webkit</span>\n        <span class=\"hljs-string\">\"user_agent\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"custom-agent\"</span>,        <span class=\"hljs-comment\"># Custom user agent</span>\n        <span class=\"hljs-string\">\"proxy\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"http://proxy:8080\"</span>,        <span class=\"hljs-comment\"># Proxy configuration</span>\n\n        <span class=\"hljs-comment\"># Performance &amp; Behavior</span>\n        <span class=\"hljs-string\">\"page_timeout\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">30000</span>,               <span class=\"hljs-comment\"># Page load timeout (ms)</span>\n        <span class=\"hljs-string\">\"verbose\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,                     <span class=\"hljs-comment\"># Enable detailed logging</span>\n        <span class=\"hljs-string\">\"semaphore_count\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">5</span>,               <span class=\"hljs-comment\"># Concurrent request limit</span>\n\n        <span class=\"hljs-comment\"># Anti-Detection Features</span>\n        <span class=\"hljs-string\">\"simulate_user\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,               <span class=\"hljs-comment\"># Simulate human behavior</span>\n        <span class=\"hljs-string\">\"magic\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,                       <span class=\"hljs-comment\"># Advanced anti-detection</span>\n        <span class=\"hljs-string\">\"override_navigator\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,          <span class=\"hljs-comment\"># Override navigator properties</span>\n\n        <span class=\"hljs-comment\"># Session Management</span>\n        <span class=\"hljs-string\">\"user_data_dir\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"./browser-data\"</span>,   <span class=\"hljs-comment\"># Browser profile location</span>\n        <span class=\"hljs-string\">\"use_managed_browser\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,         <span class=\"hljs-comment\"># Use persistent browser</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<h3 id=\"extra-parameters\">Extra Parameters</h3>\n<p>The <code>extra</code> field allows passing additional parameters directly to the crawler's <code>arun</code> function:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"extra\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"word_count_threshold\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">10</span>,          <span class=\"hljs-comment\"># Min words per block</span>\n        <span class=\"hljs-string\">\"only_text\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,                   <span class=\"hljs-comment\"># Extract only text</span>\n        <span class=\"hljs-string\">\"bypass_cache\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,                <span class=\"hljs-comment\"># Force fresh crawl</span>\n        <span class=\"hljs-string\">\"process_iframes\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># Include iframe content</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<h3 id=\"complete-examples\">Complete Examples</h3>\n<p>1.\u2000<strong>Advanced News Crawling</strong>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"headless\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"page_timeout\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">30000</span>,\n        <span class=\"hljs-string\">\"remove_overlay_elements\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>      <span class=\"hljs-comment\"># Remove popups</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"extra\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"word_count_threshold\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">50</span>,          <span class=\"hljs-comment\"># Longer content blocks</span>\n        <span class=\"hljs-string\">\"bypass_cache\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>                 <span class=\"hljs-comment\"># Fresh content</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"css_selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\".article-body\"</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div><p></p>\n<p>2.\u2000<strong>Anti-Detection Configuration</strong>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"simulate_user\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"magic\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"override_navigator\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"user_agent\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Mozilla/5.0 ...\"</span>,\n        <span class=\"hljs-string\">\"headers\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"Accept-Language\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"en-US,en;q=0.9\"</span>\n        <span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div><p></p>\n<p>3.\u2000<strong>LLM Extraction with Custom Parameters</strong>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://openai.com/pricing\"</span>,\n    <span class=\"hljs-string\">\"extraction_config\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"llm\"</span>,\n        <span class=\"hljs-string\">\"params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"provider\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"openai/gpt-4\"</span>,\n            <span class=\"hljs-string\">\"schema\"</span><span class=\"hljs-punctuation\">:</span> pricing_schema\n        <span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"verbose\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"page_timeout\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">60000</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"extra\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"word_count_threshold\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">1</span>,\n        <span class=\"hljs-string\">\"only_text\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div><p></p>\n<p>4.\u2000<strong>Session-Based Dynamic Content</strong>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"session_id\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"dynamic_session\"</span>,\n        <span class=\"hljs-string\">\"headless\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">False</span>,\n        <span class=\"hljs-string\">\"page_timeout\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">60000</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"js_code\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span><span class=\"hljs-punctuation\">]</span>,\n    <span class=\"hljs-string\">\"wait_for\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"js:() =&gt; document.querySelectorAll('.item').length &gt; 10\"</span>,\n    <span class=\"hljs-string\">\"extra\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"delay_before_return_html\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">2.0</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div><p></p>\n<p>5.\u2000<strong>Screenshot with Custom Timing</strong>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">request <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"urls\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"https://example.com\"</span>,\n    <span class=\"hljs-string\">\"screenshot\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n    <span class=\"hljs-string\">\"crawler_params\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"headless\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\">True</span>,\n        <span class=\"hljs-string\">\"screenshot_wait_for\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\".main-content\"</span>\n    <span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-string\">\"extra\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">{</span>\n        <span class=\"hljs-string\">\"delay_before_return_html\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">3.0</span>\n    <span class=\"hljs-punctuation\">}</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div><p></p>\n<h3 id=\"parameter-reference-table\">Parameter Reference Table</h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Category</th>\n<th>Parameter</th>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Browser</td>\n<td>headless</td>\n<td>bool</td>\n<td>Run browser in headless mode</td>\n</tr>\n<tr>\n<td>Browser</td>\n<td>browser_type</td>\n<td>str</td>\n<td>Browser engine selection</td>\n</tr>\n<tr>\n<td>Browser</td>\n<td>user_agent</td>\n<td>str</td>\n<td>Custom user agent string</td>\n</tr>\n<tr>\n<td>Network</td>\n<td>proxy</td>\n<td>str</td>\n<td>Proxy server URL</td>\n</tr>\n<tr>\n<td>Network</td>\n<td>headers</td>\n<td>dict</td>\n<td>Custom HTTP headers</td>\n</tr>\n<tr>\n<td>Timing</td>\n<td>page_timeout</td>\n<td>int</td>\n<td>Page load timeout (ms)</td>\n</tr>\n<tr>\n<td>Timing</td>\n<td>delay_before_return_html</td>\n<td>float</td>\n<td>Wait before capture</td>\n</tr>\n<tr>\n<td>Anti-Detection</td>\n<td>simulate_user</td>\n<td>bool</td>\n<td>Human behavior simulation</td>\n</tr>\n<tr>\n<td>Anti-Detection</td>\n<td>magic</td>\n<td>bool</td>\n<td>Advanced protection</td>\n</tr>\n<tr>\n<td>Session</td>\n<td>session_id</td>\n<td>str</td>\n<td>Browser session ID</td>\n</tr>\n<tr>\n<td>Session</td>\n<td>user_data_dir</td>\n<td>str</td>\n<td>Profile directory</td>\n</tr>\n<tr>\n<td>Content</td>\n<td>word_count_threshold</td>\n<td>int</td>\n<td>Minimum words per block</td>\n</tr>\n<tr>\n<td>Content</td>\n<td>only_text</td>\n<td>bool</td>\n<td>Text-only extraction</td>\n</tr>\n<tr>\n<td>Content</td>\n<td>process_iframes</td>\n<td>bool</td>\n<td>Include iframe content</td>\n</tr>\n<tr>\n<td>Debug</td>\n<td>verbose</td>\n<td>bool</td>\n<td>Detailed logging</td>\n</tr>\n<tr>\n<td>Debug</td>\n<td>log_console</td>\n<td>bool</td>\n<td>Browser console logs</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"troubleshooting\">Troubleshooting \ud83d\udd0d</h2>\n<h3 id=\"common-issues\">Common Issues</h3>\n<p>1.\u2000<strong>Connection Refused</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-javascript\"><span class=\"hljs-title class_\">Error</span>: <span class=\"hljs-title class_\">Connection</span> refused at <span class=\"hljs-attr\">localhost</span>:<span class=\"hljs-number\">11235</span>\n</code></pre></div>\n   Solution: Ensure the container is running and ports are properly mapped.<p></p>\n<p>2.\u2000<strong>Resource Limits</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-yaml\"><span class=\"hljs-attr\">Error:</span> <span class=\"hljs-literal\">No</span> <span class=\"hljs-string\">available</span> <span class=\"hljs-string\">slots</span>\n</code></pre></div>\n   Solution: Increase MAX_CONCURRENT_TASKS or container resources.<p></p>\n<p>3.\u2000<strong>GPU Access</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-javascript\"><span class=\"hljs-title class_\">Error</span>: <span class=\"hljs-variable constant_\">GPU</span> not found\n</code></pre></div>\n   Solution: Ensure proper NVIDIA drivers and use <code>--gpus all</code> flag.<p></p>\n<h3 id=\"debug-mode\">Debug Mode</h3>\n<p>Access container for debugging:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker run -it --entrypoint /bin/bash unclecode/crawl4ai:all\n</code></pre></div><p></p>\n<p>View container logs:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">docker logs <span class=\"hljs-selector-attr\">[container_id]</span>\n</code></pre></div><p></p>\n<h2 id=\"best-practices\">Best Practices \ud83c\udf1f</h2>\n<p>1.\u2000<strong>Resource Management</strong>\n   - Set appropriate memory and CPU limits\n   - Monitor resource usage via health endpoint\n   - Use basic version for simple crawling tasks</p>\n<p>2.\u2000<strong>Scaling</strong>\n   - Use multiple containers for high load\n   - Implement proper load balancing\n   - Monitor performance metrics</p>\n<p>3.\u2000<strong>Security</strong>\n   - Use environment variables for sensitive data\n   - Implement proper network isolation\n   - Regular security updates</p>\n<h2 id=\"api-reference\">API Reference \ud83d\udcda</h2>\n<h3 id=\"health-check\">Health Check</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">GET /health\n</code></pre></div>\n<h3 id=\"submit-crawl-task\">Submit Crawl Task</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">POST /crawl\nContent-Type: application/json\n\n{\n    <span class=\"hljs-string\">\"urls\"</span>: <span class=\"hljs-string\">\"string or array\"</span>,\n    <span class=\"hljs-string\">\"extraction_config\"</span>: {\n        <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"basic|llm|cosine|json_css\"</span>,\n        <span class=\"hljs-string\">\"params\"</span>: {}\n    },\n    <span class=\"hljs-string\">\"priority\"</span>: 1-10,\n    <span class=\"hljs-string\">\"ttl\"</span>: 3600\n}\n</code></pre></div>\n<h3 id=\"get-task-status\">Get Task Status</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">GET /task/{task_id}\n</code></pre></div>\n<p>For more details, visit the <a href=\"https://docs.crawl4ai.com/\">official documentation</a>.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Docker Deployment\nCrawl4AI provides official Docker images for easy deployment and scalability. This guide covers installation, configuration, and usage of Crawl4AI in Docker environments.\n## Quick Start \ud83d\ude80\nPull and run the basic version:\n```\n# Basic run without security\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n# Run with API security enabled\ndocker run -p 11235:11235 -e CRAWL4AI_API_TOKEN=your_secret_token unclecode/crawl4ai:basic\n\n```\n\n## Running with Docker Compose \ud83d\udc33\n### Use Docker Compose (From Local Dockerfile or Docker Hub)\nCrawl4AI provides flexibility to use Docker Compose for managing your containerized services. You can either build the image locally from the provided `Dockerfile` or use the pre-built image from Docker Hub.\n### **Option 1: Using Docker Compose to Build Locally**\nIf you want to build the image locally, use the provided `docker-compose.local.yml` file.\n```\ndocker-compose -f docker-compose.local.yml up -d\n\n```\n\nThis will: 1. Build the Docker image from the provided `Dockerfile`. 2. Start the container and expose it on `http://localhost:11235`.\n### **Option 2: Using Docker Compose with Pre-Built Image from Hub**\nIf you prefer using the pre-built image on Docker Hub, use the `docker-compose.hub.yml` file.\n```\ndocker-compose -f docker-compose.hub.yml up -d\n\n```\n\nThis will: 1. Pull the pre-built image `unclecode/crawl4ai:basic` (or `all`, depending on your configuration). 2. Start the container and expose it on `http://localhost:11235`.\n### **Stopping the Running Services**\nTo stop the services started via Docker Compose, you can use:\n```\ndocker-compose -f docker-compose.local.yml down\n# OR\ndocker-compose -f docker-compose.hub.yml down\n\n```\n\nIf the containers don\u2019t stop and the application is still running, check the running containers:\n```\ndocker ps\n\n```\n\nFind the `CONTAINER ID` of the running service and stop it forcefully:\n```\ndocker stop <CONTAINER_ID>\n\n```\n\n### **Debugging with Docker Compose**\n  * **Check Logs** : To view the container logs: \n```\ndocker-compose -f docker-compose.local.yml logs -f\n\n```\n\n  * **Remove Orphaned Containers** : If the service is still running unexpectedly: \n```\ndocker-compose -f docker-compose.local.yml down --remove-orphans\n\n```\n\n  * **Manually Remove Network** : If the network is still in use: \n```\ndocker network ls\ndocker network rm crawl4ai_default\n\n```\n\n\n\n### Why Use Docker Compose?\nDocker Compose is the recommended way to deploy Crawl4AI because: 1. It simplifies multi-container setups. 2. Allows you to define environment variables, resources, and ports in a single file. 3. Makes it easier to switch between local development and production-ready images.\nFor example, your `docker-compose.yml` could include API keys, token settings, and memory limits, making deployment quick and consistent.\n## API Security \ud83d\udd12\n### Understanding CRAWL4AI_API_TOKEN\nThe `CRAWL4AI_API_TOKEN` provides optional security for your Crawl4AI instance:\n  * If `CRAWL4AI_API_TOKEN` is set: All API endpoints (except `/health`) require authentication\n  * If `CRAWL4AI_API_TOKEN` is not set: The API is publicly accessible\n\n\n```\n# Secured Instance\ndocker run -p 11235:11235 -e CRAWL4AI_API_TOKEN=your_secret_token unclecode/crawl4ai:all\n# Unsecured Instance\ndocker run -p 11235:11235 unclecode/crawl4ai:all\n\n```\n\n### Making API Calls\nFor secured instances, include the token in all requests:\n```\nimport requests\n# Setup headers if token is being used\napi_token = \"your_secret_token\" # Same token set in CRAWL4AI_API_TOKEN\nheaders = {\"Authorization\": f\"Bearer {api_token}\"} if api_token else {}\n# Making authenticated requests\nresponse = requests.post(\n  \"http://localhost:11235/crawl\",\n  headers=headers,\n  json={\n    \"urls\": \"https://example.com\",\n    \"priority\": 10\n  }\n)\n# Checking task status\ntask_id = response.json()[\"task_id\"]\nstatus = requests.get(\n  f\"http://localhost:11235/task/{task_id}\",\n  headers=headers\n)\n\n```\n\n### Using with Docker Compose\nIn your `docker-compose.yml`: \n```\nservices:\n crawl4ai:\n  image: unclecode/crawl4ai:all\n  environment:\n   - CRAWL4AI_API_TOKEN=${CRAWL4AI_API_TOKEN:-} # Optional\n  # ... other configuration\n\n```\n\nThen either: 1. Set in `.env` file: \n```\nCRAWL4AI_API_TOKEN=your_secret_token\n\n```\n\n  1. Or set via command line: \n```\nCRAWL4AI_API_TOKEN=your_secret_token docker-compose up\n\n```\n\n\n\n> **Security Note** : If you enable the API token, make sure to keep it secure and never commit it to version control. The token will be required for all API endpoints except the health check endpoint (`/health`).\n## Configuration Options \ud83d\udd27\n### Environment Variables\nYou can configure the service using environment variables:\n```\n# Basic configuration\ndocker run -p 11235:11235 \\\n  -e MAX_CONCURRENT_TASKS=5 \\\n  unclecode/crawl4ai:all\n# With security and LLM support\ndocker run -p 11235:11235 \\\n  -e CRAWL4AI_API_TOKEN=your_secret_token \\\n  -e OPENAI_API_KEY=sk-... \\\n  -e ANTHROPIC_API_KEY=sk-ant-... \\\n  unclecode/crawl4ai:all\n\n```\n\n### Using Docker Compose (Recommended) \ud83d\udc33\nCreate a `docker-compose.yml`:\n```\nversion: '3.8'\nservices:\n crawl4ai:\n  image: unclecode/crawl4ai:all\n  ports:\n   - \"11235:11235\"\n  environment:\n   - CRAWL4AI_API_TOKEN=${CRAWL4AI_API_TOKEN:-} # Optional API security\n   - MAX_CONCURRENT_TASKS=5\n   # LLM Provider Keys\n   - OPENAI_API_KEY=${OPENAI_API_KEY:-}\n   - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}\n  volumes:\n   - /dev/shm:/dev/shm\n  deploy:\n   resources:\n    limits:\n     memory: 4G\n    reservations:\n     memory: 1G\n\n```\n\nYou can run it in two ways:\n  1. Using environment variables directly: \n```\nCRAWL4AI_API_TOKEN=secret123 OPENAI_API_KEY=sk-... docker-compose up\n\n```\n\n  2. Using a `.env` file (recommended): Create a `.env` file in the same directory: \n```\n# API Security (optional)\nCRAWL4AI_API_TOKEN=your_secret_token\n# LLM Provider Keys\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\n# Other Configuration\nMAX_CONCURRENT_TASKS=5\n\n```\n\n\n\nThen simply run: \n```\ndocker-compose up\n\n```\n\n### Testing the Deployment \ud83e\uddea\n```\nimport requests\n# For unsecured instances\ndef test_unsecured():\n  # Health check\n  health = requests.get(\"http://localhost:11235/health\")\n  print(\"Health check:\", health.json())\n  # Basic crawl\n  response = requests.post(\n    \"http://localhost:11235/crawl\",\n    json={\n      \"urls\": \"https://www.nbcnews.com/business\",\n      \"priority\": 10\n    }\n  )\n  task_id = response.json()[\"task_id\"]\n  print(\"Task ID:\", task_id)\n# For secured instances\ndef test_secured(api_token):\n  headers = {\"Authorization\": f\"Bearer {api_token}\"}\n  # Basic crawl with authentication\n  response = requests.post(\n    \"http://localhost:11235/crawl\",\n    headers=headers,\n    json={\n      \"urls\": \"https://www.nbcnews.com/business\",\n      \"priority\": 10\n    }\n  )\n  task_id = response.json()[\"task_id\"]\n  print(\"Task ID:\", task_id)\n\n```\n\n### LLM Extraction Example \ud83e\udd16\nWhen you've configured your LLM provider keys (via environment variables or `.env`), you can use LLM extraction:\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"extraction_config\": {\n    \"type\": \"llm\",\n    \"params\": {\n      \"provider\": \"openai/gpt-4\",\n      \"instruction\": \"Extract main topics from the page\"\n    }\n  }\n}\n# Make the request (add headers if using API security)\nresponse = requests.post(\"http://localhost:11235/crawl\", json=request)\n\n```\n\n> **Note** : Remember to add `.env` to your `.gitignore` to keep your API keys secure!\n## Usage Examples \ud83d\udcdd\n### Basic Crawling\n```\nrequest = {\n  \"urls\": \"https://www.nbcnews.com/business\",\n  \"priority\": 10\n}\nresponse = requests.post(\"http://localhost:11235/crawl\", json=request)\ntask_id = response.json()[\"task_id\"]\n# Get results\nresult = requests.get(f\"http://localhost:11235/task/{task_id}\")\n\n```\n\n### Structured Data Extraction\n```\nschema = {\n  \"name\": \"Crypto Prices\",\n  \"baseSelector\": \".cds-tableRow-t45thuk\",\n  \"fields\": [\n    {\n      \"name\": \"crypto\",\n      \"selector\": \"td:nth-child(1) h2\",\n      \"type\": \"text\",\n    },\n    {\n      \"name\": \"price\",\n      \"selector\": \"td:nth-child(2)\",\n      \"type\": \"text\",\n    }\n  ],\n}\nrequest = {\n  \"urls\": \"https://www.coinbase.com/explore\",\n  \"extraction_config\": {\n    \"type\": \"json_css\",\n    \"params\": {\"schema\": schema}\n  }\n}\n\n```\n\n### Dynamic Content Handling\n```\nrequest = {\n  \"urls\": \"https://www.nbcnews.com/business\",\n  \"js_code\": [\n    \"const loadMoreButton = Array.from(document.querySelectorAll('button')).find(button => button.textContent.includes('Load More')); loadMoreButton && loadMoreButton.click();\"\n  ],\n  \"wait_for\": \"article.tease-card:nth-child(10)\"\n}\n\n```\n\n### AI-Powered Extraction (Full Version)\n```\nrequest = {\n  \"urls\": \"https://www.nbcnews.com/business\",\n  \"extraction_config\": {\n    \"type\": \"cosine\",\n    \"params\": {\n      \"semantic_filter\": \"business finance economy\",\n      \"word_count_threshold\": 10,\n      \"max_dist\": 0.2,\n      \"top_k\": 3\n    }\n  }\n}\n\n```\n\n## Platform-Specific Instructions \ud83d\udcbb\n### macOS\n```\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n\n```\n\n### Ubuntu\n```\n# Basic version\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n# With GPU support\ndocker pull unclecode/crawl4ai:gpu\ndocker run --gpus all -p 11235:11235 unclecode/crawl4ai:gpu\n\n```\n\n### Windows (PowerShell)\n```\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n\n```\n\n## Testing \ud83e\uddea\nSave this as `test_docker.py`:\n```\nimport requests\nimport json\nimport time\nimport sys\nclass Crawl4AiTester:\n  def __init__(self, base_url: str = \"http://localhost:11235\"):\n    self.base_url = base_url\n  def submit_and_wait(self, request_data: dict, timeout: int = 300) -> dict:\n    # Submit crawl job\n    response = requests.post(f\"{self.base_url}/crawl\", json=request_data)\n    task_id = response.json()[\"task_id\"]\n    print(f\"Task ID: {task_id}\")\n    # Poll for result\n    start_time = time.time()\n    while True:\n      if time.time() - start_time > timeout:\n        raise TimeoutError(f\"Task {task_id} timeout\")\n      result = requests.get(f\"{self.base_url}/task/{task_id}\")\n      status = result.json()\n      if status[\"status\"] == \"completed\":\n        return status\n      time.sleep(2)\ndef test_deployment():\n  tester = Crawl4AiTester()\n  # Test basic crawl\n  request = {\n    \"urls\": \"https://www.nbcnews.com/business\",\n    \"priority\": 10\n  }\n  result = tester.submit_and_wait(request)\n  print(\"Basic crawl successful!\")\n  print(f\"Content length: {len(result['result']['markdown'])}\")\nif __name__ == \"__main__\":\n  test_deployment()\n\n```\n\n## Advanced Configuration \u2699\ufe0f\n### Crawler Parameters\nThe `crawler_params` field allows you to configure the browser instance and crawling behavior. Here are key parameters you can use:\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"crawler_params\": {\n    # Browser Configuration\n    \"headless\": True,          # Run in headless mode\n    \"browser_type\": \"chromium\",     # chromium/firefox/webkit\n    \"user_agent\": \"custom-agent\",    # Custom user agent\n    \"proxy\": \"http://proxy:8080\",    # Proxy configuration\n    # Performance & Behavior\n    \"page_timeout\": 30000,        # Page load timeout (ms)\n    \"verbose\": True,           # Enable detailed logging\n    \"semaphore_count\": 5,        # Concurrent request limit\n    # Anti-Detection Features\n    \"simulate_user\": True,        # Simulate human behavior\n    \"magic\": True,            # Advanced anti-detection\n    \"override_navigator\": True,     # Override navigator properties\n    # Session Management\n    \"user_data_dir\": \"./browser-data\",  # Browser profile location\n    \"use_managed_browser\": True,     # Use persistent browser\n  }\n}\n\n```\n\n### Extra Parameters\nThe `extra` field allows passing additional parameters directly to the crawler's `arun` function:\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"extra\": {\n    \"word_count_threshold\": 10,     # Min words per block\n    \"only_text\": True,          # Extract only text\n    \"bypass_cache\": True,        # Force fresh crawl\n    \"process_iframes\": True,       # Include iframe content\n  }\n}\n\n```\n\n### Complete Examples\n1. **Advanced News Crawling**\n```\nrequest = {\n  \"urls\": \"https://www.nbcnews.com/business\",\n  \"crawler_params\": {\n    \"headless\": True,\n    \"page_timeout\": 30000,\n    \"remove_overlay_elements\": True   # Remove popups\n  },\n  \"extra\": {\n    \"word_count_threshold\": 50,     # Longer content blocks\n    \"bypass_cache\": True         # Fresh content\n  },\n  \"css_selector\": \".article-body\"\n}\n\n```\n\n2. **Anti-Detection Configuration**\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"crawler_params\": {\n    \"simulate_user\": True,\n    \"magic\": True,\n    \"override_navigator\": True,\n    \"user_agent\": \"Mozilla/5.0 ...\",\n    \"headers\": {\n      \"Accept-Language\": \"en-US,en;q=0.9\"\n    }\n  }\n}\n\n```\n\n3. **LLM Extraction with Custom Parameters**\n```\nrequest = {\n  \"urls\": \"https://openai.com/pricing\",\n  \"extraction_config\": {\n    \"type\": \"llm\",\n    \"params\": {\n      \"provider\": \"openai/gpt-4\",\n      \"schema\": pricing_schema\n    }\n  },\n  \"crawler_params\": {\n    \"verbose\": True,\n    \"page_timeout\": 60000\n  },\n  \"extra\": {\n    \"word_count_threshold\": 1,\n    \"only_text\": True\n  }\n}\n\n```\n\n4. **Session-Based Dynamic Content**\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"crawler_params\": {\n    \"session_id\": \"dynamic_session\",\n    \"headless\": False,\n    \"page_timeout\": 60000\n  },\n  \"js_code\": [\"window.scrollTo(0, document.body.scrollHeight);\"],\n  \"wait_for\": \"js:() => document.querySelectorAll('.item').length > 10\",\n  \"extra\": {\n    \"delay_before_return_html\": 2.0\n  }\n}\n\n```\n\n5. **Screenshot with Custom Timing**\n```\nrequest = {\n  \"urls\": \"https://example.com\",\n  \"screenshot\": True,\n  \"crawler_params\": {\n    \"headless\": True,\n    \"screenshot_wait_for\": \".main-content\"\n  },\n  \"extra\": {\n    \"delay_before_return_html\": 3.0\n  }\n}\n\n```\n\n### Parameter Reference Table\nCategory | Parameter | Type | Description  \n---|---|---|---  \nBrowser | headless | bool | Run browser in headless mode  \nBrowser | browser_type | str | Browser engine selection  \nBrowser | user_agent | str | Custom user agent string  \nNetwork | proxy | str | Proxy server URL  \nNetwork | headers | dict | Custom HTTP headers  \nTiming | page_timeout | int | Page load timeout (ms)  \nTiming | delay_before_return_html | float | Wait before capture  \nAnti-Detection | simulate_user | bool | Human behavior simulation  \nAnti-Detection | magic | bool | Advanced protection  \nSession | session_id | str | Browser session ID  \nSession | user_data_dir | str | Profile directory  \nContent | word_count_threshold | int | Minimum words per block  \nContent | only_text | bool | Text-only extraction  \nContent | process_iframes | bool | Include iframe content  \nDebug | verbose | bool | Detailed logging  \nDebug | log_console | bool | Browser console logs  \n## Troubleshooting \ud83d\udd0d\n### Common Issues\n1. **Connection Refused**\n```\nError: Connection refused at localhost:11235\n\n```\n\nSolution: Ensure the container is running and ports are properly mapped. \n2. **Resource Limits**\n```\nError: No available slots\n\n```\n\nSolution: Increase MAX_CONCURRENT_TASKS or container resources. \n3. **GPU Access**\n```\nError: GPU not found\n\n```\n\nSolution: Ensure proper NVIDIA drivers and use `--gpus all` flag. \n### Debug Mode\nAccess container for debugging: \n```\ndocker run -it --entrypoint /bin/bash unclecode/crawl4ai:all\n\n```\n\nView container logs: \n```\ndocker logs [container_id]\n\n```\n\n## Best Practices \ud83c\udf1f\n1. **Resource Management** - Set appropriate memory and CPU limits - Monitor resource usage via health endpoint - Use basic version for simple crawling tasks\n2. **Scaling** - Use multiple containers for high load - Implement proper load balancing - Monitor performance metrics\n3. **Security** - Use environment variables for sensitive data - Implement proper network isolation - Regular security updates\n## API Reference \ud83d\udcda\n### Health Check\n```\nGET /health\n\n```\n\n### Submit Crawl Task\n```\nPOST /crawl\nContent-Type: application/json\n{\n  \"urls\": \"string or array\",\n  \"extraction_config\": {\n    \"type\": \"basic|llm|cosine|json_css\",\n    \"params\": {}\n  },\n  \"priority\": 1-10,\n  \"ttl\": 3600\n}\n\n```\n\n### Get Task Status\n```\nGET /task/{task_id}\n\n```\n\nFor more details, visit the [official documentation](https://docs.crawl4ai.com/core/<https:/docs.crawl4ai.com/>).\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 18,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:22",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "fit-markdown.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/fit-markdown",
      "timestamp": "2025-02-06T13:23:40.409839",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/fit-markdown/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Fit Markdown - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Fit Markdown</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#fit-markdown-with-pruning-bm25\">Fit Markdown with Pruning &amp; BM25</a></li>\n        <li><a href=\"#1-how-fit-markdown-works\">1. How \u201cFit Markdown\u201d Works</a></li><li><a href=\"#2-pruningcontentfilter\">2. PruningContentFilter</a></li><li><a href=\"#3-bm25contentfilter\">3. BM25ContentFilter</a></li><li><a href=\"#4-accessing-the-fit-output\">4. Accessing the \u201cFit\u201d Output</a></li><li><a href=\"#5-code-patterns-recap\">5. Code Patterns Recap</a></li><li><a href=\"#6-combining-with-word_count_threshold-exclusions\">6. Combining with \u201cword_count_threshold\u201d &amp; Exclusions</a></li><li><a href=\"#7-custom-filters\">7. Custom Filters</a></li><li><a href=\"#8-final-thoughts\">8. Final Thoughts</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"fit-markdown-with-pruning-bm25\">Fit Markdown with Pruning &amp; BM25</h1>\n<p><strong>Fit Markdown</strong> is a specialized <strong>filtered</strong> version of your page\u2019s markdown, focusing on the most relevant content. By default, Crawl4AI converts the entire HTML into a broad <strong>raw_markdown</strong>. With fit markdown, we apply a <strong>content filter</strong> algorithm (e.g., <strong>Pruning</strong> or <strong>BM25</strong>) to remove or rank low-value sections\u2014such as repetitive sidebars, shallow text blocks, or irrelevancies\u2014leaving a concise textual \u201ccore.\u201d</p>\n<hr>\n<h2 id=\"1-how-fit-markdown-works\">1. How \u201cFit Markdown\u201d Works</h2>\n<h3 id=\"11-the-content_filter\">1.1 The <code>content_filter</code></h3>\n<p>In <strong><code>CrawlerRunConfig</code></strong>, you can specify a <strong><code>content_filter</code></strong> to shape how content is pruned or ranked before final markdown generation. A filter\u2019s logic is applied <strong>before</strong> or <strong>during</strong> the HTML\u2192Markdown process, producing:</p>\n<ul>\n<li><strong><code>result.markdown_v2.raw_markdown</code></strong> (unfiltered)</li>\n<li><strong><code>result.markdown_v2.fit_markdown</code></strong> (filtered or \u201cfit\u201d version)</li>\n<li><strong><code>result.markdown_v2.fit_html</code></strong> (the corresponding HTML snippet that produced <code>fit_markdown</code>)</li>\n</ul>\n<blockquote>\n<p><strong>Note</strong>: We\u2019re currently storing the result in <code>markdown_v2</code>, but eventually we\u2019ll unify it as <code>result.markdown</code>.</p>\n</blockquote>\n<h3 id=\"12-common-filters\">1.2 Common Filters</h3>\n<p>1.\u2000<strong>PruningContentFilter</strong> \u2013 Scores each node by text density, link density, and tag importance, discarding those below a threshold.<br>\n2.\u2000<strong>BM25ContentFilter</strong> \u2013 Focuses on textual relevance using BM25 ranking, especially useful if you have a specific user query (e.g., \u201cmachine learning\u201d or \u201cfood nutrition\u201d).</p>\n<hr>\n<h2 id=\"2-pruningcontentfilter\">2. PruningContentFilter</h2>\n<p><strong>Pruning</strong> discards less relevant nodes based on <strong>text density, link density, and tag importance</strong>. It\u2019s a heuristic-based approach\u2014if certain sections appear too \u201cthin\u201d or too \u201cspammy,\u201d they\u2019re pruned.</p>\n<h3 id=\"21-usage-example\">2.1 Usage Example</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Step 1: Create a pruning filter</span>\n    prune_filter = PruningContentFilter(\n        <span class=\"hljs-comment\"># Lower \u2192 more content retained, higher \u2192 more content pruned</span>\n        threshold=<span class=\"hljs-number\">0.45</span>,           \n        <span class=\"hljs-comment\"># \"fixed\" or \"dynamic\"</span>\n        threshold_type=<span class=\"hljs-string\">\"dynamic\"</span>,  \n        <span class=\"hljs-comment\"># Ignore nodes with &lt;5 words</span>\n        min_word_threshold=<span class=\"hljs-number\">5</span>      \n    )\n\n    <span class=\"hljs-comment\"># Step 2: Insert it into a Markdown Generator</span>\n    md_generator = DefaultMarkdownGenerator(content_filter=prune_filter)\n\n    <span class=\"hljs-comment\"># Step 3: Pass it to CrawlerRunConfig</span>\n    config = CrawlerRunConfig(\n        markdown_generator=md_generator\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>, \n            config=config\n        )\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-comment\"># 'fit_markdown' is your pruned content, focusing on \"denser\" text</span>\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.markdown_v2.raw_markdown))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fit Markdown length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.markdown_v2.fit_markdown))\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"22-key-parameters\">2.2 Key Parameters</h3>\n<ul>\n<li><strong><code>min_word_threshold</code></strong> (int): If a block has fewer words than this, it\u2019s pruned.  </li>\n<li><strong><code>threshold_type</code></strong> (str):</li>\n<li><code>\"fixed\"</code> \u2192 each node must exceed <code>threshold</code> (0\u20131).  </li>\n<li><code>\"dynamic\"</code> \u2192 node scoring adjusts according to tag type, text/link density, etc.  </li>\n<li><strong><code>threshold</code></strong> (float, default ~0.48): The base or \u201canchor\u201d cutoff.  </li>\n</ul>\n<p><strong>Algorithmic Factors</strong>:</p>\n<ul>\n<li><strong>Text density</strong> \u2013 Encourages blocks that have a higher ratio of text to overall content.  </li>\n<li><strong>Link density</strong> \u2013 Penalizes sections that are mostly links.  </li>\n<li><strong>Tag importance</strong> \u2013 e.g., an <code>&lt;article&gt;</code> or <code>&lt;p&gt;</code> might be more important than a <code>&lt;div&gt;</code>.  </li>\n<li><strong>Structural context</strong> \u2013 If a node is deeply nested or in a suspected sidebar, it might be deprioritized.</li>\n</ul>\n<hr>\n<h2 id=\"3-bm25contentfilter\">3. BM25ContentFilter</h2>\n<p><strong>BM25</strong> is a classical text ranking algorithm often used in search engines. If you have a <strong>user query</strong> or rely on page metadata to derive a query, BM25 can identify which text chunks best match that query.</p>\n<h3 id=\"31-usage-example\">3.1 Usage Example</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> BM25ContentFilter\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1) A BM25 filter with a user query</span>\n    bm25_filter = BM25ContentFilter(\n        user_query=<span class=\"hljs-string\">\"startup fundraising tips\"</span>,\n        <span class=\"hljs-comment\"># Adjust for stricter or looser results</span>\n        bm25_threshold=<span class=\"hljs-number\">1.2</span>  \n    )\n\n    <span class=\"hljs-comment\"># 2) Insert into a Markdown Generator</span>\n    md_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\n\n    <span class=\"hljs-comment\"># 3) Pass to crawler config</span>\n    config = CrawlerRunConfig(\n        markdown_generator=md_generator\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>, \n            config=config\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fit Markdown (BM25 query-based):\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown_v2.fit_markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"32-parameters\">3.2 Parameters</h3>\n<ul>\n<li><strong><code>user_query</code></strong> (str, optional): E.g. <code>\"machine learning\"</code>. If blank, the filter tries to glean a query from page metadata.  </li>\n<li><strong><code>bm25_threshold</code></strong> (float, default 1.0):  </li>\n<li>Higher \u2192 fewer chunks but more relevant.  </li>\n<li>Lower \u2192 more inclusive.  </li>\n</ul>\n<blockquote>\n<p>In more advanced scenarios, you might see parameters like <code>use_stemming</code>, <code>case_sensitive</code>, or <code>priority_tags</code> to refine how text is tokenized or weighted.</p>\n</blockquote>\n<hr>\n<h2 id=\"4-accessing-the-fit-output\">4. Accessing the \u201cFit\u201d Output</h2>\n<p>After the crawl, your \u201cfit\u201d content is found in <strong><code>result.markdown_v2.fit_markdown</code></strong>. In future versions, it will be <strong><code>result.markdown.fit_markdown</code></strong>. Meanwhile:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">fit_md</span> = result.markdown_v2.fit_markdown\n<span class=\"hljs-attr\">fit_html</span> = result.markdown_v2.fit_html\n</code></pre></div>\n<p>If the content filter is <strong>BM25</strong>, you might see additional logic or references in <code>fit_markdown</code> that highlight relevant segments. If it\u2019s <strong>Pruning</strong>, the text is typically well-cleaned but not necessarily matched to a query.</p>\n<hr>\n<h2 id=\"5-code-patterns-recap\">5. Code Patterns Recap</h2>\n<h3 id=\"51-pruning\">5.1 Pruning</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">prune_filter = PruningContentFilter(\n    threshold=0.5,\n    threshold_type=<span class=\"hljs-string\">\"fixed\"</span>,\n    min_word_threshold=10\n)\nmd_generator = DefaultMarkdownGenerator(content_filter=prune_filter)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n<span class=\"hljs-comment\"># =&gt; result.markdown_v2.fit_markdown</span>\n</code></pre></div>\n<h3 id=\"52-bm25\">5.2 BM25</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">bm25_filter = BM25ContentFilter(\n    user_query=<span class=\"hljs-string\">\"health benefits fruit\"</span>,\n    bm25_threshold=1.2\n)\nmd_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n<span class=\"hljs-comment\"># =&gt; result.markdown_v2.fit_markdown</span>\n</code></pre></div>\n<hr>\n<h2 id=\"6-combining-with-word_count_threshold-exclusions\">6. Combining with \u201cword_count_threshold\u201d &amp; Exclusions</h2>\n<p>Remember you can also specify:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    word_count_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">10</span>,\n    excluded_tags<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"nav\"</span>, <span class=\"hljs-string\">\"footer\"</span>, <span class=\"hljs-string\">\"header\"</span><span class=\"hljs-punctuation\">]</span>,\n    exclude_external_links<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    markdown_generator<span class=\"hljs-punctuation\">=</span>DefaultMarkdownGenerator<span class=\"hljs-punctuation\">(</span>\n        content_filter<span class=\"hljs-punctuation\">=</span>PruningContentFilter<span class=\"hljs-punctuation\">(</span>threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">0.5</span><span class=\"hljs-punctuation\">)</span>\n    <span class=\"hljs-punctuation\">)</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>Thus, <strong>multi-level</strong> filtering occurs:</p>\n<ol>\n<li>The crawler\u2019s <code>excluded_tags</code> are removed from the HTML first.  </li>\n<li>The content filter (Pruning, BM25, or custom) prunes or ranks the remaining text blocks.  </li>\n<li>The final \u201cfit\u201d content is generated in <code>result.markdown_v2.fit_markdown</code>.</li>\n</ol>\n<hr>\n<h2 id=\"7-custom-filters\">7. Custom Filters</h2>\n<p>If you need a different approach (like a specialized ML model or site-specific heuristics), you can create a new class inheriting from <code>RelevantContentFilter</code> and implement <code>filter_content(html)</code>. Then inject it into your <strong>markdown generator</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> RelevantContentFilter\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyCustomFilter</span>(<span class=\"hljs-title class_ inherited__\">RelevantContentFilter</span>):\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">filter_content</span>(<span class=\"hljs-params\">self, html, min_word_threshold=<span class=\"hljs-literal\">None</span></span>):\n        <span class=\"hljs-comment\"># parse HTML, implement custom logic</span>\n        <span class=\"hljs-keyword\">return</span> [block <span class=\"hljs-keyword\">for</span> block <span class=\"hljs-keyword\">in</span> ... <span class=\"hljs-keyword\">if</span> ... some condition...]\n</code></pre></div>\n<p><strong>Steps</strong>:</p>\n<ol>\n<li>Subclass <code>RelevantContentFilter</code>.  </li>\n<li>Implement <code>filter_content(...)</code>.  </li>\n<li>Use it in your <code>DefaultMarkdownGenerator(content_filter=MyCustomFilter(...))</code>.</li>\n</ol>\n<hr>\n<h2 id=\"8-final-thoughts\">8. Final Thoughts</h2>\n<p><strong>Fit Markdown</strong> is a crucial feature for:</p>\n<ul>\n<li><strong>Summaries</strong>: Quickly get the important text from a cluttered page.  </li>\n<li><strong>Search</strong>: Combine with <strong>BM25</strong> to produce content relevant to a query.  </li>\n<li><strong>AI Pipelines</strong>: Filter out boilerplate so LLM-based extraction or summarization runs on denser text.</li>\n</ul>\n<p><strong>Key Points</strong>:\n- <strong>PruningContentFilter</strong>: Great if you just want the \u201cmeatiest\u201d text without a user query.<br>\n- <strong>BM25ContentFilter</strong>: Perfect for query-based extraction or searching.<br>\n- Combine with <strong><code>excluded_tags</code>, <code>exclude_external_links</code>, <code>word_count_threshold</code></strong> to refine your final \u201cfit\u201d text.<br>\n- Fit markdown ends up in <strong><code>result.markdown_v2.fit_markdown</code></strong>; eventually <strong><code>result.markdown.fit_markdown</code></strong> in future versions.</p>\n<p>With these tools, you can <strong>zero in</strong> on the text that truly matters, ignoring spammy or boilerplate content, and produce a concise, relevant \u201cfit markdown\u201d for your AI or data pipelines. Happy pruning and searching!</p>\n<ul>\n<li>Last Updated: 2025-01-01</li>\n</ul>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Fit Markdown with Pruning & BM25\n**Fit Markdown** is a specialized **filtered** version of your page\u2019s markdown, focusing on the most relevant content. By default, Crawl4AI converts the entire HTML into a broad **raw_markdown**. With fit markdown, we apply a **content filter** algorithm (e.g., **Pruning** or **BM25**) to remove or rank low-value sections\u2014such as repetitive sidebars, shallow text blocks, or irrelevancies\u2014leaving a concise textual \u201ccore.\u201d\n## 1. How \u201cFit Markdown\u201d Works\n### 1.1 The `content_filter`\nIn **`CrawlerRunConfig`**, you can specify a**`content_filter`**to shape how content is pruned or ranked before final markdown generation. A filter\u2019s logic is applied**before** or **during** the HTML\u2192Markdown process, producing:\n  * **`result.markdown_v2.raw_markdown`**(unfiltered)\n  * **`result.markdown_v2.fit_markdown`**(filtered or \u201cfit\u201d version)\n  * **`result.markdown_v2.fit_html`**(the corresponding HTML snippet that produced`fit_markdown`)\n\n\n> **Note** : We\u2019re currently storing the result in `markdown_v2`, but eventually we\u2019ll unify it as `result.markdown`.\n### 1.2 Common Filters\n1. **PruningContentFilter** \u2013 Scores each node by text density, link density, and tag importance, discarding those below a threshold. 2. **BM25ContentFilter** \u2013 Focuses on textual relevance using BM25 ranking, especially useful if you have a specific user query (e.g., \u201cmachine learning\u201d or \u201cfood nutrition\u201d).\n## 2. PruningContentFilter\n**Pruning** discards less relevant nodes based on **text density, link density, and tag importance**. It\u2019s a heuristic-based approach\u2014if certain sections appear too \u201cthin\u201d or too \u201cspammy,\u201d they\u2019re pruned.\n### 2.1 Usage Example\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nasync def main():\n  # Step 1: Create a pruning filter\n  prune_filter = PruningContentFilter(\n    # Lower \u2192 more content retained, higher \u2192 more content pruned\n    threshold=0.45,      \n    # \"fixed\" or \"dynamic\"\n    threshold_type=\"dynamic\", \n    # Ignore nodes with <5 words\n    min_word_threshold=5   \n  )\n  # Step 2: Insert it into a Markdown Generator\n  md_generator = DefaultMarkdownGenerator(content_filter=prune_filter)\n  # Step 3: Pass it to CrawlerRunConfig\n  config = CrawlerRunConfig(\n    markdown_generator=md_generator\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", \n      config=config\n    )\n    if result.success:\n      # 'fit_markdown' is your pruned content, focusing on \"denser\" text\n      print(\"Raw Markdown length:\", len(result.markdown_v2.raw_markdown))\n      print(\"Fit Markdown length:\", len(result.markdown_v2.fit_markdown))\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### 2.2 Key Parameters\n  * **`min_word_threshold`**(int): If a block has fewer words than this, it\u2019s pruned.\n  * **`threshold_type`**(str):\n  * `\"fixed\"` \u2192 each node must exceed `threshold` (0\u20131). \n  * `\"dynamic\"` \u2192 node scoring adjusts according to tag type, text/link density, etc. \n  * **`threshold`**(float, default ~0.48): The base or \u201canchor\u201d cutoff.\n\n\n**Algorithmic Factors** :\n  * **Text density** \u2013 Encourages blocks that have a higher ratio of text to overall content. \n  * **Link density** \u2013 Penalizes sections that are mostly links. \n  * **Tag importance** \u2013 e.g., an `<article>` or `<p>` might be more important than a `<div>`. \n  * **Structural context** \u2013 If a node is deeply nested or in a suspected sidebar, it might be deprioritized.\n\n\n## 3. BM25ContentFilter\n**BM25** is a classical text ranking algorithm often used in search engines. If you have a **user query** or rely on page metadata to derive a query, BM25 can identify which text chunks best match that query.\n### 3.1 Usage Example\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import BM25ContentFilter\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nasync def main():\n  # 1) A BM25 filter with a user query\n  bm25_filter = BM25ContentFilter(\n    user_query=\"startup fundraising tips\",\n    # Adjust for stricter or looser results\n    bm25_threshold=1.2 \n  )\n  # 2) Insert into a Markdown Generator\n  md_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\n  # 3) Pass to crawler config\n  config = CrawlerRunConfig(\n    markdown_generator=md_generator\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", \n      config=config\n    )\n    if result.success:\n      print(\"Fit Markdown (BM25 query-based):\")\n      print(result.markdown_v2.fit_markdown)\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### 3.2 Parameters\n  * **`user_query`**(str, optional): E.g.`\"machine learning\"`. If blank, the filter tries to glean a query from page metadata. \n  * **`bm25_threshold`**(float, default 1.0):\n  * Higher \u2192 fewer chunks but more relevant. \n  * Lower \u2192 more inclusive. \n\n\n> In more advanced scenarios, you might see parameters like `use_stemming`, `case_sensitive`, or `priority_tags` to refine how text is tokenized or weighted.\n## 4. Accessing the \u201cFit\u201d Output\nAfter the crawl, your \u201cfit\u201d content is found in **`result.markdown_v2.fit_markdown`**. In future versions, it will be**`result.markdown.fit_markdown`**. Meanwhile:\n```\nfit_md = result.markdown_v2.fit_markdown\nfit_html = result.markdown_v2.fit_html\n\n```\n\nIf the content filter is **BM25** , you might see additional logic or references in `fit_markdown` that highlight relevant segments. If it\u2019s **Pruning** , the text is typically well-cleaned but not necessarily matched to a query.\n## 5. Code Patterns Recap\n### 5.1 Pruning\n```\nprune_filter = PruningContentFilter(\n  threshold=0.5,\n  threshold_type=\"fixed\",\n  min_word_threshold=10\n)\nmd_generator = DefaultMarkdownGenerator(content_filter=prune_filter)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n# => result.markdown_v2.fit_markdown\n\n```\n\n### 5.2 BM25\n```\nbm25_filter = BM25ContentFilter(\n  user_query=\"health benefits fruit\",\n  bm25_threshold=1.2\n)\nmd_generator = DefaultMarkdownGenerator(content_filter=bm25_filter)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n# => result.markdown_v2.fit_markdown\n\n```\n\n## 6. Combining with \u201cword_count_threshold\u201d & Exclusions\nRemember you can also specify:\n```\nconfig = CrawlerRunConfig(\n  word_count_threshold=10,\n  excluded_tags=[\"nav\", \"footer\", \"header\"],\n  exclude_external_links=True,\n  markdown_generator=DefaultMarkdownGenerator(\n    content_filter=PruningContentFilter(threshold=0.5)\n  )\n)\n\n```\n\nThus, **multi-level** filtering occurs:\n  1. The crawler\u2019s `excluded_tags` are removed from the HTML first. \n  2. The content filter (Pruning, BM25, or custom) prunes or ranks the remaining text blocks. \n  3. The final \u201cfit\u201d content is generated in `result.markdown_v2.fit_markdown`.\n\n\n## 7. Custom Filters\nIf you need a different approach (like a specialized ML model or site-specific heuristics), you can create a new class inheriting from `RelevantContentFilter` and implement `filter_content(html)`. Then inject it into your **markdown generator** :\n```\nfrom crawl4ai.content_filter_strategy import RelevantContentFilter\nclass MyCustomFilter(RelevantContentFilter):\n  def filter_content(self, html, min_word_threshold=None):\n    # parse HTML, implement custom logic\n    return [block for block in ... if ... some condition...]\n\n```\n\n**Steps** :\n  1. Subclass `RelevantContentFilter`. \n  2. Implement `filter_content(...)`. \n  3. Use it in your `DefaultMarkdownGenerator(content_filter=MyCustomFilter(...))`.\n\n\n## 8. Final Thoughts\n**Fit Markdown** is a crucial feature for:\n  * **Summaries** : Quickly get the important text from a cluttered page. \n  * **Search** : Combine with **BM25** to produce content relevant to a query. \n  * **AI Pipelines** : Filter out boilerplate so LLM-based extraction or summarization runs on denser text.\n\n\n**Key Points** : - **PruningContentFilter** : Great if you just want the \u201cmeatiest\u201d text without a user query. - **BM25ContentFilter** : Perfect for query-based extraction or searching. - Combine with **`excluded_tags`,`exclude_external_links` , `word_count_threshold`** to refine your final \u201cfit\u201d text. - Fit markdown ends up in **`result.markdown_v2.fit_markdown`**; eventually**`result.markdown.fit_markdown`**in future versions.\nWith these tools, you can **zero in** on the text that truly matters, ignoring spammy or boilerplate content, and produce a concise, relevant \u201cfit markdown\u201d for your AI or data pipelines. Happy pruning and searching!\n  * Last Updated: 2025-01-01\n\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 19,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:24",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "hooks-auth.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/hooks-auth",
      "timestamp": "2025-02-06T13:06:18.650332",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/hooks-auth/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Hooks &amp; Auth - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Hooks &amp; Auth</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#hooks-auth-in-asyncwebcrawler\">Hooks &amp; Auth in AsyncWebCrawler</a></li>\n        <li><a href=\"#example-using-hooks-in-asyncwebcrawler\">Example: Using Hooks in AsyncWebCrawler</a></li><li><a href=\"#hook-lifecycle-summary\">Hook Lifecycle Summary</a></li><li><a href=\"#when-to-handle-authentication\">When to Handle Authentication</a></li><li><a href=\"#additional-considerations\">Additional Considerations</a></li><li><a href=\"#conclusion\">Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"hooks-auth-in-asyncwebcrawler\">Hooks &amp; Auth in AsyncWebCrawler</h1>\n<p>Crawl4AI\u2019s <strong>hooks</strong> let you customize the crawler at specific points in the pipeline:</p>\n<p>1.\u2000<strong><code>on_browser_created</code></strong> \u2013 After browser creation.<br>\n2.\u2000<strong><code>on_page_context_created</code></strong> \u2013 After a new context &amp; page are created.<br>\n3.\u2000<strong><code>before_goto</code></strong> \u2013 Just before navigating to a page.<br>\n4.\u2000<strong><code>after_goto</code></strong> \u2013 Right after navigation completes.<br>\n5.\u2000<strong><code>on_user_agent_updated</code></strong> \u2013 Whenever the user agent changes.<br>\n6.\u2000<strong><code>on_execution_started</code></strong> \u2013 Once custom JavaScript execution begins.<br>\n7.\u2000<strong><code>before_retrieve_html</code></strong> \u2013 Just before the crawler retrieves final HTML.<br>\n8.\u2000<strong><code>before_return_html</code></strong> \u2013 Right before returning the HTML content.</p>\n<p><strong>Important</strong>: Avoid heavy tasks in <code>on_browser_created</code> since you don\u2019t yet have a page context. If you need to <em>log in</em>, do so in <strong><code>on_page_context_created</code></strong>.</p>\n<blockquote>\n<p>note \"Important Hook Usage Warning\"\n    <strong>Avoid Misusing Hooks</strong>: Do not manipulate page objects in the wrong hook or at the wrong time, as it can crash the pipeline or produce incorrect results. A common mistake is attempting to handle authentication prematurely\u2014such as creating or closing pages in <code>on_browser_created</code>. </p>\n<p><strong>Use the Right Hook for Auth</strong>: If you need to log in or set tokens, use <code>on_page_context_created</code>. This ensures you have a valid page/context to work with, without disrupting the main crawling flow.</p>\n<p><strong>Identity-Based Crawling</strong>: For robust auth, consider identity-based crawling (or passing a session ID) to preserve state. Run your initial login steps in a separate, well-defined process, then feed that session to your main crawl\u2014rather than shoehorning complex authentication into early hooks. Check out <a href=\"../identity-based-crawling/\">Identity-Based Crawling</a> for more details.</p>\n<p><strong>Be Cautious</strong>: Overwriting or removing elements in the wrong hook can compromise the final crawl. Keep hooks focused on smaller tasks (like route filters, custom headers), and let your main logic (crawling, data extraction) proceed normally.</p>\n</blockquote>\n<p>Below is an example demonstration.</p>\n<hr>\n<h2 id=\"example-using-hooks-in-asyncwebcrawler\">Example: Using Hooks in AsyncWebCrawler</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> playwright.async_api <span class=\"hljs-keyword\">import</span> Page, BrowserContext\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\ud83d\udd17 Hooks Example: Demonstrating recommended usage\"</span>)\n\n    <span class=\"hljs-comment\"># 1) Configure the browser</span>\n    browser_config = BrowserConfig(\n        headless=<span class=\"hljs-literal\">True</span>,\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-comment\"># 2) Configure the crawler run</span>\n    crawler_run_config = CrawlerRunConfig(\n        js_code=<span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n        wait_for=<span class=\"hljs-string\">\"body\"</span>,\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-comment\"># 3) Create the crawler instance</span>\n    crawler = AsyncWebCrawler(config=browser_config)\n\n    <span class=\"hljs-comment\">#</span>\n    <span class=\"hljs-comment\"># Define Hook Functions</span>\n    <span class=\"hljs-comment\">#</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_browser_created</span>(<span class=\"hljs-params\">browser, **kwargs</span>):\n        <span class=\"hljs-comment\"># Called once the browser instance is created (but no pages or contexts yet)</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] on_browser_created - Browser created successfully!\"</span>)\n        <span class=\"hljs-comment\"># Typically, do minimal setup here if needed</span>\n        <span class=\"hljs-keyword\">return</span> browser\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_page_context_created</span>(<span class=\"hljs-params\">page: Page, context: BrowserContext, **kwargs</span>):\n        <span class=\"hljs-comment\"># Called right after a new page + context are created (ideal for auth or route config).</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] on_page_context_created - Setting up page &amp; context.\"</span>)\n\n        <span class=\"hljs-comment\"># Example 1: Route filtering (e.g., block images)</span>\n        <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">route_filter</span>(<span class=\"hljs-params\">route</span>):\n            <span class=\"hljs-keyword\">if</span> route.request.resource_type == <span class=\"hljs-string\">\"image\"</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[HOOK] Blocking image request: <span class=\"hljs-subst\">{route.request.url}</span>\"</span>)\n                <span class=\"hljs-keyword\">await</span> route.abort()\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-keyword\">await</span> route.continue_()\n\n        <span class=\"hljs-keyword\">await</span> context.route(<span class=\"hljs-string\">\"**\"</span>, route_filter)\n\n        <span class=\"hljs-comment\"># Example 2: (Optional) Simulate a login scenario</span>\n        <span class=\"hljs-comment\"># (We do NOT create or close pages here, just do quick steps if needed)</span>\n        <span class=\"hljs-comment\"># e.g., await page.goto(\"https://example.com/login\")</span>\n        <span class=\"hljs-comment\"># e.g., await page.fill(\"input[name='username']\", \"testuser\")</span>\n        <span class=\"hljs-comment\"># e.g., await page.fill(\"input[name='password']\", \"password123\")</span>\n        <span class=\"hljs-comment\"># e.g., await page.click(\"button[type='submit']\")</span>\n        <span class=\"hljs-comment\"># e.g., await page.wait_for_selector(\"#welcome\")</span>\n        <span class=\"hljs-comment\"># e.g., await context.add_cookies([...])</span>\n        <span class=\"hljs-comment\"># Then continue</span>\n\n        <span class=\"hljs-comment\"># Example 3: Adjust the viewport</span>\n        <span class=\"hljs-keyword\">await</span> page.set_viewport_size({<span class=\"hljs-string\">\"width\"</span>: <span class=\"hljs-number\">1080</span>, <span class=\"hljs-string\">\"height\"</span>: <span class=\"hljs-number\">600</span>})\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">before_goto</span>(<span class=\"hljs-params\">\n        page: Page, context: BrowserContext, url: <span class=\"hljs-built_in\">str</span>, **kwargs\n    </span>):\n        <span class=\"hljs-comment\"># Called before navigating to each URL.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[HOOK] before_goto - About to navigate: <span class=\"hljs-subst\">{url}</span>\"</span>)\n        <span class=\"hljs-comment\"># e.g., inject custom headers</span>\n        <span class=\"hljs-keyword\">await</span> page.set_extra_http_headers({\n            <span class=\"hljs-string\">\"Custom-Header\"</span>: <span class=\"hljs-string\">\"my-value\"</span>\n        })\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">after_goto</span>(<span class=\"hljs-params\">\n        page: Page, context: BrowserContext, \n        url: <span class=\"hljs-built_in\">str</span>, response, **kwargs\n    </span>):\n        <span class=\"hljs-comment\"># Called after navigation completes.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[HOOK] after_goto - Successfully loaded: <span class=\"hljs-subst\">{url}</span>\"</span>)\n        <span class=\"hljs-comment\"># e.g., wait for a certain element if we want to verify</span>\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-keyword\">await</span> page.wait_for_selector(<span class=\"hljs-string\">'.content'</span>, timeout=<span class=\"hljs-number\">1000</span>)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] Found .content element!\"</span>)\n        <span class=\"hljs-keyword\">except</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] .content not found, continuing anyway.\"</span>)\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_user_agent_updated</span>(<span class=\"hljs-params\">\n        page: Page, context: BrowserContext, \n        user_agent: <span class=\"hljs-built_in\">str</span>, **kwargs\n    </span>):\n        <span class=\"hljs-comment\"># Called whenever the user agent updates.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[HOOK] on_user_agent_updated - New user agent: <span class=\"hljs-subst\">{user_agent}</span>\"</span>)\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_execution_started</span>(<span class=\"hljs-params\">page: Page, context: BrowserContext, **kwargs</span>):\n        <span class=\"hljs-comment\"># Called after custom JavaScript execution begins.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] on_execution_started - JS code is running!\"</span>)\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">before_retrieve_html</span>(<span class=\"hljs-params\">page: Page, context: BrowserContext, **kwargs</span>):\n        <span class=\"hljs-comment\"># Called before final HTML retrieval.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[HOOK] before_retrieve_html - We can do final actions\"</span>)\n        <span class=\"hljs-comment\"># Example: Scroll again</span>\n        <span class=\"hljs-keyword\">await</span> page.evaluate(<span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>)\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">before_return_html</span>(<span class=\"hljs-params\">\n        page: Page, context: BrowserContext, html: <span class=\"hljs-built_in\">str</span>, **kwargs\n    </span>):\n        <span class=\"hljs-comment\"># Called just before returning the HTML in the result.</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[HOOK] before_return_html - HTML length: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(html)}</span>\"</span>)\n        <span class=\"hljs-keyword\">return</span> page\n\n    <span class=\"hljs-comment\">#</span>\n    <span class=\"hljs-comment\"># Attach Hooks</span>\n    <span class=\"hljs-comment\">#</span>\n\n    crawler.crawler_strategy.set_hook(<span class=\"hljs-string\">\"on_browser_created\"</span>, on_browser_created)\n    crawler.crawler_strategy.set_hook(\n        <span class=\"hljs-string\">\"on_page_context_created\"</span>, on_page_context_created\n    )\n    crawler.crawler_strategy.set_hook(<span class=\"hljs-string\">\"before_goto\"</span>, before_goto)\n    crawler.crawler_strategy.set_hook(<span class=\"hljs-string\">\"after_goto\"</span>, after_goto)\n    crawler.crawler_strategy.set_hook(\n        <span class=\"hljs-string\">\"on_user_agent_updated\"</span>, on_user_agent_updated\n    )\n    crawler.crawler_strategy.set_hook(\n        <span class=\"hljs-string\">\"on_execution_started\"</span>, on_execution_started\n    )\n    crawler.crawler_strategy.set_hook(\n        <span class=\"hljs-string\">\"before_retrieve_html\"</span>, before_retrieve_html\n    )\n    crawler.crawler_strategy.set_hook(\n        <span class=\"hljs-string\">\"before_return_html\"</span>, before_return_html\n    )\n\n    <span class=\"hljs-keyword\">await</span> crawler.start()\n\n    <span class=\"hljs-comment\"># 4) Run the crawler on an example page</span>\n    url = <span class=\"hljs-string\">\"https://example.com\"</span>\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(url, config=crawler_run_config)\n\n    <span class=\"hljs-keyword\">if</span> result.success:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\nCrawled URL:\"</span>, result.url)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"HTML length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.html))\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n    <span class=\"hljs-keyword\">await</span> crawler.close()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"hook-lifecycle-summary\">Hook Lifecycle Summary</h2>\n<p>1.\u2000<strong><code>on_browser_created</code></strong>:<br>\n   - Browser is up, but <strong>no</strong> pages or contexts yet.<br>\n   - Light setup only\u2014don\u2019t try to open or close pages here (that belongs in <code>on_page_context_created</code>).</p>\n<p>2.\u2000<strong><code>on_page_context_created</code></strong>:<br>\n   - Perfect for advanced <strong>auth</strong> or route blocking.<br>\n   - You have a <strong>page</strong> + <strong>context</strong> ready but haven\u2019t navigated to the target URL yet.</p>\n<p>3.\u2000<strong><code>before_goto</code></strong>:<br>\n   - Right before navigation. Typically used for setting <strong>custom headers</strong> or logging the target URL.</p>\n<p>4.\u2000<strong><code>after_goto</code></strong>:<br>\n   - After page navigation is done. Good place for verifying content or waiting on essential elements. </p>\n<p>5.\u2000<strong><code>on_user_agent_updated</code></strong>:<br>\n   - Whenever the user agent changes (for stealth or different UA modes).</p>\n<p>6.\u2000<strong><code>on_execution_started</code></strong>:<br>\n   - If you set <code>js_code</code> or run custom scripts, this runs once your JS is about to start.</p>\n<p>7.\u2000<strong><code>before_retrieve_html</code></strong>:<br>\n   - Just before the final HTML snapshot is taken. Often you do a final scroll or lazy-load triggers here.</p>\n<p>8.\u2000<strong><code>before_return_html</code></strong>:<br>\n   - The last hook before returning HTML to the <code>CrawlResult</code>. Good for logging HTML length or minor modifications.</p>\n<hr>\n<h2 id=\"when-to-handle-authentication\">When to Handle Authentication</h2>\n<p><strong>Recommended</strong>: Use <strong><code>on_page_context_created</code></strong> if you need to:</p>\n<ul>\n<li>Navigate to a login page or fill forms</li>\n<li>Set cookies or localStorage tokens</li>\n<li>Block resource routes to avoid ads</li>\n</ul>\n<p>This ensures the newly created context is under your control <strong>before</strong> <code>arun()</code> navigates to the main URL.</p>\n<hr>\n<h2 id=\"additional-considerations\">Additional Considerations</h2>\n<ul>\n<li><strong>Session Management</strong>: If you want multiple <code>arun()</code> calls to reuse a single session, pass <code>session_id=</code> in your <code>CrawlerRunConfig</code>. Hooks remain the same.  </li>\n<li><strong>Performance</strong>: Hooks can slow down crawling if they do heavy tasks. Keep them concise.  </li>\n<li><strong>Error Handling</strong>: If a hook fails, the overall crawl might fail. Catch exceptions or handle them gracefully.  </li>\n<li><strong>Concurrency</strong>: If you run <code>arun_many()</code>, each URL triggers these hooks in parallel. Ensure your hooks are thread/async-safe.</li>\n</ul>\n<hr>\n<h2 id=\"conclusion\">Conclusion</h2>\n<p>Hooks provide <strong>fine-grained</strong> control over:</p>\n<ul>\n<li><strong>Browser</strong> creation (light tasks only)</li>\n<li><strong>Page</strong> and <strong>context</strong> creation (auth, route blocking)</li>\n<li><strong>Navigation</strong> phases</li>\n<li><strong>Final HTML</strong> retrieval</li>\n</ul>\n<p>Follow the recommended usage:\n- <strong>Login</strong> or advanced tasks in <code>on_page_context_created</code><br>\n- <strong>Custom headers</strong> or logs in <code>before_goto</code> / <code>after_goto</code><br>\n- <strong>Scrolling</strong> or final checks in <code>before_retrieve_html</code> / <code>before_return_html</code></p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Hooks & Auth in AsyncWebCrawler\nCrawl4AI\u2019s **hooks** let you customize the crawler at specific points in the pipeline:\n1. **`on_browser_created`**\u2013 After browser creation. 2.**`on_page_context_created`**\u2013 After a new context & page are created. 3. **`before_goto`**\u2013 Just before navigating to a page. 4.**`after_goto`**\u2013 Right after navigation completes. 5.**`on_user_agent_updated`**\u2013 Whenever the user agent changes. 6.**`on_execution_started`**\u2013 Once custom JavaScript execution begins. 7.**`before_retrieve_html`**\u2013 Just before the crawler retrieves final HTML. 8.**`before_return_html`**\u2013 Right before returning the HTML content.\n**Important** : Avoid heavy tasks in `on_browser_created` since you don\u2019t yet have a page context. If you need to _log in_ , do so in **`on_page_context_created`**.\n> note \"Important Hook Usage Warning\" **Avoid Misusing Hooks** : Do not manipulate page objects in the wrong hook or at the wrong time, as it can crash the pipeline or produce incorrect results. A common mistake is attempting to handle authentication prematurely\u2014such as creating or closing pages in `on_browser_created`. \n> **Use the Right Hook for Auth** : If you need to log in or set tokens, use `on_page_context_created`. This ensures you have a valid page/context to work with, without disrupting the main crawling flow.\n> **Identity-Based Crawling** : For robust auth, consider identity-based crawling (or passing a session ID) to preserve state. Run your initial login steps in a separate, well-defined process, then feed that session to your main crawl\u2014rather than shoehorning complex authentication into early hooks. Check out [Identity-Based Crawling](https://docs.crawl4ai.com/advanced/<../identity-based-crawling/>) for more details.\n> **Be Cautious** : Overwriting or removing elements in the wrong hook can compromise the final crawl. Keep hooks focused on smaller tasks (like route filters, custom headers), and let your main logic (crawling, data extraction) proceed normally.\nBelow is an example demonstration.\n## Example: Using Hooks in AsyncWebCrawler\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom playwright.async_api import Page, BrowserContext\nasync def main():\n  print(\"\ud83d\udd17 Hooks Example: Demonstrating recommended usage\")\n  # 1) Configure the browser\n  browser_config = BrowserConfig(\n    headless=True,\n    verbose=True\n  )\n  # 2) Configure the crawler run\n  crawler_run_config = CrawlerRunConfig(\n    js_code=\"window.scrollTo(0, document.body.scrollHeight);\",\n    wait_for=\"body\",\n    cache_mode=CacheMode.BYPASS\n  )\n  # 3) Create the crawler instance\n  crawler = AsyncWebCrawler(config=browser_config)\n  #\n  # Define Hook Functions\n  #\n  async def on_browser_created(browser, **kwargs):\n    # Called once the browser instance is created (but no pages or contexts yet)\n    print(\"[HOOK] on_browser_created - Browser created successfully!\")\n    # Typically, do minimal setup here if needed\n    return browser\n  async def on_page_context_created(page: Page, context: BrowserContext, **kwargs):\n    # Called right after a new page + context are created (ideal for auth or route config).\n    print(\"[HOOK] on_page_context_created - Setting up page & context.\")\n    # Example 1: Route filtering (e.g., block images)\n    async def route_filter(route):\n      if route.request.resource_type == \"image\":\n        print(f\"[HOOK] Blocking image request: {route.request.url}\")\n        await route.abort()\n      else:\n        await route.continue_()\n    await context.route(\"**\", route_filter)\n    # Example 2: (Optional) Simulate a login scenario\n    # (We do NOT create or close pages here, just do quick steps if needed)\n    # e.g., await page.goto(\"https://example.com/login\")\n    # e.g., await page.fill(\"input[name='username']\", \"testuser\")\n    # e.g., await page.fill(\"input[name='password']\", \"password123\")\n    # e.g., await page.click(\"button[type='submit']\")\n    # e.g., await page.wait_for_selector(\"#welcome\")\n    # e.g., await context.add_cookies([...])\n    # Then continue\n    # Example 3: Adjust the viewport\n    await page.set_viewport_size({\"width\": 1080, \"height\": 600})\n    return page\n  async def before_goto(\n    page: Page, context: BrowserContext, url: str, **kwargs\n  ):\n    # Called before navigating to each URL.\n    print(f\"[HOOK] before_goto - About to navigate: {url}\")\n    # e.g., inject custom headers\n    await page.set_extra_http_headers({\n      \"Custom-Header\": \"my-value\"\n    })\n    return page\n  async def after_goto(\n    page: Page, context: BrowserContext, \n    url: str, response, **kwargs\n  ):\n    # Called after navigation completes.\n    print(f\"[HOOK] after_goto - Successfully loaded: {url}\")\n    # e.g., wait for a certain element if we want to verify\n    try:\n      await page.wait_for_selector('.content', timeout=1000)\n      print(\"[HOOK] Found .content element!\")\n    except:\n      print(\"[HOOK] .content not found, continuing anyway.\")\n    return page\n  async def on_user_agent_updated(\n    page: Page, context: BrowserContext, \n    user_agent: str, **kwargs\n  ):\n    # Called whenever the user agent updates.\n    print(f\"[HOOK] on_user_agent_updated - New user agent: {user_agent}\")\n    return page\n  async def on_execution_started(page: Page, context: BrowserContext, **kwargs):\n    # Called after custom JavaScript execution begins.\n    print(\"[HOOK] on_execution_started - JS code is running!\")\n    return page\n  async def before_retrieve_html(page: Page, context: BrowserContext, **kwargs):\n    # Called before final HTML retrieval.\n    print(\"[HOOK] before_retrieve_html - We can do final actions\")\n    # Example: Scroll again\n    await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n    return page\n  async def before_return_html(\n    page: Page, context: BrowserContext, html: str, **kwargs\n  ):\n    # Called just before returning the HTML in the result.\n    print(f\"[HOOK] before_return_html - HTML length: {len(html)}\")\n    return page\n  #\n  # Attach Hooks\n  #\n  crawler.crawler_strategy.set_hook(\"on_browser_created\", on_browser_created)\n  crawler.crawler_strategy.set_hook(\n    \"on_page_context_created\", on_page_context_created\n  )\n  crawler.crawler_strategy.set_hook(\"before_goto\", before_goto)\n  crawler.crawler_strategy.set_hook(\"after_goto\", after_goto)\n  crawler.crawler_strategy.set_hook(\n    \"on_user_agent_updated\", on_user_agent_updated\n  )\n  crawler.crawler_strategy.set_hook(\n    \"on_execution_started\", on_execution_started\n  )\n  crawler.crawler_strategy.set_hook(\n    \"before_retrieve_html\", before_retrieve_html\n  )\n  crawler.crawler_strategy.set_hook(\n    \"before_return_html\", before_return_html\n  )\n  await crawler.start()\n  # 4) Run the crawler on an example page\n  url = \"https://example.com\"\n  result = await crawler.arun(url, config=crawler_run_config)\n  if result.success:\n    print(\"\\nCrawled URL:\", result.url)\n    print(\"HTML length:\", len(result.html))\n  else:\n    print(\"Error:\", result.error_message)\n  await crawler.close()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## Hook Lifecycle Summary\n1. **`on_browser_created`**: - Browser is up, but**no** pages or contexts yet. - Light setup only\u2014don\u2019t try to open or close pages here (that belongs in `on_page_context_created`).\n2. **`on_page_context_created`**: - Perfect for advanced**auth** or route blocking. - You have a **page** + **context** ready but haven\u2019t navigated to the target URL yet.\n3. **`before_goto`**: - Right before navigation. Typically used for setting**custom headers** or logging the target URL.\n4. **`after_goto`**: - After page navigation is done. Good place for verifying content or waiting on essential elements.\n5. **`on_user_agent_updated`**: - Whenever the user agent changes (for stealth or different UA modes).\n6. **`on_execution_started`**: - If you set`js_code` or run custom scripts, this runs once your JS is about to start.\n7. **`before_retrieve_html`**: - Just before the final HTML snapshot is taken. Often you do a final scroll or lazy-load triggers here.\n8. **`before_return_html`**: - The last hook before returning HTML to the`CrawlResult`. Good for logging HTML length or minor modifications.\n## When to Handle Authentication\n**Recommended** : Use **`on_page_context_created`**if you need to:\n  * Navigate to a login page or fill forms\n  * Set cookies or localStorage tokens\n  * Block resource routes to avoid ads\n\n\nThis ensures the newly created context is under your control **before** `arun()` navigates to the main URL.\n## Additional Considerations\n  * **Session Management** : If you want multiple `arun()` calls to reuse a single session, pass `session_id=` in your `CrawlerRunConfig`. Hooks remain the same. \n  * **Performance** : Hooks can slow down crawling if they do heavy tasks. Keep them concise. \n  * **Error Handling** : If a hook fails, the overall crawl might fail. Catch exceptions or handle them gracefully. \n  * **Concurrency** : If you run `arun_many()`, each URL triggers these hooks in parallel. Ensure your hooks are thread/async-safe.\n\n\n## Conclusion\nHooks provide **fine-grained** control over:\n  * **Browser** creation (light tasks only)\n  * **Page** and **context** creation (auth, route blocking)\n  * **Navigation** phases\n  * **Final HTML** retrieval\n\n\nFollow the recommended usage: - **Login** or advanced tasks in `on_page_context_created` - **Custom headers** or logs in `before_goto` / `after_goto` - **Scrolling** or final checks in `before_retrieve_html` / `before_return_html`\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/session-management",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 2,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:03",
        "page_limit": 3
      }
    }
  },
  {
    "source_file": "identity-based-crawling.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/identity-based-crawling",
      "timestamp": "2025-02-06T13:06:19.854726",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/identity-based-crawling/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Identity Based Crawling - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Identity Based Crawling</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#preserve-your-identity-with-crawl4ai\">Preserve Your Identity with Crawl4AI</a></li>\n        <li><a href=\"#1-managed-browsers-your-digital-identity-solution\">1. Managed Browsers: Your Digital Identity Solution</a></li><li><a href=\"#3-using-managed-browsers-in-crawl4ai\">3. Using Managed Browsers in Crawl4AI</a></li><li><a href=\"#4-magic-mode-simplified-automation\">4. Magic Mode: Simplified Automation</a></li><li><a href=\"#5-comparing-managed-browsers-vs-magic-mode\">5. Comparing Managed Browsers vs. Magic Mode</a></li><li><a href=\"#6-summary\">6. Summary</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"preserve-your-identity-with-crawl4ai\">Preserve Your Identity with Crawl4AI</h1>\n<p>Crawl4AI empowers you to navigate and interact with the web using your <strong>authentic digital identity</strong>, ensuring you\u2019re recognized as a human and not mistaken for a bot. This tutorial covers:</p>\n<p>1.\u2000<strong>Managed Browsers</strong> \u2013 The recommended approach for persistent profiles and identity-based crawling.<br>\n2.\u2000<strong>Magic Mode</strong> \u2013 A simplified fallback solution for quick automation without persistent identity.</p>\n<hr>\n<h2 id=\"1-managed-browsers-your-digital-identity-solution\">1. Managed Browsers: Your Digital Identity Solution</h2>\n<p><strong>Managed Browsers</strong> let developers create and use <strong>persistent browser profiles</strong>. These profiles store local storage, cookies, and other session data, letting you browse as your <strong>real self</strong>\u2014complete with logins, preferences, and cookies.</p>\n<h3 id=\"key-benefits\">Key Benefits</h3>\n<ul>\n<li><strong>Authentic Browsing Experience</strong>: Retain session data and browser fingerprints as though you\u2019re a normal user.  </li>\n<li><strong>Effortless Configuration</strong>: Once you log in or solve CAPTCHAs in your chosen data directory, you can re-run crawls without repeating those steps.  </li>\n<li><strong>Empowered Data Access</strong>: If you can see the data in your own browser, you can automate its retrieval with your genuine identity.</li>\n</ul>\n<hr>\n<p>Below is a <strong>partial update</strong> to your <strong>Managed Browsers</strong> tutorial, specifically the section about <strong>creating a user-data directory</strong> using <strong>Playwright\u2019s Chromium</strong> binary rather than a system-wide Chrome/Edge. We\u2019ll show how to <strong>locate</strong> that binary and launch it with a <code>--user-data-dir</code> argument to set up your profile. You can then point <code>BrowserConfig.user_data_dir</code> to that folder for subsequent crawls.</p>\n<hr>\n<h3 id=\"creating-a-user-data-directory-command-line-approach-via-playwright\">Creating a User Data Directory (Command-Line Approach via Playwright)</h3>\n<p>If you installed Crawl4AI (which installs Playwright under the hood), you already have a Playwright-managed Chromium on your system. Follow these steps to launch that <strong>Chromium</strong> from your command line, specifying a <strong>custom</strong> data directory:</p>\n<p>1.\u2000<strong>Find</strong> the Playwright Chromium binary:\n   - On most systems, installed browsers go under a <code>~/.cache/ms-playwright/</code> folder or similar path.<br>\n   - To see an overview of installed browsers, run:\n     </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">python -m playwright install <span class=\"hljs-attr\">--dry-run</span>\n</code></pre></div>\n     or\n     <div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">playwright install <span class=\"hljs-attr\">--dry-run</span>\n</code></pre></div>\n     (depending on your environment). This shows where Playwright keeps Chromium.<p></p>\n<ul>\n<li>For instance, you might see a path like:\n     <div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome\n</code></pre></div>\n     on Linux, or a corresponding folder on macOS/Windows.</li>\n</ul>\n<p>2.\u2000<strong>Launch</strong> the Playwright Chromium binary with a <strong>custom</strong> user-data directory:\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-comment\"># Linux example</span>\n~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome \\\n    --user-data-dir=/home/&lt;you&gt;/my_chrome_profile\n</code></pre></div>\n   <div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-swift\"># macOS example (<span class=\"hljs-type\">Playwright</span>\u2019s <span class=\"hljs-keyword\">internal</span> binary)\n<span class=\"hljs-operator\">~/</span><span class=\"hljs-type\">Library</span><span class=\"hljs-regexp\">/Caches/</span>ms<span class=\"hljs-operator\">-</span>playwright<span class=\"hljs-regexp\">/chromium-1234/</span>chrome<span class=\"hljs-operator\">-</span>mac<span class=\"hljs-regexp\">/Chromium.app/</span><span class=\"hljs-type\">Contents</span><span class=\"hljs-regexp\">/MacOS/</span><span class=\"hljs-type\">Chromium</span> \\\n    <span class=\"hljs-operator\">--</span>user<span class=\"hljs-operator\">-</span>data<span class=\"hljs-operator\">-</span>dir<span class=\"hljs-operator\">=/</span><span class=\"hljs-type\">Users</span><span class=\"hljs-regexp\">/&lt;you&gt;/</span>my_chrome_profile\n</code></pre></div>\n   <div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-comment\"># Windows example (PowerShell/cmd)</span>\n<span class=\"hljs-string\">\"C:\\Users\\&lt;you&gt;\\AppData\\Local\\ms-playwright\\chromium-1234\\chrome-win\\chrome.exe\"</span> ^\n    --user-data-<span class=\"hljs-built_in\">dir</span>=<span class=\"hljs-string\">\"C:\\Users\\&lt;you&gt;\\my_chrome_profile\"</span>\n</code></pre></div><p></p>\n<p><strong>Replace</strong> the path with the actual subfolder indicated in your <code>ms-playwright</code> cache structure.<br>\n   - This <strong>opens</strong> a fresh Chromium with your new or existing data folder.<br>\n   - <strong>Log into</strong> any sites or configure your browser the way you want.<br>\n   - <strong>Close</strong> when done\u2014your profile data is saved in that folder.</p>\n<p>3.\u2000<strong>Use</strong> that folder in <strong><code>BrowserConfig.user_data_dir</code></strong>:\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\nbrowser_config = BrowserConfig(\n    headless=<span class=\"hljs-literal\">True</span>,\n    use_managed_browser=<span class=\"hljs-literal\">True</span>,\n    user_data_dir=<span class=\"hljs-string\">\"/home/&lt;you&gt;/my_chrome_profile\"</span>,\n    browser_type=<span class=\"hljs-string\">\"chromium\"</span>\n)\n</code></pre></div>\n   - Next time you run your code, it reuses that folder\u2014<strong>preserving</strong> your session data, cookies, local storage, etc.<p></p>\n<hr>\n<h2 id=\"3-using-managed-browsers-in-crawl4ai\">3. Using Managed Browsers in Crawl4AI</h2>\n<p>Once you have a data directory with your session data, pass it to <strong><code>BrowserConfig</code></strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1) Reference your persistent data directory</span>\n    browser_config = BrowserConfig(\n        headless=<span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># 'True' for automated runs</span>\n        verbose=<span class=\"hljs-literal\">True</span>,\n        use_managed_browser=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Enables persistent browser strategy</span>\n        browser_type=<span class=\"hljs-string\">\"chromium\"</span>,\n        user_data_dir=<span class=\"hljs-string\">\"/path/to/my-chrome-profile\"</span>\n    )\n\n    <span class=\"hljs-comment\"># 2) Standard crawl config</span>\n    crawl_config = CrawlerRunConfig(\n        wait_for=<span class=\"hljs-string\">\"css:.logged-in-content\"</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com/private\"</span>, config=crawl_config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Successfully accessed private data with your identity!\"</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"workflow\">Workflow</h3>\n<p>1.\u2000<strong>Login</strong> externally (via CLI or your normal Chrome with <code>--user-data-dir=...</code>).<br>\n2.\u2000<strong>Close</strong> that browser.<br>\n3.\u2000<strong>Use</strong> the same folder in <code>user_data_dir=</code> in Crawl4AI.<br>\n4.\u2000<strong>Crawl</strong> \u2013 The site sees your identity as if you\u2019re the same user who just logged in.</p>\n<hr>\n<h2 id=\"4-magic-mode-simplified-automation\">4. Magic Mode: Simplified Automation</h2>\n<p>If you <strong>don\u2019t</strong> need a persistent profile or identity-based approach, <strong>Magic Mode</strong> offers a quick way to simulate human-like browsing without storing long-term data.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n        url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n        config=CrawlerRunConfig(\n            magic=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Simplifies a lot of interaction</span>\n            remove_overlay_elements=<span class=\"hljs-literal\">True</span>,\n            page_timeout=<span class=\"hljs-number\">60000</span>\n        )\n    )\n</code></pre></div>\n<p><strong>Magic Mode</strong>:</p>\n<ul>\n<li>Simulates a user-like experience  </li>\n<li>Randomizes user agent &amp; navigator</li>\n<li>Randomizes interactions &amp; timings  </li>\n<li>Masks automation signals  </li>\n<li>Attempts pop-up handling  </li>\n</ul>\n<p><strong>But</strong> it\u2019s no substitute for <strong>true</strong> user-based sessions if you want a fully legitimate identity-based solution.</p>\n<hr>\n<h2 id=\"5-comparing-managed-browsers-vs-magic-mode\">5. Comparing Managed Browsers vs. Magic Mode</h2>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Feature</th>\n<th><strong>Managed Browsers</strong></th>\n<th><strong>Magic Mode</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Session Persistence</strong></td>\n<td>Full localStorage/cookies retained in user_data_dir</td>\n<td>No persistent data (fresh each run)</td>\n</tr>\n<tr>\n<td><strong>Genuine Identity</strong></td>\n<td>Real user profile with full rights &amp; preferences</td>\n<td>Emulated user-like patterns, but no actual identity</td>\n</tr>\n<tr>\n<td><strong>Complex Sites</strong></td>\n<td>Best for login-gated sites or heavy config</td>\n<td>Simple tasks, minimal login or config needed</td>\n</tr>\n<tr>\n<td><strong>Setup</strong></td>\n<td>External creation of user_data_dir, then use in Crawl4AI</td>\n<td>Single-line approach (<code>magic=True</code>)</td>\n</tr>\n<tr>\n<td><strong>Reliability</strong></td>\n<td>Extremely consistent (same data across runs)</td>\n<td>Good for smaller tasks, can be less stable</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"6-summary\">6. Summary</h2>\n<ul>\n<li><strong>Create</strong> your user-data directory by launching Chrome/Chromium externally with <code>--user-data-dir=/some/path</code>.  </li>\n<li><strong>Log in</strong> or configure sites as needed, then close the browser.  </li>\n<li><strong>Reference</strong> that folder in <code>BrowserConfig(user_data_dir=\"...\")</code> + <code>use_managed_browser=True</code>.  </li>\n<li>Enjoy <strong>persistent</strong> sessions that reflect your real identity.  </li>\n<li>If you only need quick, ephemeral automation, <strong>Magic Mode</strong> might suffice.</li>\n</ul>\n<p><strong>Recommended</strong>: Always prefer a <strong>Managed Browser</strong> for robust, identity-based crawling and simpler interactions with complex sites. Use <strong>Magic Mode</strong> for quick tasks or prototypes where persistent data is unnecessary.</p>\n<p>With these approaches, you preserve your <strong>authentic</strong> browsing environment, ensuring the site sees you exactly as a normal user\u2014no repeated logins or wasted time.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Preserve Your Identity with Crawl4AI\nCrawl4AI empowers you to navigate and interact with the web using your **authentic digital identity** , ensuring you\u2019re recognized as a human and not mistaken for a bot. This tutorial covers:\n1. **Managed Browsers** \u2013 The recommended approach for persistent profiles and identity-based crawling. 2. **Magic Mode** \u2013 A simplified fallback solution for quick automation without persistent identity.\n## 1. Managed Browsers: Your Digital Identity Solution\n**Managed Browsers** let developers create and use **persistent browser profiles**. These profiles store local storage, cookies, and other session data, letting you browse as your **real self** \u2014complete with logins, preferences, and cookies.\n### Key Benefits\n  * **Authentic Browsing Experience** : Retain session data and browser fingerprints as though you\u2019re a normal user. \n  * **Effortless Configuration** : Once you log in or solve CAPTCHAs in your chosen data directory, you can re-run crawls without repeating those steps. \n  * **Empowered Data Access** : If you can see the data in your own browser, you can automate its retrieval with your genuine identity.\n\n\nBelow is a **partial update** to your **Managed Browsers** tutorial, specifically the section about **creating a user-data directory** using **Playwright\u2019s Chromium** binary rather than a system-wide Chrome/Edge. We\u2019ll show how to **locate** that binary and launch it with a `--user-data-dir` argument to set up your profile. You can then point `BrowserConfig.user_data_dir` to that folder for subsequent crawls.\n### Creating a User Data Directory (Command-Line Approach via Playwright)\nIf you installed Crawl4AI (which installs Playwright under the hood), you already have a Playwright-managed Chromium on your system. Follow these steps to launch that **Chromium** from your command line, specifying a **custom** data directory:\n1. **Find** the Playwright Chromium binary: - On most systems, installed browsers go under a `~/.cache/ms-playwright/` folder or similar path. - To see an overview of installed browsers, run: \n```\npython -m playwright install --dry-run\n\n```\n\nor \n```\nplaywright install --dry-run\n\n```\n\n(depending on your environment). This shows where Playwright keeps Chromium. \n  * For instance, you might see a path like: \n```\n~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome\n\n```\n\non Linux, or a corresponding folder on macOS/Windows.\n\n\n2. **Launch** the Playwright Chromium binary with a **custom** user-data directory: \n```\n# Linux example\n~/.cache/ms-playwright/chromium-1234/chrome-linux/chrome \\\n  --user-data-dir=/home/<you>/my_chrome_profile\n\n```\n\n```\n# macOS example (Playwright\u2019s internal binary)\n~/Library/Caches/ms-playwright/chromium-1234/chrome-mac/Chromium.app/Contents/MacOS/Chromium \\\n  --user-data-dir=/Users/<you>/my_chrome_profile\n\n```\n\n```\n# Windows example (PowerShell/cmd)\n\"C:\\Users\\<you>\\AppData\\Local\\ms-playwright\\chromium-1234\\chrome-win\\chrome.exe\" ^\n  --user-data-dir=\"C:\\Users\\<you>\\my_chrome_profile\"\n\n```\n\n**Replace** the path with the actual subfolder indicated in your `ms-playwright` cache structure. - This **opens** a fresh Chromium with your new or existing data folder. - **Log into** any sites or configure your browser the way you want. - **Close** when done\u2014your profile data is saved in that folder.\n3. **Use** that folder in **`BrowserConfig.user_data_dir`**:\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nbrowser_config = BrowserConfig(\n  headless=True,\n  use_managed_browser=True,\n  user_data_dir=\"/home/<you>/my_chrome_profile\",\n  browser_type=\"chromium\"\n)\n\n```\n\n- Next time you run your code, it reuses that folder\u2014**preserving** your session data, cookies, local storage, etc. \n## 3. Using Managed Browsers in Crawl4AI\nOnce you have a data directory with your session data, pass it to **`BrowserConfig`**:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  # 1) Reference your persistent data directory\n  browser_config = BrowserConfig(\n    headless=True,       # 'True' for automated runs\n    verbose=True,\n    use_managed_browser=True, # Enables persistent browser strategy\n    browser_type=\"chromium\",\n    user_data_dir=\"/path/to/my-chrome-profile\"\n  )\n  # 2) Standard crawl config\n  crawl_config = CrawlerRunConfig(\n    wait_for=\"css:.logged-in-content\"\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    result = await crawler.arun(url=\"https://example.com/private\", config=crawl_config)\n    if result.success:\n      print(\"Successfully accessed private data with your identity!\")\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### Workflow\n1. **Login** externally (via CLI or your normal Chrome with `--user-data-dir=...`). 2. **Close** that browser. 3. **Use** the same folder in `user_data_dir=` in Crawl4AI. 4. **Crawl** \u2013 The site sees your identity as if you\u2019re the same user who just logged in.\n## 4. Magic Mode: Simplified Automation\nIf you **don\u2019t** need a persistent profile or identity-based approach, **Magic Mode** offers a quick way to simulate human-like browsing without storing long-term data.\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(\n    url=\"https://example.com\",\n    config=CrawlerRunConfig(\n      magic=True, # Simplifies a lot of interaction\n      remove_overlay_elements=True,\n      page_timeout=60000\n    )\n  )\n\n```\n\n**Magic Mode** :\n  * Simulates a user-like experience \n  * Randomizes user agent & navigator\n  * Randomizes interactions & timings \n  * Masks automation signals \n  * Attempts pop-up handling \n\n\n**But** it\u2019s no substitute for **true** user-based sessions if you want a fully legitimate identity-based solution.\n## 5. Comparing Managed Browsers vs. Magic Mode\nFeature | **Managed Browsers** | **Magic Mode**  \n---|---|---  \n**Session Persistence** | Full localStorage/cookies retained in user_data_dir | No persistent data (fresh each run)  \n**Genuine Identity** | Real user profile with full rights & preferences | Emulated user-like patterns, but no actual identity  \n**Complex Sites** | Best for login-gated sites or heavy config | Simple tasks, minimal login or config needed  \n**Setup** | External creation of user_data_dir, then use in Crawl4AI | Single-line approach (`magic=True`)  \n**Reliability** | Extremely consistent (same data across runs) | Good for smaller tasks, can be less stable  \n## 6. Summary\n  * **Create** your user-data directory by launching Chrome/Chromium externally with `--user-data-dir=/some/path`. \n  * **Log in** or configure sites as needed, then close the browser. \n  * **Reference** that folder in `BrowserConfig(user_data_dir=\"...\")` + `use_managed_browser=True`. \n  * Enjoy **persistent** sessions that reflect your real identity. \n  * If you only need quick, ephemeral automation, **Magic Mode** might suffice.\n\n\n**Recommended** : Always prefer a **Managed Browser** for robust, identity-based crawling and simpler interactions with complex sites. Use **Magic Mode** for quick tasks or prototypes where persistent data is unnecessary.\nWith these approaches, you preserve your **authentic** browsing environment, ensuring the site sees you exactly as a normal user\u2014no repeated logins or wasted time.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/session-management",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 3,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:04",
        "page_limit": 3
      }
    }
  },
  {
    "source_file": "installation.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/installation",
      "timestamp": "2025-02-06T13:23:41.547941",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/installation/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Installation - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Installation</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#installation-setup-2023-edition\">Installation &amp; Setup (2023 Edition)</a></li>\n        <li><a href=\"#1-basic-installation\">1. Basic Installation</a></li><li><a href=\"#2-initial-setup-diagnostics\">2. Initial Setup &amp; Diagnostics</a></li><li><a href=\"#3-verifying-installation-a-simple-crawl-skip-this-step-if-you-already-run-crawl4ai-doctor\">3. Verifying Installation: A Simple Crawl (Skip this step if you already run crawl4ai-doctor)</a></li><li><a href=\"#4-advanced-installation-optional\">4. Advanced Installation (Optional)</a></li><li><a href=\"#5-docker-experimental\">5. Docker (Experimental)</a></li><li><a href=\"#6-local-server-mode-legacy\">6. Local Server Mode (Legacy)</a></li><li><a href=\"#summary\">Summary</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"installation-setup-2023-edition\">Installation &amp; Setup (2023 Edition)</h1>\n<h2 id=\"1-basic-installation\">1. Basic Installation</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">pip install crawl4ai\n</code></pre></div>\n<p>This installs the <strong>core</strong> Crawl4AI library along with essential dependencies.\u2000<strong>No</strong> advanced features (like transformers or PyTorch) are included yet.</p>\n<h2 id=\"2-initial-setup-diagnostics\">2. Initial Setup &amp; Diagnostics</h2>\n<h3 id=\"21-run-the-setup-command\">2.1 Run the Setup Command</h3>\n<p>After installing, call:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">crawl4ai-setup\n</code></pre></div>\n<p><strong>What does it do?</strong>\n- Installs or updates required Playwright browsers (Chromium, Firefox, etc.)\n- Performs OS-level checks (e.g., missing libs on Linux)\n- Confirms your environment is ready to crawl</p>\n<h3 id=\"22-diagnostics\">2.2 Diagnostics</h3>\n<p>Optionally, you can run <strong>diagnostics</strong> to confirm everything is functioning:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">crawl4ai-doctor\n</code></pre></div>\n<p>This command attempts to:\n- Check Python version compatibility\n- Verify Playwright installation\n- Inspect environment variables or library conflicts</p>\n<p>If any issues arise, follow its suggestions (e.g., installing additional system packages) and re-run <code>crawl4ai-setup</code>.</p>\n<hr>\n<h2 id=\"3-verifying-installation-a-simple-crawl-skip-this-step-if-you-already-run-crawl4ai-doctor\">3. Verifying Installation: A Simple Crawl (Skip this step if you already run <code>crawl4ai-doctor</code>)</h2>\n<p>Below is a minimal Python script demonstrating a <strong>basic</strong> crawl. It uses our new <strong><code>BrowserConfig</code></strong> and <strong><code>CrawlerRunConfig</code></strong> for clarity, though no custom settings are passed in this example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://www.example.com\"</span>,\n        )\n        <span class=\"hljs-built_in\">print</span>(result.markdown[:<span class=\"hljs-number\">300</span>])  <span class=\"hljs-comment\"># Show the first 300 characters of extracted text</span>\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Expected</strong> outcome:\n- A headless browser session loads <code>example.com</code>\n- Crawl4AI returns ~300 characters of markdown.<br>\nIf errors occur, rerun <code>crawl4ai-doctor</code> or manually ensure Playwright is installed correctly.</p>\n<hr>\n<h2 id=\"4-advanced-installation-optional\">4. Advanced Installation (Optional)</h2>\n<p><strong>Warning</strong>: Only install these <strong>if you truly need them</strong>. They bring in larger dependencies, including big models, which can increase disk usage and memory load significantly.</p>\n<h3 id=\"41-torch-transformers-or-all\">4.1 Torch, Transformers, or All</h3>\n<ul>\n<li>\n<p><strong>Text Clustering (Torch)</strong><br>\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">pip install crawl4ai<span class=\"hljs-selector-attr\">[torch]</span>\ncrawl4ai-setup\n</code></pre></div>\n  Installs PyTorch-based features (e.g., cosine similarity or advanced semantic chunking).<p></p>\n</li>\n<li>\n<p><strong>Transformers</strong><br>\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">pip install crawl4ai<span class=\"hljs-selector-attr\">[transformer]</span>\ncrawl4ai-setup\n</code></pre></div>\n  Adds Hugging Face-based summarization or generation strategies.<p></p>\n</li>\n<li>\n<p><strong>All Features</strong><br>\n  </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">pip install crawl4ai<span class=\"hljs-selector-attr\">[all]</span>\ncrawl4ai-setup\n</code></pre></div><p></p>\n</li>\n</ul>\n<h4 id=\"optional-pre-fetching-models\">(Optional) Pre-Fetching Models</h4>\n<p></p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-undefined\">crawl4ai-download-models\n</code></pre></div>\nThis step caches large models locally (if needed).\u2000<strong>Only do this</strong> if your workflow requires them.<p></p>\n<hr>\n<h2 id=\"5-docker-experimental\">5. Docker (Experimental)</h2>\n<p>We provide a <strong>temporary</strong> Docker approach for testing.\u2000<strong>It\u2019s not stable and may break</strong> with future releases. We plan a major Docker revamp in a future stable version, 2025 Q1. If you still want to try:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">docker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n</code></pre></div>\n<p>You can then make POST requests to <code>http://localhost:11235/crawl</code> to perform crawls.\u2000<strong>Production usage</strong> is discouraged until our new Docker approach is ready (planned in Jan or Feb 2025).</p>\n<hr>\n<h2 id=\"6-local-server-mode-legacy\">6. Local Server Mode (Legacy)</h2>\n<p>Some older docs mention running Crawl4AI as a local server. This approach has been <strong>partially replaced</strong> by the new Docker-based prototype and upcoming stable server release. You can experiment, but expect major changes. Official local server instructions will arrive once the new Docker architecture is finalized.</p>\n<hr>\n<h2 id=\"summary\">Summary</h2>\n<p>1.\u2000<strong>Install</strong> with <code>pip install crawl4ai</code> and run <code>crawl4ai-setup</code>.\n2.\u2000<strong>Diagnose</strong> with <code>crawl4ai-doctor</code> if you see errors.\n3.\u2000<strong>Verify</strong> by crawling <code>example.com</code> with minimal <code>BrowserConfig</code> + <code>CrawlerRunConfig</code>.\n4.\u2000<strong>Advanced</strong> features (Torch, Transformers) are <strong>optional</strong>\u2014avoid them if you don\u2019t need them (they significantly increase resource usage).\n5.\u2000<strong>Docker</strong> is <strong>experimental</strong>\u2014use at your own risk until the stable version is released.\n6.\u2000<strong>Local server</strong> references in older docs are largely deprecated; a new solution is in progress.</p>\n<p><strong>Got questions?</strong> Check <a href=\"https://github.com/unclecode/crawl4ai/issues\">GitHub issues</a> for updates or ask the community!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Installation & Setup (2023 Edition)\n## 1. Basic Installation\n```\npip install crawl4ai\n\n```\n\nThis installs the **core** Crawl4AI library along with essential dependencies. **No** advanced features (like transformers or PyTorch) are included yet.\n## 2. Initial Setup & Diagnostics\n### 2.1 Run the Setup Command\nAfter installing, call:\n```\ncrawl4ai-setup\n\n```\n\n**What does it do?** - Installs or updates required Playwright browsers (Chromium, Firefox, etc.) - Performs OS-level checks (e.g., missing libs on Linux) - Confirms your environment is ready to crawl\n### 2.2 Diagnostics\nOptionally, you can run **diagnostics** to confirm everything is functioning:\n```\ncrawl4ai-doctor\n\n```\n\nThis command attempts to: - Check Python version compatibility - Verify Playwright installation - Inspect environment variables or library conflicts\nIf any issues arise, follow its suggestions (e.g., installing additional system packages) and re-run `crawl4ai-setup`.\n## 3. Verifying Installation: A Simple Crawl (Skip this step if you already run `crawl4ai-doctor`)\nBelow is a minimal Python script demonstrating a **basic** crawl. It uses our new **`BrowserConfig`**and**`CrawlerRunConfig`**for clarity, though no custom settings are passed in this example:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://www.example.com\",\n    )\n    print(result.markdown[:300]) # Show the first 300 characters of extracted text\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Expected** outcome: - A headless browser session loads `example.com` - Crawl4AI returns ~300 characters of markdown. If errors occur, rerun `crawl4ai-doctor` or manually ensure Playwright is installed correctly.\n## 4. Advanced Installation (Optional)\n**Warning** : Only install these **if you truly need them**. They bring in larger dependencies, including big models, which can increase disk usage and memory load significantly.\n### 4.1 Torch, Transformers, or All\n  * **Text Clustering (Torch)**\n```\npip install crawl4ai[torch]\ncrawl4ai-setup\n\n```\n\nInstalls PyTorch-based features (e.g., cosine similarity or advanced semantic chunking). \n  * **Transformers**\n```\npip install crawl4ai[transformer]\ncrawl4ai-setup\n\n```\n\nAdds Hugging Face-based summarization or generation strategies. \n  * **All Features**\n```\npip install crawl4ai[all]\ncrawl4ai-setup\n\n```\n\n\n\n#### (Optional) Pre-Fetching Models\n```\ncrawl4ai-download-models\n\n```\n\nThis step caches large models locally (if needed). **Only do this** if your workflow requires them. \n## 5. Docker (Experimental)\nWe provide a **temporary** Docker approach for testing. **It\u2019s not stable and may break** with future releases. We plan a major Docker revamp in a future stable version, 2025 Q1. If you still want to try:\n```\ndocker pull unclecode/crawl4ai:basic\ndocker run -p 11235:11235 unclecode/crawl4ai:basic\n\n```\n\nYou can then make POST requests to `http://localhost:11235/crawl` to perform crawls. **Production usage** is discouraged until our new Docker approach is ready (planned in Jan or Feb 2025).\n## 6. Local Server Mode (Legacy)\nSome older docs mention running Crawl4AI as a local server. This approach has been **partially replaced** by the new Docker-based prototype and upcoming stable server release. You can experiment, but expect major changes. Official local server instructions will arrive once the new Docker architecture is finalized.\n## Summary\n1. **Install** with `pip install crawl4ai` and run `crawl4ai-setup`. 2. **Diagnose** with `crawl4ai-doctor` if you see errors. 3. **Verify** by crawling `example.com` with minimal `BrowserConfig` + `CrawlerRunConfig`. 4. **Advanced** features (Torch, Transformers) are **optional** \u2014avoid them if you don\u2019t need them (they significantly increase resource usage). 5. **Docker** is **experimental** \u2014use at your own risk until the stable version is released. 6. **Local server** references in older docs are largely deprecated; a new solution is in progress.\n**Got questions?** Check for updates or ask the community!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 20,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:25",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "lazy-loading.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/lazy-loading",
      "timestamp": "2025-02-06T13:23:19.904062",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/lazy-loading/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Lazy Loading - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Lazy Loading</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#handling-lazy-loaded-images\">Handling Lazy-Loaded Images</a></li>\n        <li><a href=\"#example-ensuring-lazy-images-appear\">Example: Ensuring Lazy Images Appear</a></li><li><a href=\"#combining-with-other-link-media-filters\">Combining with Other Link &amp; Media Filters</a></li>\n        <li><a href=\"#tips-troubleshooting\">Tips &amp; Troubleshooting</a></li>\n        \n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h2 id=\"handling-lazy-loaded-images\">Handling Lazy-Loaded Images</h2>\n<p>Many websites now load images <strong>lazily</strong> as you scroll. If you need to ensure they appear in your final crawl (and in <code>result.media</code>), consider:</p>\n<p>1.\u2000<strong><code>wait_for_images=True</code></strong> \u2013 Wait for images to fully load.<br>\n2.\u2000<strong><code>scan_full_page</code></strong> \u2013 Force the crawler to scroll the entire page, triggering lazy loads.<br>\n3.\u2000<strong><code>scroll_delay</code></strong> \u2013 Add small delays between scroll steps.  </p>\n<p><strong>Note</strong>: If the site requires multiple \u201cLoad More\u201d triggers or complex interactions, see the <a href=\"../../core/page-interaction/\">Page Interaction docs</a>.</p>\n<h3 id=\"example-ensuring-lazy-images-appear\">Example: Ensuring Lazy Images Appear</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, BrowserConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Force the crawler to wait until images are fully loaded</span>\n        wait_for_images=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Option 1: If you want to automatically scroll the page to load images</span>\n        scan_full_page=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Tells the crawler to try scrolling the entire page</span>\n        scroll_delay=<span class=\"hljs-number\">0.5</span>,     <span class=\"hljs-comment\"># Delay (seconds) between scroll steps</span>\n\n        <span class=\"hljs-comment\"># Option 2: If the site uses a 'Load More' or JS triggers for images,</span>\n        <span class=\"hljs-comment\"># you can also specify js_code or wait_for logic here.</span>\n\n        cache_mode=CacheMode.BYPASS,\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://www.example.com/gallery\"</span>, config=config)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            images = result.media.get(<span class=\"hljs-string\">\"images\"</span>, [])\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Images found:\"</span>, <span class=\"hljs-built_in\">len</span>(images))\n            <span class=\"hljs-keyword\">for</span> i, img <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(images[:<span class=\"hljs-number\">5</span>]):\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[Image <span class=\"hljs-subst\">{i}</span>] URL: <span class=\"hljs-subst\">{img[<span class=\"hljs-string\">'src'</span>]}</span>, Score: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'score'</span>,<span class=\"hljs-string\">'N/A'</span>)}</span>\"</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Explanation</strong>:</p>\n<ul>\n<li><strong><code>wait_for_images=True</code></strong><br>\n  The crawler tries to ensure images have finished loading before finalizing the HTML.  </li>\n<li><strong><code>scan_full_page=True</code></strong><br>\n  Tells the crawler to attempt scrolling from top to bottom. Each scroll step helps trigger lazy loading.  </li>\n<li><strong><code>scroll_delay=0.5</code></strong><br>\n  Pause half a second between each scroll step. Helps the site load images before continuing.</li>\n</ul>\n<p><strong>When to Use</strong>:</p>\n<ul>\n<li><strong>Lazy-Loading</strong>: If images appear only when the user scrolls into view, <code>scan_full_page</code> + <code>scroll_delay</code> helps the crawler see them.  </li>\n<li><strong>Heavier Pages</strong>: If a page is extremely long, be mindful that scanning the entire page can be slow. Adjust <code>scroll_delay</code> or the max scroll steps as needed.</li>\n</ul>\n<hr>\n<h2 id=\"combining-with-other-link-media-filters\">Combining with Other Link &amp; Media Filters</h2>\n<p>You can still combine <strong>lazy-load</strong> logic with the usual <strong>exclude_external_images</strong>, <strong>exclude_domains</strong>, or link filtration:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">config <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    wait_for_images<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    scan_full_page<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    scroll_delay<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">0.5</span>,\n\n    <span class=\"hljs-comment\"># Filter out external images if you only want local ones</span>\n    exclude_external_images<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n\n    <span class=\"hljs-comment\"># Exclude certain domains for links</span>\n    exclude_domains<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-string\">\"spammycdn.com\"</span><span class=\"hljs-punctuation\">]</span>,\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>This approach ensures you see <strong>all</strong> images from the main domain while ignoring external ones, and the crawler physically scrolls the entire page so that lazy-loading triggers.</p>\n<hr>\n<h2 id=\"tips-troubleshooting\">Tips &amp; Troubleshooting</h2>\n<p>1.\u2000<strong>Long Pages</strong><br>\n   - Setting <code>scan_full_page=True</code> on extremely long or infinite-scroll pages can be resource-intensive.<br>\n   - Consider using <a href=\"../../core/page-interaction/\">hooks</a> or specialized logic to load specific sections or \u201cLoad More\u201d triggers repeatedly.</p>\n<p>2.\u2000<strong>Mixed Image Behavior</strong><br>\n   - Some sites load images in batches as you scroll. If you\u2019re missing images, increase your <code>scroll_delay</code> or call multiple partial scrolls in a loop with JS code or hooks.</p>\n<p>3.\u2000<strong>Combining with Dynamic Wait</strong><br>\n   - If the site has a placeholder that only changes to a real image after a certain event, you might do <code>wait_for=\"css:img.loaded\"</code> or a custom JS <code>wait_for</code>.</p>\n<p>4.\u2000<strong>Caching</strong><br>\n   - If <code>cache_mode</code> is enabled, repeated crawls might skip some network fetches. If you suspect caching is missing new images, set <code>cache_mode=CacheMode.BYPASS</code> for fresh fetches.</p>\n<hr>\n<p>With <strong>lazy-loading</strong> support, <strong>wait_for_images</strong>, and <strong>scan_full_page</strong> settings, you can capture the entire gallery or feed of images you expect\u2014even if the site only loads them as the user scrolls. Combine these with the standard media filtering and domain exclusion for a complete link &amp; media handling strategy.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "## Handling Lazy-Loaded Images\nMany websites now load images **lazily** as you scroll. If you need to ensure they appear in your final crawl (and in `result.media`), consider:\n1. **`wait_for_images=True`**\u2013 Wait for images to fully load. 2.**`scan_full_page`**\u2013 Force the crawler to scroll the entire page, triggering lazy loads. 3.**`scroll_delay`**\u2013 Add small delays between scroll steps.\n**Note** : If the site requires multiple \u201cLoad More\u201d triggers or complex interactions, see the [Page Interaction docs](https://docs.crawl4ai.com/advanced/core/page-interaction/>).\n### Example: Ensuring Lazy Images Appear\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, BrowserConfig\nfrom crawl4ai.async_configs import CacheMode\nasync def main():\n  config = CrawlerRunConfig(\n    # Force the crawler to wait until images are fully loaded\n    wait_for_images=True,\n    # Option 1: If you want to automatically scroll the page to load images\n    scan_full_page=True, # Tells the crawler to try scrolling the entire page\n    scroll_delay=0.5,   # Delay (seconds) between scroll steps\n    # Option 2: If the site uses a 'Load More' or JS triggers for images,\n    # you can also specify js_code or wait_for logic here.\n    cache_mode=CacheMode.BYPASS,\n    verbose=True\n  )\n  async with AsyncWebCrawler(config=BrowserConfig(headless=True)) as crawler:\n    result = await crawler.arun(\"https://www.example.com/gallery\", config=config)\n    if result.success:\n      images = result.media.get(\"images\", [])\n      print(\"Images found:\", len(images))\n      for i, img in enumerate(images[:5]):\n        print(f\"[Image {i}] URL: {img['src']}, Score: {img.get('score','N/A')}\")\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Explanation** :\n  * **`wait_for_images=True`**The crawler tries to ensure images have finished loading before finalizing the HTML.\n  * **`scan_full_page=True`**Tells the crawler to attempt scrolling from top to bottom. Each scroll step helps trigger lazy loading.\n  * **`scroll_delay=0.5`**Pause half a second between each scroll step. Helps the site load images before continuing.\n\n\n**When to Use** :\n  * **Lazy-Loading** : If images appear only when the user scrolls into view, `scan_full_page` + `scroll_delay` helps the crawler see them. \n  * **Heavier Pages** : If a page is extremely long, be mindful that scanning the entire page can be slow. Adjust `scroll_delay` or the max scroll steps as needed.\n\n\n## Combining with Other Link & Media Filters\nYou can still combine **lazy-load** logic with the usual **exclude_external_images** , **exclude_domains** , or link filtration:\n```\nconfig = CrawlerRunConfig(\n  wait_for_images=True,\n  scan_full_page=True,\n  scroll_delay=0.5,\n  # Filter out external images if you only want local ones\n  exclude_external_images=True,\n  # Exclude certain domains for links\n  exclude_domains=[\"spammycdn.com\"],\n)\n\n```\n\nThis approach ensures you see **all** images from the main domain while ignoring external ones, and the crawler physically scrolls the entire page so that lazy-loading triggers.\n## Tips & Troubleshooting\n1. **Long Pages** - Setting `scan_full_page=True` on extremely long or infinite-scroll pages can be resource-intensive. - Consider using [hooks](https://docs.crawl4ai.com/advanced/core/page-interaction/>) or specialized logic to load specific sections or \u201cLoad More\u201d triggers repeatedly.\n2. **Mixed Image Behavior** - Some sites load images in batches as you scroll. If you\u2019re missing images, increase your `scroll_delay` or call multiple partial scrolls in a loop with JS code or hooks.\n3. **Combining with Dynamic Wait** - If the site has a placeholder that only changes to a real image after a certain event, you might do `wait_for=\"css:img.loaded\"` or a custom JS `wait_for`.\n4. **Caching** - If `cache_mode` is enabled, repeated crawls might skip some network fetches. If you suspect caching is missing new images, set `cache_mode=CacheMode.BYPASS` for fresh fetches.\nWith **lazy-loading** support, **wait_for_images** , and **scan_full_page** settings, you can capture the entire gallery or feed of images you expect\u2014even if the site only loads them as the user scrolls. Combine these with the standard media filtering and domain exclusion for a complete link & media handling strategy.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/session-management",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 2,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:03",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "link-media.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/link-media",
      "timestamp": "2025-02-06T13:23:42.782400",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/link-media/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Link &amp; Media - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Link &amp; Media</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#link-media\">Link &amp; Media</a></li>\n        <li><a href=\"#1-link-extraction\">1. Link Extraction</a></li><li><a href=\"#2-domain-filtering\">2. Domain Filtering</a></li><li><a href=\"#3-media-extraction\">3. Media Extraction</a></li><li><a href=\"#4-putting-it-all-together-link-media-filtering\">4. Putting It All Together: Link &amp; Media Filtering</a></li><li><a href=\"#5-common-pitfalls-tips\">5. Common Pitfalls &amp; Tips</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"link-media\">Link &amp; Media</h1>\n<p>In this tutorial, you\u2019ll learn how to:</p>\n<ol>\n<li>Extract links (internal, external) from crawled pages  </li>\n<li>Filter or exclude specific domains (e.g., social media or custom domains)  </li>\n<li>Access and manage media data (especially images) in the crawl result  </li>\n<li>Configure your crawler to exclude or prioritize certain images</li>\n</ol>\n<blockquote>\n<p><strong>Prerequisites</strong><br>\n- You have completed or are familiar with the <a href=\"../simple-crawling/\">AsyncWebCrawler Basics</a> tutorial.<br>\n- You can run Crawl4AI in your environment (Playwright, Python, etc.).</p>\n</blockquote>\n<hr>\n<p>Below is a revised version of the <strong>Link Extraction</strong> and <strong>Media Extraction</strong> sections that includes example data structures showing how links and media items are stored in <code>CrawlResult</code>. Feel free to adjust any field names or descriptions to match your actual output.</p>\n<hr>\n<h2 id=\"1-link-extraction\">1. Link Extraction</h2>\n<h3 id=\"11-resultlinks\">1.1 <code>result.links</code></h3>\n<p>When you call <code>arun()</code> or <code>arun_many()</code> on a URL, Crawl4AI automatically extracts links and stores them in the <code>links</code> field of <code>CrawlResult</code>. By default, the crawler tries to distinguish <strong>internal</strong> links (same domain) from <strong>external</strong> links (different domains).</p>\n<p><strong>Basic Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://www.example.com\"</span>)\n    <span class=\"hljs-keyword\">if</span> result.success:\n        internal_links = result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])\n        external_links = result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(internal_links)}</span> internal links.\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(internal_links)}</span> external links.\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.media)}</span> media items.\"</span>)\n\n        <span class=\"hljs-comment\"># Each link is typically a dictionary with fields like:</span>\n        <span class=\"hljs-comment\"># { \"href\": \"...\", \"text\": \"...\", \"title\": \"...\", \"base_domain\": \"...\" }</span>\n        <span class=\"hljs-keyword\">if</span> internal_links:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Sample Internal Link:\"</span>, internal_links[<span class=\"hljs-number\">0</span>])\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n</code></pre></div>\n<p><strong>Structure Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">result.links = {\n  <span class=\"hljs-string\">\"internal\"</span>: [\n    {\n      <span class=\"hljs-string\">\"href\"</span>: <span class=\"hljs-string\">\"https://kidocode.com/\"</span>,\n      <span class=\"hljs-string\">\"text\"</span>: <span class=\"hljs-string\">\"\"</span>,\n      <span class=\"hljs-string\">\"title\"</span>: <span class=\"hljs-string\">\"\"</span>,\n      <span class=\"hljs-string\">\"base_domain\"</span>: <span class=\"hljs-string\">\"kidocode.com\"</span>\n    },\n    {\n      <span class=\"hljs-string\">\"href\"</span>: <span class=\"hljs-string\">\"https://kidocode.com/degrees/technology\"</span>,\n      <span class=\"hljs-string\">\"text\"</span>: <span class=\"hljs-string\">\"Technology Degree\"</span>,\n      <span class=\"hljs-string\">\"title\"</span>: <span class=\"hljs-string\">\"KidoCode Tech Program\"</span>,\n      <span class=\"hljs-string\">\"base_domain\"</span>: <span class=\"hljs-string\">\"kidocode.com\"</span>\n    },\n    <span class=\"hljs-comment\"># ...</span>\n  ],\n  <span class=\"hljs-string\">\"external\"</span>: [\n    <span class=\"hljs-comment\"># possibly other links leading to third-party sites</span>\n  ]\n}\n</code></pre></div>\n<ul>\n<li><strong><code>href</code></strong>: The raw hyperlink URL.  </li>\n<li><strong><code>text</code></strong>: The link text (if any) within the <code>&lt;a&gt;</code> tag.  </li>\n<li><strong><code>title</code></strong>: The <code>title</code> attribute of the link (if present).  </li>\n<li><strong><code>base_domain</code></strong>: The domain extracted from <code>href</code>. Helpful for filtering or grouping by domain.</li>\n</ul>\n<hr>\n<h2 id=\"2-domain-filtering\">2. Domain Filtering</h2>\n<p>Some websites contain hundreds of third-party or affiliate links. You can filter out certain domains at <strong>crawl time</strong> by configuring the crawler. The most relevant parameters in <code>CrawlerRunConfig</code> are:</p>\n<ul>\n<li><strong><code>exclude_external_links</code></strong>: If <code>True</code>, discard any link pointing outside the root domain.  </li>\n<li><strong><code>exclude_social_media_domains</code></strong>: Provide a list of social media platforms (e.g., <code>[\"facebook.com\", \"twitter.com\"]</code>) to exclude from your crawl.  </li>\n<li><strong><code>exclude_social_media_links</code></strong>: If <code>True</code>, automatically skip known social platforms.  </li>\n<li><strong><code>exclude_domains</code></strong>: Provide a list of custom domains you want to exclude (e.g., <code>[\"spammyads.com\", \"tracker.net\"]</code>).</li>\n</ul>\n<h3 id=\"21-example-excluding-external-social-media-links\">2.1 Example: Excluding External &amp; Social Media Links</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    crawler_cfg = CrawlerRunConfig(\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,          <span class=\"hljs-comment\"># No links outside primary domain</span>\n        exclude_social_media_links=<span class=\"hljs-literal\">True</span>       <span class=\"hljs-comment\"># Skip recognized social media domains</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            <span class=\"hljs-string\">\"https://www.example.com\"</span>,\n            config=crawler_cfg\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[OK] Crawled:\"</span>, result.url)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Internal links count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"External links count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])))  \n            <span class=\"hljs-comment\"># Likely zero external links in this scenario</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[ERROR]\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"22-example-excluding-specific-domains\">2.2 Example: Excluding Specific Domains</h3>\n<p>If you want to let external links in, but specifically exclude a domain (e.g., <code>suspiciousads.com</code>), do this:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">crawler_cfg = CrawlerRunConfig(\n    exclude_domains=[<span class=\"hljs-string\">\"suspiciousads.com\"</span>]\n)\n</code></pre></div>\n<p>This approach is handy when you still want external links but need to block certain sites you consider spammy.</p>\n<hr>\n<h2 id=\"3-media-extraction\">3. Media Extraction</h2>\n<h3 id=\"31-accessing-resultmedia\">3.1 Accessing <code>result.media</code></h3>\n<p>By default, Crawl4AI collects images, audio, and video URLs it finds on the page. These are stored in <code>result.media</code>, a dictionary keyed by media type (e.g., <code>images</code>, <code>videos</code>, <code>audio</code>).</p>\n<p><strong>Basic Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">if</span> result.success:\n    images_info = result.media.get(<span class=\"hljs-string\">\"images\"</span>, [])\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(images_info)}</span> images in total.\"</span>)\n    <span class=\"hljs-keyword\">for</span> i, img <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(images_info[:<span class=\"hljs-number\">5</span>]):  <span class=\"hljs-comment\"># Inspect just the first 5</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[Image <span class=\"hljs-subst\">{i}</span>] URL: <span class=\"hljs-subst\">{img[<span class=\"hljs-string\">'src'</span>]}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Alt text: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'alt'</span>, <span class=\"hljs-string\">''</span>)}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Score: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'score'</span>)}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Description: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'desc'</span>, <span class=\"hljs-string\">''</span>)}</span>\\n\"</span>)\n</code></pre></div>\n<p><strong>Structure Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">result.media = {\n  <span class=\"hljs-string\">\"images\"</span>: [\n    {\n      <span class=\"hljs-string\">\"src\"</span>: <span class=\"hljs-string\">\"https://cdn.prod.website-files.com/.../Group%2089.svg\"</span>,\n      <span class=\"hljs-string\">\"alt\"</span>: <span class=\"hljs-string\">\"coding school for kids\"</span>,\n      <span class=\"hljs-string\">\"desc\"</span>: <span class=\"hljs-string\">\"Trial Class Degrees degrees All Degrees AI Degree Technology ...\"</span>,\n      <span class=\"hljs-string\">\"score\"</span>: <span class=\"hljs-number\">3</span>,\n      <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"image\"</span>,\n      <span class=\"hljs-string\">\"group_id\"</span>: <span class=\"hljs-number\">0</span>,\n      <span class=\"hljs-string\">\"format\"</span>: <span class=\"hljs-literal\">None</span>,\n      <span class=\"hljs-string\">\"width\"</span>: <span class=\"hljs-literal\">None</span>,\n      <span class=\"hljs-string\">\"height\"</span>: <span class=\"hljs-literal\">None</span>\n    },\n    <span class=\"hljs-comment\"># ...</span>\n  ],\n  <span class=\"hljs-string\">\"videos\"</span>: [\n    <span class=\"hljs-comment\"># Similar structure but with video-specific fields</span>\n  ],\n  <span class=\"hljs-string\">\"audio\"</span>: [\n    <span class=\"hljs-comment\"># Similar structure but with audio-specific fields</span>\n  ]\n}\n</code></pre></div>\n<p>Depending on your Crawl4AI version or scraping strategy, these dictionaries can include fields like:</p>\n<ul>\n<li><strong><code>src</code></strong>: The media URL (e.g., image source)  </li>\n<li><strong><code>alt</code></strong>: The alt text for images (if present)  </li>\n<li><strong><code>desc</code></strong>: A snippet of nearby text or a short description (optional)  </li>\n<li><strong><code>score</code></strong>: A heuristic relevance score if you\u2019re using content-scoring features  </li>\n<li><strong><code>width</code></strong>, <strong><code>height</code></strong>: If the crawler detects dimensions for the image/video  </li>\n<li><strong><code>type</code></strong>: Usually <code>\"image\"</code>, <code>\"video\"</code>, or <code>\"audio\"</code>  </li>\n<li><strong><code>group_id</code></strong>: If you\u2019re grouping related media items, the crawler might assign an ID  </li>\n</ul>\n<p>With these details, you can easily filter out or focus on certain images (for instance, ignoring images with very low scores or a different domain), or gather metadata for analytics.</p>\n<h3 id=\"32-excluding-external-images\">3.2 Excluding External Images</h3>\n<p>If you\u2019re dealing with heavy pages or want to skip third-party images (advertisements, for example), you can turn on:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">crawler_cfg <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    exclude_external_images<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>This setting attempts to discard images from outside the primary domain, keeping only those from the site you\u2019re crawling.</p>\n<h3 id=\"33-additional-media-config\">3.3 Additional Media Config</h3>\n<ul>\n<li><strong><code>screenshot</code></strong>: Set to <code>True</code> if you want a full-page screenshot stored as <code>base64</code> in <code>result.screenshot</code>.  </li>\n<li><strong><code>pdf</code></strong>: Set to <code>True</code> if you want a PDF version of the page in <code>result.pdf</code>.  </li>\n<li><strong><code>wait_for_images</code></strong>: If <code>True</code>, attempts to wait until images are fully loaded before final extraction.</li>\n</ul>\n<hr>\n<h2 id=\"4-putting-it-all-together-link-media-filtering\">4. Putting It All Together: Link &amp; Media Filtering</h2>\n<p>Here\u2019s a combined example demonstrating how to filter out external links, skip certain domains, and exclude external images:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Suppose we want to keep only internal links, remove certain domains, </span>\n    <span class=\"hljs-comment\"># and discard external images from the final crawl data.</span>\n    crawler_cfg = CrawlerRunConfig(\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        exclude_domains=[<span class=\"hljs-string\">\"spammyads.com\"</span>],\n        exclude_social_media_links=<span class=\"hljs-literal\">True</span>,   <span class=\"hljs-comment\"># skip Twitter, Facebook, etc.</span>\n        exclude_external_images=<span class=\"hljs-literal\">True</span>,      <span class=\"hljs-comment\"># keep only images from main domain</span>\n        wait_for_images=<span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># ensure images are loaded</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://www.example.com\"</span>, config=crawler_cfg)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[OK] Crawled:\"</span>, result.url)\n\n            <span class=\"hljs-comment\"># 1. Links</span>\n            in_links = result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])\n            ext_links = result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Internal link count:\"</span>, <span class=\"hljs-built_in\">len</span>(in_links))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"External link count:\"</span>, <span class=\"hljs-built_in\">len</span>(ext_links))  <span class=\"hljs-comment\"># should be zero with exclude_external_links=True</span>\n\n            <span class=\"hljs-comment\"># 2. Images</span>\n            images = result.media.get(<span class=\"hljs-string\">\"images\"</span>, [])\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Images found:\"</span>, <span class=\"hljs-built_in\">len</span>(images))\n\n            <span class=\"hljs-comment\"># Let's see a snippet of these images</span>\n            <span class=\"hljs-keyword\">for</span> i, img <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(images[:<span class=\"hljs-number\">3</span>]):\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"  - <span class=\"hljs-subst\">{img[<span class=\"hljs-string\">'src'</span>]}</span> (alt=<span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'alt'</span>,<span class=\"hljs-string\">''</span>)}</span>, score=<span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'score'</span>,<span class=\"hljs-string\">'N/A'</span>)}</span>)\"</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[ERROR] Failed to crawl. Reason:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"5-common-pitfalls-tips\">5. Common Pitfalls &amp; Tips</h2>\n<p>1.\u2000<strong>Conflicting Flags</strong>:<br>\n   - <code>exclude_external_links=True</code> but then also specifying <code>exclude_social_media_links=True</code> is typically fine, but understand that the first setting already discards <em>all</em> external links. The second becomes somewhat redundant.<br>\n   - <code>exclude_external_images=True</code> but want to keep some external images? Currently no partial domain-based setting for images, so you might need a custom approach or hook logic.</p>\n<p>2.\u2000<strong>Relevancy Scores</strong>:<br>\n   - If your version of Crawl4AI or your scraping strategy includes an <code>img[\"score\"]</code>, it\u2019s typically a heuristic based on size, position, or content analysis. Evaluate carefully if you rely on it.</p>\n<p>3.\u2000<strong>Performance</strong>:<br>\n   - Excluding certain domains or external images can speed up your crawl, especially for large, media-heavy pages.<br>\n   - If you want a \u201cfull\u201d link map, do <em>not</em> exclude them. Instead, you can post-filter in your own code.</p>\n<p>4.\u2000<strong>Social Media Lists</strong>:<br>\n   - <code>exclude_social_media_links=True</code> typically references an internal list of known social domains like Facebook, Twitter, LinkedIn, etc. If you need to add or remove from that list, look for library settings or a local config file (depending on your version).</p>\n<hr>\n<p><strong>That\u2019s it for Link &amp; Media Analysis!</strong> You\u2019re now equipped to filter out unwanted sites and zero in on the images and videos that matter for your project.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Link & Media\nIn this tutorial, you\u2019ll learn how to:\n  1. Extract links (internal, external) from crawled pages \n  2. Filter or exclude specific domains (e.g., social media or custom domains) \n  3. Access and manage media data (especially images) in the crawl result \n  4. Configure your crawler to exclude or prioritize certain images\n\n\n> **Prerequisites** - You have completed or are familiar with the [AsyncWebCrawler Basics](https://docs.crawl4ai.com/core/<../simple-crawling/>) tutorial. - You can run Crawl4AI in your environment (Playwright, Python, etc.).\nBelow is a revised version of the **Link Extraction** and **Media Extraction** sections that includes example data structures showing how links and media items are stored in `CrawlResult`. Feel free to adjust any field names or descriptions to match your actual output.\n## 1. Link Extraction\n### 1.1 `result.links`\nWhen you call `arun()` or `arun_many()` on a URL, Crawl4AI automatically extracts links and stores them in the `links` field of `CrawlResult`. By default, the crawler tries to distinguish **internal** links (same domain) from **external** links (different domains).\n**Basic Example** :\n```\nfrom crawl4ai import AsyncWebCrawler\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(\"https://www.example.com\")\n  if result.success:\n    internal_links = result.links.get(\"internal\", [])\n    external_links = result.links.get(\"external\", [])\n    print(f\"Found {len(internal_links)} internal links.\")\n    print(f\"Found {len(internal_links)} external links.\")\n    print(f\"Found {len(result.media)} media items.\")\n    # Each link is typically a dictionary with fields like:\n    # { \"href\": \"...\", \"text\": \"...\", \"title\": \"...\", \"base_domain\": \"...\" }\n    if internal_links:\n      print(\"Sample Internal Link:\", internal_links[0])\n  else:\n    print(\"Crawl failed:\", result.error_message)\n\n```\n\n**Structure Example** :\n```\nresult.links = {\n \"internal\": [\n  {\n   \"href\": \"https://kidocode.com/\",\n   \"text\": \"\",\n   \"title\": \"\",\n   \"base_domain\": \"kidocode.com\"\n  },\n  {\n   \"href\": \"https://kidocode.com/degrees/technology\",\n   \"text\": \"Technology Degree\",\n   \"title\": \"KidoCode Tech Program\",\n   \"base_domain\": \"kidocode.com\"\n  },\n  # ...\n ],\n \"external\": [\n  # possibly other links leading to third-party sites\n ]\n}\n\n```\n\n  * **`href`**: The raw hyperlink URL.\n  * **`text`**: The link text (if any) within the`<a>` tag. \n  * **`title`**: The`title` attribute of the link (if present). \n  * **`base_domain`**: The domain extracted from`href`. Helpful for filtering or grouping by domain.\n\n\n## 2. Domain Filtering\nSome websites contain hundreds of third-party or affiliate links. You can filter out certain domains at **crawl time** by configuring the crawler. The most relevant parameters in `CrawlerRunConfig` are:\n  * **`exclude_external_links`**: If`True` , discard any link pointing outside the root domain. \n  * **`exclude_social_media_domains`**: Provide a list of social media platforms (e.g.,`[\"facebook.com\", \"twitter.com\"]`) to exclude from your crawl. \n  * **`exclude_social_media_links`**: If`True` , automatically skip known social platforms. \n  * **`exclude_domains`**: Provide a list of custom domains you want to exclude (e.g.,`[\"spammyads.com\", \"tracker.net\"]`).\n\n\n### 2.1 Example: Excluding External & Social Media Links\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  crawler_cfg = CrawlerRunConfig(\n    exclude_external_links=True,     # No links outside primary domain\n    exclude_social_media_links=True    # Skip recognized social media domains\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      \"https://www.example.com\",\n      config=crawler_cfg\n    )\n    if result.success:\n      print(\"[OK] Crawled:\", result.url)\n      print(\"Internal links count:\", len(result.links.get(\"internal\", [])))\n      print(\"External links count:\", len(result.links.get(\"external\", []))) \n      # Likely zero external links in this scenario\n    else:\n      print(\"[ERROR]\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### 2.2 Example: Excluding Specific Domains\nIf you want to let external links in, but specifically exclude a domain (e.g., `suspiciousads.com`), do this:\n```\ncrawler_cfg = CrawlerRunConfig(\n  exclude_domains=[\"suspiciousads.com\"]\n)\n\n```\n\nThis approach is handy when you still want external links but need to block certain sites you consider spammy.\n## 3. Media Extraction\n### 3.1 Accessing `result.media`\nBy default, Crawl4AI collects images, audio, and video URLs it finds on the page. These are stored in `result.media`, a dictionary keyed by media type (e.g., `images`, `videos`, `audio`).\n**Basic Example** :\n```\nif result.success:\n  images_info = result.media.get(\"images\", [])\n  print(f\"Found {len(images_info)} images in total.\")\n  for i, img in enumerate(images_info[:5]): # Inspect just the first 5\n    print(f\"[Image {i}] URL: {img['src']}\")\n    print(f\"      Alt text: {img.get('alt', '')}\")\n    print(f\"      Score: {img.get('score')}\")\n    print(f\"      Description: {img.get('desc', '')}\\n\")\n\n```\n\n**Structure Example** :\n```\nresult.media = {\n \"images\": [\n  {\n   \"src\": \"https://cdn.prod.website-files.com/.../Group%2089.svg\",\n   \"alt\": \"coding school for kids\",\n   \"desc\": \"Trial Class Degrees degrees All Degrees AI Degree Technology ...\",\n   \"score\": 3,\n   \"type\": \"image\",\n   \"group_id\": 0,\n   \"format\": None,\n   \"width\": None,\n   \"height\": None\n  },\n  # ...\n ],\n \"videos\": [\n  # Similar structure but with video-specific fields\n ],\n \"audio\": [\n  # Similar structure but with audio-specific fields\n ]\n}\n\n```\n\nDepending on your Crawl4AI version or scraping strategy, these dictionaries can include fields like:\n  * **`src`**: The media URL (e.g., image source)\n  * **`alt`**: The alt text for images (if present)\n  * **`desc`**: A snippet of nearby text or a short description (optional)\n  * **`score`**: A heuristic relevance score if you\u2019re using content-scoring features\n  * **`width`**,**`height`**: If the crawler detects dimensions for the image/video\n  * **`type`**: Usually`\"image\"` , `\"video\"`, or `\"audio\"`\n  * **`group_id`**: If you\u2019re grouping related media items, the crawler might assign an ID\n\n\nWith these details, you can easily filter out or focus on certain images (for instance, ignoring images with very low scores or a different domain), or gather metadata for analytics.\n### 3.2 Excluding External Images\nIf you\u2019re dealing with heavy pages or want to skip third-party images (advertisements, for example), you can turn on:\n```\ncrawler_cfg = CrawlerRunConfig(\n  exclude_external_images=True\n)\n\n```\n\nThis setting attempts to discard images from outside the primary domain, keeping only those from the site you\u2019re crawling.\n### 3.3 Additional Media Config\n  * **`screenshot`**: Set to`True` if you want a full-page screenshot stored as `base64` in `result.screenshot`. \n  * **`pdf`**: Set to`True` if you want a PDF version of the page in `result.pdf`. \n  * **`wait_for_images`**: If`True` , attempts to wait until images are fully loaded before final extraction.\n\n\n## 4. Putting It All Together: Link & Media Filtering\nHere\u2019s a combined example demonstrating how to filter out external links, skip certain domains, and exclude external images:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  # Suppose we want to keep only internal links, remove certain domains, \n  # and discard external images from the final crawl data.\n  crawler_cfg = CrawlerRunConfig(\n    exclude_external_links=True,\n    exclude_domains=[\"spammyads.com\"],\n    exclude_social_media_links=True,  # skip Twitter, Facebook, etc.\n    exclude_external_images=True,   # keep only images from main domain\n    wait_for_images=True,       # ensure images are loaded\n    verbose=True\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://www.example.com\", config=crawler_cfg)\n    if result.success:\n      print(\"[OK] Crawled:\", result.url)\n      # 1. Links\n      in_links = result.links.get(\"internal\", [])\n      ext_links = result.links.get(\"external\", [])\n      print(\"Internal link count:\", len(in_links))\n      print(\"External link count:\", len(ext_links)) # should be zero with exclude_external_links=True\n      # 2. Images\n      images = result.media.get(\"images\", [])\n      print(\"Images found:\", len(images))\n      # Let's see a snippet of these images\n      for i, img in enumerate(images[:3]):\n        print(f\" - {img['src']} (alt={img.get('alt','')}, score={img.get('score','N/A')})\")\n    else:\n      print(\"[ERROR] Failed to crawl. Reason:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 5. Common Pitfalls & Tips\n1. **Conflicting Flags** : - `exclude_external_links=True` but then also specifying `exclude_social_media_links=True` is typically fine, but understand that the first setting already discards _all_ external links. The second becomes somewhat redundant. - `exclude_external_images=True` but want to keep some external images? Currently no partial domain-based setting for images, so you might need a custom approach or hook logic.\n2. **Relevancy Scores** : - If your version of Crawl4AI or your scraping strategy includes an `img[\"score\"]`, it\u2019s typically a heuristic based on size, position, or content analysis. Evaluate carefully if you rely on it.\n3. **Performance** : - Excluding certain domains or external images can speed up your crawl, especially for large, media-heavy pages. - If you want a \u201cfull\u201d link map, do _not_ exclude them. Instead, you can post-filter in your own code.\n4. **Social Media Lists** : - `exclude_social_media_links=True` typically references an internal list of known social domains like Facebook, Twitter, LinkedIn, etc. If you need to add or remove from that list, look for library settings or a local config file (depending on your version).\n**That\u2019s it for Link & Media Analysis!** You\u2019re now equipped to filter out unwanted sites and zero in on the images and videos that matter for your project.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 21,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:26",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "llm-strategies.json",
    "content": {
      "url": "https://docs.crawl4ai.com/extraction/llm-strategies",
      "timestamp": "2025-02-06T13:23:52.553522",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/extraction/llm-strategies/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>LLM Strategies - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">LLM Strategies</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#extracting-json-llm\">Extracting JSON (LLM)</a></li>\n        <li><a href=\"#1-why-use-an-llm\">1. Why Use an LLM?</a></li><li><a href=\"#2-provider-agnostic-via-lightllm\">2. Provider-Agnostic via LightLLM</a></li><li><a href=\"#3-how-llm-extraction-works\">3. How LLM Extraction Works</a></li><li><a href=\"#4-key-parameters\">4. Key Parameters</a></li><li><a href=\"#5-putting-it-in-crawlerrunconfig\">5. Putting It in CrawlerRunConfig</a></li><li><a href=\"#6-chunking-details\">6. Chunking Details</a></li><li><a href=\"#7-input-format\">7. Input Format</a></li><li><a href=\"#8-token-usage-show-usage\">8. Token Usage &amp; Show Usage</a></li><li><a href=\"#9-example-building-a-knowledge-graph\">9. Example: Building a Knowledge Graph</a></li><li><a href=\"#10-best-practices-caveats\">10. Best Practices &amp; Caveats</a></li><li><a href=\"#11-conclusion\">11. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"extracting-json-llm\">Extracting JSON (LLM)</h1>\n<p>In some cases, you need to extract <strong>complex or unstructured</strong> information from a webpage that a simple CSS/XPath schema cannot easily parse. Or you want <strong>AI</strong>-driven insights, classification, or summarization. For these scenarios, Crawl4AI provides an <strong>LLM-based extraction strategy</strong> that:</p>\n<ol>\n<li>Works with <strong>any</strong> large language model supported by <a href=\"https://github.com/LightLLM\">LightLLM</a> (Ollama, OpenAI, Claude, and more).  </li>\n<li>Automatically splits content into chunks (if desired) to handle token limits, then combines results.  </li>\n<li>Lets you define a <strong>schema</strong> (like a Pydantic model) or a simpler \u201cblock\u201d extraction approach.</li>\n</ol>\n<p><strong>Important</strong>: LLM-based extraction can be slower and costlier than schema-based approaches. If your page data is highly structured, consider using <a href=\"../no-llm-strategies/\"><code>JsonCssExtractionStrategy</code></a> or <a href=\"../no-llm-strategies/\"><code>JsonXPathExtractionStrategy</code></a> first. But if you need AI to interpret or reorganize content, read on!</p>\n<hr>\n<h2 id=\"1-why-use-an-llm\">1. Why Use an LLM?</h2>\n<ul>\n<li><strong>Complex Reasoning</strong>: If the site\u2019s data is unstructured, scattered, or full of natural language context.  </li>\n<li><strong>Semantic Extraction</strong>: Summaries, knowledge graphs, or relational data that require comprehension.  </li>\n<li><strong>Flexible</strong>: You can pass instructions to the model to do more advanced transformations or classification.</li>\n</ul>\n<hr>\n<h2 id=\"2-provider-agnostic-via-lightllm\">2. Provider-Agnostic via LightLLM</h2>\n<p>Crawl4AI uses a \u201cprovider string\u201d (e.g., <code>\"openai/gpt-4o\"</code>, <code>\"ollama/llama2.0\"</code>, <code>\"aws/titan\"</code>) to identify your LLM.\u2000<strong>Any</strong> model that LightLLM supports is fair game. You just provide:</p>\n<ul>\n<li><strong><code>provider</code></strong>: The <code>&lt;provider&gt;/&lt;model_name&gt;</code> identifier (e.g., <code>\"openai/gpt-4\"</code>, <code>\"ollama/llama2\"</code>, <code>\"huggingface/google-flan\"</code>, etc.).  </li>\n<li><strong><code>api_token</code></strong>: If needed (for OpenAI, HuggingFace, etc.); local models or Ollama might not require it.  </li>\n<li><strong><code>api_base</code></strong> (optional): If your provider has a custom endpoint.  </li>\n</ul>\n<p>This means you <strong>aren\u2019t locked</strong> into a single LLM vendor. Switch or experiment easily.</p>\n<hr>\n<h2 id=\"3-how-llm-extraction-works\">3. How LLM Extraction Works</h2>\n<h3 id=\"31-flow\">3.1 Flow</h3>\n<p>1.\u2000<strong>Chunking</strong> (optional): The HTML or markdown is split into smaller segments if it\u2019s very long (based on <code>chunk_token_threshold</code>, overlap, etc.).<br>\n2.\u2000<strong>Prompt Construction</strong>: For each chunk, the library forms a prompt that includes your <strong><code>instruction</code></strong> (and possibly schema or examples).<br>\n3.\u2000<strong>LLM Inference</strong>: Each chunk is sent to the model in parallel or sequentially (depending on your concurrency).<br>\n4.\u2000<strong>Combining</strong>: The results from each chunk are merged and parsed into JSON.</p>\n<h3 id=\"32-extraction_type\">3.2 <code>extraction_type</code></h3>\n<ul>\n<li><strong><code>\"schema\"</code></strong>: The model tries to return JSON conforming to your Pydantic-based schema.  </li>\n<li><strong><code>\"block\"</code></strong>: The model returns freeform text, or smaller JSON structures, which the library collects.  </li>\n</ul>\n<p>For structured data, <code>\"schema\"</code> is recommended. You provide <code>schema=YourPydanticModel.model_json_schema()</code>.</p>\n<hr>\n<h2 id=\"4-key-parameters\">4. Key Parameters</h2>\n<p>Below is an overview of important LLM extraction parameters. All are typically set inside <code>LLMExtractionStrategy(...)</code>. You then put that strategy in your <code>CrawlerRunConfig(..., extraction_strategy=...)</code>.</p>\n<p>1.\u2000<strong><code>provider</code></strong> (str): e.g., <code>\"openai/gpt-4\"</code>, <code>\"ollama/llama2\"</code>.<br>\n2.\u2000<strong><code>api_token</code></strong> (str): The API key or token for that model. May not be needed for local models.<br>\n3.\u2000<strong><code>schema</code></strong> (dict): A JSON schema describing the fields you want. Usually generated by <code>YourModel.model_json_schema()</code>.<br>\n4.\u2000<strong><code>extraction_type</code></strong> (str): <code>\"schema\"</code> or <code>\"block\"</code>.<br>\n5.\u2000<strong><code>instruction</code></strong> (str): Prompt text telling the LLM what you want extracted. E.g., \u201cExtract these fields as a JSON array.\u201d<br>\n6.\u2000<strong><code>chunk_token_threshold</code></strong> (int): Maximum tokens per chunk. If your content is huge, you can break it up for the LLM.<br>\n7.\u2000<strong><code>overlap_rate</code></strong> (float): Overlap ratio between adjacent chunks. E.g., <code>0.1</code> means 10% of each chunk is repeated to preserve context continuity.<br>\n8.\u2000<strong><code>apply_chunking</code></strong> (bool): Set <code>True</code> to chunk automatically. If you want a single pass, set <code>False</code>.<br>\n9.\u2000<strong><code>input_format</code></strong> (str): Determines <strong>which</strong> crawler result is passed to the LLM. Options include:<br>\n   - <code>\"markdown\"</code>: The raw markdown (default).<br>\n   - <code>\"fit_markdown\"</code>: The filtered \u201cfit\u201d markdown if you used a content filter.<br>\n   - <code>\"html\"</code>: The cleaned or raw HTML.<br>\n10.\u2000<strong><code>extra_args</code></strong> (dict): Additional LLM parameters like <code>temperature</code>, <code>max_tokens</code>, <code>top_p</code>, etc.<br>\n11.\u2000<strong><code>show_usage()</code></strong>: A method you can call to print out usage info (token usage per chunk, total cost if known).  </p>\n<p><strong>Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">extraction_strategy <span class=\"hljs-punctuation\">=</span> LLMExtractionStrategy<span class=\"hljs-punctuation\">(</span>\n    provider<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"openai/gpt-4\"</span>,\n    api_token<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"YOUR_OPENAI_KEY\"</span>,\n    <span class=\"hljs-keyword\">schema</span><span class=\"hljs-punctuation\">=</span>MyModel.model_json_schema<span class=\"hljs-punctuation\">(</span><span class=\"hljs-punctuation\">)</span>,\n    extraction_type<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"schema\"</span>,\n    instruction<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"Extract a list of items from the text with 'name' and 'price' fields.\"</span>,\n    chunk_token_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">1200</span>,\n    overlap_rate<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">0.1</span>,\n    apply_chunking<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    input_format<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"html\"</span>,\n    extra_args<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"temperature\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">0.1</span>, <span class=\"hljs-string\">\"max_tokens\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-number\">1000</span><span class=\"hljs-punctuation\">}</span>,\n    verbose<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<hr>\n<h2 id=\"5-putting-it-in-crawlerrunconfig\">5. Putting It in <code>CrawlerRunConfig</code></h2>\n<p><strong>Important</strong>: In Crawl4AI, all strategy definitions should go inside the <code>CrawlerRunConfig</code>, not directly as a param in <code>arun()</code>. Here\u2019s a full example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> pydantic <span class=\"hljs-keyword\">import</span> BaseModel, Field\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">List</span>\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> LLMExtractionStrategy\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Product</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    name: <span class=\"hljs-built_in\">str</span>\n    price: <span class=\"hljs-built_in\">str</span>\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1. Define the LLM extraction strategy</span>\n    llm_strategy = LLMExtractionStrategy(\n        provider=<span class=\"hljs-string\">\"openai/gpt-4o-mini\"</span>,            <span class=\"hljs-comment\"># e.g. \"ollama/llama2\"</span>\n        api_token=os.getenv(<span class=\"hljs-string\">'OPENAI_API_KEY'</span>),\n        schema=Product.schema_json(),            <span class=\"hljs-comment\"># Or use model_json_schema()</span>\n        extraction_type=<span class=\"hljs-string\">\"schema\"</span>,\n        instruction=<span class=\"hljs-string\">\"Extract all product objects with 'name' and 'price' from the content.\"</span>,\n        chunk_token_threshold=<span class=\"hljs-number\">1000</span>,\n        overlap_rate=<span class=\"hljs-number\">0.0</span>,\n        apply_chunking=<span class=\"hljs-literal\">True</span>,\n        input_format=<span class=\"hljs-string\">\"markdown\"</span>,   <span class=\"hljs-comment\"># or \"html\", \"fit_markdown\"</span>\n        extra_args={<span class=\"hljs-string\">\"temperature\"</span>: <span class=\"hljs-number\">0.0</span>, <span class=\"hljs-string\">\"max_tokens\"</span>: <span class=\"hljs-number\">800</span>}\n    )\n\n    <span class=\"hljs-comment\"># 2. Build the crawler config</span>\n    crawl_config = CrawlerRunConfig(\n        extraction_strategy=llm_strategy,\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-comment\"># 3. Create a browser config if needed</span>\n    browser_cfg = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># 4. Let's say we want to crawl a single page</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com/products\"</span>,\n            config=crawl_config\n        )\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-comment\"># 5. The extracted content is presumably JSON</span>\n            data = json.loads(result.extracted_content)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extracted items:\"</span>, data)\n\n            <span class=\"hljs-comment\"># 6. Show usage stats</span>\n            llm_strategy.show_usage()  <span class=\"hljs-comment\"># prints token usage</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"6-chunking-details\">6. Chunking Details</h2>\n<h3 id=\"61-chunk_token_threshold\">6.1 <code>chunk_token_threshold</code></h3>\n<p>If your page is large, you might exceed your LLM\u2019s context window.\u2000<strong><code>chunk_token_threshold</code></strong> sets the approximate max tokens per chunk. The library calculates word\u2192token ratio using <code>word_token_rate</code> (often ~0.75 by default). If chunking is enabled (<code>apply_chunking=True</code>), the text is split into segments.</p>\n<h3 id=\"62-overlap_rate\">6.2 <code>overlap_rate</code></h3>\n<p>To keep context continuous across chunks, we can overlap them. E.g., <code>overlap_rate=0.1</code> means each subsequent chunk includes 10% of the previous chunk\u2019s text. This is helpful if your needed info might straddle chunk boundaries.</p>\n<h3 id=\"63-performance-parallelism\">6.3 Performance &amp; Parallelism</h3>\n<p>By chunking, you can potentially process multiple chunks in parallel (depending on your concurrency settings and the LLM provider). This reduces total time if the site is huge or has many sections.</p>\n<hr>\n<h2 id=\"7-input-format\">7. Input Format</h2>\n<p>By default, <strong>LLMExtractionStrategy</strong> uses <code>input_format=\"markdown\"</code>, meaning the <strong>crawler\u2019s final markdown</strong> is fed to the LLM. You can change to:</p>\n<ul>\n<li><strong><code>html</code></strong>: The cleaned HTML or raw HTML (depending on your crawler config) goes into the LLM.  </li>\n<li><strong><code>fit_markdown</code></strong>: If you used, for instance, <code>PruningContentFilter</code>, the \u201cfit\u201d version of the markdown is used. This can drastically reduce tokens if you trust the filter.  </li>\n<li><strong><code>markdown</code></strong>: Standard markdown output from the crawler\u2019s <code>markdown_generator</code>.</li>\n</ul>\n<p>This setting is crucial: if the LLM instructions rely on HTML tags, pick <code>\"html\"</code>. If you prefer a text-based approach, pick <code>\"markdown\"</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">LLMExtractionStrategy(\n    <span class=\"hljs-comment\"># ...</span>\n    input_format=<span class=\"hljs-string\">\"html\"</span>,  <span class=\"hljs-comment\"># Instead of \"markdown\" or \"fit_markdown\"</span>\n)\n</code></pre></div>\n<hr>\n<h2 id=\"8-token-usage-show-usage\">8. Token Usage &amp; Show Usage</h2>\n<p>To keep track of tokens and cost, each chunk is processed with an LLM call. We record usage in:</p>\n<ul>\n<li><strong><code>usages</code></strong> (list): token usage per chunk or call.  </li>\n<li><strong><code>total_usage</code></strong>: sum of all chunk calls.  </li>\n<li><strong><code>show_usage()</code></strong>: prints a usage report (if the provider returns usage data).</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">llm_strategy = LLMExtractionStrategy(...)\n<span class=\"hljs-comment\"># ...</span>\nllm_strategy.show_usage()\n<span class=\"hljs-comment\"># e.g. \u201cTotal usage: 1241 tokens across 2 chunk calls\u201d</span>\n</code></pre></div>\n<p>If your model provider doesn\u2019t return usage info, these fields might be partial or empty.</p>\n<hr>\n<h2 id=\"9-example-building-a-knowledge-graph\">9. Example: Building a Knowledge Graph</h2>\n<p>Below is a snippet combining <strong><code>LLMExtractionStrategy</code></strong> with a Pydantic schema for a knowledge graph. Notice how we pass an <strong><code>instruction</code></strong> telling the model what to parse.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">List</span>\n<span class=\"hljs-keyword\">from</span> pydantic <span class=\"hljs-keyword\">import</span> BaseModel, Field\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> LLMExtractionStrategy\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Entity</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    name: <span class=\"hljs-built_in\">str</span>\n    description: <span class=\"hljs-built_in\">str</span>\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Relationship</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    entity1: Entity\n    entity2: Entity\n    description: <span class=\"hljs-built_in\">str</span>\n    relation_type: <span class=\"hljs-built_in\">str</span>\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">KnowledgeGraph</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    entities: <span class=\"hljs-type\">List</span>[Entity]\n    relationships: <span class=\"hljs-type\">List</span>[Relationship]\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># LLM extraction strategy</span>\n    llm_strat = LLMExtractionStrategy(\n        provider=<span class=\"hljs-string\">\"openai/gpt-4\"</span>,\n        api_token=os.getenv(<span class=\"hljs-string\">'OPENAI_API_KEY'</span>),\n        schema=KnowledgeGraph.schema_json(),\n        extraction_type=<span class=\"hljs-string\">\"schema\"</span>,\n        instruction=<span class=\"hljs-string\">\"Extract entities and relationships from the content. Return valid JSON.\"</span>,\n        chunk_token_threshold=<span class=\"hljs-number\">1400</span>,\n        apply_chunking=<span class=\"hljs-literal\">True</span>,\n        input_format=<span class=\"hljs-string\">\"html\"</span>,\n        extra_args={<span class=\"hljs-string\">\"temperature\"</span>: <span class=\"hljs-number\">0.1</span>, <span class=\"hljs-string\">\"max_tokens\"</span>: <span class=\"hljs-number\">1500</span>}\n    )\n\n    crawl_config = CrawlerRunConfig(\n        extraction_strategy=llm_strat,\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Example page</span>\n        url = <span class=\"hljs-string\">\"https://www.nbcnews.com/business\"</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=url, config=crawl_config)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"kb_result.json\"</span>, <span class=\"hljs-string\">\"w\"</span>, encoding=<span class=\"hljs-string\">\"utf-8\"</span>) <span class=\"hljs-keyword\">as</span> f:\n                f.write(result.extracted_content)\n            llm_strat.show_usage()\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key Observations</strong>:</p>\n<ul>\n<li><strong><code>extraction_type=\"schema\"</code></strong> ensures we get JSON fitting our <code>KnowledgeGraph</code>.  </li>\n<li><strong><code>input_format=\"html\"</code></strong> means we feed HTML to the model.  </li>\n<li><strong><code>instruction</code></strong> guides the model to output a structured knowledge graph.  </li>\n</ul>\n<hr>\n<h2 id=\"10-best-practices-caveats\">10. Best Practices &amp; Caveats</h2>\n<p>1.\u2000<strong>Cost &amp; Latency</strong>: LLM calls can be slow or expensive. Consider chunking or smaller coverage if you only need partial data.<br>\n2.\u2000<strong>Model Token Limits</strong>: If your page + instruction exceed the context window, chunking is essential.<br>\n3.\u2000<strong>Instruction Engineering</strong>: Well-crafted instructions can drastically improve output reliability.<br>\n4.\u2000<strong>Schema Strictness</strong>: <code>\"schema\"</code> extraction tries to parse the model output as JSON. If the model returns invalid JSON, partial extraction might happen, or you might get an error.<br>\n5.\u2000<strong>Parallel vs. Serial</strong>: The library can process multiple chunks in parallel, but you must watch out for rate limits on certain providers.<br>\n6.\u2000<strong>Check Output</strong>: Sometimes, an LLM might omit fields or produce extraneous text. You may want to post-validate with Pydantic or do additional cleanup.</p>\n<hr>\n<h2 id=\"11-conclusion\">11. Conclusion</h2>\n<p><strong>LLM-based extraction</strong> in Crawl4AI is <strong>provider-agnostic</strong>, letting you choose from hundreds of models via LightLLM. It\u2019s perfect for <strong>semantically complex</strong> tasks or generating advanced structures like knowledge graphs. However, it\u2019s <strong>slower</strong> and potentially costlier than schema-based approaches. Keep these tips in mind:</p>\n<ul>\n<li>Put your LLM strategy <strong>in <code>CrawlerRunConfig</code></strong>.  </li>\n<li>Use <strong><code>input_format</code></strong> to pick which form (markdown, HTML, fit_markdown) the LLM sees.  </li>\n<li>Tweak <strong><code>chunk_token_threshold</code></strong>, <strong><code>overlap_rate</code></strong>, and <strong><code>apply_chunking</code></strong> to handle large content efficiently.  </li>\n<li>Monitor token usage with <code>show_usage()</code>.</li>\n</ul>\n<p>If your site\u2019s data is consistent or repetitive, consider <a href=\"../no-llm-strategies/\"><code>JsonCssExtractionStrategy</code></a> first for speed and simplicity. But if you need an <strong>AI-driven</strong> approach, <code>LLMExtractionStrategy</code> offers a flexible, multi-provider solution for extracting structured JSON from any website.</p>\n<p><strong>Next Steps</strong>:</p>\n<p>1.\u2000<strong>Experiment with Different Providers</strong><br>\n   - Try switching the <code>provider</code> (e.g., <code>\"ollama/llama2\"</code>, <code>\"openai/gpt-4o\"</code>, etc.) to see differences in speed, accuracy, or cost.<br>\n   - Pass different <code>extra_args</code> like <code>temperature</code>, <code>top_p</code>, and <code>max_tokens</code> to fine-tune your results.</p>\n<p>2.\u2000<strong>Performance Tuning</strong><br>\n   - If pages are large, tweak <code>chunk_token_threshold</code>, <code>overlap_rate</code>, or <code>apply_chunking</code> to optimize throughput.<br>\n   - Check the usage logs with <code>show_usage()</code> to keep an eye on token consumption and identify potential bottlenecks.</p>\n<p>3.\u2000<strong>Validate Outputs</strong><br>\n   - If using <code>extraction_type=\"schema\"</code>, parse the LLM\u2019s JSON with a Pydantic model for a final validation step.<br>\n   - Log or handle any parse errors gracefully, especially if the model occasionally returns malformed JSON.</p>\n<p>4.\u2000<strong>Explore Hooks &amp; Automation</strong><br>\n   - Integrate LLM extraction with <a href=\"../../advanced/hooks-auth/\">hooks</a> for complex pre/post-processing.<br>\n   - Use a multi-step pipeline: crawl, filter, LLM-extract, then store or index results for further analysis.</p>\n<p><strong>Last Updated</strong>: 2025-01-01</p>\n<hr>\n<p>That\u2019s it for <strong>Extracting JSON (LLM)</strong>\u2014now you can harness AI to parse, classify, or reorganize data on the web. Happy crawling!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Extracting JSON (LLM)\nIn some cases, you need to extract **complex or unstructured** information from a webpage that a simple CSS/XPath schema cannot easily parse. Or you want **AI** -driven insights, classification, or summarization. For these scenarios, Crawl4AI provides an **LLM-based extraction strategy** that:\n  1. Works with **any** large language model supported by (Ollama, OpenAI, Claude, and more). \n  2. Automatically splits content into chunks (if desired) to handle token limits, then combines results. \n  3. Lets you define a **schema** (like a Pydantic model) or a simpler \u201cblock\u201d extraction approach.\n\n\n**Important** : LLM-based extraction can be slower and costlier than schema-based approaches. If your page data is highly structured, consider using `JsonCssExtractionStrategy`[](https://docs.crawl4ai.com/extraction/<../no-llm-strategies/>) or `JsonXPathExtractionStrategy`[](https://docs.crawl4ai.com/extraction/<../no-llm-strategies/>) first. But if you need AI to interpret or reorganize content, read on!\n## 1. Why Use an LLM?\n  * **Complex Reasoning** : If the site\u2019s data is unstructured, scattered, or full of natural language context. \n  * **Semantic Extraction** : Summaries, knowledge graphs, or relational data that require comprehension. \n  * **Flexible** : You can pass instructions to the model to do more advanced transformations or classification.\n\n\n## 2. Provider-Agnostic via LightLLM\nCrawl4AI uses a \u201cprovider string\u201d (e.g., `\"openai/gpt-4o\"`, `\"ollama/llama2.0\"`, `\"aws/titan\"`) to identify your LLM. **Any** model that LightLLM supports is fair game. You just provide:\n  * **`provider`**: The`<provider>/<model_name>` identifier (e.g., `\"openai/gpt-4\"`, `\"ollama/llama2\"`, `\"huggingface/google-flan\"`, etc.). \n  * **`api_token`**: If needed (for OpenAI, HuggingFace, etc.); local models or Ollama might not require it.\n  * **`api_base`**(optional): If your provider has a custom endpoint.\n\n\nThis means you **aren\u2019t locked** into a single LLM vendor. Switch or experiment easily.\n## 3. How LLM Extraction Works\n### 3.1 Flow\n1. **Chunking** (optional): The HTML or markdown is split into smaller segments if it\u2019s very long (based on `chunk_token_threshold`, overlap, etc.). 2. **Prompt Construction** : For each chunk, the library forms a prompt that includes your **`instruction`**(and possibly schema or examples). 3.**LLM Inference** : Each chunk is sent to the model in parallel or sequentially (depending on your concurrency). 4. **Combining** : The results from each chunk are merged and parsed into JSON.\n### 3.2 `extraction_type`\n  * **`\"schema\"`**: The model tries to return JSON conforming to your Pydantic-based schema.\n  * **`\"block\"`**: The model returns freeform text, or smaller JSON structures, which the library collects.\n\n\nFor structured data, `\"schema\"` is recommended. You provide `schema=YourPydanticModel.model_json_schema()`.\n## 4. Key Parameters\nBelow is an overview of important LLM extraction parameters. All are typically set inside `LLMExtractionStrategy(...)`. You then put that strategy in your `CrawlerRunConfig(..., extraction_strategy=...)`.\n1. **`provider`**(str): e.g.,`\"openai/gpt-4\"` , `\"ollama/llama2\"`. 2. **`api_token`**(str): The API key or token for that model. May not be needed for local models. 3.**`schema`**(dict): A JSON schema describing the fields you want. Usually generated by`YourModel.model_json_schema()`. 4. **`extraction_type`**(str):`\"schema\"` or `\"block\"`. 5. **`instruction`**(str): Prompt text telling the LLM what you want extracted. E.g., \u201cExtract these fields as a JSON array.\u201d 6.**`chunk_token_threshold`**(int): Maximum tokens per chunk. If your content is huge, you can break it up for the LLM. 7.**`overlap_rate`**(float): Overlap ratio between adjacent chunks. E.g.,`0.1` means 10% of each chunk is repeated to preserve context continuity. 8. **`apply_chunking`**(bool): Set`True` to chunk automatically. If you want a single pass, set `False`. 9. **`input_format`**(str): Determines**which** crawler result is passed to the LLM. Options include: - `\"markdown\"`: The raw markdown (default). - `\"fit_markdown\"`: The filtered \u201cfit\u201d markdown if you used a content filter. - `\"html\"`: The cleaned or raw HTML. 10. **`extra_args`**(dict): Additional LLM parameters like`temperature` , `max_tokens`, `top_p`, etc. 11. **`show_usage()`**: A method you can call to print out usage info (token usage per chunk, total cost if known).\n**Example** :\n```\nextraction_strategy = LLMExtractionStrategy(\n  provider=\"openai/gpt-4\",\n  api_token=\"YOUR_OPENAI_KEY\",\n  schema=MyModel.model_json_schema(),\n  extraction_type=\"schema\",\n  instruction=\"Extract a list of items from the text with 'name' and 'price' fields.\",\n  chunk_token_threshold=1200,\n  overlap_rate=0.1,\n  apply_chunking=True,\n  input_format=\"html\",\n  extra_args={\"temperature\": 0.1, \"max_tokens\": 1000},\n  verbose=True\n)\n\n```\n\n## 5. Putting It in `CrawlerRunConfig`\n**Important** : In Crawl4AI, all strategy definitions should go inside the `CrawlerRunConfig`, not directly as a param in `arun()`. Here\u2019s a full example:\n```\nimport os\nimport asyncio\nimport json\nfrom pydantic import BaseModel, Field\nfrom typing import List\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\nclass Product(BaseModel):\n  name: str\n  price: str\nasync def main():\n  # 1. Define the LLM extraction strategy\n  llm_strategy = LLMExtractionStrategy(\n    provider=\"openai/gpt-4o-mini\",      # e.g. \"ollama/llama2\"\n    api_token=os.getenv('OPENAI_API_KEY'),\n    schema=Product.schema_json(),      # Or use model_json_schema()\n    extraction_type=\"schema\",\n    instruction=\"Extract all product objects with 'name' and 'price' from the content.\",\n    chunk_token_threshold=1000,\n    overlap_rate=0.0,\n    apply_chunking=True,\n    input_format=\"markdown\",  # or \"html\", \"fit_markdown\"\n    extra_args={\"temperature\": 0.0, \"max_tokens\": 800}\n  )\n  # 2. Build the crawler config\n  crawl_config = CrawlerRunConfig(\n    extraction_strategy=llm_strategy,\n    cache_mode=CacheMode.BYPASS\n  )\n  # 3. Create a browser config if needed\n  browser_cfg = BrowserConfig(headless=True)\n  async with AsyncWebCrawler(config=browser_cfg) as crawler:\n    # 4. Let's say we want to crawl a single page\n    result = await crawler.arun(\n      url=\"https://example.com/products\",\n      config=crawl_config\n    )\n    if result.success:\n      # 5. The extracted content is presumably JSON\n      data = json.loads(result.extracted_content)\n      print(\"Extracted items:\", data)\n      # 6. Show usage stats\n      llm_strategy.show_usage() # prints token usage\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 6. Chunking Details\n### 6.1 `chunk_token_threshold`\nIf your page is large, you might exceed your LLM\u2019s context window. **`chunk_token_threshold`**sets the approximate max tokens per chunk. The library calculates word\u2192token ratio using`word_token_rate` (often ~0.75 by default). If chunking is enabled (`apply_chunking=True`), the text is split into segments.\n### 6.2 `overlap_rate`\nTo keep context continuous across chunks, we can overlap them. E.g., `overlap_rate=0.1` means each subsequent chunk includes 10% of the previous chunk\u2019s text. This is helpful if your needed info might straddle chunk boundaries.\n### 6.3 Performance & Parallelism\nBy chunking, you can potentially process multiple chunks in parallel (depending on your concurrency settings and the LLM provider). This reduces total time if the site is huge or has many sections.\n## 7. Input Format\nBy default, **LLMExtractionStrategy** uses `input_format=\"markdown\"`, meaning the **crawler\u2019s final markdown** is fed to the LLM. You can change to:\n  * **`html`**: The cleaned HTML or raw HTML (depending on your crawler config) goes into the LLM.\n  * **`fit_markdown`**: If you used, for instance,`PruningContentFilter` , the \u201cfit\u201d version of the markdown is used. This can drastically reduce tokens if you trust the filter. \n  * **`markdown`**: Standard markdown output from the crawler\u2019s`markdown_generator`.\n\n\nThis setting is crucial: if the LLM instructions rely on HTML tags, pick `\"html\"`. If you prefer a text-based approach, pick `\"markdown\"`.\n```\nLLMExtractionStrategy(\n  # ...\n  input_format=\"html\", # Instead of \"markdown\" or \"fit_markdown\"\n)\n\n```\n\n## 8. Token Usage & Show Usage\nTo keep track of tokens and cost, each chunk is processed with an LLM call. We record usage in:\n  * **`usages`**(list): token usage per chunk or call.\n  * **`total_usage`**: sum of all chunk calls.\n  * **`show_usage()`**: prints a usage report (if the provider returns usage data).\n\n\n```\nllm_strategy = LLMExtractionStrategy(...)\n# ...\nllm_strategy.show_usage()\n# e.g. \u201cTotal usage: 1241 tokens across 2 chunk calls\u201d\n\n```\n\nIf your model provider doesn\u2019t return usage info, these fields might be partial or empty.\n## 9. Example: Building a Knowledge Graph\nBelow is a snippet combining **`LLMExtractionStrategy`**with a Pydantic schema for a knowledge graph. Notice how we pass an**`instruction`**telling the model what to parse.\n```\nimport os\nimport json\nimport asyncio\nfrom typing import List\nfrom pydantic import BaseModel, Field\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\nclass Entity(BaseModel):\n  name: str\n  description: str\nclass Relationship(BaseModel):\n  entity1: Entity\n  entity2: Entity\n  description: str\n  relation_type: str\nclass KnowledgeGraph(BaseModel):\n  entities: List[Entity]\n  relationships: List[Relationship]\nasync def main():\n  # LLM extraction strategy\n  llm_strat = LLMExtractionStrategy(\n    provider=\"openai/gpt-4\",\n    api_token=os.getenv('OPENAI_API_KEY'),\n    schema=KnowledgeGraph.schema_json(),\n    extraction_type=\"schema\",\n    instruction=\"Extract entities and relationships from the content. Return valid JSON.\",\n    chunk_token_threshold=1400,\n    apply_chunking=True,\n    input_format=\"html\",\n    extra_args={\"temperature\": 0.1, \"max_tokens\": 1500}\n  )\n  crawl_config = CrawlerRunConfig(\n    extraction_strategy=llm_strat,\n    cache_mode=CacheMode.BYPASS\n  )\n  async with AsyncWebCrawler(config=BrowserConfig(headless=True)) as crawler:\n    # Example page\n    url = \"https://www.nbcnews.com/business\"\n    result = await crawler.arun(url=url, config=crawl_config)\n    if result.success:\n      with open(\"kb_result.json\", \"w\", encoding=\"utf-8\") as f:\n        f.write(result.extracted_content)\n      llm_strat.show_usage()\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key Observations** :\n  * **`extraction_type=\"schema\"`**ensures we get JSON fitting our`KnowledgeGraph`. \n  * **`input_format=\"html\"`**means we feed HTML to the model.\n  * **`instruction`**guides the model to output a structured knowledge graph.\n\n\n## 10. Best Practices & Caveats\n1. **Cost & Latency**: LLM calls can be slow or expensive. Consider chunking or smaller coverage if you only need partial data. 2. **Model Token Limits** : If your page + instruction exceed the context window, chunking is essential. 3. **Instruction Engineering** : Well-crafted instructions can drastically improve output reliability. 4. **Schema Strictness** : `\"schema\"` extraction tries to parse the model output as JSON. If the model returns invalid JSON, partial extraction might happen, or you might get an error. 5. **Parallel vs. Serial** : The library can process multiple chunks in parallel, but you must watch out for rate limits on certain providers. 6. **Check Output** : Sometimes, an LLM might omit fields or produce extraneous text. You may want to post-validate with Pydantic or do additional cleanup.\n## 11. Conclusion\n**LLM-based extraction** in Crawl4AI is **provider-agnostic** , letting you choose from hundreds of models via LightLLM. It\u2019s perfect for **semantically complex** tasks or generating advanced structures like knowledge graphs. However, it\u2019s **slower** and potentially costlier than schema-based approaches. Keep these tips in mind:\n  * Put your LLM strategy **in`CrawlerRunConfig`**. \n  * Use **`input_format`**to pick which form (markdown, HTML, fit_markdown) the LLM sees.\n  * Tweak **`chunk_token_threshold`**,**`overlap_rate`**, and**`apply_chunking`**to handle large content efficiently.\n  * Monitor token usage with `show_usage()`.\n\n\nIf your site\u2019s data is consistent or repetitive, consider `JsonCssExtractionStrategy`[](https://docs.crawl4ai.com/extraction/<../no-llm-strategies/>) first for speed and simplicity. But if you need an **AI-driven** approach, `LLMExtractionStrategy` offers a flexible, multi-provider solution for extracting structured JSON from any website.\n**Next Steps** :\n1. **Experiment with Different Providers** - Try switching the `provider` (e.g., `\"ollama/llama2\"`, `\"openai/gpt-4o\"`, etc.) to see differences in speed, accuracy, or cost. - Pass different `extra_args` like `temperature`, `top_p`, and `max_tokens` to fine-tune your results.\n2. **Performance Tuning** - If pages are large, tweak `chunk_token_threshold`, `overlap_rate`, or `apply_chunking` to optimize throughput. - Check the usage logs with `show_usage()` to keep an eye on token consumption and identify potential bottlenecks.\n3. **Validate Outputs** - If using `extraction_type=\"schema\"`, parse the LLM\u2019s JSON with a Pydantic model for a final validation step. - Log or handle any parse errors gracefully, especially if the model occasionally returns malformed JSON.\n4. **Explore Hooks & Automation** - Integrate LLM extraction with [hooks](https://docs.crawl4ai.com/extraction/advanced/hooks-auth/>) for complex pre/post-processing. - Use a multi-step pipeline: crawl, filter, LLM-extract, then store or index results for further analysis.\n**Last Updated** : 2025-01-01\nThat\u2019s it for **Extracting JSON (LLM)** \u2014now you can harness AI to parse, classify, or reorganize data on the web. Happy crawling!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/chunking",
        "https://docs.crawl4ai.com/clustring-strategies",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/no-llm-strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 29,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:36",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "local-files.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/local-files",
      "timestamp": "2025-02-06T13:23:43.952252",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/local-files/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Local Files &amp; Raw HTML - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Local Files &amp; Raw HTML</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#prefix-based-input-handling-in-crawl4ai\">Prefix-Based Input Handling in Crawl4AI</a></li>\n        <li><a href=\"#crawling-a-web-url\">Crawling a Web URL</a></li><li><a href=\"#crawling-a-local-html-file\">Crawling a Local HTML File</a></li><li><a href=\"#crawling-raw-html-content\">Crawling Raw HTML Content</a></li><li><a href=\"#complete-example\">Complete Example</a></li>\n        <li><a href=\"#conclusion\">Conclusion</a></li>\n        \n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"prefix-based-input-handling-in-crawl4ai\">Prefix-Based Input Handling in Crawl4AI</h1>\n<p>This guide will walk you through using the Crawl4AI library to crawl web pages, local HTML files, and raw HTML strings. We'll demonstrate these capabilities using a Wikipedia page as an example.</p>\n<h2 id=\"crawling-a-web-url\">Crawling a Web URL</h2>\n<p>To crawl a live web page, provide the URL starting with <code>http://</code> or <code>https://</code>, using a <code>CrawlerRunConfig</code> object:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_web</span>():\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://en.wikipedia.org/wiki/apple\"</span>, \n            config=config\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_web())\n</code></pre></div>\n<h2 id=\"crawling-a-local-html-file\">Crawling a Local HTML File</h2>\n<p>To crawl a local HTML file, prefix the file path with <code>file://</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_local_file</span>():\n    local_file_path = <span class=\"hljs-string\">\"/path/to/apple.html\"</span>  <span class=\"hljs-comment\"># Replace with your file path</span>\n    file_url = <span class=\"hljs-string\">f\"file://<span class=\"hljs-subst\">{local_file_path}</span>\"</span>\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=file_url, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content from Local File:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl local file: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_local_file())\n</code></pre></div>\n<h2 id=\"crawling-raw-html-content\">Crawling Raw HTML Content</h2>\n<p>To crawl raw HTML content, prefix the HTML string with <code>raw:</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_raw_html</span>():\n    raw_html = <span class=\"hljs-string\">\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\"</span>\n    raw_html_url = <span class=\"hljs-string\">f\"raw:<span class=\"hljs-subst\">{raw_html}</span>\"</span>\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=raw_html_url, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content from Raw HTML:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl raw HTML: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_raw_html())\n</code></pre></div>\n<hr>\n<h1 id=\"complete-example\">Complete Example</h1>\n<p>Below is a comprehensive script that:</p>\n<ol>\n<li>Crawls the Wikipedia page for \"Apple.\"</li>\n<li>Saves the HTML content to a local file (<code>apple.html</code>).</li>\n<li>Crawls the local HTML file and verifies the markdown length matches the original crawl.</li>\n<li>Crawls the raw HTML content from the saved file and verifies consistency.</li>\n</ol>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> pathlib <span class=\"hljs-keyword\">import</span> Path\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    wikipedia_url = <span class=\"hljs-string\">\"https://en.wikipedia.org/wiki/apple\"</span>\n    script_dir = Path(__file__).parent\n    html_file_path = script_dir / <span class=\"hljs-string\">\"apple.html\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Step 1: Crawl the Web URL</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n=== Step 1: Crawling the Wikipedia URL ===\"</span>)\n        web_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=wikipedia_url, config=web_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl <span class=\"hljs-subst\">{wikipedia_url}</span>: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(html_file_path, <span class=\"hljs-string\">'w'</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>) <span class=\"hljs-keyword\">as</span> f:\n            f.write(result.html)\n        web_crawl_length = <span class=\"hljs-built_in\">len</span>(result.markdown)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Length of markdown from web crawl: <span class=\"hljs-subst\">{web_crawl_length}</span>\\n\"</span>)\n\n        <span class=\"hljs-comment\"># Step 2: Crawl from the Local HTML File</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"=== Step 2: Crawling from the Local HTML File ===\"</span>)\n        file_url = <span class=\"hljs-string\">f\"file://<span class=\"hljs-subst\">{html_file_path.resolve()}</span>\"</span>\n        file_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        local_result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=file_url, config=file_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> local_result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl local file <span class=\"hljs-subst\">{file_url}</span>: <span class=\"hljs-subst\">{local_result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        local_crawl_length = <span class=\"hljs-built_in\">len</span>(local_result.markdown)\n        <span class=\"hljs-keyword\">assert</span> web_crawl_length == local_crawl_length, <span class=\"hljs-string\">\"Markdown length mismatch\"</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\u2705 Markdown length matches between web and local file crawl.\\n\"</span>)\n\n        <span class=\"hljs-comment\"># Step 3: Crawl Using Raw HTML Content</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"=== Step 3: Crawling Using Raw HTML Content ===\"</span>)\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(html_file_path, <span class=\"hljs-string\">'r'</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>) <span class=\"hljs-keyword\">as</span> f:\n            raw_html_content = f.read()\n        raw_html_url = <span class=\"hljs-string\">f\"raw:<span class=\"hljs-subst\">{raw_html_content}</span>\"</span>\n        raw_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        raw_result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=raw_html_url, config=raw_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> raw_result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl raw HTML content: <span class=\"hljs-subst\">{raw_result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        raw_crawl_length = <span class=\"hljs-built_in\">len</span>(raw_result.markdown)\n        <span class=\"hljs-keyword\">assert</span> web_crawl_length == raw_crawl_length, <span class=\"hljs-string\">\"Markdown length mismatch\"</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\u2705 Markdown length matches between web and raw HTML crawl.\\n\"</span>)\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"All tests passed successfully!\"</span>)\n    <span class=\"hljs-keyword\">if</span> html_file_path.exists():\n        os.remove(html_file_path)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h1 id=\"conclusion\">Conclusion</h1>\n<p>With the unified <code>url</code> parameter and prefix-based handling in <strong>Crawl4AI</strong>, you can seamlessly handle web URLs, local HTML files, and raw HTML content. Use <code>CrawlerRunConfig</code> for flexible and consistent configuration in all scenarios.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Prefix-Based Input Handling in Crawl4AI\nThis guide will walk you through using the Crawl4AI library to crawl web pages, local HTML files, and raw HTML strings. We'll demonstrate these capabilities using a Wikipedia page as an example.\n## Crawling a Web URL\nTo crawl a live web page, provide the URL starting with `http://` or `https://`, using a `CrawlerRunConfig` object:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_web():\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://en.wikipedia.org/wiki/apple\", \n      config=config\n    )\n    if result.success:\n      print(\"Markdown Content:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl: {result.error_message}\")\nasyncio.run(crawl_web())\n\n```\n\n## Crawling a Local HTML File\nTo crawl a local HTML file, prefix the file path with `file://`.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_local_file():\n  local_file_path = \"/path/to/apple.html\" # Replace with your file path\n  file_url = f\"file://{local_file_path}\"\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=file_url, config=config)\n    if result.success:\n      print(\"Markdown Content from Local File:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl local file: {result.error_message}\")\nasyncio.run(crawl_local_file())\n\n```\n\n## Crawling Raw HTML Content\nTo crawl raw HTML content, prefix the HTML string with `raw:`.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_raw_html():\n  raw_html = \"<html><body><h1>Hello, World!</h1></body></html>\"\n  raw_html_url = f\"raw:{raw_html}\"\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=raw_html_url, config=config)\n    if result.success:\n      print(\"Markdown Content from Raw HTML:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl raw HTML: {result.error_message}\")\nasyncio.run(crawl_raw_html())\n\n```\n\n# Complete Example\nBelow is a comprehensive script that:\n  1. Crawls the Wikipedia page for \"Apple.\"\n  2. Saves the HTML content to a local file (`apple.html`).\n  3. Crawls the local HTML file and verifies the markdown length matches the original crawl.\n  4. Crawls the raw HTML content from the saved file and verifies consistency.\n\n\n```\nimport os\nimport sys\nimport asyncio\nfrom pathlib import Path\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def main():\n  wikipedia_url = \"https://en.wikipedia.org/wiki/apple\"\n  script_dir = Path(__file__).parent\n  html_file_path = script_dir / \"apple.html\"\n  async with AsyncWebCrawler() as crawler:\n    # Step 1: Crawl the Web URL\n    print(\"\\n=== Step 1: Crawling the Wikipedia URL ===\")\n    web_config = CrawlerRunConfig(bypass_cache=True)\n    result = await crawler.arun(url=wikipedia_url, config=web_config)\n    if not result.success:\n      print(f\"Failed to crawl {wikipedia_url}: {result.error_message}\")\n      return\n    with open(html_file_path, 'w', encoding='utf-8') as f:\n      f.write(result.html)\n    web_crawl_length = len(result.markdown)\n    print(f\"Length of markdown from web crawl: {web_crawl_length}\\n\")\n    # Step 2: Crawl from the Local HTML File\n    print(\"=== Step 2: Crawling from the Local HTML File ===\")\n    file_url = f\"file://{html_file_path.resolve()}\"\n    file_config = CrawlerRunConfig(bypass_cache=True)\n    local_result = await crawler.arun(url=file_url, config=file_config)\n    if not local_result.success:\n      print(f\"Failed to crawl local file {file_url}: {local_result.error_message}\")\n      return\n    local_crawl_length = len(local_result.markdown)\n    assert web_crawl_length == local_crawl_length, \"Markdown length mismatch\"\n    print(\"\u2705 Markdown length matches between web and local file crawl.\\n\")\n    # Step 3: Crawl Using Raw HTML Content\n    print(\"=== Step 3: Crawling Using Raw HTML Content ===\")\n    with open(html_file_path, 'r', encoding='utf-8') as f:\n      raw_html_content = f.read()\n    raw_html_url = f\"raw:{raw_html_content}\"\n    raw_config = CrawlerRunConfig(bypass_cache=True)\n    raw_result = await crawler.arun(url=raw_html_url, config=raw_config)\n    if not raw_result.success:\n      print(f\"Failed to crawl raw HTML content: {raw_result.error_message}\")\n      return\n    raw_crawl_length = len(raw_result.markdown)\n    assert web_crawl_length == raw_crawl_length, \"Markdown length mismatch\"\n    print(\"\u2705 Markdown length matches between web and raw HTML crawl.\\n\")\n    print(\"All tests passed successfully!\")\n  if html_file_path.exists():\n    os.remove(html_file_path)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n# Conclusion\nWith the unified `url` parameter and prefix-based handling in **Crawl4AI** , you can seamlessly handle web URLs, local HTML files, and raw HTML content. Use `CrawlerRunConfig` for flexible and consistent configuration in all scenarios.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 22,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:27",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "markdown-generation.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/markdown-generation",
      "timestamp": "2025-02-06T13:23:45.310043",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/markdown-generation/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Markdown Generation - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Markdown Generation</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#markdown-generation-basics\">Markdown Generation Basics</a></li>\n        <li><a href=\"#1-quick-example\">1. Quick Example</a></li><li><a href=\"#2-how-markdown-generation-works\">2. How Markdown Generation Works</a></li><li><a href=\"#3-configuring-the-default-markdown-generator\">3. Configuring the Default Markdown Generator</a></li><li><a href=\"#4-content-filters\">4. Content Filters</a></li><li><a href=\"#5-using-fit-markdown\">5. Using Fit Markdown</a></li><li><a href=\"#6-the-markdowngenerationresult-object\">6. The MarkdownGenerationResult Object</a></li><li><a href=\"#7-combining-filters-bm25-pruning-in-two-passes\">7. Combining Filters (BM25 + Pruning) in Two Passes</a></li><li><a href=\"#8-common-pitfalls-tips\">8. Common Pitfalls &amp; Tips</a></li><li><a href=\"#9-summary-next-steps\">9. Summary &amp; Next Steps</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"markdown-generation-basics\">Markdown Generation Basics</h1>\n<p>One of Crawl4AI\u2019s core features is generating <strong>clean, structured markdown</strong> from web pages. Originally built to solve the problem of extracting only the \u201cactual\u201d content and discarding boilerplate or noise, Crawl4AI\u2019s markdown system remains one of its biggest draws for AI workflows.</p>\n<p>In this tutorial, you\u2019ll learn:</p>\n<ol>\n<li>How to configure the <strong>Default Markdown Generator</strong>  </li>\n<li>How <strong>content filters</strong> (BM25 or Pruning) help you refine markdown and discard junk  </li>\n<li>The difference between raw markdown (<code>result.markdown</code>) and filtered markdown (<code>fit_markdown</code>)  </li>\n</ol>\n<blockquote>\n<p><strong>Prerequisites</strong><br>\n- You\u2019ve completed or read <a href=\"../simple-crawling/\">AsyncWebCrawler Basics</a> to understand how to run a simple crawl.<br>\n- You know how to configure <code>CrawlerRunConfig</code>.</p>\n</blockquote>\n<hr>\n<h2 id=\"1-quick-example\">1. Quick Example</h2>\n<p>Here\u2019s a minimal code snippet that uses the <strong>DefaultMarkdownGenerator</strong> with no additional filtering:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        markdown_generator=DefaultMarkdownGenerator()\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown Output:\\n\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)  <span class=\"hljs-comment\"># The unfiltered markdown from the page</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>What\u2019s happening?</strong><br>\n- <code>CrawlerRunConfig( markdown_generator = DefaultMarkdownGenerator() )</code> instructs Crawl4AI to convert the final HTML into markdown at the end of each crawl.<br>\n- The resulting markdown is accessible via <code>result.markdown</code>.</p>\n<hr>\n<h2 id=\"2-how-markdown-generation-works\">2. How Markdown Generation Works</h2>\n<h3 id=\"21-html-to-text-conversion-forked-modified\">2.1 HTML-to-Text Conversion (Forked &amp; Modified)</h3>\n<p>Under the hood, <strong>DefaultMarkdownGenerator</strong> uses a specialized HTML-to-text approach that:</p>\n<ul>\n<li>Preserves headings, code blocks, bullet points, etc.  </li>\n<li>Removes extraneous tags (scripts, styles) that don\u2019t add meaningful content.  </li>\n<li>Can optionally generate references for links or skip them altogether.</li>\n</ul>\n<p>A set of <strong>options</strong> (passed as a dict) allows you to customize precisely how HTML converts to markdown. These map to standard html2text-like configuration plus your own enhancements (e.g., ignoring internal links, preserving certain tags verbatim, or adjusting line widths).</p>\n<h3 id=\"22-link-citations-references\">2.2 Link Citations &amp; References</h3>\n<p>By default, the generator can convert <code>&lt;a href=\"...\"&gt;</code> elements into <code>[text][1]</code> citations, then place the actual links at the bottom of the document. This is handy for research workflows that demand references in a structured manner.</p>\n<h3 id=\"23-optional-content-filters\">2.3 Optional Content Filters</h3>\n<p>Before or after the HTML-to-Markdown step, you can apply a <strong>content filter</strong> (like BM25 or Pruning) to reduce noise and produce a \u201cfit_markdown\u201d\u2014a heavily pruned version focusing on the page\u2019s main text. We\u2019ll cover these filters shortly.</p>\n<hr>\n<h2 id=\"3-configuring-the-default-markdown-generator\">3. Configuring the Default Markdown Generator</h2>\n<p>You can tweak the output by passing an <code>options</code> dict to <code>DefaultMarkdownGenerator</code>. For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Example: ignore all links, don't escape HTML, and wrap text at 80 characters</span>\n    md_generator = DefaultMarkdownGenerator(\n        options={\n            <span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>,\n            <span class=\"hljs-string\">\"escape_html\"</span>: <span class=\"hljs-literal\">False</span>,\n            <span class=\"hljs-string\">\"body_width\"</span>: <span class=\"hljs-number\">80</span>\n        }\n    )\n\n    config = CrawlerRunConfig(\n        markdown_generator=md_generator\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/docs\"</span>, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown:\\n\"</span>, result.markdown[:<span class=\"hljs-number\">500</span>])  <span class=\"hljs-comment\"># Just a snippet</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    <span class=\"hljs-keyword\">import</span> asyncio\n    asyncio.run(main())\n</code></pre></div>\n<p>Some commonly used <code>options</code>:</p>\n<ul>\n<li><strong><code>ignore_links</code></strong> (bool): Whether to remove all hyperlinks in the final markdown.  </li>\n<li><strong><code>ignore_images</code></strong> (bool): Remove all <code>![image]()</code> references.  </li>\n<li><strong><code>escape_html</code></strong> (bool): Turn HTML entities into text (default is often <code>True</code>).  </li>\n<li><strong><code>body_width</code></strong> (int): Wrap text at N characters. <code>0</code> or <code>None</code> means no wrapping.  </li>\n<li><strong><code>skip_internal_links</code></strong> (bool): If <code>True</code>, omit <code>#localAnchors</code> or internal links referencing the same page.  </li>\n<li><strong><code>include_sup_sub</code></strong> (bool): Attempt to handle <code>&lt;sup&gt;</code> / <code>&lt;sub&gt;</code> in a more readable way.</li>\n</ul>\n<hr>\n<h2 id=\"4-content-filters\">4. Content Filters</h2>\n<p><strong>Content filters</strong> selectively remove or rank sections of text before turning them into Markdown. This is especially helpful if your page has ads, nav bars, or other clutter you don\u2019t want.</p>\n<h3 id=\"41-bm25contentfilter\">4.1 BM25ContentFilter</h3>\n<p>If you have a <strong>search query</strong>, BM25 is a good choice:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> BM25ContentFilter\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\nbm25_filter = BM25ContentFilter(\n    user_query=<span class=\"hljs-string\">\"machine learning\"</span>,\n    bm25_threshold=<span class=\"hljs-number\">1.2</span>,\n    use_stemming=<span class=\"hljs-literal\">True</span>\n)\n\nmd_generator = DefaultMarkdownGenerator(\n    content_filter=bm25_filter,\n    options={<span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>}\n)\n\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n</code></pre></div>\n<ul>\n<li><strong><code>user_query</code></strong>: The term you want to focus on. BM25 tries to keep only content blocks relevant to that query.  </li>\n<li><strong><code>bm25_threshold</code></strong>: Raise it to keep fewer blocks; lower it to keep more.  </li>\n<li><strong><code>use_stemming</code></strong>: If <code>True</code>, variations of words match (e.g., \u201clearn,\u201d \u201clearning,\u201d \u201clearnt\u201d).</li>\n</ul>\n<p><strong>No query provided?</strong> BM25 tries to glean a context from page metadata, or you can simply treat it as a scorched-earth approach that discards text with low generic score. Realistically, you want to supply a query for best results.</p>\n<h3 id=\"42-pruningcontentfilter\">4.2 PruningContentFilter</h3>\n<p>If you <strong>don\u2019t</strong> have a specific query, or if you just want a robust \u201cjunk remover,\u201d use <code>PruningContentFilter</code>. It analyzes text density, link density, HTML structure, and known patterns (like \u201cnav,\u201d \u201cfooter\u201d) to systematically prune extraneous or repetitive sections.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-cpp\">from crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n\nprune_filter = <span class=\"hljs-built_in\">PruningContentFilter</span>(\n    threshold=<span class=\"hljs-number\">0.5</span>,\n    threshold_type=<span class=\"hljs-string\">\"fixed\"</span>,  <span class=\"hljs-meta\"># or <span class=\"hljs-string\">\"dynamic\"</span></span>\n    min_word_threshold=<span class=\"hljs-number\">50</span>\n)\n</code></pre></div>\n<ul>\n<li><strong><code>threshold</code></strong>: Score boundary. Blocks below this score get removed.  </li>\n<li><strong><code>threshold_type</code></strong>:  <ul>\n<li><code>\"fixed\"</code>: Straight comparison (<code>score &gt;= threshold</code> keeps the block).  </li>\n<li><code>\"dynamic\"</code>: The filter adjusts threshold in a data-driven manner.  </li>\n</ul>\n</li>\n<li><strong><code>min_word_threshold</code></strong>: Discard blocks under N words as likely too short or unhelpful.</li>\n</ul>\n<p><strong>When to Use PruningContentFilter</strong><br>\n- You want a broad cleanup without a user query.<br>\n- The page has lots of repeated sidebars, footers, or disclaimers that hamper text extraction.</p>\n<h3 id=\"43-llmcontentfilter\">4.3 LLMContentFilter</h3>\n<p>For intelligent content filtering and high-quality markdown generation, you can use the <strong>LLMContentFilter</strong>. This filter leverages LLMs to generate relevant markdown while preserving the original content's meaning and structure:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> LLMContentFilter\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Initialize LLM filter with specific instruction</span>\n    <span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n        provider=<span class=\"hljs-string\">\"openai/gpt-4o\"</span>,  <span class=\"hljs-comment\"># or your preferred provider</span>\n        api_token=<span class=\"hljs-string\">\"your-api-token\"</span>,  <span class=\"hljs-comment\"># or use environment variable</span>\n        instruction=<span class=\"hljs-string\">\"\"\"\n        Focus on extracting the core educational content.\n        Include:\n        - Key concepts and explanations\n        - Important code examples\n        - Essential technical details\n        Exclude:\n        - Navigation elements\n        - Sidebars\n        - Footer content\n        Format the output as clean markdown with proper code blocks and headers.\n        \"\"\"</span>,\n        chunk_token_threshold=<span class=\"hljs-number\">4096</span>,  <span class=\"hljs-comment\"># Adjust based on your needs</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    config = CrawlerRunConfig(\n        content_filter=<span class=\"hljs-built_in\">filter</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n        <span class=\"hljs-built_in\">print</span>(result.fit_markdown)  <span class=\"hljs-comment\"># Filtered markdown content</span>\n</code></pre></div>\n<p><strong>Key Features:</strong>\n- <strong>Intelligent Filtering</strong>: Uses LLMs to understand and extract relevant content while maintaining context\n- <strong>Customizable Instructions</strong>: Tailor the filtering process with specific instructions\n- <strong>Chunk Processing</strong>: Handles large documents by processing them in chunks (controlled by <code>chunk_token_threshold</code>)\n- <strong>Parallel Processing</strong>: For better performance, use smaller <code>chunk_token_threshold</code> (e.g., 2048 or 4096) to enable parallel processing of content chunks</p>\n<p><strong>Two Common Use Cases:</strong></p>\n<ol>\n<li>\n<p><strong>Exact Content Preservation</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n    instruction=<span class=\"hljs-string\">\"\"\"\n    Extract the main educational content while preserving its original wording and substance completely.\n    1. Maintain the exact language and terminology\n    2. Keep all technical explanations and examples intact\n    3. Preserve the original flow and structure\n    4. Remove only clearly irrelevant elements like navigation menus and ads\n    \"\"\"</span>,\n    chunk_token_threshold=<span class=\"hljs-number\">4096</span>\n)\n</code></pre></div><p></p>\n</li>\n<li>\n<p><strong>Focused Content Extraction</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-built_in\">filter</span> = LLMContentFilter(\n    instruction=<span class=\"hljs-string\">\"\"\"\n    Focus on extracting specific types of content:\n    - Technical documentation\n    - Code examples\n    - API references\n    Reformat the content into clear, well-structured markdown\n    \"\"\"</span>,\n    chunk_token_threshold=<span class=\"hljs-number\">4096</span>\n)\n</code></pre></div><p></p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Performance Tip</strong>: Set a smaller <code>chunk_token_threshold</code> (e.g., 2048 or 4096) to enable parallel processing of content chunks. The default value is infinity, which processes the entire content as a single chunk.</p>\n</blockquote>\n<hr>\n<h2 id=\"5-using-fit-markdown\">5. Using Fit Markdown</h2>\n<p>When a content filter is active, the library produces two forms of markdown inside <code>result.markdown_v2</code> or (if using the simplified field) <code>result.markdown</code>:</p>\n<p>1.\u2000<strong><code>raw_markdown</code></strong>: The full unfiltered markdown.<br>\n2.\u2000<strong><code>fit_markdown</code></strong>: A \u201cfit\u201d version where the filter has removed or trimmed noisy segments.</p>\n<p><strong>Note</strong>:  </p>\n<blockquote>\n<p>In earlier examples, you may see references to <code>result.markdown_v2</code>. Depending on your library version, you might access <code>result.markdown</code>, <code>result.markdown_v2</code>, or an object named <code>MarkdownGenerationResult</code>. The idea is the same: you\u2019ll have a raw version and a filtered (\u201cfit\u201d) version if a filter is used.</p>\n</blockquote>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        markdown_generator=DefaultMarkdownGenerator(\n            content_filter=PruningContentFilter(threshold=<span class=\"hljs-number\">0.6</span>),\n            options={<span class=\"hljs-string\">\"ignore_links\"</span>: <span class=\"hljs-literal\">True</span>}\n        )\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://news.example.com/tech\"</span>, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw markdown:\\n\"</span>, result.markdown)\n\n            <span class=\"hljs-comment\"># If a filter is used, we also have .fit_markdown:</span>\n            md_object = result.markdown_v2  <span class=\"hljs-comment\"># or your equivalent</span>\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Filtered markdown:\\n\"</span>, md_object.fit_markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"6-the-markdowngenerationresult-object\">6. The <code>MarkdownGenerationResult</code> Object</h2>\n<p>If your library stores detailed markdown output in an object like <code>MarkdownGenerationResult</code>, you\u2019ll see fields such as:</p>\n<ul>\n<li><strong><code>raw_markdown</code></strong>: The direct HTML-to-markdown transformation (no filtering).  </li>\n<li><strong><code>markdown_with_citations</code></strong>: A version that moves links to reference-style footnotes.  </li>\n<li><strong><code>references_markdown</code></strong>: A separate string or section containing the gathered references.  </li>\n<li><strong><code>fit_markdown</code></strong>: The filtered markdown if you used a content filter.  </li>\n<li><strong><code>fit_html</code></strong>: The corresponding HTML snippet used to generate <code>fit_markdown</code> (helpful for debugging or advanced usage).</li>\n</ul>\n<p><strong>Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-swift\">md_obj <span class=\"hljs-operator\">=</span> result.markdown_v2  # your library\u2019s naming may vary\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"RAW:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.raw_markdown)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"CITED:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.markdown_with_citations)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"REFERENCES:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.references_markdown)\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"FIT:<span class=\"hljs-subst\">\\n</span>\"</span>, md_obj.fit_markdown)\n</code></pre></div>\n<p><strong>Why Does This Matter?</strong><br>\n- You can supply <code>raw_markdown</code> to an LLM if you want the entire text.<br>\n- Or feed <code>fit_markdown</code> into a vector database to reduce token usage.<br>\n- <code>references_markdown</code> can help you keep track of link provenance.</p>\n<hr>\n<p>Below is a <strong>revised section</strong> under \u201cCombining Filters (BM25 + Pruning)\u201d that demonstrates how you can run <strong>two</strong> passes of content filtering without re-crawling, by taking the HTML (or text) from a first pass and feeding it into the second filter. It uses real code patterns from the snippet you provided for <strong>BM25ContentFilter</strong>, which directly accepts <strong>HTML</strong> strings (and can also handle plain text with minimal adaptation).</p>\n<hr>\n<h2 id=\"7-combining-filters-bm25-pruning-in-two-passes\">7. Combining Filters (BM25 + Pruning) in Two Passes</h2>\n<p>You might want to <strong>prune out</strong> noisy boilerplate first (with <code>PruningContentFilter</code>), and then <strong>rank what\u2019s left</strong> against a user query (with <code>BM25ContentFilter</code>). You don\u2019t have to crawl the page twice. Instead:</p>\n<p>1.\u2000<strong>First pass</strong>: Apply <code>PruningContentFilter</code> directly to the raw HTML from <code>result.html</code> (the crawler\u2019s downloaded HTML).<br>\n2.\u2000<strong>Second pass</strong>: Take the pruned HTML (or text) from step 1, and feed it into <code>BM25ContentFilter</code>, focusing on a user query.</p>\n<h3 id=\"two-pass-example\">Two-Pass Example</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter, BM25ContentFilter\n<span class=\"hljs-keyword\">from</span> bs4 <span class=\"hljs-keyword\">import</span> BeautifulSoup\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1. Crawl with minimal or no markdown generator, just get raw HTML</span>\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># If you only want raw HTML, you can skip passing a markdown_generator</span>\n        <span class=\"hljs-comment\"># or provide one but focus on .html in this example</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com/tech-article\"</span>, config=config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success <span class=\"hljs-keyword\">or</span> <span class=\"hljs-keyword\">not</span> result.html:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed or no HTML content.\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        raw_html = result.html\n\n        <span class=\"hljs-comment\"># 2. First pass: PruningContentFilter on raw HTML</span>\n        pruning_filter = PruningContentFilter(threshold=<span class=\"hljs-number\">0.5</span>, min_word_threshold=<span class=\"hljs-number\">50</span>)\n\n        <span class=\"hljs-comment\"># filter_content returns a list of \"text chunks\" or cleaned HTML sections</span>\n        pruned_chunks = pruning_filter.filter_content(raw_html)\n        <span class=\"hljs-comment\"># This list is basically pruned content blocks, presumably in HTML or text form</span>\n\n        <span class=\"hljs-comment\"># For demonstration, let's combine these chunks back into a single HTML-like string</span>\n        <span class=\"hljs-comment\"># or you could do further processing. It's up to your pipeline design.</span>\n        pruned_html = <span class=\"hljs-string\">\"\\n\"</span>.join(pruned_chunks)\n\n        <span class=\"hljs-comment\"># 3. Second pass: BM25ContentFilter with a user query</span>\n        bm25_filter = BM25ContentFilter(\n            user_query=<span class=\"hljs-string\">\"machine learning\"</span>,\n            bm25_threshold=<span class=\"hljs-number\">1.2</span>,\n            language=<span class=\"hljs-string\">\"english\"</span>\n        )\n\n        <span class=\"hljs-comment\"># returns a list of text chunks</span>\n        bm25_chunks = bm25_filter.filter_content(pruned_html)  \n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> bm25_chunks:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Nothing matched the BM25 query after pruning.\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-comment\"># 4. Combine or display final results</span>\n        final_text = <span class=\"hljs-string\">\"\\n---\\n\"</span>.join(bm25_chunks)\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"==== PRUNED OUTPUT (first pass) ====\"</span>)\n        <span class=\"hljs-built_in\">print</span>(pruned_html[:<span class=\"hljs-number\">500</span>], <span class=\"hljs-string\">\"... (truncated)\"</span>)  <span class=\"hljs-comment\"># preview</span>\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n==== BM25 OUTPUT (second pass) ====\"</span>)\n        <span class=\"hljs-built_in\">print</span>(final_text[:<span class=\"hljs-number\">500</span>], <span class=\"hljs-string\">\"... (truncated)\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"whats-happening\">What\u2019s Happening?</h3>\n<p>1.\u2000<strong>Raw HTML</strong>: We crawl once and store the raw HTML in <code>result.html</code>.<br>\n2.\u2000<strong>PruningContentFilter</strong>: Takes HTML + optional parameters. It extracts blocks of text or partial HTML, removing headings/sections deemed \u201cnoise.\u201d It returns a <strong>list of text chunks</strong>.<br>\n3.\u2000<strong>Combine or Transform</strong>: We join these pruned chunks back into a single HTML-like string. (Alternatively, you could store them in a list for further logic\u2014whatever suits your pipeline.)<br>\n4.\u2000<strong>BM25ContentFilter</strong>: We feed the pruned string into <code>BM25ContentFilter</code> with a user query. This second pass further narrows the content to chunks relevant to \u201cmachine learning.\u201d</p>\n<p><strong>No Re-Crawling</strong>: We used <code>raw_html</code> from the first pass, so there\u2019s no need to run <code>arun()</code> again\u2014<strong>no second network request</strong>.</p>\n<h3 id=\"tips-variations\">Tips &amp; Variations</h3>\n<ul>\n<li><strong>Plain Text vs. HTML</strong>: If your pruned output is mostly text, BM25 can still handle it; just keep in mind it expects a valid string input. If you supply partial HTML (like <code>\"&lt;p&gt;some text&lt;/p&gt;\"</code>), it will parse it as HTML.  </li>\n<li><strong>Chaining in a Single Pipeline</strong>: If your code supports it, you can chain multiple filters automatically. Otherwise, manual two-pass filtering (as shown) is straightforward.  </li>\n<li><strong>Adjust Thresholds</strong>: If you see too much or too little text in step one, tweak <code>threshold=0.5</code> or <code>min_word_threshold=50</code>. Similarly, <code>bm25_threshold=1.2</code> can be raised/lowered for more or fewer chunks in step two.</li>\n</ul>\n<h3 id=\"one-pass-combination\">One-Pass Combination?</h3>\n<p>If your codebase or pipeline design allows applying multiple filters in one pass, you could do so. But often it\u2019s simpler\u2014and more transparent\u2014to run them sequentially, analyzing each step\u2019s result.</p>\n<p><strong>Bottom Line</strong>: By <strong>manually chaining</strong> your filtering logic in two passes, you get powerful incremental control over the final content. First, remove \u201cglobal\u201d clutter with Pruning, then refine further with BM25-based query relevance\u2014without incurring a second network crawl.</p>\n<hr>\n<h2 id=\"8-common-pitfalls-tips\">8. Common Pitfalls &amp; Tips</h2>\n<p>1.\u2000<strong>No Markdown Output?</strong><br>\n   - Make sure the crawler actually retrieved HTML. If the site is heavily JS-based, you may need to enable dynamic rendering or wait for elements.<br>\n   - Check if your content filter is too aggressive. Lower thresholds or disable the filter to see if content reappears.</p>\n<p>2.\u2000<strong>Performance Considerations</strong><br>\n   - Very large pages with multiple filters can be slower. Consider <code>cache_mode</code> to avoid re-downloading.<br>\n   - If your final use case is LLM ingestion, consider summarizing further or chunking big texts.</p>\n<p>3.\u2000<strong>Take Advantage of <code>fit_markdown</code></strong><br>\n   - Great for RAG pipelines, semantic search, or any scenario where extraneous boilerplate is unwanted.<br>\n   - Still verify the textual quality\u2014some sites have crucial data in footers or sidebars.</p>\n<p>4.\u2000<strong>Adjusting <code>html2text</code> Options</strong><br>\n   - If you see lots of raw HTML slipping into the text, turn on <code>escape_html</code>.<br>\n   - If code blocks look messy, experiment with <code>mark_code</code> or <code>handle_code_in_pre</code>.</p>\n<hr>\n<h2 id=\"9-summary-next-steps\">9. Summary &amp; Next Steps</h2>\n<p>In this <strong>Markdown Generation Basics</strong> tutorial, you learned to:</p>\n<ul>\n<li>Configure the <strong>DefaultMarkdownGenerator</strong> with HTML-to-text options.  </li>\n<li>Use <strong>BM25ContentFilter</strong> for query-specific extraction or <strong>PruningContentFilter</strong> for general noise removal.  </li>\n<li>Distinguish between raw and filtered markdown (<code>fit_markdown</code>).  </li>\n<li>Leverage the <code>MarkdownGenerationResult</code> object to handle different forms of output (citations, references, etc.).</li>\n</ul>\n<p>Now you can produce high-quality Markdown from any website, focusing on exactly the content you need\u2014an essential step for powering AI models, summarization pipelines, or knowledge-base queries.</p>\n<p><strong>Last Updated</strong>: 2025-01-01</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Markdown Generation Basics\nOne of Crawl4AI\u2019s core features is generating **clean, structured markdown** from web pages. Originally built to solve the problem of extracting only the \u201cactual\u201d content and discarding boilerplate or noise, Crawl4AI\u2019s markdown system remains one of its biggest draws for AI workflows.\nIn this tutorial, you\u2019ll learn:\n  1. How to configure the **Default Markdown Generator**\n  2. How **content filters** (BM25 or Pruning) help you refine markdown and discard junk \n  3. The difference between raw markdown (`result.markdown`) and filtered markdown (`fit_markdown`) \n\n\n> **Prerequisites** - You\u2019ve completed or read [AsyncWebCrawler Basics](https://docs.crawl4ai.com/core/<../simple-crawling/>) to understand how to run a simple crawl. - You know how to configure `CrawlerRunConfig`.\n## 1. Quick Example\nHere\u2019s a minimal code snippet that uses the **DefaultMarkdownGenerator** with no additional filtering:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nasync def main():\n  config = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator()\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\", config=config)\n    if result.success:\n      print(\"Raw Markdown Output:\\n\")\n      print(result.markdown) # The unfiltered markdown from the page\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**What\u2019s happening?** - `CrawlerRunConfig( markdown_generator = DefaultMarkdownGenerator() )` instructs Crawl4AI to convert the final HTML into markdown at the end of each crawl. - The resulting markdown is accessible via `result.markdown`.\n## 2. How Markdown Generation Works\n### 2.1 HTML-to-Text Conversion (Forked & Modified)\nUnder the hood, **DefaultMarkdownGenerator** uses a specialized HTML-to-text approach that:\n  * Preserves headings, code blocks, bullet points, etc. \n  * Removes extraneous tags (scripts, styles) that don\u2019t add meaningful content. \n  * Can optionally generate references for links or skip them altogether.\n\n\nA set of **options** (passed as a dict) allows you to customize precisely how HTML converts to markdown. These map to standard html2text-like configuration plus your own enhancements (e.g., ignoring internal links, preserving certain tags verbatim, or adjusting line widths).\n### 2.2 Link Citations & References\nBy default, the generator can convert `<a href=\"...\">` elements into `[text][1]` citations, then place the actual links at the bottom of the document. This is handy for research workflows that demand references in a structured manner.\n### 2.3 Optional Content Filters\nBefore or after the HTML-to-Markdown step, you can apply a **content filter** (like BM25 or Pruning) to reduce noise and produce a \u201cfit_markdown\u201d\u2014a heavily pruned version focusing on the page\u2019s main text. We\u2019ll cover these filters shortly.\n## 3. Configuring the Default Markdown Generator\nYou can tweak the output by passing an `options` dict to `DefaultMarkdownGenerator`. For example:\n```\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Example: ignore all links, don't escape HTML, and wrap text at 80 characters\n  md_generator = DefaultMarkdownGenerator(\n    options={\n      \"ignore_links\": True,\n      \"escape_html\": False,\n      \"body_width\": 80\n    }\n  )\n  config = CrawlerRunConfig(\n    markdown_generator=md_generator\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com/docs\", config=config)\n    if result.success:\n      print(\"Markdown:\\n\", result.markdown[:500]) # Just a snippet\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  import asyncio\n  asyncio.run(main())\n\n```\n\nSome commonly used `options`:\n  * **`ignore_links`**(bool): Whether to remove all hyperlinks in the final markdown.\n  * **`ignore_images`**(bool): Remove all`![image]()` references. \n  * **`escape_html`**(bool): Turn HTML entities into text (default is often`True`). \n  * **`body_width`**(int): Wrap text at N characters.`0` or `None` means no wrapping. \n  * **`skip_internal_links`**(bool): If`True` , omit `#localAnchors` or internal links referencing the same page. \n  * **`include_sup_sub`**(bool): Attempt to handle`<sup>` / `<sub>` in a more readable way.\n\n\n## 4. Content Filters\n**Content filters** selectively remove or rank sections of text before turning them into Markdown. This is especially helpful if your page has ads, nav bars, or other clutter you don\u2019t want.\n### 4.1 BM25ContentFilter\nIf you have a **search query** , BM25 is a good choice:\n```\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai.content_filter_strategy import BM25ContentFilter\nfrom crawl4ai import CrawlerRunConfig\nbm25_filter = BM25ContentFilter(\n  user_query=\"machine learning\",\n  bm25_threshold=1.2,\n  use_stemming=True\n)\nmd_generator = DefaultMarkdownGenerator(\n  content_filter=bm25_filter,\n  options={\"ignore_links\": True}\n)\nconfig = CrawlerRunConfig(markdown_generator=md_generator)\n\n```\n\n  * **`user_query`**: The term you want to focus on. BM25 tries to keep only content blocks relevant to that query.\n  * **`bm25_threshold`**: Raise it to keep fewer blocks; lower it to keep more.\n  * **`use_stemming`**: If`True` , variations of words match (e.g., \u201clearn,\u201d \u201clearning,\u201d \u201clearnt\u201d).\n\n\n**No query provided?** BM25 tries to glean a context from page metadata, or you can simply treat it as a scorched-earth approach that discards text with low generic score. Realistically, you want to supply a query for best results.\n### 4.2 PruningContentFilter\nIf you **don\u2019t** have a specific query, or if you just want a robust \u201cjunk remover,\u201d use `PruningContentFilter`. It analyzes text density, link density, HTML structure, and known patterns (like \u201cnav,\u201d \u201cfooter\u201d) to systematically prune extraneous or repetitive sections.\n```\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nprune_filter = PruningContentFilter(\n  threshold=0.5,\n  threshold_type=\"fixed\", # or \"dynamic\"\n  min_word_threshold=50\n)\n\n```\n\n  * **`threshold`**: Score boundary. Blocks below this score get removed.\n  * **`threshold_type`**:\n    * `\"fixed\"`: Straight comparison (`score >= threshold` keeps the block). \n    * `\"dynamic\"`: The filter adjusts threshold in a data-driven manner. \n  * **`min_word_threshold`**: Discard blocks under N words as likely too short or unhelpful.\n\n\n**When to Use PruningContentFilter** - You want a broad cleanup without a user query. - The page has lots of repeated sidebars, footers, or disclaimers that hamper text extraction.\n### 4.3 LLMContentFilter\nFor intelligent content filtering and high-quality markdown generation, you can use the **LLMContentFilter**. This filter leverages LLMs to generate relevant markdown while preserving the original content's meaning and structure:\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import LLMContentFilter\nasync def main():\n  # Initialize LLM filter with specific instruction\n  filter = LLMContentFilter(\n    provider=\"openai/gpt-4o\", # or your preferred provider\n    api_token=\"your-api-token\", # or use environment variable\n    instruction=\"\"\"\n    Focus on extracting the core educational content.\n    Include:\n    - Key concepts and explanations\n    - Important code examples\n    - Essential technical details\n    Exclude:\n    - Navigation elements\n    - Sidebars\n    - Footer content\n    Format the output as clean markdown with proper code blocks and headers.\n    \"\"\",\n    chunk_token_threshold=4096, # Adjust based on your needs\n    verbose=True\n  )\n  config = CrawlerRunConfig(\n    content_filter=filter\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\", config=config)\n    print(result.fit_markdown) # Filtered markdown content\n\n```\n\n**Key Features:** - **Intelligent Filtering** : Uses LLMs to understand and extract relevant content while maintaining context - **Customizable Instructions** : Tailor the filtering process with specific instructions - **Chunk Processing** : Handles large documents by processing them in chunks (controlled by `chunk_token_threshold`) - **Parallel Processing** : For better performance, use smaller `chunk_token_threshold` (e.g., 2048 or 4096) to enable parallel processing of content chunks\n**Two Common Use Cases:**\n  1. **Exact Content Preservation** : \n```\nfilter = LLMContentFilter(\n  instruction=\"\"\"\n  Extract the main educational content while preserving its original wording and substance completely.\n  1. Maintain the exact language and terminology\n  2. Keep all technical explanations and examples intact\n  3. Preserve the original flow and structure\n  4. Remove only clearly irrelevant elements like navigation menus and ads\n  \"\"\",\n  chunk_token_threshold=4096\n)\n\n```\n\n  2. **Focused Content Extraction** : \n```\nfilter = LLMContentFilter(\n  instruction=\"\"\"\n  Focus on extracting specific types of content:\n  - Technical documentation\n  - Code examples\n  - API references\n  Reformat the content into clear, well-structured markdown\n  \"\"\",\n  chunk_token_threshold=4096\n)\n\n```\n\n\n\n> **Performance Tip** : Set a smaller `chunk_token_threshold` (e.g., 2048 or 4096) to enable parallel processing of content chunks. The default value is infinity, which processes the entire content as a single chunk.\n## 5. Using Fit Markdown\nWhen a content filter is active, the library produces two forms of markdown inside `result.markdown_v2` or (if using the simplified field) `result.markdown`:\n1. **`raw_markdown`**: The full unfiltered markdown. 2.**`fit_markdown`**: A \u201cfit\u201d version where the filter has removed or trimmed noisy segments.\n**Note** : \n> In earlier examples, you may see references to `result.markdown_v2`. Depending on your library version, you might access `result.markdown`, `result.markdown_v2`, or an object named `MarkdownGenerationResult`. The idea is the same: you\u2019ll have a raw version and a filtered (\u201cfit\u201d) version if a filter is used.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nasync def main():\n  config = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator(\n      content_filter=PruningContentFilter(threshold=0.6),\n      options={\"ignore_links\": True}\n    )\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://news.example.com/tech\", config=config)\n    if result.success:\n      print(\"Raw markdown:\\n\", result.markdown)\n      # If a filter is used, we also have .fit_markdown:\n      md_object = result.markdown_v2 # or your equivalent\n      print(\"Filtered markdown:\\n\", md_object.fit_markdown)\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 6. The `MarkdownGenerationResult` Object\nIf your library stores detailed markdown output in an object like `MarkdownGenerationResult`, you\u2019ll see fields such as:\n  * **`raw_markdown`**: The direct HTML-to-markdown transformation (no filtering).\n  * **`markdown_with_citations`**: A version that moves links to reference-style footnotes.\n  * **`references_markdown`**: A separate string or section containing the gathered references.\n  * **`fit_markdown`**: The filtered markdown if you used a content filter.\n  * **`fit_html`**: The corresponding HTML snippet used to generate`fit_markdown` (helpful for debugging or advanced usage).\n\n\n**Example** :\n```\nmd_obj = result.markdown_v2 # your library\u2019s naming may vary\nprint(\"RAW:\\n\", md_obj.raw_markdown)\nprint(\"CITED:\\n\", md_obj.markdown_with_citations)\nprint(\"REFERENCES:\\n\", md_obj.references_markdown)\nprint(\"FIT:\\n\", md_obj.fit_markdown)\n\n```\n\n**Why Does This Matter?** - You can supply `raw_markdown` to an LLM if you want the entire text. - Or feed `fit_markdown` into a vector database to reduce token usage. - `references_markdown` can help you keep track of link provenance.\nBelow is a **revised section** under \u201cCombining Filters (BM25 + Pruning)\u201d that demonstrates how you can run **two** passes of content filtering without re-crawling, by taking the HTML (or text) from a first pass and feeding it into the second filter. It uses real code patterns from the snippet you provided for **BM25ContentFilter** , which directly accepts **HTML** strings (and can also handle plain text with minimal adaptation).\n## 7. Combining Filters (BM25 + Pruning) in Two Passes\nYou might want to **prune out** noisy boilerplate first (with `PruningContentFilter`), and then **rank what\u2019s left** against a user query (with `BM25ContentFilter`). You don\u2019t have to crawl the page twice. Instead:\n1. **First pass** : Apply `PruningContentFilter` directly to the raw HTML from `result.html` (the crawler\u2019s downloaded HTML). 2. **Second pass** : Take the pruned HTML (or text) from step 1, and feed it into `BM25ContentFilter`, focusing on a user query.\n### Two-Pass Example\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import PruningContentFilter, BM25ContentFilter\nfrom bs4 import BeautifulSoup\nasync def main():\n  # 1. Crawl with minimal or no markdown generator, just get raw HTML\n  config = CrawlerRunConfig(\n    # If you only want raw HTML, you can skip passing a markdown_generator\n    # or provide one but focus on .html in this example\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com/tech-article\", config=config)\n    if not result.success or not result.html:\n      print(\"Crawl failed or no HTML content.\")\n      return\n    raw_html = result.html\n    # 2. First pass: PruningContentFilter on raw HTML\n    pruning_filter = PruningContentFilter(threshold=0.5, min_word_threshold=50)\n    # filter_content returns a list of \"text chunks\" or cleaned HTML sections\n    pruned_chunks = pruning_filter.filter_content(raw_html)\n    # This list is basically pruned content blocks, presumably in HTML or text form\n    # For demonstration, let's combine these chunks back into a single HTML-like string\n    # or you could do further processing. It's up to your pipeline design.\n    pruned_html = \"\\n\".join(pruned_chunks)\n    # 3. Second pass: BM25ContentFilter with a user query\n    bm25_filter = BM25ContentFilter(\n      user_query=\"machine learning\",\n      bm25_threshold=1.2,\n      language=\"english\"\n    )\n    # returns a list of text chunks\n    bm25_chunks = bm25_filter.filter_content(pruned_html) \n    if not bm25_chunks:\n      print(\"Nothing matched the BM25 query after pruning.\")\n      return\n    # 4. Combine or display final results\n    final_text = \"\\n---\\n\".join(bm25_chunks)\n    print(\"==== PRUNED OUTPUT (first pass) ====\")\n    print(pruned_html[:500], \"... (truncated)\") # preview\n    print(\"\\n==== BM25 OUTPUT (second pass) ====\")\n    print(final_text[:500], \"... (truncated)\")\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### What\u2019s Happening?\n1. **Raw HTML** : We crawl once and store the raw HTML in `result.html`. 2. **PruningContentFilter** : Takes HTML + optional parameters. It extracts blocks of text or partial HTML, removing headings/sections deemed \u201cnoise.\u201d It returns a **list of text chunks**. 3. **Combine or Transform** : We join these pruned chunks back into a single HTML-like string. (Alternatively, you could store them in a list for further logic\u2014whatever suits your pipeline.) 4. **BM25ContentFilter** : We feed the pruned string into `BM25ContentFilter` with a user query. This second pass further narrows the content to chunks relevant to \u201cmachine learning.\u201d\n**No Re-Crawling** : We used `raw_html` from the first pass, so there\u2019s no need to run `arun()` again\u2014**no second network request**.\n### Tips & Variations\n  * **Plain Text vs. HTML** : If your pruned output is mostly text, BM25 can still handle it; just keep in mind it expects a valid string input. If you supply partial HTML (like `\"<p>some text</p>\"`), it will parse it as HTML. \n  * **Chaining in a Single Pipeline** : If your code supports it, you can chain multiple filters automatically. Otherwise, manual two-pass filtering (as shown) is straightforward. \n  * **Adjust Thresholds** : If you see too much or too little text in step one, tweak `threshold=0.5` or `min_word_threshold=50`. Similarly, `bm25_threshold=1.2` can be raised/lowered for more or fewer chunks in step two.\n\n\n### One-Pass Combination?\nIf your codebase or pipeline design allows applying multiple filters in one pass, you could do so. But often it\u2019s simpler\u2014and more transparent\u2014to run them sequentially, analyzing each step\u2019s result.\n**Bottom Line** : By **manually chaining** your filtering logic in two passes, you get powerful incremental control over the final content. First, remove \u201cglobal\u201d clutter with Pruning, then refine further with BM25-based query relevance\u2014without incurring a second network crawl.\n## 8. Common Pitfalls & Tips\n1. **No Markdown Output?** - Make sure the crawler actually retrieved HTML. If the site is heavily JS-based, you may need to enable dynamic rendering or wait for elements. - Check if your content filter is too aggressive. Lower thresholds or disable the filter to see if content reappears.\n2. **Performance Considerations** - Very large pages with multiple filters can be slower. Consider `cache_mode` to avoid re-downloading. - If your final use case is LLM ingestion, consider summarizing further or chunking big texts.\n3. **Take Advantage of`fit_markdown`** - Great for RAG pipelines, semantic search, or any scenario where extraneous boilerplate is unwanted. - Still verify the textual quality\u2014some sites have crucial data in footers or sidebars.\n4. **Adjusting`html2text` Options** - If you see lots of raw HTML slipping into the text, turn on `escape_html`. - If code blocks look messy, experiment with `mark_code` or `handle_code_in_pre`.\n## 9. Summary & Next Steps\nIn this **Markdown Generation Basics** tutorial, you learned to:\n  * Configure the **DefaultMarkdownGenerator** with HTML-to-text options. \n  * Use **BM25ContentFilter** for query-specific extraction or **PruningContentFilter** for general noise removal. \n  * Distinguish between raw and filtered markdown (`fit_markdown`). \n  * Leverage the `MarkdownGenerationResult` object to handle different forms of output (citations, references, etc.).\n\n\nNow you can produce high-quality Markdown from any website, focusing on exactly the content you need\u2014an essential step for powering AI models, summarization pipelines, or knowledge-base queries.\n**Last Updated** : 2025-01-01\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 23,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:29",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "multi-url-crawling.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/multi-url-crawling",
      "timestamp": "2025-02-06T13:23:21.170214",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/multi-url-crawling/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Multi-URL Crawling - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Multi-URL Crawling</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#advanced-multi-url-crawling-with-dispatchers\">Advanced Multi-URL Crawling with Dispatchers</a></li>\n        <li><a href=\"#1-introduction\">1. Introduction</a></li><li><a href=\"#2-core-components\">2. Core Components</a></li><li><a href=\"#3-available-dispatchers\">3. Available Dispatchers</a></li><li><a href=\"#4-usage-examples\">4. Usage Examples</a></li><li><a href=\"#5-dispatch-results\">5. Dispatch Results</a></li><li><a href=\"#6-summary\">6. Summary</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"advanced-multi-url-crawling-with-dispatchers\">Advanced Multi-URL Crawling with Dispatchers</h1>\n<blockquote>\n<p><strong>Heads Up</strong>: Crawl4AI supports advanced dispatchers for <strong>parallel</strong> or <strong>throttled</strong> crawling, providing dynamic rate limiting and memory usage checks. The built-in <code>arun_many()</code> function uses these dispatchers to handle concurrency efficiently.</p>\n</blockquote>\n<h2 id=\"1-introduction\">1. Introduction</h2>\n<p>When crawling many URLs:</p>\n<ul>\n<li><strong>Basic</strong>: Use <code>arun()</code> in a loop (simple but less efficient)</li>\n<li><strong>Better</strong>: Use <code>arun_many()</code>, which efficiently handles multiple URLs with proper concurrency control</li>\n<li><strong>Best</strong>: Customize dispatcher behavior for your specific needs (memory management, rate limits, etc.)</li>\n</ul>\n<p><strong>Why Dispatchers?</strong>  </p>\n<ul>\n<li><strong>Adaptive</strong>: Memory-based dispatchers can pause or slow down based on system resources</li>\n<li><strong>Rate-limiting</strong>: Built-in rate limiting with exponential backoff for 429/503 responses</li>\n<li><strong>Real-time Monitoring</strong>: Live dashboard of ongoing tasks, memory usage, and performance</li>\n<li><strong>Flexibility</strong>: Choose between memory-adaptive or semaphore-based concurrency</li>\n</ul>\n<hr>\n<h2 id=\"2-core-components\">2. Core Components</h2>\n<h3 id=\"21-rate-limiter\">2.1 Rate Limiter</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RateLimiter</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        <span class=\"hljs-comment\"># Random delay range between requests</span>\n        base_delay: <span class=\"hljs-type\">Tuple</span>[<span class=\"hljs-built_in\">float</span>, <span class=\"hljs-built_in\">float</span>] = (<span class=\"hljs-params\"><span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span></span>),  \n\n        <span class=\"hljs-comment\"># Maximum backoff delay</span>\n        max_delay: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">60.0</span>,                        \n\n        <span class=\"hljs-comment\"># Retries before giving up</span>\n        max_retries: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">3</span>,                          \n\n        <span class=\"hljs-comment\"># Status codes triggering backoff</span>\n        rate_limit_codes: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>] = [<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]        \n    </span>)\n</code></pre></div>\n<p>Here\u2019s the revised and simplified explanation of the <strong>RateLimiter</strong>, focusing on constructor parameters and adhering to your markdown style and mkDocs guidelines.</p>\n<h4 id=\"ratelimiter-constructor-parameters\">RateLimiter Constructor Parameters</h4>\n<p>The <strong>RateLimiter</strong> is a utility that helps manage the pace of requests to avoid overloading servers or getting blocked due to rate limits. It operates internally to delay requests and handle retries but can be configured using its constructor parameters.</p>\n<p><strong>Parameters of the <code>RateLimiter</code> constructor:</strong></p>\n<p>1.\u2002<strong><code>base_delay</code></strong> (<code>Tuple[float, float]</code>, default: <code>(1.0, 3.0)</code>)<br>\n\u2002\u2002The range for a random delay (in seconds) between consecutive requests to the same domain.</p>\n<ul>\n<li>A random delay is chosen between <code>base_delay[0]</code> and <code>base_delay[1]</code> for each request.  </li>\n<li>This prevents sending requests at a predictable frequency, reducing the chances of triggering rate limits.</li>\n</ul>\n<p><strong>Example:</strong><br>\nIf <code>base_delay = (2.0, 5.0)</code>, delays could be randomly chosen as <code>2.3s</code>, <code>4.1s</code>, etc.</p>\n<hr>\n<p>2.\u2002<strong><code>max_delay</code></strong> (<code>float</code>, default: <code>60.0</code>)<br>\n\u2002\u2002The maximum allowable delay when rate-limiting errors occur.</p>\n<ul>\n<li>When servers return rate-limit responses (e.g., 429 or 503), the delay increases exponentially with jitter.  </li>\n<li>The <code>max_delay</code> ensures the delay doesn\u2019t grow unreasonably high, capping it at this value.</li>\n</ul>\n<p><strong>Example:</strong><br>\nFor a <code>max_delay = 30.0</code>, even if backoff calculations suggest a delay of <code>45s</code>, it will cap at <code>30s</code>.</p>\n<hr>\n<p>3.\u2002<strong><code>max_retries</code></strong> (<code>int</code>, default: <code>3</code>)<br>\n\u2002\u2002The maximum number of retries for a request if rate-limiting errors occur.</p>\n<ul>\n<li>After encountering a rate-limit response, the <code>RateLimiter</code> retries the request up to this number of times.  </li>\n<li>If all retries fail, the request is marked as failed, and the process continues.</li>\n</ul>\n<p><strong>Example:</strong><br>\nIf <code>max_retries = 3</code>, the system retries a failed request three times before giving up.</p>\n<hr>\n<p>4.\u2002<strong><code>rate_limit_codes</code></strong> (<code>List[int]</code>, default: <code>[429, 503]</code>)<br>\n\u2002\u2002A list of HTTP status codes that trigger the rate-limiting logic.</p>\n<ul>\n<li>These status codes indicate the server is overwhelmed or actively limiting requests.  </li>\n<li>You can customize this list to include other codes based on specific server behavior.</li>\n</ul>\n<p><strong>Example:</strong><br>\nIf <code>rate_limit_codes = [429, 503, 504]</code>, the crawler will back off on these three error codes.</p>\n<hr>\n<p><strong>How to Use the <code>RateLimiter</code>:</strong></p>\n<p>Here\u2019s an example of initializing and using a <code>RateLimiter</code> in your project:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">from crawl4ai import RateLimiter\n\n<span class=\"hljs-comment\"># Create a RateLimiter with custom settings</span>\nrate_limiter <span class=\"hljs-punctuation\">=</span> RateLimiter<span class=\"hljs-punctuation\">(</span>\n    base_delay<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">(</span><span class=\"hljs-number\">2.0</span>, <span class=\"hljs-number\">4.0</span><span class=\"hljs-punctuation\">)</span>,  <span class=\"hljs-comment\"># Random delay between 2-4 seconds</span>\n    max_delay<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">30.0</span>,         <span class=\"hljs-comment\"># Cap delay at 30 seconds</span>\n    max_retries<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">5</span>,          <span class=\"hljs-comment\"># Retry up to 5 times on rate-limiting errors</span>\n    rate_limit_codes<span class=\"hljs-punctuation\">=</span><span class=\"hljs-punctuation\">[</span><span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span><span class=\"hljs-punctuation\">]</span>  <span class=\"hljs-comment\"># Handle these HTTP status codes</span>\n<span class=\"hljs-punctuation\">)</span>\n\n<span class=\"hljs-comment\"># RateLimiter will handle delays and retries internally</span>\n<span class=\"hljs-comment\"># No additional setup is required for its operation</span>\n</code></pre></div>\n<p>The <code>RateLimiter</code> integrates seamlessly with dispatchers like <code>MemoryAdaptiveDispatcher</code> and <code>SemaphoreDispatcher</code>, ensuring requests are paced correctly without user intervention. Its internal mechanisms manage delays and retries to avoid overwhelming servers while maximizing efficiency.</p>\n<h3 id=\"22-crawler-monitor\">2.2 Crawler Monitor</h3>\n<p>The CrawlerMonitor provides real-time visibility into crawling operations:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> CrawlerMonitor, DisplayMode\nmonitor = CrawlerMonitor(\n    <span class=\"hljs-comment\"># Maximum rows in live display</span>\n    max_visible_rows=<span class=\"hljs-number\">15</span>,          \n\n    <span class=\"hljs-comment\"># DETAILED or AGGREGATED view</span>\n    display_mode=DisplayMode.DETAILED  \n)\n</code></pre></div>\n<p><strong>Display Modes</strong>:</p>\n<ol>\n<li><strong>DETAILED</strong>: Shows individual task status, memory usage, and timing</li>\n<li><strong>AGGREGATED</strong>: Displays summary statistics and overall progress</li>\n</ol>\n<hr>\n<h2 id=\"3-available-dispatchers\">3. Available Dispatchers</h2>\n<h3 id=\"31-memoryadaptivedispatcher-default\">3.1 MemoryAdaptiveDispatcher (Default)</h3>\n<p>Automatically manages concurrency based on system memory usage:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_dispatcher <span class=\"hljs-keyword\">import</span> MemoryAdaptiveDispatcher\n\ndispatcher = MemoryAdaptiveDispatcher(\n    memory_threshold_percent=<span class=\"hljs-number\">90.0</span>,  <span class=\"hljs-comment\"># Pause if memory exceeds this</span>\n    check_interval=<span class=\"hljs-number\">1.0</span>,             <span class=\"hljs-comment\"># How often to check memory</span>\n    max_session_permit=<span class=\"hljs-number\">10</span>,          <span class=\"hljs-comment\"># Maximum concurrent tasks</span>\n    rate_limiter=RateLimiter(       <span class=\"hljs-comment\"># Optional rate limiting</span>\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">2.0</span>),\n        max_delay=<span class=\"hljs-number\">30.0</span>,\n        max_retries=<span class=\"hljs-number\">2</span>\n    ),\n    monitor=CrawlerMonitor(         <span class=\"hljs-comment\"># Optional monitoring</span>\n        max_visible_rows=<span class=\"hljs-number\">15</span>,\n        display_mode=DisplayMode.DETAILED\n    )\n)\n</code></pre></div>\n<p><strong>Constructor Parameters:</strong></p>\n<p>1.\u2002<strong><code>memory_threshold_percent</code></strong> (<code>float</code>, default: <code>90.0</code>)<br>\n\u2002\u2002Specifies the memory usage threshold (as a percentage). If system memory usage exceeds this value, the dispatcher pauses crawling to prevent system overload.</p>\n<p>2.\u2002<strong><code>check_interval</code></strong> (<code>float</code>, default: <code>1.0</code>)<br>\n\u2002\u2002The interval (in seconds) at which the dispatcher checks system memory usage.</p>\n<p>3.\u2002<strong><code>max_session_permit</code></strong> (<code>int</code>, default: <code>10</code>)<br>\n\u2002\u2002The maximum number of concurrent crawling tasks allowed. This ensures resource limits are respected while maintaining concurrency.</p>\n<p>4.\u2002<strong><code>memory_wait_timeout</code></strong> (<code>float</code>, default: <code>300.0</code>)<br>\n\u2002\u2002Optional timeout (in seconds). If memory usage exceeds <code>memory_threshold_percent</code> for longer than this duration, a <code>MemoryError</code> is raised.</p>\n<p>5.\u2002<strong><code>rate_limiter</code></strong> (<code>RateLimiter</code>, default: <code>None</code>)<br>\n\u2002\u2002Optional rate-limiting logic to avoid server-side blocking (e.g., for handling 429 or 503 errors). See <strong>RateLimiter</strong> for details.</p>\n<p>6.\u2002<strong><code>monitor</code></strong> (<code>CrawlerMonitor</code>, default: <code>None</code>)<br>\n\u2002\u2002Optional monitoring for real-time task tracking and performance insights. See <strong>CrawlerMonitor</strong> for details.</p>\n<hr>\n<h3 id=\"32-semaphoredispatcher\">3.2 SemaphoreDispatcher</h3>\n<p>Provides simple concurrency control with a fixed limit:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_dispatcher <span class=\"hljs-keyword\">import</span> SemaphoreDispatcher\n\ndispatcher = SemaphoreDispatcher(\n    max_session_permit=<span class=\"hljs-number\">20</span>,         <span class=\"hljs-comment\"># Maximum concurrent tasks</span>\n    rate_limiter=RateLimiter(      <span class=\"hljs-comment\"># Optional rate limiting</span>\n        base_delay=(<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1.0</span>),\n        max_delay=<span class=\"hljs-number\">10.0</span>\n    ),\n    monitor=CrawlerMonitor(        <span class=\"hljs-comment\"># Optional monitoring</span>\n        max_visible_rows=<span class=\"hljs-number\">15</span>,\n        display_mode=DisplayMode.DETAILED\n    )\n)\n</code></pre></div>\n<p><strong>Constructor Parameters:</strong></p>\n<p>1.\u2002<strong><code>max_session_permit</code></strong> (<code>int</code>, default: <code>20</code>)<br>\n\u2002\u2002The maximum number of concurrent crawling tasks allowed, irrespective of semaphore slots.</p>\n<p>2.\u2002<strong><code>rate_limiter</code></strong> (<code>RateLimiter</code>, default: <code>None</code>)<br>\n\u2002\u2002Optional rate-limiting logic to avoid overwhelming servers. See <strong>RateLimiter</strong> for details.</p>\n<p>3.\u2002<strong><code>monitor</code></strong> (<code>CrawlerMonitor</code>, default: <code>None</code>)<br>\n\u2002\u2002Optional monitoring for tracking task progress and resource usage. See <strong>CrawlerMonitor</strong> for details.</p>\n<hr>\n<h2 id=\"4-usage-examples\">4. Usage Examples</h2>\n<h3 id=\"41-batch-processing-default\">4.1 Batch Processing (Default)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_batch</span>():\n    browser_config = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>, verbose=<span class=\"hljs-literal\">False</span>)\n    run_config = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        stream=<span class=\"hljs-literal\">False</span>  <span class=\"hljs-comment\"># Default: get all results at once</span>\n    )\n\n    dispatcher = MemoryAdaptiveDispatcher(\n        memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,\n        check_interval=<span class=\"hljs-number\">1.0</span>,\n        max_session_permit=<span class=\"hljs-number\">10</span>,\n        monitor=CrawlerMonitor(\n            display_mode=DisplayMode.DETAILED\n        )\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Get all results at once</span>\n        results = <span class=\"hljs-keyword\">await</span> crawler.arun_many(\n            urls=urls,\n            config=run_config,\n            dispatcher=dispatcher\n        )\n\n        <span class=\"hljs-comment\"># Process all results after completion</span>\n        <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:\n            <span class=\"hljs-keyword\">if</span> result.success:\n                <span class=\"hljs-keyword\">await</span> process_result(result)\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl <span class=\"hljs-subst\">{result.url}</span>: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n</code></pre></div>\n<p><strong>Review:</strong><br>\n- <strong>Purpose:</strong> Executes a batch crawl with all URLs processed together after crawling is complete.<br>\n- <strong>Dispatcher:</strong> Uses <code>MemoryAdaptiveDispatcher</code> to manage concurrency and system memory.<br>\n- <strong>Stream:</strong> Disabled (<code>stream=False</code>), so all results are collected at once for post-processing.<br>\n- <strong>Best Use Case:</strong> When you need to analyze results in bulk rather than individually during the crawl.</p>\n<hr>\n<h3 id=\"42-streaming-mode\">4.2 Streaming Mode</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_streaming</span>():\n    browser_config = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>, verbose=<span class=\"hljs-literal\">False</span>)\n    run_config = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        stream=<span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Enable streaming mode</span>\n    )\n\n    dispatcher = MemoryAdaptiveDispatcher(\n        memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,\n        check_interval=<span class=\"hljs-number\">1.0</span>,\n        max_session_permit=<span class=\"hljs-number\">10</span>,\n        monitor=CrawlerMonitor(\n            display_mode=DisplayMode.DETAILED\n        )\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Process results as they become available</span>\n        <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">await</span> crawler.arun_many(\n            urls=urls,\n            config=run_config,\n            dispatcher=dispatcher\n        ):\n            <span class=\"hljs-keyword\">if</span> result.success:\n                <span class=\"hljs-comment\"># Process each result immediately</span>\n                <span class=\"hljs-keyword\">await</span> process_result(result)\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl <span class=\"hljs-subst\">{result.url}</span>: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n</code></pre></div>\n<p><strong>Review:</strong><br>\n- <strong>Purpose:</strong> Enables streaming to process results as soon as they\u2019re available.<br>\n- <strong>Dispatcher:</strong> Uses <code>MemoryAdaptiveDispatcher</code> for concurrency and memory management.<br>\n- <strong>Stream:</strong> Enabled (<code>stream=True</code>), allowing real-time processing during crawling.<br>\n- <strong>Best Use Case:</strong> When you need to act on results immediately, such as for real-time analytics or progressive data storage.</p>\n<hr>\n<h3 id=\"43-semaphore-based-crawling\">4.3 Semaphore-based Crawling</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_with_semaphore</span>(<span class=\"hljs-params\">urls</span>):\n    browser_config = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>, verbose=<span class=\"hljs-literal\">False</span>)\n    run_config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n\n    dispatcher = SemaphoreDispatcher(\n        semaphore_count=<span class=\"hljs-number\">5</span>,\n        rate_limiter=RateLimiter(\n            base_delay=(<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1.0</span>),\n            max_delay=<span class=\"hljs-number\">10.0</span>\n        ),\n        monitor=CrawlerMonitor(\n            max_visible_rows=<span class=\"hljs-number\">15</span>,\n            display_mode=DisplayMode.DETAILED\n        )\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        results = <span class=\"hljs-keyword\">await</span> crawler.arun_many(\n            urls, \n            config=run_config,\n            dispatcher=dispatcher\n        )\n        <span class=\"hljs-keyword\">return</span> results\n</code></pre></div>\n<p><strong>Review:</strong><br>\n- <strong>Purpose:</strong> Uses <code>SemaphoreDispatcher</code> to limit concurrency with a fixed number of slots.<br>\n- <strong>Dispatcher:</strong> Configured with a semaphore to control parallel crawling tasks.<br>\n- <strong>Rate Limiter:</strong> Prevents servers from being overwhelmed by pacing requests.<br>\n- <strong>Best Use Case:</strong> When you want precise control over the number of concurrent requests, independent of system memory.</p>\n<hr>\n<h3 id=\"44-robotstxt-consideration\">4.4 Robots.txt Consideration</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    urls = [\n        <span class=\"hljs-string\">\"https://example1.com\"</span>,\n        <span class=\"hljs-string\">\"https://example2.com\"</span>,\n        <span class=\"hljs-string\">\"https://example3.com\"</span>\n    ]\n\n    config = CrawlerRunConfig(\n        cache_mode=CacheMode.ENABLED,\n        check_robots_txt=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Will respect robots.txt for each URL</span>\n        semaphore_count=<span class=\"hljs-number\">3</span>      <span class=\"hljs-comment\"># Max concurrent requests</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> crawler.arun_many(urls, config=config):\n            <span class=\"hljs-keyword\">if</span> result.success:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Successfully crawled <span class=\"hljs-subst\">{result.url}</span>\"</span>)\n            <span class=\"hljs-keyword\">elif</span> result.status_code == <span class=\"hljs-number\">403</span> <span class=\"hljs-keyword\">and</span> <span class=\"hljs-string\">\"robots.txt\"</span> <span class=\"hljs-keyword\">in</span> result.error_message:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Skipped <span class=\"hljs-subst\">{result.url}</span> - blocked by robots.txt\"</span>)\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl <span class=\"hljs-subst\">{result.url}</span>: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Review:</strong><br>\n- <strong>Purpose:</strong> Ensures compliance with <code>robots.txt</code> rules for ethical and legal web crawling.<br>\n- <strong>Configuration:</strong> Set <code>check_robots_txt=True</code> to validate each URL against <code>robots.txt</code> before crawling.<br>\n- <strong>Dispatcher:</strong> Handles requests with concurrency limits (<code>semaphore_count=3</code>).<br>\n- <strong>Best Use Case:</strong> When crawling websites that strictly enforce robots.txt policies or for responsible crawling practices.</p>\n<hr>\n<h2 id=\"5-dispatch-results\">5. Dispatch Results</h2>\n<p>Each crawl result includes dispatch information:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\"><span class=\"hljs-keyword\">@dataclass</span>\nclass <span class=\"hljs-attribute\">DispatchResult</span>:\n    task_<span class=\"hljs-attribute\">id</span>: str\n    memory_<span class=\"hljs-attribute\">usage</span>: float\n    peak_<span class=\"hljs-attribute\">memory</span>: float\n    start_<span class=\"hljs-attribute\">time</span>: datetime\n    end_<span class=\"hljs-attribute\">time</span>: datetime\n    error_<span class=\"hljs-attribute\">message</span>: str = <span class=\"hljs-string\">\"\"</span>\n</code></pre></div>\n<p>Access via <code>result.dispatch_result</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:\n    <span class=\"hljs-keyword\">if</span> result.success:\n        dr = result.dispatch_result\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"URL: <span class=\"hljs-subst\">{result.url}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Memory: <span class=\"hljs-subst\">{dr.memory_usage:<span class=\"hljs-number\">.1</span>f}</span>MB\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Duration: <span class=\"hljs-subst\">{dr.end_time - dr.start_time}</span>\"</span>)\n</code></pre></div>\n<h2 id=\"6-summary\">6. Summary</h2>\n<p>1.\u2002<strong>Two Dispatcher Types</strong>:</p>\n<ul>\n<li>MemoryAdaptiveDispatcher (default): Dynamic concurrency based on memory</li>\n<li>SemaphoreDispatcher: Fixed concurrency limit</li>\n</ul>\n<p>2.\u2002<strong>Optional Components</strong>:</p>\n<ul>\n<li>RateLimiter: Smart request pacing and backoff</li>\n<li>CrawlerMonitor: Real-time progress visualization</li>\n</ul>\n<p>3.\u2002<strong>Key Benefits</strong>:</p>\n<ul>\n<li>Automatic memory management</li>\n<li>Built-in rate limiting</li>\n<li>Live progress monitoring</li>\n<li>Flexible concurrency control</li>\n</ul>\n<p>Choose the dispatcher that best fits your needs:</p>\n<ul>\n<li><strong>MemoryAdaptiveDispatcher</strong>: For large crawls or limited resources</li>\n<li><strong>SemaphoreDispatcher</strong>: For simple, fixed-concurrency scenarios</li>\n</ul>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Advanced Multi-URL Crawling with Dispatchers\n> **Heads Up** : Crawl4AI supports advanced dispatchers for **parallel** or **throttled** crawling, providing dynamic rate limiting and memory usage checks. The built-in `arun_many()` function uses these dispatchers to handle concurrency efficiently.\n## 1. Introduction\nWhen crawling many URLs:\n  * **Basic** : Use `arun()` in a loop (simple but less efficient)\n  * **Better** : Use `arun_many()`, which efficiently handles multiple URLs with proper concurrency control\n  * **Best** : Customize dispatcher behavior for your specific needs (memory management, rate limits, etc.)\n\n\n**Why Dispatchers?**\n  * **Adaptive** : Memory-based dispatchers can pause or slow down based on system resources\n  * **Rate-limiting** : Built-in rate limiting with exponential backoff for 429/503 responses\n  * **Real-time Monitoring** : Live dashboard of ongoing tasks, memory usage, and performance\n  * **Flexibility** : Choose between memory-adaptive or semaphore-based concurrency\n\n\n## 2. Core Components\n### 2.1 Rate Limiter\n```\nclass RateLimiter:\n  def __init__(\n    # Random delay range between requests\n    base_delay: Tuple[float, float] = (1.0, 3.0), \n    # Maximum backoff delay\n    max_delay: float = 60.0,            \n    # Retries before giving up\n    max_retries: int = 3,             \n    # Status codes triggering backoff\n    rate_limit_codes: List[int] = [429, 503]    \n  )\n\n```\n\nHere\u2019s the revised and simplified explanation of the **RateLimiter** , focusing on constructor parameters and adhering to your markdown style and mkDocs guidelines.\n#### RateLimiter Constructor Parameters\nThe **RateLimiter** is a utility that helps manage the pace of requests to avoid overloading servers or getting blocked due to rate limits. It operates internally to delay requests and handle retries but can be configured using its constructor parameters.\n**Parameters of the`RateLimiter` constructor:**\n1. **`base_delay`**(`Tuple[float, float]` , default: `(1.0, 3.0)`) The range for a random delay (in seconds) between consecutive requests to the same domain.\n  * A random delay is chosen between `base_delay[0]` and `base_delay[1]` for each request. \n  * This prevents sending requests at a predictable frequency, reducing the chances of triggering rate limits.\n\n\n**Example:** If `base_delay = (2.0, 5.0)`, delays could be randomly chosen as `2.3s`, `4.1s`, etc.\n2. **`max_delay`**(`float` , default: `60.0`) The maximum allowable delay when rate-limiting errors occur.\n  * When servers return rate-limit responses (e.g., 429 or 503), the delay increases exponentially with jitter. \n  * The `max_delay` ensures the delay doesn\u2019t grow unreasonably high, capping it at this value.\n\n\n**Example:** For a `max_delay = 30.0`, even if backoff calculations suggest a delay of `45s`, it will cap at `30s`.\n3. **`max_retries`**(`int` , default: `3`) The maximum number of retries for a request if rate-limiting errors occur.\n  * After encountering a rate-limit response, the `RateLimiter` retries the request up to this number of times. \n  * If all retries fail, the request is marked as failed, and the process continues.\n\n\n**Example:** If `max_retries = 3`, the system retries a failed request three times before giving up.\n4. **`rate_limit_codes`**(`List[int]` , default: `[429, 503]`) A list of HTTP status codes that trigger the rate-limiting logic.\n  * These status codes indicate the server is overwhelmed or actively limiting requests. \n  * You can customize this list to include other codes based on specific server behavior.\n\n\n**Example:** If `rate_limit_codes = [429, 503, 504]`, the crawler will back off on these three error codes.\n**How to Use the`RateLimiter` :**\nHere\u2019s an example of initializing and using a `RateLimiter` in your project:\n```\nfrom crawl4ai import RateLimiter\n# Create a RateLimiter with custom settings\nrate_limiter = RateLimiter(\n  base_delay=(2.0, 4.0), # Random delay between 2-4 seconds\n  max_delay=30.0,     # Cap delay at 30 seconds\n  max_retries=5,     # Retry up to 5 times on rate-limiting errors\n  rate_limit_codes=[429, 503] # Handle these HTTP status codes\n)\n# RateLimiter will handle delays and retries internally\n# No additional setup is required for its operation\n\n```\n\nThe `RateLimiter` integrates seamlessly with dispatchers like `MemoryAdaptiveDispatcher` and `SemaphoreDispatcher`, ensuring requests are paced correctly without user intervention. Its internal mechanisms manage delays and retries to avoid overwhelming servers while maximizing efficiency.\n### 2.2 Crawler Monitor\nThe CrawlerMonitor provides real-time visibility into crawling operations:\n```\nfrom crawl4ai import CrawlerMonitor, DisplayMode\nmonitor = CrawlerMonitor(\n  # Maximum rows in live display\n  max_visible_rows=15,     \n  # DETAILED or AGGREGATED view\n  display_mode=DisplayMode.DETAILED \n)\n\n```\n\n**Display Modes** :\n  1. **DETAILED** : Shows individual task status, memory usage, and timing\n  2. **AGGREGATED** : Displays summary statistics and overall progress\n\n\n## 3. Available Dispatchers\n### 3.1 MemoryAdaptiveDispatcher (Default)\nAutomatically manages concurrency based on system memory usage:\n```\nfrom crawl4ai.async_dispatcher import MemoryAdaptiveDispatcher\ndispatcher = MemoryAdaptiveDispatcher(\n  memory_threshold_percent=90.0, # Pause if memory exceeds this\n  check_interval=1.0,       # How often to check memory\n  max_session_permit=10,     # Maximum concurrent tasks\n  rate_limiter=RateLimiter(    # Optional rate limiting\n    base_delay=(1.0, 2.0),\n    max_delay=30.0,\n    max_retries=2\n  ),\n  monitor=CrawlerMonitor(     # Optional monitoring\n    max_visible_rows=15,\n    display_mode=DisplayMode.DETAILED\n  )\n)\n\n```\n\n**Constructor Parameters:**\n1. **`memory_threshold_percent`**(`float` , default: `90.0`) Specifies the memory usage threshold (as a percentage). If system memory usage exceeds this value, the dispatcher pauses crawling to prevent system overload.\n2. **`check_interval`**(`float` , default: `1.0`) The interval (in seconds) at which the dispatcher checks system memory usage.\n3. **`max_session_permit`**(`int` , default: `10`) The maximum number of concurrent crawling tasks allowed. This ensures resource limits are respected while maintaining concurrency.\n4. **`memory_wait_timeout`**(`float` , default: `300.0`) Optional timeout (in seconds). If memory usage exceeds `memory_threshold_percent` for longer than this duration, a `MemoryError` is raised.\n5. **`rate_limiter`**(`RateLimiter` , default: `None`) Optional rate-limiting logic to avoid server-side blocking (e.g., for handling 429 or 503 errors). See **RateLimiter** for details.\n6. **`monitor`**(`CrawlerMonitor` , default: `None`) Optional monitoring for real-time task tracking and performance insights. See **CrawlerMonitor** for details.\n### 3.2 SemaphoreDispatcher\nProvides simple concurrency control with a fixed limit:\n```\nfrom crawl4ai.async_dispatcher import SemaphoreDispatcher\ndispatcher = SemaphoreDispatcher(\n  max_session_permit=20,     # Maximum concurrent tasks\n  rate_limiter=RateLimiter(   # Optional rate limiting\n    base_delay=(0.5, 1.0),\n    max_delay=10.0\n  ),\n  monitor=CrawlerMonitor(    # Optional monitoring\n    max_visible_rows=15,\n    display_mode=DisplayMode.DETAILED\n  )\n)\n\n```\n\n**Constructor Parameters:**\n1. **`max_session_permit`**(`int` , default: `20`) The maximum number of concurrent crawling tasks allowed, irrespective of semaphore slots.\n2. **`rate_limiter`**(`RateLimiter` , default: `None`) Optional rate-limiting logic to avoid overwhelming servers. See **RateLimiter** for details.\n3. **`monitor`**(`CrawlerMonitor` , default: `None`) Optional monitoring for tracking task progress and resource usage. See **CrawlerMonitor** for details.\n## 4. Usage Examples\n### 4.1 Batch Processing (Default)\n```\nasync def crawl_batch():\n  browser_config = BrowserConfig(headless=True, verbose=False)\n  run_config = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    stream=False # Default: get all results at once\n  )\n  dispatcher = MemoryAdaptiveDispatcher(\n    memory_threshold_percent=70.0,\n    check_interval=1.0,\n    max_session_permit=10,\n    monitor=CrawlerMonitor(\n      display_mode=DisplayMode.DETAILED\n    )\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    # Get all results at once\n    results = await crawler.arun_many(\n      urls=urls,\n      config=run_config,\n      dispatcher=dispatcher\n    )\n    # Process all results after completion\n    for result in results:\n      if result.success:\n        await process_result(result)\n      else:\n        print(f\"Failed to crawl {result.url}: {result.error_message}\")\n\n```\n\n**Review:** - **Purpose:** Executes a batch crawl with all URLs processed together after crawling is complete. - **Dispatcher:** Uses `MemoryAdaptiveDispatcher` to manage concurrency and system memory. - **Stream:** Disabled (`stream=False`), so all results are collected at once for post-processing. - **Best Use Case:** When you need to analyze results in bulk rather than individually during the crawl.\n### 4.2 Streaming Mode\n```\nasync def crawl_streaming():\n  browser_config = BrowserConfig(headless=True, verbose=False)\n  run_config = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    stream=True # Enable streaming mode\n  )\n  dispatcher = MemoryAdaptiveDispatcher(\n    memory_threshold_percent=70.0,\n    check_interval=1.0,\n    max_session_permit=10,\n    monitor=CrawlerMonitor(\n      display_mode=DisplayMode.DETAILED\n    )\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    # Process results as they become available\n    async for result in await crawler.arun_many(\n      urls=urls,\n      config=run_config,\n      dispatcher=dispatcher\n    ):\n      if result.success:\n        # Process each result immediately\n        await process_result(result)\n      else:\n        print(f\"Failed to crawl {result.url}: {result.error_message}\")\n\n```\n\n**Review:** - **Purpose:** Enables streaming to process results as soon as they\u2019re available. - **Dispatcher:** Uses `MemoryAdaptiveDispatcher` for concurrency and memory management. - **Stream:** Enabled (`stream=True`), allowing real-time processing during crawling. - **Best Use Case:** When you need to act on results immediately, such as for real-time analytics or progressive data storage.\n### 4.3 Semaphore-based Crawling\n```\nasync def crawl_with_semaphore(urls):\n  browser_config = BrowserConfig(headless=True, verbose=False)\n  run_config = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n  dispatcher = SemaphoreDispatcher(\n    semaphore_count=5,\n    rate_limiter=RateLimiter(\n      base_delay=(0.5, 1.0),\n      max_delay=10.0\n    ),\n    monitor=CrawlerMonitor(\n      max_visible_rows=15,\n      display_mode=DisplayMode.DETAILED\n    )\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    results = await crawler.arun_many(\n      urls, \n      config=run_config,\n      dispatcher=dispatcher\n    )\n    return results\n\n```\n\n**Review:** - **Purpose:** Uses `SemaphoreDispatcher` to limit concurrency with a fixed number of slots. - **Dispatcher:** Configured with a semaphore to control parallel crawling tasks. - **Rate Limiter:** Prevents servers from being overwhelmed by pacing requests. - **Best Use Case:** When you want precise control over the number of concurrent requests, independent of system memory.\n### 4.4 Robots.txt Consideration\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nasync def main():\n  urls = [\n    \"https://example1.com\",\n    \"https://example2.com\",\n    \"https://example3.com\"\n  ]\n  config = CrawlerRunConfig(\n    cache_mode=CacheMode.ENABLED,\n    check_robots_txt=True, # Will respect robots.txt for each URL\n    semaphore_count=3   # Max concurrent requests\n  )\n  async with AsyncWebCrawler() as crawler:\n    async for result in crawler.arun_many(urls, config=config):\n      if result.success:\n        print(f\"Successfully crawled {result.url}\")\n      elif result.status_code == 403 and \"robots.txt\" in result.error_message:\n        print(f\"Skipped {result.url} - blocked by robots.txt\")\n      else:\n        print(f\"Failed to crawl {result.url}: {result.error_message}\")\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Review:** - **Purpose:** Ensures compliance with `robots.txt` rules for ethical and legal web crawling. - **Configuration:** Set `check_robots_txt=True` to validate each URL against `robots.txt` before crawling. - **Dispatcher:** Handles requests with concurrency limits (`semaphore_count=3`). - **Best Use Case:** When crawling websites that strictly enforce robots.txt policies or for responsible crawling practices.\n## 5. Dispatch Results\nEach crawl result includes dispatch information:\n```\n@dataclass\nclass DispatchResult:\n  task_id: str\n  memory_usage: float\n  peak_memory: float\n  start_time: datetime\n  end_time: datetime\n  error_message: str = \"\"\n\n```\n\nAccess via `result.dispatch_result`:\n```\nfor result in results:\n  if result.success:\n    dr = result.dispatch_result\n    print(f\"URL: {result.url}\")\n    print(f\"Memory: {dr.memory_usage:.1f}MB\")\n    print(f\"Duration: {dr.end_time - dr.start_time}\")\n\n```\n\n## 6. Summary\n1. **Two Dispatcher Types** :\n  * MemoryAdaptiveDispatcher (default): Dynamic concurrency based on memory\n  * SemaphoreDispatcher: Fixed concurrency limit\n\n\n2. **Optional Components** :\n  * RateLimiter: Smart request pacing and backoff\n  * CrawlerMonitor: Real-time progress visualization\n\n\n3. **Key Benefits** :\n  * Automatic memory management\n  * Built-in rate limiting\n  * Live progress monitoring\n  * Flexible concurrency control\n\n\nChoose the dispatcher that best fits your needs:\n  * **MemoryAdaptiveDispatcher** : For large crawls or limited resources\n  * **SemaphoreDispatcher** : For simple, fixed-concurrency scenarios\n\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/session-management",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 3,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:04",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "no-llm-strategies.json",
    "content": {
      "url": "https://docs.crawl4ai.com/extraction/no-llm-strategies",
      "timestamp": "2025-02-06T13:23:53.913765",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/extraction/no-llm-strategies/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>LLM-Free Strategies - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">LLM-Free Strategies</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#extracting-json-no-llm\">Extracting JSON (No LLM)</a></li>\n        <li><a href=\"#1-intro-to-schema-based-extraction\">1. Intro to Schema-Based Extraction</a></li><li><a href=\"#2-simple-example-crypto-prices\">2. Simple Example: Crypto Prices</a></li><li><a href=\"#3-advanced-schema-nested-structures\">3. Advanced Schema &amp; Nested Structures</a></li><li><a href=\"#4-why-no-llm-is-often-better\">4. Why \u201cNo LLM\u201d Is Often Better</a></li><li><a href=\"#5-base-element-attributes-additional-fields\">5. Base Element Attributes &amp; Additional Fields</a></li><li><a href=\"#6-putting-it-all-together-larger-example\">6. Putting It All Together: Larger Example</a></li><li><a href=\"#7-tips-best-practices\">7. Tips &amp; Best Practices</a></li><li><a href=\"#8-schema-generation-utility\">8. Schema Generation Utility</a></li><li><a href=\"#9-conclusion\">9. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"extracting-json-no-llm\">Extracting JSON (No LLM)</h1>\n<p>One of Crawl4AI\u2019s <strong>most powerful</strong> features is extracting <strong>structured JSON</strong> from websites <strong>without</strong> relying on large language models. By defining a <strong>schema</strong> with CSS or XPath selectors, you can extract data instantly\u2014even from complex or nested HTML structures\u2014without the cost, latency, or environmental impact of an LLM.</p>\n<p><strong>Why avoid LLM for basic extractions?</strong></p>\n<p>1.\u2000<strong>Faster &amp; Cheaper</strong>: No API calls or GPU overhead.<br>\n2.\u2000<strong>Lower Carbon Footprint</strong>: LLM inference can be energy-intensive. A well-defined schema is practically carbon-free.<br>\n3.\u2000<strong>Precise &amp; Repeatable</strong>: CSS/XPath selectors do exactly what you specify. LLM outputs can vary or hallucinate.<br>\n4.\u2000<strong>Scales Readily</strong>: For thousands of pages, schema-based extraction runs quickly and in parallel.</p>\n<p>Below, we\u2019ll explore how to craft these schemas and use them with <strong>JsonCssExtractionStrategy</strong> (or <strong>JsonXPathExtractionStrategy</strong> if you prefer XPath). We\u2019ll also highlight advanced features like <strong>nested fields</strong> and <strong>base element attributes</strong>.</p>\n<hr>\n<h2 id=\"1-intro-to-schema-based-extraction\">1. Intro to Schema-Based Extraction</h2>\n<p>A schema defines:</p>\n<ol>\n<li>A <strong>base selector</strong> that identifies each \u201ccontainer\u201d element on the page (e.g., a product row, a blog post card).<br>\n2.\u2000<strong>Fields</strong> describing which CSS/XPath selectors to use for each piece of data you want to capture (text, attribute, HTML block, etc.).<br>\n3.\u2000<strong>Nested</strong> or <strong>list</strong> types for repeated or hierarchical structures.  </li>\n</ol>\n<p>For example, if you have a list of products, each one might have a name, price, reviews, and \u201crelated products.\u201d This approach is faster and more reliable than an LLM for consistent, structured pages.</p>\n<hr>\n<h2 id=\"2-simple-example-crypto-prices\">2. Simple Example: Crypto Prices</h2>\n<p>Let\u2019s begin with a <strong>simple</strong> schema-based extraction using the <code>JsonCssExtractionStrategy</code>. Below is a snippet that extracts cryptocurrency prices from a site (similar to the legacy Coinbase example). Notice we <strong>don\u2019t</strong> call any LLM:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_crypto_prices</span>():\n    <span class=\"hljs-comment\"># 1. Define a simple extraction schema</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Crypto Prices\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.crypto-row\"</span>,    <span class=\"hljs-comment\"># Repeated elements</span>\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"coin_name\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2.coin-name\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"price\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"span.coin-price\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            }\n        ]\n    }\n\n    <span class=\"hljs-comment\"># 2. Create the extraction strategy</span>\n    extraction_strategy = JsonCssExtractionStrategy(schema, verbose=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-comment\"># 3. Set up your crawler config (if needed)</span>\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># e.g., pass js_code or wait_for if the page is dynamic</span>\n        <span class=\"hljs-comment\"># wait_for=\"css:.crypto-row:nth-child(20)\"</span>\n        cache_mode = CacheMode.BYPASS,\n        extraction_strategy=extraction_strategy,\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(verbose=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># 4. Run the crawl and extraction</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com/crypto-prices\"</span>,\n\n            config=config\n        )\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-comment\"># 5. Parse the extracted JSON</span>\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Extracted <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(data)}</span> coin entries\"</span>)\n        <span class=\"hljs-built_in\">print</span>(json.dumps(data[<span class=\"hljs-number\">0</span>], indent=<span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">if</span> data <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"No data found\"</span>)\n\nasyncio.run(extract_crypto_prices())\n</code></pre></div>\n<p><strong>Highlights</strong>:</p>\n<ul>\n<li><strong><code>baseSelector</code></strong>: Tells us where each \u201citem\u201d (crypto row) is.  </li>\n<li><strong><code>fields</code></strong>: Two fields (<code>coin_name</code>, <code>price</code>) using simple CSS selectors.  </li>\n<li>Each field defines a <strong><code>type</code></strong> (e.g., <code>text</code>, <code>attribute</code>, <code>html</code>, <code>regex</code>, etc.).</li>\n</ul>\n<p>No LLM is needed, and the performance is <strong>near-instant</strong> for hundreds or thousands of items.</p>\n<hr>\n<h3 id=\"xpath-example-with-raw-html\"><strong>XPath Example with <code>raw://</code> HTML</strong></h3>\n<p>Below is a short example demonstrating <strong>XPath</strong> extraction plus the <strong><code>raw://</code></strong> scheme. We\u2019ll pass a <strong>dummy HTML</strong> directly (no network request) and define the extraction strategy in <code>CrawlerRunConfig</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonXPathExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_crypto_prices_xpath</span>():\n    <span class=\"hljs-comment\"># 1. Minimal dummy HTML with some repeating rows</span>\n    dummy_html = <span class=\"hljs-string\">\"\"\"\n    &lt;html&gt;\n      &lt;body&gt;\n        &lt;div class='crypto-row'&gt;\n          &lt;h2 class='coin-name'&gt;Bitcoin&lt;/h2&gt;\n          &lt;span class='coin-price'&gt;$28,000&lt;/span&gt;\n        &lt;/div&gt;\n        &lt;div class='crypto-row'&gt;\n          &lt;h2 class='coin-name'&gt;Ethereum&lt;/h2&gt;\n          &lt;span class='coin-price'&gt;$1,800&lt;/span&gt;\n        &lt;/div&gt;\n      &lt;/body&gt;\n    &lt;/html&gt;\n    \"\"\"</span>\n\n    <span class=\"hljs-comment\"># 2. Define the JSON schema (XPath version)</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Crypto Prices via XPath\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"//div[@class='crypto-row']\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"coin_name\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".//h2[@class='coin-name']\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"price\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".//span[@class='coin-price']\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            }\n        ]\n    }\n\n    <span class=\"hljs-comment\"># 3. Place the strategy in the CrawlerRunConfig</span>\n    config = CrawlerRunConfig(\n        extraction_strategy=JsonXPathExtractionStrategy(schema, verbose=<span class=\"hljs-literal\">True</span>)\n    )\n\n    <span class=\"hljs-comment\"># 4. Use raw:// scheme to pass dummy_html directly</span>\n    raw_url = <span class=\"hljs-string\">f\"raw://<span class=\"hljs-subst\">{dummy_html}</span>\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(verbose=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=raw_url,\n            config=config\n        )\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n            <span class=\"hljs-keyword\">return</span>\n\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Extracted <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(data)}</span> coin rows\"</span>)\n        <span class=\"hljs-keyword\">if</span> data:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"First item:\"</span>, data[<span class=\"hljs-number\">0</span>])\n\nasyncio.run(extract_crypto_prices_xpath())\n</code></pre></div>\n<p><strong>Key Points</strong>:</p>\n<p>1.\u2000<strong><code>JsonXPathExtractionStrategy</code></strong> is used instead of <code>JsonCssExtractionStrategy</code>.<br>\n2.\u2000<strong><code>baseSelector</code></strong> and each field\u2019s <code>\"selector\"</code> use <strong>XPath</strong> instead of CSS.<br>\n3.\u2000<strong><code>raw://</code></strong> lets us pass <code>dummy_html</code> with no real network request\u2014handy for local testing.<br>\n4. Everything (including the extraction strategy) is in <strong><code>CrawlerRunConfig</code></strong>.  </p>\n<p>That\u2019s how you keep the config self-contained, illustrate <strong>XPath</strong> usage, and demonstrate the <strong>raw</strong> scheme for direct HTML input\u2014all while avoiding the old approach of passing <code>extraction_strategy</code> directly to <code>arun()</code>.</p>\n<hr>\n<h2 id=\"3-advanced-schema-nested-structures\">3. Advanced Schema &amp; Nested Structures</h2>\n<p>Real sites often have <strong>nested</strong> or repeated data\u2014like categories containing products, which themselves have a list of reviews or features. For that, we can define <strong>nested</strong> or <strong>list</strong> (and even <strong>nested_list</strong>) fields.</p>\n<h3 id=\"sample-e-commerce-html\">Sample E-Commerce HTML</h3>\n<p>We have a <strong>sample e-commerce</strong> HTML file on GitHub (example):\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">https://gist.githubusercontent.com/githubusercontent/2d7b8ba3cd8ab6cf3c8da771ddb36878/raw/1ae2f90c6861ce7dd84cc50d3df9920dee5e1fd2/sample_ecommerce.html\n</code></pre></div>\nThis snippet includes categories, products, features, reviews, and related items. Let\u2019s see how to define a schema that fully captures that structure <strong>without LLM</strong>.<p></p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\"><span class=\"hljs-keyword\">schema</span> <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"E-commerce Product Catalog\"</span>,\n    <span class=\"hljs-string\">\"baseSelector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"div.category\"</span>,\n    <span class=\"hljs-comment\"># (1) We can define optional baseFields if we want to extract attributes </span>\n    <span class=\"hljs-comment\"># from the category container</span>\n    <span class=\"hljs-string\">\"baseFields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"data_cat_id\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"data-cat-id\"</span><span class=\"hljs-punctuation\">}</span>, \n    <span class=\"hljs-punctuation\">]</span>,\n    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"category_name\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"h2.category-name\"</span>,\n            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n        <span class=\"hljs-punctuation\">}</span>,\n        <span class=\"hljs-punctuation\">{</span>\n            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"products\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"div.product\"</span>,\n            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"nested_list\"</span>,    <span class=\"hljs-comment\"># repeated sub-objects</span>\n            <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"name\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"h3.product-name\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                <span class=\"hljs-punctuation\">}</span>,\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"price\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"p.product-price\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                <span class=\"hljs-punctuation\">}</span>,\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"details\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"div.product-details\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"nested\"</span>,  <span class=\"hljs-comment\"># single sub-object</span>\n                    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"brand\"</span>,\n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.brand\"</span>,\n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>,\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"model\"</span>,\n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.model\"</span>,\n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>\n                    <span class=\"hljs-punctuation\">]</span>\n                <span class=\"hljs-punctuation\">}</span>,\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"features\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"ul.product-features li\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"list\"</span>,\n                    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n                        <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"feature\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span><span class=\"hljs-punctuation\">}</span> \n                    <span class=\"hljs-punctuation\">]</span>\n                <span class=\"hljs-punctuation\">}</span>,\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"reviews\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"div.review\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"nested_list\"</span>,\n                    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"reviewer\"</span>, \n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.reviewer\"</span>, \n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>,\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"rating\"</span>, \n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.rating\"</span>, \n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>,\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"comment\"</span>, \n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"p.review-text\"</span>, \n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>\n                    <span class=\"hljs-punctuation\">]</span>\n                <span class=\"hljs-punctuation\">}</span>,\n                <span class=\"hljs-punctuation\">{</span>\n                    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"related_products\"</span>,\n                    <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"ul.related-products li\"</span>,\n                    <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"list\"</span>,\n                    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"name\"</span>, \n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.related-name\"</span>, \n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>,\n                        <span class=\"hljs-punctuation\">{</span>\n                            <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"price\"</span>, \n                            <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.related-price\"</span>, \n                            <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>\n                        <span class=\"hljs-punctuation\">}</span>\n                    <span class=\"hljs-punctuation\">]</span>\n                <span class=\"hljs-punctuation\">}</span>\n            <span class=\"hljs-punctuation\">]</span>\n        <span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<p>Key Takeaways:</p>\n<ul>\n<li><strong>Nested vs. List</strong>:  </li>\n<li><strong><code>type: \"nested\"</code></strong> means a <strong>single</strong> sub-object (like <code>details</code>).  </li>\n<li><strong><code>type: \"list\"</code></strong> means multiple items that are <strong>simple</strong> dictionaries or single text fields.  </li>\n<li><strong><code>type: \"nested_list\"</code></strong> means repeated <strong>complex</strong> objects (like <code>products</code> or <code>reviews</code>).</li>\n<li><strong>Base Fields</strong>: We can extract <strong>attributes</strong> from the container element via <code>\"baseFields\"</code>. For instance, <code>\"data_cat_id\"</code> might be <code>data-cat-id=\"elect123\"</code>.  </li>\n<li><strong>Transforms</strong>: We can also define a <code>transform</code> if we want to lower/upper case, strip whitespace, or even run a custom function.</li>\n</ul>\n<h3 id=\"running-the-extraction\">Running the Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\necommerce_schema = {\n    <span class=\"hljs-comment\"># ... the advanced schema from above ...</span>\n}\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_ecommerce_data</span>():\n    strategy = JsonCssExtractionStrategy(ecommerce_schema, verbose=<span class=\"hljs-literal\">True</span>)\n\n    config = CrawlerRunConfig()\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(verbose=<span class=\"hljs-literal\">True</span>) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://gist.githubusercontent.com/githubusercontent/2d7b8ba3cd8ab6cf3c8da771ddb36878/raw/1ae2f90c6861ce7dd84cc50d3df9920dee5e1fd2/sample_ecommerce.html\"</span>,\n            extraction_strategy=strategy,\n            config=config\n        )\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-comment\"># Parse the JSON output</span>\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(json.dumps(data, indent=<span class=\"hljs-number\">2</span>) <span class=\"hljs-keyword\">if</span> data <span class=\"hljs-keyword\">else</span> <span class=\"hljs-string\">\"No data found.\"</span>)\n\nasyncio.run(extract_ecommerce_data())\n</code></pre></div>\n<p>If all goes well, you get a <strong>structured</strong> JSON array with each \u201ccategory,\u201d containing an array of <code>products</code>. Each product includes <code>details</code>, <code>features</code>, <code>reviews</code>, etc. All of that <strong>without</strong> an LLM.</p>\n<hr>\n<h2 id=\"4-why-no-llm-is-often-better\">4. Why \u201cNo LLM\u201d Is Often Better</h2>\n<p>1.\u2000<strong>Zero Hallucination</strong>: Schema-based extraction doesn\u2019t guess text. It either finds it or not.<br>\n2.\u2000<strong>Guaranteed Structure</strong>: The same schema yields consistent JSON across many pages, so your downstream pipeline can rely on stable keys.<br>\n3.\u2000<strong>Speed</strong>: LLM-based extraction can be 10\u20131000x slower for large-scale crawling.<br>\n4.\u2000<strong>Scalable</strong>: Adding or updating a field is a matter of adjusting the schema, not re-tuning a model.</p>\n<p><strong>When might you consider an LLM?</strong> Possibly if the site is extremely unstructured or you want AI summarization. But always try a schema approach first for repeated or consistent data patterns.</p>\n<hr>\n<h2 id=\"5-base-element-attributes-additional-fields\">5. Base Element Attributes &amp; Additional Fields</h2>\n<p>It\u2019s easy to <strong>extract attributes</strong> (like <code>href</code>, <code>src</code>, or <code>data-xxx</code>) from your base or nested elements using:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-json\"><span class=\"hljs-punctuation\">{</span>\n  <span class=\"hljs-attr\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"href\"</span><span class=\"hljs-punctuation\">,</span>\n  <span class=\"hljs-attr\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"attribute\"</span><span class=\"hljs-punctuation\">,</span>\n  <span class=\"hljs-attr\">\"attribute\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"href\"</span><span class=\"hljs-punctuation\">,</span>\n  <span class=\"hljs-attr\">\"default\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-literal\"><span class=\"hljs-keyword\">null</span></span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<p>You can define them in <strong><code>baseFields</code></strong> (extracted from the main container element) or in each field\u2019s sub-lists. This is especially helpful if you need an item\u2019s link or ID stored in the parent <code>&lt;div&gt;</code>.</p>\n<hr>\n<h2 id=\"6-putting-it-all-together-larger-example\">6. Putting It All Together: Larger Example</h2>\n<p>Consider a blog site. We have a schema that extracts the <strong>URL</strong> from each post card (via <code>baseFields</code> with an <code>\"attribute\": \"href\"</code>), plus the title, date, summary, and author:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\"><span class=\"hljs-keyword\">schema</span> <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n  <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Blog Posts\"</span>,\n  <span class=\"hljs-string\">\"baseSelector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"a.blog-post-card\"</span>,\n  <span class=\"hljs-string\">\"baseFields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n    <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"post_url\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"href\"</span><span class=\"hljs-punctuation\">}</span>\n  <span class=\"hljs-punctuation\">]</span>,\n  <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n    <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"h2.post-title\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"default\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"No Title\"</span><span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"date\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"time.post-date\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"default\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"\"</span><span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"summary\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"p.post-summary\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"default\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"\"</span><span class=\"hljs-punctuation\">}</span>,\n    <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"author\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"span.post-author\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span>, <span class=\"hljs-string\">\"default\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"\"</span><span class=\"hljs-punctuation\">}</span>\n  <span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n<p>Then run with <code>JsonCssExtractionStrategy(schema)</code> to get an array of blog post objects, each with <code>\"post_url\"</code>, <code>\"title\"</code>, <code>\"date\"</code>, <code>\"summary\"</code>, <code>\"author\"</code>.</p>\n<hr>\n<h2 id=\"7-tips-best-practices\">7. Tips &amp; Best Practices</h2>\n<p>1.\u2000<strong>Inspect the DOM</strong> in Chrome DevTools or Firefox\u2019s Inspector to find stable selectors.<br>\n2.\u2000<strong>Start Simple</strong>: Verify you can extract a single field. Then add complexity like nested objects or lists.<br>\n3.\u2000<strong>Test</strong> your schema on partial HTML or a test page before a big crawl.<br>\n4.\u2000<strong>Combine with JS Execution</strong> if the site loads content dynamically. You can pass <code>js_code</code> or <code>wait_for</code> in <code>CrawlerRunConfig</code>.<br>\n5.\u2000<strong>Look at Logs</strong> when <code>verbose=True</code>: if your selectors are off or your schema is malformed, it\u2019ll often show warnings.<br>\n6.\u2000<strong>Use baseFields</strong> if you need attributes from the container element (e.g., <code>href</code>, <code>data-id</code>), especially for the \u201cparent\u201d item.<br>\n7.\u2000<strong>Performance</strong>: For large pages, make sure your selectors are as narrow as possible.</p>\n<hr>\n<h2 id=\"8-schema-generation-utility\">8. Schema Generation Utility</h2>\n<p>While manually crafting schemas is powerful and precise, Crawl4AI now offers a convenient utility to <strong>automatically generate</strong> extraction schemas using LLM. This is particularly useful when:</p>\n<ol>\n<li>You're dealing with a new website structure and want a quick starting point</li>\n<li>You need to extract complex nested data structures</li>\n<li>You want to avoid the learning curve of CSS/XPath selector syntax</li>\n</ol>\n<h3 id=\"using-the-schema-generator\">Using the Schema Generator</h3>\n<p>The schema generator is available as a static method on both <code>JsonCssExtractionStrategy</code> and <code>JsonXPathExtractionStrategy</code>. You can choose between OpenAI's GPT-4 or the open-source Ollama for schema generation:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy, JsonXPathExtractionStrategy\n\n<span class=\"hljs-comment\"># Sample HTML with product information</span>\nhtml = <span class=\"hljs-string\">\"\"\"\n&lt;div class=\"product-card\"&gt;\n    &lt;h2 class=\"title\"&gt;Gaming Laptop&lt;/h2&gt;\n    &lt;div class=\"price\"&gt;$999.99&lt;/div&gt;\n    &lt;div class=\"specs\"&gt;\n        &lt;ul&gt;\n            &lt;li&gt;16GB RAM&lt;/li&gt;\n            &lt;li&gt;1TB SSD&lt;/li&gt;\n        &lt;/ul&gt;\n    &lt;/div&gt;\n&lt;/div&gt;\n\"\"\"</span>\n\n<span class=\"hljs-comment\"># Option 1: Using OpenAI (requires API token)</span>\ncss_schema = JsonCssExtractionStrategy.generate_schema(\n    html,\n    schema_type=<span class=\"hljs-string\">\"css\"</span>,  <span class=\"hljs-comment\"># This is the default</span>\n    llm_provider=<span class=\"hljs-string\">\"openai/gpt-4o\"</span>,  <span class=\"hljs-comment\"># Default provider</span>\n    api_token=<span class=\"hljs-string\">\"your-openai-token\"</span>  <span class=\"hljs-comment\"># Required for OpenAI</span>\n)\n\n<span class=\"hljs-comment\"># Option 2: Using Ollama (open source, no token needed)</span>\nxpath_schema = JsonXPathExtractionStrategy.generate_schema(\n    html,\n    schema_type=<span class=\"hljs-string\">\"xpath\"</span>,\n    llm_provider=<span class=\"hljs-string\">\"ollama/llama3.3\"</span>,  <span class=\"hljs-comment\"># Open source alternative</span>\n    api_token=<span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># Not needed for Ollama</span>\n)\n\n<span class=\"hljs-comment\"># Use the generated schema for fast, repeated extractions</span>\nstrategy = JsonCssExtractionStrategy(css_schema)\n</code></pre></div>\n<h3 id=\"llm-provider-options\">LLM Provider Options</h3>\n<ol>\n<li><strong>OpenAI GPT-4 (<code>openai/gpt4o</code>)</strong></li>\n<li>Default provider</li>\n<li>Requires an API token</li>\n<li>Generally provides more accurate schemas</li>\n<li>\n<p>Set via environment variable: <code>OPENAI_API_KEY</code></p>\n</li>\n<li>\n<p><strong>Ollama (<code>ollama/llama3.3</code>)</strong></p>\n</li>\n<li>Open source alternative</li>\n<li>No API token required</li>\n<li>Self-hosted option</li>\n<li>Good for development and testing</li>\n</ol>\n<h3 id=\"benefits-of-schema-generation\">Benefits of Schema Generation</h3>\n<ol>\n<li><strong>One-Time Cost</strong>: While schema generation uses LLM, it's a one-time cost. The generated schema can be reused for unlimited extractions without further LLM calls.</li>\n<li><strong>Smart Pattern Recognition</strong>: The LLM analyzes the HTML structure and identifies common patterns, often producing more robust selectors than manual attempts.</li>\n<li><strong>Automatic Nesting</strong>: Complex nested structures are automatically detected and properly represented in the schema.</li>\n<li><strong>Learning Tool</strong>: The generated schemas serve as excellent examples for learning how to write your own schemas.</li>\n</ol>\n<h3 id=\"best-practices\">Best Practices</h3>\n<ol>\n<li><strong>Review Generated Schemas</strong>: While the generator is smart, always review and test the generated schema before using it in production.</li>\n<li><strong>Provide Representative HTML</strong>: The better your sample HTML represents the overall structure, the more accurate the generated schema will be.</li>\n<li><strong>Consider Both CSS and XPath</strong>: Try both schema types and choose the one that works best for your specific case.</li>\n<li><strong>Cache Generated Schemas</strong>: Since generation uses LLM, save successful schemas for reuse.</li>\n<li><strong>API Token Security</strong>: Never hardcode API tokens. Use environment variables or secure configuration management.</li>\n<li><strong>Choose Provider Wisely</strong>: </li>\n<li>Use OpenAI for production-quality schemas</li>\n<li>Use Ollama for development, testing, or when you need a self-hosted solution</li>\n</ol>\n<p>That's it for <strong>Extracting JSON (No LLM)</strong>! You've seen how schema-based approaches (either CSS or XPath) can handle everything from simple lists to deeply nested product catalogs\u2014instantly, with minimal overhead. Enjoy building robust scrapers that produce consistent, structured JSON for your data pipelines!</p>\n<hr>\n<h2 id=\"9-conclusion\">9. Conclusion</h2>\n<p>With <strong>JsonCssExtractionStrategy</strong> (or <strong>JsonXPathExtractionStrategy</strong>), you can build powerful, <strong>LLM-free</strong> pipelines that:</p>\n<ul>\n<li>Scrape any consistent site for structured data.  </li>\n<li>Support nested objects, repeating lists, or advanced transformations.  </li>\n<li>Scale to thousands of pages quickly and reliably.</li>\n</ul>\n<p><strong>Next Steps</strong>:</p>\n<ul>\n<li>Combine your extracted JSON with advanced filtering or summarization in a second pass if needed.  </li>\n<li>For dynamic pages, combine strategies with <code>js_code</code> or infinite scroll hooking to ensure all content is loaded.</li>\n</ul>\n<p><strong>Remember</strong>: For repeated, structured data, you don\u2019t need to pay for or wait on an LLM. A well-crafted schema plus CSS or XPath gets you the data faster, cleaner, and cheaper\u2014<strong>the real power</strong> of Crawl4AI.</p>\n<p><strong>Last Updated</strong>: 2025-01-01</p>\n<hr>\n<p>That\u2019s it for <strong>Extracting JSON (No LLM)</strong>! You\u2019ve seen how schema-based approaches (either CSS or XPath) can handle everything from simple lists to deeply nested product catalogs\u2014instantly, with minimal overhead. Enjoy building robust scrapers that produce consistent, structured JSON for your data pipelines!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Extracting JSON (No LLM)\nOne of Crawl4AI\u2019s **most powerful** features is extracting **structured JSON** from websites **without** relying on large language models. By defining a **schema** with CSS or XPath selectors, you can extract data instantly\u2014even from complex or nested HTML structures\u2014without the cost, latency, or environmental impact of an LLM.\n**Why avoid LLM for basic extractions?**\n1. **Faster & Cheaper**: No API calls or GPU overhead. 2. **Lower Carbon Footprint** : LLM inference can be energy-intensive. A well-defined schema is practically carbon-free. 3. **Precise & Repeatable**: CSS/XPath selectors do exactly what you specify. LLM outputs can vary or hallucinate. 4. **Scales Readily** : For thousands of pages, schema-based extraction runs quickly and in parallel.\nBelow, we\u2019ll explore how to craft these schemas and use them with **JsonCssExtractionStrategy** (or **JsonXPathExtractionStrategy** if you prefer XPath). We\u2019ll also highlight advanced features like **nested fields** and **base element attributes**.\n## 1. Intro to Schema-Based Extraction\nA schema defines:\n  1. A **base selector** that identifies each \u201ccontainer\u201d element on the page (e.g., a product row, a blog post card). 2. **Fields** describing which CSS/XPath selectors to use for each piece of data you want to capture (text, attribute, HTML block, etc.). 3. **Nested** or **list** types for repeated or hierarchical structures. \n\n\nFor example, if you have a list of products, each one might have a name, price, reviews, and \u201crelated products.\u201d This approach is faster and more reliable than an LLM for consistent, structured pages.\n## 2. Simple Example: Crypto Prices\nLet\u2019s begin with a **simple** schema-based extraction using the `JsonCssExtractionStrategy`. Below is a snippet that extracts cryptocurrency prices from a site (similar to the legacy Coinbase example). Notice we **don\u2019t** call any LLM:\n```\nimport json\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def extract_crypto_prices():\n  # 1. Define a simple extraction schema\n  schema = {\n    \"name\": \"Crypto Prices\",\n    \"baseSelector\": \"div.crypto-row\",  # Repeated elements\n    \"fields\": [\n      {\n        \"name\": \"coin_name\",\n        \"selector\": \"h2.coin-name\",\n        \"type\": \"text\"\n      },\n      {\n        \"name\": \"price\",\n        \"selector\": \"span.coin-price\",\n        \"type\": \"text\"\n      }\n    ]\n  }\n  # 2. Create the extraction strategy\n  extraction_strategy = JsonCssExtractionStrategy(schema, verbose=True)\n  # 3. Set up your crawler config (if needed)\n  config = CrawlerRunConfig(\n    # e.g., pass js_code or wait_for if the page is dynamic\n    # wait_for=\"css:.crypto-row:nth-child(20)\"\n    cache_mode = CacheMode.BYPASS,\n    extraction_strategy=extraction_strategy,\n  )\n  async with AsyncWebCrawler(verbose=True) as crawler:\n    # 4. Run the crawl and extraction\n    result = await crawler.arun(\n      url=\"https://example.com/crypto-prices\",\n      config=config\n    )\n    if not result.success:\n      print(\"Crawl failed:\", result.error_message)\n      return\n    # 5. Parse the extracted JSON\n    data = json.loads(result.extracted_content)\n    print(f\"Extracted {len(data)} coin entries\")\n    print(json.dumps(data[0], indent=2) if data else \"No data found\")\nasyncio.run(extract_crypto_prices())\n\n```\n\n**Highlights** :\n  * **`baseSelector`**: Tells us where each \u201citem\u201d (crypto row) is.\n  * **`fields`**: Two fields (`coin_name` , `price`) using simple CSS selectors. \n  * Each field defines a **`type`**(e.g.,`text` , `attribute`, `html`, `regex`, etc.).\n\n\nNo LLM is needed, and the performance is **near-instant** for hundreds or thousands of items.\n### **XPath Example with`raw://` HTML**\nBelow is a short example demonstrating **XPath** extraction plus the **`raw://`**scheme. We\u2019ll pass a**dummy HTML** directly (no network request) and define the extraction strategy in `CrawlerRunConfig`.\n```\nimport json\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import JsonXPathExtractionStrategy\nasync def extract_crypto_prices_xpath():\n  # 1. Minimal dummy HTML with some repeating rows\n  dummy_html = \"\"\"\n  <html>\n   <body>\n    <div class='crypto-row'>\n     <h2 class='coin-name'>Bitcoin</h2>\n     <span class='coin-price'>$28,000</span>\n    </div>\n    <div class='crypto-row'>\n     <h2 class='coin-name'>Ethereum</h2>\n     <span class='coin-price'>$1,800</span>\n    </div>\n   </body>\n  </html>\n  \"\"\"\n  # 2. Define the JSON schema (XPath version)\n  schema = {\n    \"name\": \"Crypto Prices via XPath\",\n    \"baseSelector\": \"//div[@class='crypto-row']\",\n    \"fields\": [\n      {\n        \"name\": \"coin_name\",\n        \"selector\": \".//h2[@class='coin-name']\",\n        \"type\": \"text\"\n      },\n      {\n        \"name\": \"price\",\n        \"selector\": \".//span[@class='coin-price']\",\n        \"type\": \"text\"\n      }\n    ]\n  }\n  # 3. Place the strategy in the CrawlerRunConfig\n  config = CrawlerRunConfig(\n    extraction_strategy=JsonXPathExtractionStrategy(schema, verbose=True)\n  )\n  # 4. Use raw:// scheme to pass dummy_html directly\n  raw_url = f\"raw://{dummy_html}\"\n  async with AsyncWebCrawler(verbose=True) as crawler:\n    result = await crawler.arun(\n      url=raw_url,\n      config=config\n    )\n    if not result.success:\n      print(\"Crawl failed:\", result.error_message)\n      return\n    data = json.loads(result.extracted_content)\n    print(f\"Extracted {len(data)} coin rows\")\n    if data:\n      print(\"First item:\", data[0])\nasyncio.run(extract_crypto_prices_xpath())\n\n```\n\n**Key Points** :\n1. **`JsonXPathExtractionStrategy`**is used instead of`JsonCssExtractionStrategy`. 2. **`baseSelector`**and each field\u2019s`\"selector\"` use **XPath** instead of CSS. 3. **`raw://`**lets us pass`dummy_html` with no real network request\u2014handy for local testing. 4. Everything (including the extraction strategy) is in **`CrawlerRunConfig`**.\nThat\u2019s how you keep the config self-contained, illustrate **XPath** usage, and demonstrate the **raw** scheme for direct HTML input\u2014all while avoiding the old approach of passing `extraction_strategy` directly to `arun()`.\n## 3. Advanced Schema & Nested Structures\nReal sites often have **nested** or repeated data\u2014like categories containing products, which themselves have a list of reviews or features. For that, we can define **nested** or **list** (and even **nested_list**) fields.\n### Sample E-Commerce HTML\nWe have a **sample e-commerce** HTML file on GitHub (example): \n```\nhttps://gist.githubusercontent.com/githubusercontent/2d7b8ba3cd8ab6cf3c8da771ddb36878/raw/1ae2f90c6861ce7dd84cc50d3df9920dee5e1fd2/sample_ecommerce.html\n\n```\n\nThis snippet includes categories, products, features, reviews, and related items. Let\u2019s see how to define a schema that fully captures that structure **without LLM**. \n```\nschema = {\n  \"name\": \"E-commerce Product Catalog\",\n  \"baseSelector\": \"div.category\",\n  # (1) We can define optional baseFields if we want to extract attributes \n  # from the category container\n  \"baseFields\": [\n    {\"name\": \"data_cat_id\", \"type\": \"attribute\", \"attribute\": \"data-cat-id\"}, \n  ],\n  \"fields\": [\n    {\n      \"name\": \"category_name\",\n      \"selector\": \"h2.category-name\",\n      \"type\": \"text\"\n    },\n    {\n      \"name\": \"products\",\n      \"selector\": \"div.product\",\n      \"type\": \"nested_list\",  # repeated sub-objects\n      \"fields\": [\n        {\n          \"name\": \"name\",\n          \"selector\": \"h3.product-name\",\n          \"type\": \"text\"\n        },\n        {\n          \"name\": \"price\",\n          \"selector\": \"p.product-price\",\n          \"type\": \"text\"\n        },\n        {\n          \"name\": \"details\",\n          \"selector\": \"div.product-details\",\n          \"type\": \"nested\", # single sub-object\n          \"fields\": [\n            {\n              \"name\": \"brand\",\n              \"selector\": \"span.brand\",\n              \"type\": \"text\"\n            },\n            {\n              \"name\": \"model\",\n              \"selector\": \"span.model\",\n              \"type\": \"text\"\n            }\n          ]\n        },\n        {\n          \"name\": \"features\",\n          \"selector\": \"ul.product-features li\",\n          \"type\": \"list\",\n          \"fields\": [\n            {\"name\": \"feature\", \"type\": \"text\"} \n          ]\n        },\n        {\n          \"name\": \"reviews\",\n          \"selector\": \"div.review\",\n          \"type\": \"nested_list\",\n          \"fields\": [\n            {\n              \"name\": \"reviewer\", \n              \"selector\": \"span.reviewer\", \n              \"type\": \"text\"\n            },\n            {\n              \"name\": \"rating\", \n              \"selector\": \"span.rating\", \n              \"type\": \"text\"\n            },\n            {\n              \"name\": \"comment\", \n              \"selector\": \"p.review-text\", \n              \"type\": \"text\"\n            }\n          ]\n        },\n        {\n          \"name\": \"related_products\",\n          \"selector\": \"ul.related-products li\",\n          \"type\": \"list\",\n          \"fields\": [\n            {\n              \"name\": \"name\", \n              \"selector\": \"span.related-name\", \n              \"type\": \"text\"\n            },\n            {\n              \"name\": \"price\", \n              \"selector\": \"span.related-price\", \n              \"type\": \"text\"\n            }\n          ]\n        }\n      ]\n    }\n  ]\n}\n\n```\n\nKey Takeaways:\n  * **Nested vs. List** : \n  * **`type: \"nested\"`**means a**single** sub-object (like `details`). \n  * **`type: \"list\"`**means multiple items that are**simple** dictionaries or single text fields. \n  * **`type: \"nested_list\"`**means repeated**complex** objects (like `products` or `reviews`).\n  * **Base Fields** : We can extract **attributes** from the container element via `\"baseFields\"`. For instance, `\"data_cat_id\"` might be `data-cat-id=\"elect123\"`. \n  * **Transforms** : We can also define a `transform` if we want to lower/upper case, strip whitespace, or even run a custom function.\n\n\n### Running the Extraction\n```\nimport json\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\necommerce_schema = {\n  # ... the advanced schema from above ...\n}\nasync def extract_ecommerce_data():\n  strategy = JsonCssExtractionStrategy(ecommerce_schema, verbose=True)\n  config = CrawlerRunConfig()\n  async with AsyncWebCrawler(verbose=True) as crawler:\n    result = await crawler.arun(\n      url=\"https://gist.githubusercontent.com/githubusercontent/2d7b8ba3cd8ab6cf3c8da771ddb36878/raw/1ae2f90c6861ce7dd84cc50d3df9920dee5e1fd2/sample_ecommerce.html\",\n      extraction_strategy=strategy,\n      config=config\n    )\n    if not result.success:\n      print(\"Crawl failed:\", result.error_message)\n      return\n    # Parse the JSON output\n    data = json.loads(result.extracted_content)\n    print(json.dumps(data, indent=2) if data else \"No data found.\")\nasyncio.run(extract_ecommerce_data())\n\n```\n\nIf all goes well, you get a **structured** JSON array with each \u201ccategory,\u201d containing an array of `products`. Each product includes `details`, `features`, `reviews`, etc. All of that **without** an LLM.\n## 4. Why \u201cNo LLM\u201d Is Often Better\n1. **Zero Hallucination** : Schema-based extraction doesn\u2019t guess text. It either finds it or not. 2. **Guaranteed Structure** : The same schema yields consistent JSON across many pages, so your downstream pipeline can rely on stable keys. 3. **Speed** : LLM-based extraction can be 10\u20131000x slower for large-scale crawling. 4. **Scalable** : Adding or updating a field is a matter of adjusting the schema, not re-tuning a model.\n**When might you consider an LLM?** Possibly if the site is extremely unstructured or you want AI summarization. But always try a schema approach first for repeated or consistent data patterns.\n## 5. Base Element Attributes & Additional Fields\nIt\u2019s easy to **extract attributes** (like `href`, `src`, or `data-xxx`) from your base or nested elements using:\n```\n{\n \"name\": \"href\",\n \"type\": \"attribute\",\n \"attribute\": \"href\",\n \"default\": null\n}\n\n```\n\nYou can define them in **`baseFields`**(extracted from the main container element) or in each field\u2019s sub-lists. This is especially helpful if you need an item\u2019s link or ID stored in the parent`<div>`.\n## 6. Putting It All Together: Larger Example\nConsider a blog site. We have a schema that extracts the **URL** from each post card (via `baseFields` with an `\"attribute\": \"href\"`), plus the title, date, summary, and author:\n```\nschema = {\n \"name\": \"Blog Posts\",\n \"baseSelector\": \"a.blog-post-card\",\n \"baseFields\": [\n  {\"name\": \"post_url\", \"type\": \"attribute\", \"attribute\": \"href\"}\n ],\n \"fields\": [\n  {\"name\": \"title\", \"selector\": \"h2.post-title\", \"type\": \"text\", \"default\": \"No Title\"},\n  {\"name\": \"date\", \"selector\": \"time.post-date\", \"type\": \"text\", \"default\": \"\"},\n  {\"name\": \"summary\", \"selector\": \"p.post-summary\", \"type\": \"text\", \"default\": \"\"},\n  {\"name\": \"author\", \"selector\": \"span.post-author\", \"type\": \"text\", \"default\": \"\"}\n ]\n}\n\n```\n\nThen run with `JsonCssExtractionStrategy(schema)` to get an array of blog post objects, each with `\"post_url\"`, `\"title\"`, `\"date\"`, `\"summary\"`, `\"author\"`.\n## 7. Tips & Best Practices\n1. **Inspect the DOM** in Chrome DevTools or Firefox\u2019s Inspector to find stable selectors. 2. **Start Simple** : Verify you can extract a single field. Then add complexity like nested objects or lists. 3. **Test** your schema on partial HTML or a test page before a big crawl. 4. **Combine with JS Execution** if the site loads content dynamically. You can pass `js_code` or `wait_for` in `CrawlerRunConfig`. 5. **Look at Logs** when `verbose=True`: if your selectors are off or your schema is malformed, it\u2019ll often show warnings. 6. **Use baseFields** if you need attributes from the container element (e.g., `href`, `data-id`), especially for the \u201cparent\u201d item. 7. **Performance** : For large pages, make sure your selectors are as narrow as possible.\n## 8. Schema Generation Utility\nWhile manually crafting schemas is powerful and precise, Crawl4AI now offers a convenient utility to **automatically generate** extraction schemas using LLM. This is particularly useful when:\n  1. You're dealing with a new website structure and want a quick starting point\n  2. You need to extract complex nested data structures\n  3. You want to avoid the learning curve of CSS/XPath selector syntax\n\n\n### Using the Schema Generator\nThe schema generator is available as a static method on both `JsonCssExtractionStrategy` and `JsonXPathExtractionStrategy`. You can choose between OpenAI's GPT-4 or the open-source Ollama for schema generation:\n```\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy, JsonXPathExtractionStrategy\n# Sample HTML with product information\nhtml = \"\"\"\n<div class=\"product-card\">\n  <h2 class=\"title\">Gaming Laptop</h2>\n  <div class=\"price\">$999.99</div>\n  <div class=\"specs\">\n    <ul>\n      <li>16GB RAM</li>\n      <li>1TB SSD</li>\n    </ul>\n  </div>\n</div>\n\"\"\"\n# Option 1: Using OpenAI (requires API token)\ncss_schema = JsonCssExtractionStrategy.generate_schema(\n  html,\n  schema_type=\"css\", # This is the default\n  llm_provider=\"openai/gpt-4o\", # Default provider\n  api_token=\"your-openai-token\" # Required for OpenAI\n)\n# Option 2: Using Ollama (open source, no token needed)\nxpath_schema = JsonXPathExtractionStrategy.generate_schema(\n  html,\n  schema_type=\"xpath\",\n  llm_provider=\"ollama/llama3.3\", # Open source alternative\n  api_token=None # Not needed for Ollama\n)\n# Use the generated schema for fast, repeated extractions\nstrategy = JsonCssExtractionStrategy(css_schema)\n\n```\n\n### LLM Provider Options\n  1. **OpenAI GPT-4 (`openai/gpt4o`)**\n  2. Default provider\n  3. Requires an API token\n  4. Generally provides more accurate schemas\n  5. Set via environment variable: `OPENAI_API_KEY`\n  6. **Ollama (`ollama/llama3.3`)**\n  7. Open source alternative\n  8. No API token required\n  9. Self-hosted option\n  10. Good for development and testing\n\n\n### Benefits of Schema Generation\n  1. **One-Time Cost** : While schema generation uses LLM, it's a one-time cost. The generated schema can be reused for unlimited extractions without further LLM calls.\n  2. **Smart Pattern Recognition** : The LLM analyzes the HTML structure and identifies common patterns, often producing more robust selectors than manual attempts.\n  3. **Automatic Nesting** : Complex nested structures are automatically detected and properly represented in the schema.\n  4. **Learning Tool** : The generated schemas serve as excellent examples for learning how to write your own schemas.\n\n\n### Best Practices\n  1. **Review Generated Schemas** : While the generator is smart, always review and test the generated schema before using it in production.\n  2. **Provide Representative HTML** : The better your sample HTML represents the overall structure, the more accurate the generated schema will be.\n  3. **Consider Both CSS and XPath** : Try both schema types and choose the one that works best for your specific case.\n  4. **Cache Generated Schemas** : Since generation uses LLM, save successful schemas for reuse.\n  5. **API Token Security** : Never hardcode API tokens. Use environment variables or secure configuration management.\n  6. **Choose Provider Wisely** : \n  7. Use OpenAI for production-quality schemas\n  8. Use Ollama for development, testing, or when you need a self-hosted solution\n\n\nThat's it for **Extracting JSON (No LLM)**! You've seen how schema-based approaches (either CSS or XPath) can handle everything from simple lists to deeply nested product catalogs\u2014instantly, with minimal overhead. Enjoy building robust scrapers that produce consistent, structured JSON for your data pipelines!\n## 9. Conclusion\nWith **JsonCssExtractionStrategy** (or **JsonXPathExtractionStrategy**), you can build powerful, **LLM-free** pipelines that:\n  * Scrape any consistent site for structured data. \n  * Support nested objects, repeating lists, or advanced transformations. \n  * Scale to thousands of pages quickly and reliably.\n\n\n**Next Steps** :\n  * Combine your extracted JSON with advanced filtering or summarization in a second pass if needed. \n  * For dynamic pages, combine strategies with `js_code` or infinite scroll hooking to ensure all content is loaded.\n\n\n**Remember** : For repeated, structured data, you don\u2019t need to pay for or wait on an LLM. A well-crafted schema plus CSS or XPath gets you the data faster, cleaner, and cheaper\u2014**the real power** of Crawl4AI.\n**Last Updated** : 2025-01-01\nThat\u2019s it for **Extracting JSON (No LLM)**! You\u2019ve seen how schema-based approaches (either CSS or XPath) can handle everything from simple lists to deeply nested product catalogs\u2014instantly, with minimal overhead. Enjoy building robust scrapers that produce consistent, structured JSON for your data pipelines!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/chunking",
        "https://docs.crawl4ai.com/clustring-strategies",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/llm-strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 30,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:37",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "page-interaction.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/page-interaction",
      "timestamp": "2025-02-06T13:23:46.458402",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/page-interaction/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Page Interaction - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Page Interaction</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#page-interaction\">Page Interaction</a></li>\n        <li><a href=\"#1-javascript-execution\">1. JavaScript Execution</a></li><li><a href=\"#2-wait-conditions\">2. Wait Conditions</a></li><li><a href=\"#3-handling-dynamic-content\">3. Handling Dynamic Content</a></li><li><a href=\"#4-timing-control\">4. Timing Control</a></li><li><a href=\"#5-multi-step-interaction-example\">5. Multi-Step Interaction Example</a></li><li><a href=\"#6-combine-interaction-with-extraction\">6. Combine Interaction with Extraction</a></li><li><a href=\"#7-relevant-crawlerrunconfig-parameters\">7. Relevant CrawlerRunConfig Parameters</a></li><li><a href=\"#8-conclusion\">8. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"page-interaction\">Page Interaction</h1>\n<p>Crawl4AI provides powerful features for interacting with <strong>dynamic</strong> webpages, handling JavaScript execution, waiting for conditions, and managing multi-step flows. By combining <strong>js_code</strong>, <strong>wait_for</strong>, and certain <strong>CrawlerRunConfig</strong> parameters, you can:</p>\n<ol>\n<li>Click \u201cLoad More\u201d buttons  </li>\n<li>Fill forms and submit them  </li>\n<li>Wait for elements or data to appear  </li>\n<li>Reuse sessions across multiple steps  </li>\n</ol>\n<p>Below is a quick overview of how to do it.</p>\n<hr>\n<h2 id=\"1-javascript-execution\">1. JavaScript Execution</h2>\n<h3 id=\"basic-execution\">Basic Execution</h3>\n<p><strong><code>js_code</code></strong> in <strong><code>CrawlerRunConfig</code></strong> accepts either a single JS string or a list of JS snippets.<br>\n<strong>Example</strong>: We\u2019ll scroll to the bottom of the page, then optionally click a \u201cLoad More\u201d button.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Single JS command</span>\n    config = CrawlerRunConfig(\n        js_code=<span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># Example site</span>\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawled length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n    <span class=\"hljs-comment\"># Multiple commands</span>\n    js_commands = [\n        <span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n        <span class=\"hljs-comment\"># 'More' link on Hacker News</span>\n        <span class=\"hljs-string\">\"document.querySelector('a.morelink')?.click();\"</span>,  \n    ]\n    config = CrawlerRunConfig(js_code=js_commands)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># Another pass</span>\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"After scroll+click, length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Relevant <code>CrawlerRunConfig</code> params</strong>:\n- <strong><code>js_code</code></strong>: A string or list of strings with JavaScript to run after the page loads.\n- <strong><code>js_only</code></strong>: If set to <code>True</code> on subsequent calls, indicates we\u2019re continuing an existing session without a new full navigation.<br>\n- <strong><code>session_id</code></strong>: If you want to keep the same page across multiple calls, specify an ID.</p>\n<hr>\n<h2 id=\"2-wait-conditions\">2. Wait Conditions</h2>\n<h3 id=\"21-css-based-waiting\">2.1 CSS-Based Waiting</h3>\n<p>Sometimes, you just want to wait for a specific element to appear. For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Wait for at least 30 items on Hacker News</span>\n        wait_for=<span class=\"hljs-string\">\"css:.athing:nth-child(30)\"</span>  \n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"We have at least 30 items loaded!\"</span>)\n        <span class=\"hljs-comment\"># Rough check</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Total items in HTML:\"</span>, result.cleaned_html.count(<span class=\"hljs-string\">\"athing\"</span>))  \n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key param</strong>:\n- <strong><code>wait_for=\"css:...\"</code></strong>: Tells the crawler to wait until that CSS selector is present.</p>\n<h3 id=\"22-javascript-based-waiting\">2.2 JavaScript-Based Waiting</h3>\n<p>For more complex conditions (e.g., waiting for content length to exceed a threshold), prefix <code>js:</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">wait_condition</span> = <span class=\"hljs-string\">\"\"\"() =&gt; {\n    const items = document.querySelectorAll('.athing');\n    return items.length &gt; 50;  // Wait for at least 51 items\n}\"\"\"</span>\n\n<span class=\"hljs-attr\">config</span> = CrawlerRunConfig(wait_for=f<span class=\"hljs-string\">\"js:{wait_condition}\"</span>)\n</code></pre></div>\n<p><strong>Behind the Scenes</strong>: Crawl4AI keeps polling the JS function until it returns <code>true</code> or a timeout occurs.</p>\n<hr>\n<h2 id=\"3-handling-dynamic-content\">3. Handling Dynamic Content</h2>\n<p>Many modern sites require <strong>multiple steps</strong>: scrolling, clicking \u201cLoad More,\u201d or updating via JavaScript. Below are typical patterns.</p>\n<h3 id=\"31-load-more-example-hacker-news-more-link\">3.1 Load More Example (Hacker News \u201cMore\u201d Link)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Step 1: Load initial Hacker News page</span>\n    config = CrawlerRunConfig(\n        wait_for=<span class=\"hljs-string\">\"css:.athing:nth-child(30)\"</span>  <span class=\"hljs-comment\"># Wait for 30 items</span>\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Initial items loaded.\"</span>)\n\n        <span class=\"hljs-comment\"># Step 2: Let's scroll and click the \"More\" link</span>\n        load_more_js = [\n            <span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n            <span class=\"hljs-comment\"># The \"More\" link at page bottom</span>\n            <span class=\"hljs-string\">\"document.querySelector('a.morelink')?.click();\"</span>  \n        ]\n\n        next_page_conf = CrawlerRunConfig(\n            js_code=load_more_js,\n            wait_for=<span class=\"hljs-string\">\"\"\"js:() =&gt; {\n                return document.querySelectorAll('.athing').length &gt; 30;\n            }\"\"\"</span>,\n            <span class=\"hljs-comment\"># Mark that we do not re-navigate, but run JS in the same session:</span>\n            js_only=<span class=\"hljs-literal\">True</span>,\n            session_id=<span class=\"hljs-string\">\"hn_session\"</span>\n        )\n\n        <span class=\"hljs-comment\"># Re-use the same crawler session</span>\n        result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># same URL but continuing session</span>\n            config=next_page_conf\n        )\n        total_items = result2.cleaned_html.count(<span class=\"hljs-string\">\"athing\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Items after load-more:\"</span>, total_items)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key params</strong>:\n- <strong><code>session_id=\"hn_session\"</code></strong>: Keep the same page across multiple calls to <code>arun()</code>.\n- <strong><code>js_only=True</code></strong>: We\u2019re not performing a full reload, just applying JS in the existing page.\n- <strong><code>wait_for</code></strong> with <code>js:</code>: Wait for item count to grow beyond 30.</p>\n<hr>\n<h3 id=\"32-form-interaction\">3.2 Form Interaction</h3>\n<p>If the site has a search or login form, you can fill fields and submit them with <strong><code>js_code</code></strong>. For instance, if GitHub had a local search form:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">js_form_interaction = <span class=\"hljs-string\">\"\"\"\ndocument.querySelector('#your-search').value = 'TypeScript commits';\ndocument.querySelector('form').submit();\n\"\"\"</span>\n\nconfig = CrawlerRunConfig(\n    js_code=js_form_interaction,\n    wait_for=<span class=\"hljs-string\">\"css:.commit\"</span>\n)\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://github.com/search\"</span>, config=config)\n</code></pre></div>\n<p><strong>In reality</strong>: Replace IDs or classes with the real site\u2019s form selectors.</p>\n<hr>\n<h2 id=\"4-timing-control\">4. Timing Control</h2>\n<p>1.\u2000<strong><code>page_timeout</code></strong> (ms): Overall page load or script execution time limit.<br>\n2.\u2000<strong><code>delay_before_return_html</code></strong> (seconds): Wait an extra moment before capturing the final HTML.<br>\n3.\u2000<strong><code>mean_delay</code></strong> &amp; <strong><code>max_range</code></strong>: If you call <code>arun_many()</code> with multiple URLs, these add a random pause between each request.</p>\n<p><strong>Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">config = CrawlerRunConfig(\n    page_timeout=60000,  <span class=\"hljs-comment\"># 60s limit</span>\n    delay_before_return_html=2.5\n)\n</code></pre></div>\n<hr>\n<h2 id=\"5-multi-step-interaction-example\">5. Multi-Step Interaction Example</h2>\n<p>Below is a simplified script that does multiple \u201cLoad More\u201d clicks on GitHub\u2019s TypeScript commits page. It <strong>re-uses</strong> the same session to accumulate new commits each time. The code includes the relevant <strong><code>CrawlerRunConfig</code></strong> parameters you\u2019d rely on.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">multi_page_commits</span>():\n    browser_cfg = BrowserConfig(\n        headless=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Visible for demonstration</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n    session_id = <span class=\"hljs-string\">\"github_ts_commits\"</span>\n\n    base_wait = <span class=\"hljs-string\">\"\"\"js:() =&gt; {\n        const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n        return commits.length &gt; 0;\n    }\"\"\"</span>\n\n    <span class=\"hljs-comment\"># Step 1: Load initial commits</span>\n    config1 = CrawlerRunConfig(\n        wait_for=base_wait,\n        session_id=session_id,\n        cache_mode=CacheMode.BYPASS,\n        <span class=\"hljs-comment\"># Not using js_only yet since it's our first load</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>,\n            config=config1\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Initial commits loaded. Count:\"</span>, result.cleaned_html.count(<span class=\"hljs-string\">\"commit\"</span>))\n\n        <span class=\"hljs-comment\"># Step 2: For subsequent pages, we run JS to click 'Next Page' if it exists</span>\n        js_next_page = <span class=\"hljs-string\">\"\"\"\n        const selector = 'a[data-testid=\"pagination-next-button\"]';\n        const button = document.querySelector(selector);\n        if (button) button.click();\n        \"\"\"</span>\n\n        <span class=\"hljs-comment\"># Wait until new commits appear</span>\n        wait_for_more = <span class=\"hljs-string\">\"\"\"js:() =&gt; {\n            const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n            if (!window.firstCommit &amp;&amp; commits.length&gt;0) {\n                window.firstCommit = commits[0].textContent;\n                return false;\n            }\n            // If top commit changes, we have new commits\n            const topNow = commits[0]?.textContent.trim();\n            return topNow &amp;&amp; topNow !== window.firstCommit;\n        }\"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">2</span>):  <span class=\"hljs-comment\"># let's do 2 more \"Next\" pages</span>\n            config_next = CrawlerRunConfig(\n                session_id=session_id,\n                js_code=js_next_page,\n                wait_for=wait_for_more,\n                js_only=<span class=\"hljs-literal\">True</span>,       <span class=\"hljs-comment\"># We're continuing from the open tab</span>\n                cache_mode=CacheMode.BYPASS\n            )\n            result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(\n                url=<span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>,\n                config=config_next\n            )\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page+<span class=\"hljs-number\">2</span>}</span> commits count:\"</span>, result2.cleaned_html.count(<span class=\"hljs-string\">\"commit\"</span>))\n\n        <span class=\"hljs-comment\"># Optionally kill session</span>\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">await</span> multi_page_commits()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key Points</strong>:</p>\n<ul>\n<li><strong><code>session_id</code></strong>: Keep the same page open.  </li>\n<li><strong><code>js_code</code></strong> + <strong><code>wait_for</code></strong> + <strong><code>js_only=True</code></strong>: We do partial refreshes, waiting for new commits to appear.  </li>\n<li><strong><code>cache_mode=CacheMode.BYPASS</code></strong> ensures we always see fresh data each step.</li>\n</ul>\n<hr>\n<h2 id=\"6-combine-interaction-with-extraction\">6. Combine Interaction with Extraction</h2>\n<p>Once dynamic content is loaded, you can attach an <strong><code>extraction_strategy</code></strong> (like <code>JsonCssExtractionStrategy</code> or <code>LLMExtractionStrategy</code>). For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">schema</span> <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Commits\"</span>,\n    <span class=\"hljs-string\">\"baseSelector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"li.Box-sc-g0xbh4-0\"</span>,\n    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"h4.markdown-title\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span><span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\nconfig <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    session_id<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"ts_commits_session\"</span>,\n    js_code<span class=\"hljs-punctuation\">=</span>js_next_page,\n    wait_for<span class=\"hljs-punctuation\">=</span>wait_for_more,\n    extraction_strategy<span class=\"hljs-punctuation\">=</span>JsonCssExtractionStrategy<span class=\"hljs-punctuation\">(</span><span class=\"hljs-keyword\">schema</span><span class=\"hljs-punctuation\">)</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>When done, check <code>result.extracted_content</code> for the JSON.</p>\n<hr>\n<h2 id=\"7-relevant-crawlerrunconfig-parameters\">7. Relevant <code>CrawlerRunConfig</code> Parameters</h2>\n<p>Below are the key interaction-related parameters in <code>CrawlerRunConfig</code>. For a full list, see <a href=\"../../api/parameters/\">Configuration Parameters</a>.</p>\n<ul>\n<li><strong><code>js_code</code></strong>: JavaScript to run after initial load.  </li>\n<li><strong><code>js_only</code></strong>: If <code>True</code>, no new page navigation\u2014only JS in the existing session.  </li>\n<li><strong><code>wait_for</code></strong>: CSS (<code>\"css:...\"</code>) or JS (<code>\"js:...\"</code>) expression to wait for.  </li>\n<li><strong><code>session_id</code></strong>: Reuse the same page across calls.  </li>\n<li><strong><code>cache_mode</code></strong>: Whether to read/write from the cache or bypass.  </li>\n<li><strong><code>remove_overlay_elements</code></strong>: Remove certain popups automatically.  </li>\n<li><strong><code>simulate_user</code>, <code>override_navigator</code>, <code>magic</code></strong>: Anti-bot or \u201chuman-like\u201d interactions.</li>\n</ul>\n<hr>\n<h2 id=\"8-conclusion\">8. Conclusion</h2>\n<p>Crawl4AI\u2019s <strong>page interaction</strong> features let you:</p>\n<p>1.\u2000<strong>Execute JavaScript</strong> for scrolling, clicks, or form filling.<br>\n2.\u2000<strong>Wait</strong> for CSS or custom JS conditions before capturing data.<br>\n3.\u2000<strong>Handle</strong> multi-step flows (like \u201cLoad More\u201d) with partial reloads or persistent sessions.<br>\n4. Combine with <strong>structured extraction</strong> for dynamic sites.</p>\n<p>With these tools, you can scrape modern, interactive webpages confidently. For advanced hooking, user simulation, or in-depth config, check the <a href=\"../../api/parameters/\">API reference</a> or related advanced docs. Happy scripting!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Page Interaction\nCrawl4AI provides powerful features for interacting with **dynamic** webpages, handling JavaScript execution, waiting for conditions, and managing multi-step flows. By combining **js_code** , **wait_for** , and certain **CrawlerRunConfig** parameters, you can:\n  1. Click \u201cLoad More\u201d buttons \n  2. Fill forms and submit them \n  3. Wait for elements or data to appear \n  4. Reuse sessions across multiple steps \n\n\nBelow is a quick overview of how to do it.\n## 1. JavaScript Execution\n### Basic Execution\n**`js_code`**in**`CrawlerRunConfig`**accepts either a single JS string or a list of JS snippets.**Example** : We\u2019ll scroll to the bottom of the page, then optionally click a \u201cLoad More\u201d button.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Single JS command\n  config = CrawlerRunConfig(\n    js_code=\"window.scrollTo(0, document.body.scrollHeight);\"\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # Example site\n      config=config\n    )\n    print(\"Crawled length:\", len(result.cleaned_html))\n  # Multiple commands\n  js_commands = [\n    \"window.scrollTo(0, document.body.scrollHeight);\",\n    # 'More' link on Hacker News\n    \"document.querySelector('a.morelink')?.click();\", \n  ]\n  config = CrawlerRunConfig(js_code=js_commands)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # Another pass\n      config=config\n    )\n    print(\"After scroll+click, length:\", len(result.cleaned_html))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Relevant`CrawlerRunConfig` params**: - **`js_code`**: A string or list of strings with JavaScript to run after the page loads. -**`js_only`**: If set to`True` on subsequent calls, indicates we\u2019re continuing an existing session without a new full navigation. - **`session_id`**: If you want to keep the same page across multiple calls, specify an ID.\n## 2. Wait Conditions\n### 2.1 CSS-Based Waiting\nSometimes, you just want to wait for a specific element to appear. For example:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  config = CrawlerRunConfig(\n    # Wait for at least 30 items on Hacker News\n    wait_for=\"css:.athing:nth-child(30)\" \n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\",\n      config=config\n    )\n    print(\"We have at least 30 items loaded!\")\n    # Rough check\n    print(\"Total items in HTML:\", result.cleaned_html.count(\"athing\")) \nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key param** : - **`wait_for=\"css:...\"`**: Tells the crawler to wait until that CSS selector is present.\n### 2.2 JavaScript-Based Waiting\nFor more complex conditions (e.g., waiting for content length to exceed a threshold), prefix `js:`:\n```\nwait_condition = \"\"\"() => {\n  const items = document.querySelectorAll('.athing');\n  return items.length > 50; // Wait for at least 51 items\n}\"\"\"\nconfig = CrawlerRunConfig(wait_for=f\"js:{wait_condition}\")\n\n```\n\n**Behind the Scenes** : Crawl4AI keeps polling the JS function until it returns `true` or a timeout occurs.\n## 3. Handling Dynamic Content\nMany modern sites require **multiple steps** : scrolling, clicking \u201cLoad More,\u201d or updating via JavaScript. Below are typical patterns.\n### 3.1 Load More Example (Hacker News \u201cMore\u201d Link)\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Step 1: Load initial Hacker News page\n  config = CrawlerRunConfig(\n    wait_for=\"css:.athing:nth-child(30)\" # Wait for 30 items\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\",\n      config=config\n    )\n    print(\"Initial items loaded.\")\n    # Step 2: Let's scroll and click the \"More\" link\n    load_more_js = [\n      \"window.scrollTo(0, document.body.scrollHeight);\",\n      # The \"More\" link at page bottom\n      \"document.querySelector('a.morelink')?.click();\" \n    ]\n    next_page_conf = CrawlerRunConfig(\n      js_code=load_more_js,\n      wait_for=\"\"\"js:() => {\n        return document.querySelectorAll('.athing').length > 30;\n      }\"\"\",\n      # Mark that we do not re-navigate, but run JS in the same session:\n      js_only=True,\n      session_id=\"hn_session\"\n    )\n    # Re-use the same crawler session\n    result2 = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # same URL but continuing session\n      config=next_page_conf\n    )\n    total_items = result2.cleaned_html.count(\"athing\")\n    print(\"Items after load-more:\", total_items)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key params** : - **`session_id=\"hn_session\"`**: Keep the same page across multiple calls to`arun()`. - **`js_only=True`**: We\u2019re not performing a full reload, just applying JS in the existing page. -**`wait_for`**with`js:` : Wait for item count to grow beyond 30.\n### 3.2 Form Interaction\nIf the site has a search or login form, you can fill fields and submit them with **`js_code`**. For instance, if GitHub had a local search form:\n```\njs_form_interaction = \"\"\"\ndocument.querySelector('#your-search').value = 'TypeScript commits';\ndocument.querySelector('form').submit();\n\"\"\"\nconfig = CrawlerRunConfig(\n  js_code=js_form_interaction,\n  wait_for=\"css:.commit\"\n)\nresult = await crawler.arun(url=\"https://github.com/search\", config=config)\n\n```\n\n**In reality** : Replace IDs or classes with the real site\u2019s form selectors.\n## 4. Timing Control\n1. **`page_timeout`**(ms): Overall page load or script execution time limit. 2.**`delay_before_return_html`**(seconds): Wait an extra moment before capturing the final HTML. 3.**`mean_delay`** & **`max_range`**: If you call`arun_many()` with multiple URLs, these add a random pause between each request.\n**Example** :\n```\nconfig = CrawlerRunConfig(\n  page_timeout=60000, # 60s limit\n  delay_before_return_html=2.5\n)\n\n```\n\n## 5. Multi-Step Interaction Example\nBelow is a simplified script that does multiple \u201cLoad More\u201d clicks on GitHub\u2019s TypeScript commits page. It **re-uses** the same session to accumulate new commits each time. The code includes the relevant **`CrawlerRunConfig`**parameters you\u2019d rely on.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nasync def multi_page_commits():\n  browser_cfg = BrowserConfig(\n    headless=False, # Visible for demonstration\n    verbose=True\n  )\n  session_id = \"github_ts_commits\"\n  base_wait = \"\"\"js:() => {\n    const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n    return commits.length > 0;\n  }\"\"\"\n  # Step 1: Load initial commits\n  config1 = CrawlerRunConfig(\n    wait_for=base_wait,\n    session_id=session_id,\n    cache_mode=CacheMode.BYPASS,\n    # Not using js_only yet since it's our first load\n  )\n  async with AsyncWebCrawler(config=browser_cfg) as crawler:\n    result = await crawler.arun(\n      url=\"https://github.com/microsoft/TypeScript/commits/main\",\n      config=config1\n    )\n    print(\"Initial commits loaded. Count:\", result.cleaned_html.count(\"commit\"))\n    # Step 2: For subsequent pages, we run JS to click 'Next Page' if it exists\n    js_next_page = \"\"\"\n    const selector = 'a[data-testid=\"pagination-next-button\"]';\n    const button = document.querySelector(selector);\n    if (button) button.click();\n    \"\"\"\n    # Wait until new commits appear\n    wait_for_more = \"\"\"js:() => {\n      const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n      if (!window.firstCommit && commits.length>0) {\n        window.firstCommit = commits[0].textContent;\n        return false;\n      }\n      // If top commit changes, we have new commits\n      const topNow = commits[0]?.textContent.trim();\n      return topNow && topNow !== window.firstCommit;\n    }\"\"\"\n    for page in range(2): # let's do 2 more \"Next\" pages\n      config_next = CrawlerRunConfig(\n        session_id=session_id,\n        js_code=js_next_page,\n        wait_for=wait_for_more,\n        js_only=True,    # We're continuing from the open tab\n        cache_mode=CacheMode.BYPASS\n      )\n      result2 = await crawler.arun(\n        url=\"https://github.com/microsoft/TypeScript/commits/main\",\n        config=config_next\n      )\n      print(f\"Page {page+2} commits count:\", result2.cleaned_html.count(\"commit\"))\n    # Optionally kill session\n    await crawler.crawler_strategy.kill_session(session_id)\nasync def main():\n  await multi_page_commits()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key Points** :\n  * **`session_id`**: Keep the same page open.\n  * **`js_code`**+**`wait_for`**+**`js_only=True`**: We do partial refreshes, waiting for new commits to appear.\n  * **`cache_mode=CacheMode.BYPASS`**ensures we always see fresh data each step.\n\n\n## 6. Combine Interaction with Extraction\nOnce dynamic content is loaded, you can attach an **`extraction_strategy`**(like`JsonCssExtractionStrategy` or `LLMExtractionStrategy`). For example:\n```\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nschema = {\n  \"name\": \"Commits\",\n  \"baseSelector\": \"li.Box-sc-g0xbh4-0\",\n  \"fields\": [\n    {\"name\": \"title\", \"selector\": \"h4.markdown-title\", \"type\": \"text\"}\n  ]\n}\nconfig = CrawlerRunConfig(\n  session_id=\"ts_commits_session\",\n  js_code=js_next_page,\n  wait_for=wait_for_more,\n  extraction_strategy=JsonCssExtractionStrategy(schema)\n)\n\n```\n\nWhen done, check `result.extracted_content` for the JSON.\n## 7. Relevant `CrawlerRunConfig` Parameters\nBelow are the key interaction-related parameters in `CrawlerRunConfig`. For a full list, see [Configuration Parameters](https://docs.crawl4ai.com/core/api/parameters/>).\n  * **`js_code`**: JavaScript to run after initial load.\n  * **`js_only`**: If`True` , no new page navigation\u2014only JS in the existing session. \n  * **`wait_for`**: CSS (`\"css:...\"`) or JS (`\"js:...\"`) expression to wait for. \n  * **`session_id`**: Reuse the same page across calls.\n  * **`cache_mode`**: Whether to read/write from the cache or bypass.\n  * **`remove_overlay_elements`**: Remove certain popups automatically.\n  * **`simulate_user`,`override_navigator` , `magic`**: Anti-bot or \u201chuman-like\u201d interactions.\n\n\n## 8. Conclusion\nCrawl4AI\u2019s **page interaction** features let you:\n1. **Execute JavaScript** for scrolling, clicks, or form filling. 2. **Wait** for CSS or custom JS conditions before capturing data. 3. **Handle** multi-step flows (like \u201cLoad More\u201d) with partial reloads or persistent sessions. 4. Combine with **structured extraction** for dynamic sites.\nWith these tools, you can scrape modern, interactive webpages confidently. For advanced hooking, user simulation, or in-depth config, check the [API reference](https://docs.crawl4ai.com/core/api/parameters/>) or related advanced docs. Happy scripting!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/quickstart",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 24,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:30",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "parameters.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/parameters",
      "timestamp": "2025-02-06T13:23:30.721749",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/parameters/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Browser &amp; Crawler Config - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Browser &amp; Crawler Config</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#1-browserconfig-controlling-the-browser\">1. BrowserConfig \u2013 Controlling the Browser</a></li>\n        <li><a href=\"#11-parameter-highlights\">1.1 Parameter Highlights</a></li><li><a href=\"#2-crawlerrunconfig-controlling-each-crawl\">2. CrawlerRunConfig \u2013 Controlling Each Crawl</a></li>\n        <li><a href=\"#21-parameter-highlights\">2.1 Parameter Highlights</a></li><li><a href=\"#22-helper-methods\">2.2 Helper Methods</a></li><li><a href=\"#23-example-usage\">2.3 Example Usage</a></li><li><a href=\"#3-putting-it-all-together\">3. Putting It All Together</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"1-browserconfig-controlling-the-browser\">1.\u2000<strong>BrowserConfig</strong> \u2013 Controlling the Browser</h1>\n<p><code>BrowserConfig</code> focuses on <strong>how</strong> the browser is launched and behaves. This includes headless mode, proxies, user agents, and other environment tweaks.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig\n\nbrowser_cfg = BrowserConfig(\n    browser_type=<span class=\"hljs-string\">\"chromium\"</span>,\n    headless=<span class=\"hljs-literal\">True</span>,\n    viewport_width=<span class=\"hljs-number\">1280</span>,\n    viewport_height=<span class=\"hljs-number\">720</span>,\n    proxy=<span class=\"hljs-string\">\"http://user:pass@proxy:8080\"</span>,\n    user_agent=<span class=\"hljs-string\">\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/116.0.0.0 Safari/537.36\"</span>,\n)\n</code></pre></div>\n<h2 id=\"11-parameter-highlights\">1.1 Parameter Highlights</h2>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>browser_type</code></strong></td>\n<td><code>\"chromium\"</code>, <code>\"firefox\"</code>, <code>\"webkit\"</code><br><em>(default: <code>\"chromium\"</code>)</em></td>\n<td>Which browser engine to use. <code>\"chromium\"</code> is typical for many sites, <code>\"firefox\"</code> or <code>\"webkit\"</code> for specialized tests.</td>\n</tr>\n<tr>\n<td><strong><code>headless</code></strong></td>\n<td><code>bool</code> (default: <code>True</code>)</td>\n<td>Headless means no visible UI. <code>False</code> is handy for debugging.</td>\n</tr>\n<tr>\n<td><strong><code>viewport_width</code></strong></td>\n<td><code>int</code> (default: <code>1080</code>)</td>\n<td>Initial page width (in px). Useful for testing responsive layouts.</td>\n</tr>\n<tr>\n<td><strong><code>viewport_height</code></strong></td>\n<td><code>int</code> (default: <code>600</code>)</td>\n<td>Initial page height (in px).</td>\n</tr>\n<tr>\n<td><strong><code>proxy</code></strong></td>\n<td><code>str</code> (default: <code>None</code>)</td>\n<td>Single-proxy URL if you want all traffic to go through it, e.g. <code>\"http://user:pass@proxy:8080\"</code>.</td>\n</tr>\n<tr>\n<td><strong><code>proxy_config</code></strong></td>\n<td><code>dict</code> (default: <code>None</code>)</td>\n<td>For advanced or multi-proxy needs, specify details like <code>{\"server\": \"...\", \"username\": \"...\", ...}</code>.</td>\n</tr>\n<tr>\n<td><strong><code>use_persistent_context</code></strong></td>\n<td><code>bool</code> (default: <code>False</code>)</td>\n<td>If <code>True</code>, uses a <strong>persistent</strong> browser context (keep cookies, sessions across runs). Also sets <code>use_managed_browser=True</code>.</td>\n</tr>\n<tr>\n<td><strong><code>user_data_dir</code></strong></td>\n<td><code>str or None</code> (default: <code>None</code>)</td>\n<td>Directory to store user data (profiles, cookies). Must be set if you want permanent sessions.</td>\n</tr>\n<tr>\n<td><strong><code>ignore_https_errors</code></strong></td>\n<td><code>bool</code> (default: <code>True</code>)</td>\n<td>If <code>True</code>, continues despite invalid certificates (common in dev/staging).</td>\n</tr>\n<tr>\n<td><strong><code>java_script_enabled</code></strong></td>\n<td><code>bool</code> (default: <code>True</code>)</td>\n<td>Disable if you want no JS overhead, or if only static content is needed.</td>\n</tr>\n<tr>\n<td><strong><code>cookies</code></strong></td>\n<td><code>list</code> (default: <code>[]</code>)</td>\n<td>Pre-set cookies, each a dict like <code>{\"name\": \"session\", \"value\": \"...\", \"url\": \"...\"}</code>.</td>\n</tr>\n<tr>\n<td><strong><code>headers</code></strong></td>\n<td><code>dict</code> (default: <code>{}</code>)</td>\n<td>Extra HTTP headers for every request, e.g. <code>{\"Accept-Language\": \"en-US\"}</code>.</td>\n</tr>\n<tr>\n<td><strong><code>user_agent</code></strong></td>\n<td><code>str</code> (default: Chrome-based UA)</td>\n<td>Your custom or random user agent. <code>user_agent_mode=\"random\"</code> can shuffle it.</td>\n</tr>\n<tr>\n<td><strong><code>light_mode</code></strong></td>\n<td><code>bool</code> (default: <code>False</code>)</td>\n<td>Disables some background features for performance gains.</td>\n</tr>\n<tr>\n<td><strong><code>text_mode</code></strong></td>\n<td><code>bool</code> (default: <code>False</code>)</td>\n<td>If <code>True</code>, tries to disable images/other heavy content for speed.</td>\n</tr>\n<tr>\n<td><strong><code>use_managed_browser</code></strong></td>\n<td><code>bool</code> (default: <code>False</code>)</td>\n<td>For advanced \u201cmanaged\u201d interactions (debugging, CDP usage). Typically set automatically if persistent context is on.</td>\n</tr>\n<tr>\n<td><strong><code>extra_args</code></strong></td>\n<td><code>list</code> (default: <code>[]</code>)</td>\n<td>Additional flags for the underlying browser process, e.g. <code>[\"--disable-extensions\"]</code>.</td>\n</tr>\n</tbody>\n</table>\n<p><strong>Tips</strong>:\n- Set <code>headless=False</code> to visually <strong>debug</strong> how pages load or how interactions proceed.<br>\n- If you need <strong>authentication</strong> storage or repeated sessions, consider <code>use_persistent_context=True</code> and specify <code>user_data_dir</code>.<br>\n- For large pages, you might need a bigger <code>viewport_width</code> and <code>viewport_height</code> to handle dynamic content.</p>\n<hr>\n<h1 id=\"2-crawlerrunconfig-controlling-each-crawl\">2.\u2000<strong>CrawlerRunConfig</strong> \u2013 Controlling Each Crawl</h1>\n<p>While <code>BrowserConfig</code> sets up the <strong>environment</strong>, <code>CrawlerRunConfig</code> details <strong>how</strong> each <strong>crawl operation</strong> should behave: caching, content filtering, link or domain blocking, timeouts, JavaScript code, etc.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\nrun_cfg = CrawlerRunConfig(\n    wait_for=<span class=\"hljs-string\">\"css:.main-content\"</span>,\n    word_count_threshold=<span class=\"hljs-number\">15</span>,\n    excluded_tags=[<span class=\"hljs-string\">\"nav\"</span>, <span class=\"hljs-string\">\"footer\"</span>],\n    exclude_external_links=<span class=\"hljs-literal\">True</span>,\n    stream=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Enable streaming for arun_many()</span>\n)\n</code></pre></div>\n<h2 id=\"21-parameter-highlights\">2.1 Parameter Highlights</h2>\n<p>We group them by category. </p>\n<h3 id=\"a-content-processing\">A) <strong>Content Processing</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>word_count_threshold</code></strong></td>\n<td><code>int</code> (default: ~200)</td>\n<td>Skips text blocks below X words. Helps ignore trivial sections.</td>\n</tr>\n<tr>\n<td><strong><code>extraction_strategy</code></strong></td>\n<td><code>ExtractionStrategy</code> (default: None)</td>\n<td>If set, extracts structured data (CSS-based, LLM-based, etc.).</td>\n</tr>\n<tr>\n<td><strong><code>markdown_generator</code></strong></td>\n<td><code>MarkdownGenerationStrategy</code> (None)</td>\n<td>If you want specialized markdown output (citations, filtering, chunking, etc.).</td>\n</tr>\n<tr>\n<td><strong><code>content_filter</code></strong></td>\n<td><code>RelevantContentFilter</code> (None)</td>\n<td>Filters out irrelevant text blocks. E.g., <code>PruningContentFilter</code> or <code>BM25ContentFilter</code>.</td>\n</tr>\n<tr>\n<td><strong><code>css_selector</code></strong></td>\n<td><code>str</code> (None)</td>\n<td>Retains only the part of the page matching this selector.</td>\n</tr>\n<tr>\n<td><strong><code>excluded_tags</code></strong></td>\n<td><code>list</code> (None)</td>\n<td>Removes entire tags (e.g. <code>[\"script\", \"style\"]</code>).</td>\n</tr>\n<tr>\n<td><strong><code>excluded_selector</code></strong></td>\n<td><code>str</code> (None)</td>\n<td>Like <code>css_selector</code> but to exclude. E.g. <code>\"#ads, .tracker\"</code>.</td>\n</tr>\n<tr>\n<td><strong><code>only_text</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, tries to extract text-only content.</td>\n</tr>\n<tr>\n<td><strong><code>prettiify</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, beautifies final HTML (slower, purely cosmetic).</td>\n</tr>\n<tr>\n<td><strong><code>keep_data_attributes</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, preserve <code>data-*</code> attributes in cleaned HTML.</td>\n</tr>\n<tr>\n<td><strong><code>remove_forms</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, remove all <code>&lt;form&gt;</code> elements.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3 id=\"b-caching-session\">B) <strong>Caching &amp; Session</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>cache_mode</code></strong></td>\n<td><code>CacheMode or None</code></td>\n<td>Controls how caching is handled (<code>ENABLED</code>, <code>BYPASS</code>, <code>DISABLED</code>, etc.). If <code>None</code>, typically defaults to <code>ENABLED</code>.</td>\n</tr>\n<tr>\n<td><strong><code>session_id</code></strong></td>\n<td><code>str or None</code></td>\n<td>Assign a unique ID to reuse a single browser session across multiple <code>arun()</code> calls.</td>\n</tr>\n<tr>\n<td><strong><code>bypass_cache</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, acts like <code>CacheMode.BYPASS</code>.</td>\n</tr>\n<tr>\n<td><strong><code>disable_cache</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, acts like <code>CacheMode.DISABLED</code>.</td>\n</tr>\n<tr>\n<td><strong><code>no_cache_read</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, acts like <code>CacheMode.WRITE_ONLY</code> (writes cache but never reads).</td>\n</tr>\n<tr>\n<td><strong><code>no_cache_write</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, acts like <code>CacheMode.READ_ONLY</code> (reads cache but never writes).</td>\n</tr>\n</tbody>\n</table>\n<p>Use these for controlling whether you read or write from a local content cache. Handy for large batch crawls or repeated site visits.</p>\n<hr>\n<h3 id=\"c-page-navigation-timing\">C) <strong>Page Navigation &amp; Timing</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>wait_until</code></strong></td>\n<td><code>str</code> (domcontentloaded)</td>\n<td>Condition for navigation to \u201ccomplete\u201d. Often <code>\"networkidle\"</code> or <code>\"domcontentloaded\"</code>.</td>\n</tr>\n<tr>\n<td><strong><code>page_timeout</code></strong></td>\n<td><code>int</code> (60000 ms)</td>\n<td>Timeout for page navigation or JS steps. Increase for slow sites.</td>\n</tr>\n<tr>\n<td><strong><code>wait_for</code></strong></td>\n<td><code>str or None</code></td>\n<td>Wait for a CSS (<code>\"css:selector\"</code>) or JS (<code>\"js:() =&gt; bool\"</code>) condition before content extraction.</td>\n</tr>\n<tr>\n<td><strong><code>wait_for_images</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Wait for images to load before finishing. Slows down if you only want text.</td>\n</tr>\n<tr>\n<td><strong><code>delay_before_return_html</code></strong></td>\n<td><code>float</code> (0.1)</td>\n<td>Additional pause (seconds) before final HTML is captured. Good for last-second updates.</td>\n</tr>\n<tr>\n<td><strong><code>check_robots_txt</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Whether to check and respect robots.txt rules before crawling. If True, caches robots.txt for efficiency.</td>\n</tr>\n<tr>\n<td><strong><code>mean_delay</code></strong> and <strong><code>max_range</code></strong></td>\n<td><code>float</code> (0.1, 0.3)</td>\n<td>If you call <code>arun_many()</code>, these define random delay intervals between crawls, helping avoid detection or rate limits.</td>\n</tr>\n<tr>\n<td><strong><code>semaphore_count</code></strong></td>\n<td><code>int</code> (5)</td>\n<td>Max concurrency for <code>arun_many()</code>. Increase if you have resources for parallel crawls.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3 id=\"d-page-interaction\">D) <strong>Page Interaction</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>js_code</code></strong></td>\n<td><code>str or list[str]</code> (None)</td>\n<td>JavaScript to run after load. E.g. <code>\"document.querySelector('button')?.click();\"</code>.</td>\n</tr>\n<tr>\n<td><strong><code>js_only</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, indicates we\u2019re reusing an existing session and only applying JS. No full reload.</td>\n</tr>\n<tr>\n<td><strong><code>ignore_body_visibility</code></strong></td>\n<td><code>bool</code> (True)</td>\n<td>Skip checking if <code>&lt;body&gt;</code> is visible. Usually best to keep <code>True</code>.</td>\n</tr>\n<tr>\n<td><strong><code>scan_full_page</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, auto-scroll the page to load dynamic content (infinite scroll).</td>\n</tr>\n<tr>\n<td><strong><code>scroll_delay</code></strong></td>\n<td><code>float</code> (0.2)</td>\n<td>Delay between scroll steps if <code>scan_full_page=True</code>.</td>\n</tr>\n<tr>\n<td><strong><code>process_iframes</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Inlines iframe content for single-page extraction.</td>\n</tr>\n<tr>\n<td><strong><code>remove_overlay_elements</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Removes potential modals/popups blocking the main content.</td>\n</tr>\n<tr>\n<td><strong><code>simulate_user</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Simulate user interactions (mouse movements) to avoid bot detection.</td>\n</tr>\n<tr>\n<td><strong><code>override_navigator</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Override <code>navigator</code> properties in JS for stealth.</td>\n</tr>\n<tr>\n<td><strong><code>magic</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Automatic handling of popups/consent banners. Experimental.</td>\n</tr>\n<tr>\n<td><strong><code>adjust_viewport_to_content</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Resizes viewport to match page content height.</td>\n</tr>\n</tbody>\n</table>\n<p>If your page is a single-page app with repeated JS updates, set <code>js_only=True</code> in subsequent calls, plus a <code>session_id</code> for reusing the same tab.</p>\n<hr>\n<h3 id=\"e-media-handling\">E) <strong>Media Handling</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>screenshot</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Capture a screenshot (base64) in <code>result.screenshot</code>.</td>\n</tr>\n<tr>\n<td><strong><code>screenshot_wait_for</code></strong></td>\n<td><code>float or None</code></td>\n<td>Extra wait time before the screenshot.</td>\n</tr>\n<tr>\n<td><strong><code>screenshot_height_threshold</code></strong></td>\n<td><code>int</code> (~20000)</td>\n<td>If the page is taller than this, alternate screenshot strategies are used.</td>\n</tr>\n<tr>\n<td><strong><code>pdf</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>If <code>True</code>, returns a PDF in <code>result.pdf</code>.</td>\n</tr>\n<tr>\n<td><strong><code>image_description_min_word_threshold</code></strong></td>\n<td><code>int</code> (~50)</td>\n<td>Minimum words for an image\u2019s alt text or description to be considered valid.</td>\n</tr>\n<tr>\n<td><strong><code>image_score_threshold</code></strong></td>\n<td><code>int</code> (~3)</td>\n<td>Filter out low-scoring images. The crawler scores images by relevance (size, context, etc.).</td>\n</tr>\n<tr>\n<td><strong><code>exclude_external_images</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Exclude images from other domains.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3 id=\"f-linkdomain-handling\">F) <strong>Link/Domain Handling</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>exclude_social_media_domains</code></strong></td>\n<td><code>list</code> (e.g. Facebook/Twitter)</td>\n<td>A default list can be extended. Any link to these domains is removed from final output.</td>\n</tr>\n<tr>\n<td><strong><code>exclude_external_links</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Removes all links pointing outside the current domain.</td>\n</tr>\n<tr>\n<td><strong><code>exclude_social_media_links</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Strips links specifically to social sites (like Facebook or Twitter).</td>\n</tr>\n<tr>\n<td><strong><code>exclude_domains</code></strong></td>\n<td><code>list</code> ([])</td>\n<td>Provide a custom list of domains to exclude (like <code>[\"ads.com\", \"trackers.io\"]</code>).</td>\n</tr>\n</tbody>\n</table>\n<p>Use these for link-level content filtering (often to keep crawls \u201cinternal\u201d or to remove spammy domains).</p>\n<hr>\n<h3 id=\"g-rate-limiting-resource-management\">G) <strong>Rate Limiting &amp; Resource Management</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>enable_rate_limiting</code></strong></td>\n<td><code>bool</code> (default: <code>False</code>)</td>\n<td>Enable intelligent rate limiting for multiple URLs</td>\n</tr>\n<tr>\n<td><strong><code>rate_limit_config</code></strong></td>\n<td><code>RateLimitConfig</code> (default: <code>None</code>)</td>\n<td>Configuration for rate limiting behavior</td>\n</tr>\n</tbody>\n</table>\n<p>The <code>RateLimitConfig</code> class has these fields:</p>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Field</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>base_delay</code></strong></td>\n<td><code>Tuple[float, float]</code> (1.0, 3.0)</td>\n<td>Random delay range between requests to the same domain</td>\n</tr>\n<tr>\n<td><strong><code>max_delay</code></strong></td>\n<td><code>float</code> (60.0)</td>\n<td>Maximum delay after rate limit detection</td>\n</tr>\n<tr>\n<td><strong><code>max_retries</code></strong></td>\n<td><code>int</code> (3)</td>\n<td>Number of retries before giving up on rate-limited requests</td>\n</tr>\n<tr>\n<td><strong><code>rate_limit_codes</code></strong></td>\n<td><code>List[int]</code> ([429, 503])</td>\n<td>HTTP status codes that trigger rate limiting behavior</td>\n</tr>\n</tbody>\n</table>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>memory_threshold_percent</code></strong></td>\n<td><code>float</code> (70.0)</td>\n<td>Maximum memory usage before pausing new crawls</td>\n</tr>\n<tr>\n<td><strong><code>check_interval</code></strong></td>\n<td><code>float</code> (1.0)</td>\n<td>How often to check system resources (in seconds)</td>\n</tr>\n<tr>\n<td><strong><code>max_session_permit</code></strong></td>\n<td><code>int</code> (20)</td>\n<td>Maximum number of concurrent crawl sessions</td>\n</tr>\n<tr>\n<td><strong><code>display_mode</code></strong></td>\n<td><code>str</code> (<code>None</code>, \"DETAILED\", \"AGGREGATED\")</td>\n<td>How to display progress information</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h3 id=\"h-debug-logging\">H) <strong>Debug &amp; Logging</strong></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th><strong>Parameter</strong></th>\n<th><strong>Type / Default</strong></th>\n<th><strong>What It Does</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong><code>verbose</code></strong></td>\n<td><code>bool</code> (True)</td>\n<td>Prints logs detailing each step of crawling, interactions, or errors.</td>\n</tr>\n<tr>\n<td><strong><code>log_console</code></strong></td>\n<td><code>bool</code> (False)</td>\n<td>Logs the page\u2019s JavaScript console output if you want deeper JS debugging.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"22-helper-methods\">2.2 Helper Methods</h2>\n<p>Both <code>BrowserConfig</code> and <code>CrawlerRunConfig</code> provide a <code>clone()</code> method to create modified copies:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\"><span class=\"hljs-comment\"># Create a base configuration</span>\nbase_config = CrawlerRunConfig(\n    cache_mode=CacheMode.ENABLED,\n    word_count_threshold=200\n)\n\n<span class=\"hljs-comment\"># Create variations using clone()</span>\nstream_config = base_config.clone(stream=True)\nno_cache_config = base_config.clone(\n    cache_mode=CacheMode.BYPASS,\n    stream=True\n)\n</code></pre></div>\n<p>The <code>clone()</code> method is particularly useful when you need slightly different configurations for different use cases, without modifying the original config.</p>\n<h2 id=\"23-example-usage\">2.3 Example Usage</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, RateLimitConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Configure the browser</span>\n    browser_cfg = BrowserConfig(\n        headless=<span class=\"hljs-literal\">False</span>,\n        viewport_width=<span class=\"hljs-number\">1280</span>,\n        viewport_height=<span class=\"hljs-number\">720</span>,\n        proxy=<span class=\"hljs-string\">\"http://user:pass@myproxy:8080\"</span>,\n        text_mode=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-comment\"># Configure the run</span>\n    run_cfg = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        session_id=<span class=\"hljs-string\">\"my_session\"</span>,\n        css_selector=<span class=\"hljs-string\">\"main.article\"</span>,\n        excluded_tags=[<span class=\"hljs-string\">\"script\"</span>, <span class=\"hljs-string\">\"style\"</span>],\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        wait_for=<span class=\"hljs-string\">\"css:.article-loaded\"</span>,\n        screenshot=<span class=\"hljs-literal\">True</span>,\n        enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n        rate_limit_config=RateLimitConfig(\n            base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),\n            max_delay=<span class=\"hljs-number\">60.0</span>,\n            max_retries=<span class=\"hljs-number\">3</span>,\n            rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]\n        ),\n        memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,\n        check_interval=<span class=\"hljs-number\">1.0</span>,\n        max_session_permit=<span class=\"hljs-number\">20</span>,\n        display_mode=<span class=\"hljs-string\">\"DETAILED\"</span>,\n        stream=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com/news\"</span>,\n            config=run_cfg\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Final cleaned_html length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n            <span class=\"hljs-keyword\">if</span> result.screenshot:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Screenshot captured (base64, length):\"</span>, <span class=\"hljs-built_in\">len</span>(result.screenshot))\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n\n<span class=\"hljs-comment\">## 2.4 Compliance &amp; Ethics</span>\n\n| **Parameter**          | **<span class=\"hljs-type\">Type</span> / Default**      | **What It Does**                                                                                                    |\n|-----------------------|-------------------------|----------------------------------------------------------------------------------------------------------------------|\n| **`check_robots_txt`**| `<span class=\"hljs-built_in\">bool</span>` (<span class=\"hljs-literal\">False</span>)          | When <span class=\"hljs-literal\">True</span>, checks <span class=\"hljs-keyword\">and</span> respects robots.txt rules before crawling. Uses efficient caching <span class=\"hljs-keyword\">with</span> SQLite backend.          |\n| **`user_agent`**      | `<span class=\"hljs-built_in\">str</span>` (<span class=\"hljs-literal\">None</span>)            | User agent string to identify your crawler. Used <span class=\"hljs-keyword\">for</span> robots.txt checking when enabled.                                |\n\n```python\nrun_config = CrawlerRunConfig(\n    check_robots_txt=<span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Enable robots.txt compliance</span>\n    user_agent=<span class=\"hljs-string\">\"MyBot/1.0\"</span>  <span class=\"hljs-comment\"># Identify your crawler</span>\n)\n</code></pre></div>\n<h2 id=\"3-putting-it-all-together\">3. Putting It All Together</h2>\n<ul>\n<li><strong>Use</strong> <code>BrowserConfig</code> for <strong>global</strong> browser settings: engine, headless, proxy, user agent.  </li>\n<li><strong>Use</strong> <code>CrawlerRunConfig</code> for each crawl\u2019s <strong>context</strong>: how to filter content, handle caching, wait for dynamic elements, or run JS.  </li>\n<li><strong>Pass</strong> both configs to <code>AsyncWebCrawler</code> (the <code>BrowserConfig</code>) and then to <code>arun()</code> (the <code>CrawlerRunConfig</code>).  </li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-sql\"># <span class=\"hljs-keyword\">Create</span> a modified <span class=\"hljs-keyword\">copy</span> <span class=\"hljs-keyword\">with</span> the clone() <span class=\"hljs-keyword\">method</span>\nstream_cfg <span class=\"hljs-operator\">=</span> run_cfg.clone(\n    stream<span class=\"hljs-operator\">=</span><span class=\"hljs-literal\">True</span>,\n    cache_mode<span class=\"hljs-operator\">=</span>CacheMode.BYPASS\n)\n</code></pre></div>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# 1. **BrowserConfig** \u2013 Controlling the Browser\n`BrowserConfig` focuses on **how** the browser is launched and behaves. This includes headless mode, proxies, user agents, and other environment tweaks.\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig\nbrowser_cfg = BrowserConfig(\n  browser_type=\"chromium\",\n  headless=True,\n  viewport_width=1280,\n  viewport_height=720,\n  proxy=\"http://user:pass@proxy:8080\",\n  user_agent=\"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/116.0.0.0 Safari/537.36\",\n)\n\n```\n\n## 1.1 Parameter Highlights\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`browser_type`**| `\"chromium\"` , `\"firefox\"`, `\"webkit\"`_(default:`\"chromium\"`)_ | Which browser engine to use. `\"chromium\"` is typical for many sites, `\"firefox\"` or `\"webkit\"` for specialized tests.  \n**`headless`**| `bool` (default: `True`) | Headless means no visible UI. `False` is handy for debugging.  \n**`viewport_width`**| `int` (default: `1080`) | Initial page width (in px). Useful for testing responsive layouts.  \n**`viewport_height`**| `int` (default: `600`) | Initial page height (in px).  \n**`proxy`**| `str` (default: `None`) | Single-proxy URL if you want all traffic to go through it, e.g. `\"http://user:pass@proxy:8080\"`.  \n**`proxy_config`**| `dict` (default: `None`) | For advanced or multi-proxy needs, specify details like `{\"server\": \"...\", \"username\": \"...\", ...}`.  \n**`use_persistent_context`**| `bool` (default: `False`) | If `True`, uses a **persistent** browser context (keep cookies, sessions across runs). Also sets `use_managed_browser=True`.  \n**`user_data_dir`**| `str or None` (default: `None`) | Directory to store user data (profiles, cookies). Must be set if you want permanent sessions.  \n**`ignore_https_errors`**| `bool` (default: `True`) | If `True`, continues despite invalid certificates (common in dev/staging).  \n**`java_script_enabled`**| `bool` (default: `True`) | Disable if you want no JS overhead, or if only static content is needed.  \n**`cookies`**| `list` (default: `[]`) | Pre-set cookies, each a dict like `{\"name\": \"session\", \"value\": \"...\", \"url\": \"...\"}`.  \n**`headers`**| `dict` (default: `{}`) | Extra HTTP headers for every request, e.g. `{\"Accept-Language\": \"en-US\"}`.  \n**`user_agent`**| `str` (default: Chrome-based UA) | Your custom or random user agent. `user_agent_mode=\"random\"` can shuffle it.  \n**`light_mode`**| `bool` (default: `False`) | Disables some background features for performance gains.  \n**`text_mode`**| `bool` (default: `False`) | If `True`, tries to disable images/other heavy content for speed.  \n**`use_managed_browser`**| `bool` (default: `False`) | For advanced \u201cmanaged\u201d interactions (debugging, CDP usage). Typically set automatically if persistent context is on.  \n**`extra_args`**| `list` (default: `[]`) | Additional flags for the underlying browser process, e.g. `[\"--disable-extensions\"]`.  \n**Tips** : - Set `headless=False` to visually **debug** how pages load or how interactions proceed. - If you need **authentication** storage or repeated sessions, consider `use_persistent_context=True` and specify `user_data_dir`. - For large pages, you might need a bigger `viewport_width` and `viewport_height` to handle dynamic content.\n# 2. **CrawlerRunConfig** \u2013 Controlling Each Crawl\nWhile `BrowserConfig` sets up the **environment** , `CrawlerRunConfig` details **how** each **crawl operation** should behave: caching, content filtering, link or domain blocking, timeouts, JavaScript code, etc.\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nrun_cfg = CrawlerRunConfig(\n  wait_for=\"css:.main-content\",\n  word_count_threshold=15,\n  excluded_tags=[\"nav\", \"footer\"],\n  exclude_external_links=True,\n  stream=True, # Enable streaming for arun_many()\n)\n\n```\n\n## 2.1 Parameter Highlights\nWe group them by category. \n### A) **Content Processing**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`word_count_threshold`**| `int` (default: ~200) | Skips text blocks below X words. Helps ignore trivial sections.  \n**`extraction_strategy`**| `ExtractionStrategy` (default: None) | If set, extracts structured data (CSS-based, LLM-based, etc.).  \n**`markdown_generator`**| `MarkdownGenerationStrategy` (None) | If you want specialized markdown output (citations, filtering, chunking, etc.).  \n**`content_filter`**| `RelevantContentFilter` (None) | Filters out irrelevant text blocks. E.g., `PruningContentFilter` or `BM25ContentFilter`.  \n**`css_selector`**| `str` (None) | Retains only the part of the page matching this selector.  \n**`excluded_tags`**| `list` (None) | Removes entire tags (e.g. `[\"script\", \"style\"]`).  \n**`excluded_selector`**| `str` (None) | Like `css_selector` but to exclude. E.g. `\"#ads, .tracker\"`.  \n**`only_text`**| `bool` (False) | If `True`, tries to extract text-only content.  \n**`prettiify`**| `bool` (False) | If `True`, beautifies final HTML (slower, purely cosmetic).  \n**`keep_data_attributes`**| `bool` (False) | If `True`, preserve `data-*` attributes in cleaned HTML.  \n**`remove_forms`**| `bool` (False) | If `True`, remove all `<form>` elements.  \n### B) **Caching & Session**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`cache_mode`**| `CacheMode or None` | Controls how caching is handled (`ENABLED`, `BYPASS`, `DISABLED`, etc.). If `None`, typically defaults to `ENABLED`.  \n**`session_id`**| `str or None` | Assign a unique ID to reuse a single browser session across multiple `arun()` calls.  \n**`bypass_cache`**| `bool` (False) | If `True`, acts like `CacheMode.BYPASS`.  \n**`disable_cache`**| `bool` (False) | If `True`, acts like `CacheMode.DISABLED`.  \n**`no_cache_read`**| `bool` (False) | If `True`, acts like `CacheMode.WRITE_ONLY` (writes cache but never reads).  \n**`no_cache_write`**| `bool` (False) | If `True`, acts like `CacheMode.READ_ONLY` (reads cache but never writes).  \nUse these for controlling whether you read or write from a local content cache. Handy for large batch crawls or repeated site visits.\n### C) **Page Navigation & Timing**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`wait_until`**| `str` (domcontentloaded) | Condition for navigation to \u201ccomplete\u201d. Often `\"networkidle\"` or `\"domcontentloaded\"`.  \n**`page_timeout`**| `int` (60000 ms) | Timeout for page navigation or JS steps. Increase for slow sites.  \n**`wait_for`**| `str or None` | Wait for a CSS (`\"css:selector\"`) or JS (`\"js:() => bool\"`) condition before content extraction.  \n**`wait_for_images`**| `bool` (False) | Wait for images to load before finishing. Slows down if you only want text.  \n**`delay_before_return_html`**| `float` (0.1) | Additional pause (seconds) before final HTML is captured. Good for last-second updates.  \n**`check_robots_txt`**| `bool` (False) | Whether to check and respect robots.txt rules before crawling. If True, caches robots.txt for efficiency.  \n**`mean_delay`**and**`max_range`**| `float` (0.1, 0.3) | If you call `arun_many()`, these define random delay intervals between crawls, helping avoid detection or rate limits.  \n**`semaphore_count`**| `int` (5) | Max concurrency for `arun_many()`. Increase if you have resources for parallel crawls.  \n### D) **Page Interaction**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`js_code`**| `str or list[str]` (None) | JavaScript to run after load. E.g. `\"document.querySelector('button')?.click();\"`.  \n**`js_only`**| `bool` (False) | If `True`, indicates we\u2019re reusing an existing session and only applying JS. No full reload.  \n**`ignore_body_visibility`**| `bool` (True) | Skip checking if `<body>` is visible. Usually best to keep `True`.  \n**`scan_full_page`**| `bool` (False) | If `True`, auto-scroll the page to load dynamic content (infinite scroll).  \n**`scroll_delay`**| `float` (0.2) | Delay between scroll steps if `scan_full_page=True`.  \n**`process_iframes`**| `bool` (False) | Inlines iframe content for single-page extraction.  \n**`remove_overlay_elements`**| `bool` (False) | Removes potential modals/popups blocking the main content.  \n**`simulate_user`**| `bool` (False) | Simulate user interactions (mouse movements) to avoid bot detection.  \n**`override_navigator`**| `bool` (False) | Override `navigator` properties in JS for stealth.  \n**`magic`**| `bool` (False) | Automatic handling of popups/consent banners. Experimental.  \n**`adjust_viewport_to_content`**| `bool` (False) | Resizes viewport to match page content height.  \nIf your page is a single-page app with repeated JS updates, set `js_only=True` in subsequent calls, plus a `session_id` for reusing the same tab.\n### E) **Media Handling**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`screenshot`**| `bool` (False) | Capture a screenshot (base64) in `result.screenshot`.  \n**`screenshot_wait_for`**| `float or None` | Extra wait time before the screenshot.  \n**`screenshot_height_threshold`**| `int` (~20000) | If the page is taller than this, alternate screenshot strategies are used.  \n**`pdf`**| `bool` (False) | If `True`, returns a PDF in `result.pdf`.  \n**`image_description_min_word_threshold`**| `int` (~50) | Minimum words for an image\u2019s alt text or description to be considered valid.  \n**`image_score_threshold`**| `int` (~3) | Filter out low-scoring images. The crawler scores images by relevance (size, context, etc.).  \n**`exclude_external_images`**| `bool` (False) | Exclude images from other domains.  \n### F) **Link/Domain Handling**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`exclude_social_media_domains`**| `list` (e.g. Facebook/Twitter) | A default list can be extended. Any link to these domains is removed from final output.  \n**`exclude_external_links`**| `bool` (False) | Removes all links pointing outside the current domain.  \n**`exclude_social_media_links`**| `bool` (False) | Strips links specifically to social sites (like Facebook or Twitter).  \n**`exclude_domains`**| `list` ([]) | Provide a custom list of domains to exclude (like `[\"ads.com\", \"trackers.io\"]`).  \nUse these for link-level content filtering (often to keep crawls \u201cinternal\u201d or to remove spammy domains).\n### G) **Rate Limiting & Resource Management**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`enable_rate_limiting`**| `bool` (default: `False`) | Enable intelligent rate limiting for multiple URLs  \n**`rate_limit_config`**| `RateLimitConfig` (default: `None`) | Configuration for rate limiting behavior  \nThe `RateLimitConfig` class has these fields:\n**Field** | **Type / Default** | **What It Does**  \n---|---|---  \n**`base_delay`**| `Tuple[float, float]` (1.0, 3.0) | Random delay range between requests to the same domain  \n**`max_delay`**| `float` (60.0) | Maximum delay after rate limit detection  \n**`max_retries`**| `int` (3) | Number of retries before giving up on rate-limited requests  \n**`rate_limit_codes`**| `List[int]` ([429, 503]) | HTTP status codes that trigger rate limiting behavior  \n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`memory_threshold_percent`**| `float` (70.0) | Maximum memory usage before pausing new crawls  \n**`check_interval`**| `float` (1.0) | How often to check system resources (in seconds)  \n**`max_session_permit`**| `int` (20) | Maximum number of concurrent crawl sessions  \n**`display_mode`**| `str` (`None`, \"DETAILED\", \"AGGREGATED\") | How to display progress information  \n### H) **Debug & Logging**\n**Parameter** | **Type / Default** | **What It Does**  \n---|---|---  \n**`verbose`**| `bool` (True) | Prints logs detailing each step of crawling, interactions, or errors.  \n**`log_console`**| `bool` (False) | Logs the page\u2019s JavaScript console output if you want deeper JS debugging.  \n## 2.2 Helper Methods\nBoth `BrowserConfig` and `CrawlerRunConfig` provide a `clone()` method to create modified copies:\n```\n# Create a base configuration\nbase_config = CrawlerRunConfig(\n  cache_mode=CacheMode.ENABLED,\n  word_count_threshold=200\n)\n# Create variations using clone()\nstream_config = base_config.clone(stream=True)\nno_cache_config = base_config.clone(\n  cache_mode=CacheMode.BYPASS,\n  stream=True\n)\n\n```\n\nThe `clone()` method is particularly useful when you need slightly different configurations for different use cases, without modifying the original config.\n## 2.3 Example Usage\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode, RateLimitConfig\nasync def main():\n  # Configure the browser\n  browser_cfg = BrowserConfig(\n    headless=False,\n    viewport_width=1280,\n    viewport_height=720,\n    proxy=\"http://user:pass@myproxy:8080\",\n    text_mode=True\n  )\n  # Configure the run\n  run_cfg = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    session_id=\"my_session\",\n    css_selector=\"main.article\",\n    excluded_tags=[\"script\", \"style\"],\n    exclude_external_links=True,\n    wait_for=\"css:.article-loaded\",\n    screenshot=True,\n    enable_rate_limiting=True,\n    rate_limit_config=RateLimitConfig(\n      base_delay=(1.0, 3.0),\n      max_delay=60.0,\n      max_retries=3,\n      rate_limit_codes=[429, 503]\n    ),\n    memory_threshold_percent=70.0,\n    check_interval=1.0,\n    max_session_permit=20,\n    display_mode=\"DETAILED\",\n    stream=True\n  )\n  async with AsyncWebCrawler(config=browser_cfg) as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com/news\",\n      config=run_cfg\n    )\n    if result.success:\n      print(\"Final cleaned_html length:\", len(result.cleaned_html))\n      if result.screenshot:\n        print(\"Screenshot captured (base64, length):\", len(result.screenshot))\n    else:\n      print(\"Crawl failed:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n## 2.4 Compliance & Ethics\n| **Parameter**     | **Type / Default**   | **What It Does**                                                  |\n|-----------------------|-------------------------|----------------------------------------------------------------------------------------------------------------------|\n| **`check_robots_txt`**| `bool` (False)     | When True, checks and respects robots.txt rules before crawling. Uses efficient caching with SQLite backend.     |\n| **`user_agent`**   | `str` (None)      | User agent string to identify your crawler. Used for robots.txt checking when enabled.                |\n```python\nrun_config = CrawlerRunConfig(\n  check_robots_txt=True, # Enable robots.txt compliance\n  user_agent=\"MyBot/1.0\" # Identify your crawler\n)\n\n```\n\n## 3. Putting It All Together\n  * **Use** `BrowserConfig` for **global** browser settings: engine, headless, proxy, user agent. \n  * **Use** `CrawlerRunConfig` for each crawl\u2019s **context** : how to filter content, handle caching, wait for dynamic elements, or run JS. \n  * **Pass** both configs to `AsyncWebCrawler` (the `BrowserConfig`) and then to `arun()` (the `CrawlerRunConfig`). \n\n\n```\n# Create a modified copy with the clone() method\nstream_cfg = run_cfg.clone(\n  stream=True,\n  cache_mode=CacheMode.BYPASS\n)\n\n```\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun",
        "https://docs.crawl4ai.com/arun_many",
        "https://docs.crawl4ai.com/async-webcrawler",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/strategies"
      ],
      "depth": 1,
      "stats": {
        "processed": 11,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:14",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "proxy-security.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/proxy-security",
      "timestamp": "2025-02-06T13:23:22.299620",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/proxy-security/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Proxy &amp; Security - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Proxy &amp; Security</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#proxy\">Proxy</a></li>\n        <li><a href=\"#basic-proxy-setup\">Basic Proxy Setup</a></li><li><a href=\"#authenticated-proxy\">Authenticated Proxy</a></li><li><a href=\"#rotating-proxies\">Rotating Proxies</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"proxy\">Proxy</h1>\n<h2 id=\"basic-proxy-setup\">Basic Proxy Setup</h2>\n<p>Simple proxy configuration with <code>BrowserConfig</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs import BrowserConfig\n\n<span class=\"hljs-meta\"># Using proxy URL</span>\nbrowser_config = BrowserConfig(proxy=<span class=\"hljs-string\">\"http://proxy.example.com:8080\"</span>)\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>(<span class=\"hljs-params\">config=browser_config</span>) <span class=\"hljs-keyword\">as</span> crawler:\n    result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>)\n\n<span class=\"hljs-meta\"># Using SOCKS proxy</span>\nbrowser_config = BrowserConfig(proxy=<span class=\"hljs-string\">\"socks5://proxy.example.com:1080\"</span>)\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>(<span class=\"hljs-params\">config=browser_config</span>) <span class=\"hljs-keyword\">as</span> crawler:\n    result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>)\n</code></pre></div>\n<h2 id=\"authenticated-proxy\">Authenticated Proxy</h2>\n<p>Use an authenticated proxy with <code>BrowserConfig</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs import BrowserConfig\n\nproxy_config = {\n    <span class=\"hljs-string\">\"server\"</span>: <span class=\"hljs-string\">\"http://proxy.example.com:8080\"</span>,\n    <span class=\"hljs-string\">\"username\"</span>: <span class=\"hljs-string\">\"user\"</span>,\n    <span class=\"hljs-string\">\"password\"</span>: <span class=\"hljs-string\">\"pass\"</span>\n}\n\nbrowser_config = BrowserConfig(proxy_config=proxy_config)\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>(<span class=\"hljs-params\">config=browser_config</span>) <span class=\"hljs-keyword\">as</span> crawler:\n    result</span> = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>)\n</code></pre></div>\n<p>Here's the corrected documentation:</p>\n<h2 id=\"rotating-proxies\">Rotating Proxies</h2>\n<p>Example using a proxy rotation service dynamically:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">get_next_proxy</span>():\n    <span class=\"hljs-comment\"># Your proxy rotation logic here</span>\n    <span class=\"hljs-keyword\">return</span> {<span class=\"hljs-string\">\"server\"</span>: <span class=\"hljs-string\">\"http://next.proxy.com:8080\"</span>}\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    browser_config = BrowserConfig()\n    run_config = CrawlerRunConfig()\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># For each URL, create a new run config with different proxy</span>\n        <span class=\"hljs-keyword\">for</span> url <span class=\"hljs-keyword\">in</span> urls:\n            proxy = <span class=\"hljs-keyword\">await</span> get_next_proxy()\n            <span class=\"hljs-comment\"># Clone the config and update proxy - this creates a new browser context</span>\n            current_config = run_config.clone(proxy_config=proxy)\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=url, config=current_config)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    <span class=\"hljs-keyword\">import</span> asyncio\n    asyncio.run(main())\n</code></pre></div>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Proxy\n## Basic Proxy Setup\nSimple proxy configuration with `BrowserConfig`:\n```\nfrom crawl4ai.async_configs import BrowserConfig\n# Using proxy URL\nbrowser_config = BrowserConfig(proxy=\"http://proxy.example.com:8080\")\nasync with AsyncWebCrawler(config=browser_config) as crawler:\n  result = await crawler.arun(url=\"https://example.com\")\n# Using SOCKS proxy\nbrowser_config = BrowserConfig(proxy=\"socks5://proxy.example.com:1080\")\nasync with AsyncWebCrawler(config=browser_config) as crawler:\n  result = await crawler.arun(url=\"https://example.com\")\n\n```\n\n## Authenticated Proxy\nUse an authenticated proxy with `BrowserConfig`:\n```\nfrom crawl4ai.async_configs import BrowserConfig\nproxy_config = {\n  \"server\": \"http://proxy.example.com:8080\",\n  \"username\": \"user\",\n  \"password\": \"pass\"\n}\nbrowser_config = BrowserConfig(proxy_config=proxy_config)\nasync with AsyncWebCrawler(config=browser_config) as crawler:\n  result = await crawler.arun(url=\"https://example.com\")\n\n```\n\nHere's the corrected documentation:\n## Rotating Proxies\nExample using a proxy rotation service dynamically:\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def get_next_proxy():\n  # Your proxy rotation logic here\n  return {\"server\": \"http://next.proxy.com:8080\"}\nasync def main():\n  browser_config = BrowserConfig()\n  run_config = CrawlerRunConfig()\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    # For each URL, create a new run config with different proxy\n    for url in urls:\n      proxy = await get_next_proxy()\n      # Clone the config and update proxy - this creates a new browser context\n      current_config = run_config.clone(proxy_config=proxy)\n      result = await crawler.arun(url=url, config=current_config)\nif __name__ == \"__main__\":\n  import asyncio\n  asyncio.run(main())\n\n```\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/session-management",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 4,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:06",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "quickstart.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/quickstart",
      "timestamp": "2025-02-06T13:23:47.786574",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/quickstart/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Quick Start - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"./\" class=\"menu-item active\" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Quick Start</span>\n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#getting-started-with-crawl4ai\">Getting Started with Crawl4AI</a></li>\n        <li><a href=\"#1-introduction\">1. Introduction</a></li><li><a href=\"#2-your-first-crawl\">2. Your First Crawl</a></li><li><a href=\"#3-basic-configuration-light-introduction\">3. Basic Configuration (Light Introduction)</a></li><li><a href=\"#4-generating-markdown-output\">4. Generating Markdown Output</a></li><li><a href=\"#5-simple-data-extraction-css-based\">5. Simple Data Extraction (CSS-based)</a></li><li><a href=\"#6-simple-data-extraction-llm-based\">6. Simple Data Extraction (LLM-based)</a></li><li><a href=\"#7-multi-url-concurrency-preview\">7. Multi-URL Concurrency (Preview)</a></li><li><a href=\"#8-dynamic-content-example\">8. Dynamic Content Example</a></li><li><a href=\"#9-next-steps\">9. Next Steps</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"getting-started-with-crawl4ai\">Getting Started with Crawl4AI</h1>\n<p>Welcome to <strong>Crawl4AI</strong>, an open-source LLM-friendly Web Crawler &amp; Scraper. In this tutorial, you\u2019ll:</p>\n<ol>\n<li>Run your <strong>first crawl</strong> using minimal configuration.  </li>\n<li>Generate <strong>Markdown</strong> output (and learn how it\u2019s influenced by content filters).  </li>\n<li>Experiment with a simple <strong>CSS-based extraction</strong> strategy.  </li>\n<li>See a glimpse of <strong>LLM-based extraction</strong> (including open-source and closed-source model options).  </li>\n<li>Crawl a <strong>dynamic</strong> page that loads content via JavaScript.</li>\n</ol>\n<hr>\n<h2 id=\"1-introduction\">1. Introduction</h2>\n<p>Crawl4AI provides:</p>\n<ul>\n<li>An asynchronous crawler, <strong><code>AsyncWebCrawler</code></strong>.  </li>\n<li>Configurable browser and run settings via <strong><code>BrowserConfig</code></strong> and <strong><code>CrawlerRunConfig</code></strong>.  </li>\n<li>Automatic HTML-to-Markdown conversion via <strong><code>DefaultMarkdownGenerator</code></strong> (supports optional filters).  </li>\n<li>Multiple extraction strategies (LLM-based or \u201ctraditional\u201d CSS/XPath-based).</li>\n</ul>\n<p>By the end of this guide, you\u2019ll have performed a basic crawl, generated Markdown, tried out two extraction strategies, and crawled a dynamic page that uses \u201cLoad More\u201d buttons or JavaScript updates.</p>\n<hr>\n<h2 id=\"2-your-first-crawl\">2. Your First Crawl</h2>\n<p>Here\u2019s a minimal Python script that creates an <strong><code>AsyncWebCrawler</code></strong>, fetches a webpage, and prints the first 300 characters of its Markdown output:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>)\n        <span class=\"hljs-built_in\">print</span>(result.markdown[:<span class=\"hljs-number\">300</span>])  <span class=\"hljs-comment\"># Print first 300 chars</span>\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>What\u2019s happening?</strong>\n- <strong><code>AsyncWebCrawler</code></strong> launches a headless browser (Chromium by default).\n- It fetches <code>https://example.com</code>.\n- Crawl4AI automatically converts the HTML into Markdown.</p>\n<p>You now have a simple, working crawl!</p>\n<hr>\n<h2 id=\"3-basic-configuration-light-introduction\">3. Basic Configuration (Light Introduction)</h2>\n<p>Crawl4AI\u2019s crawler can be heavily customized using two main classes:</p>\n<p>1.\u2000<strong><code>BrowserConfig</code></strong>: Controls browser behavior (headless or full UI, user agent, JavaScript toggles, etc.).<br>\n2.\u2000<strong><code>CrawlerRunConfig</code></strong>: Controls how each crawl runs (caching, extraction, timeouts, hooking, etc.).</p>\n<p>Below is an example with minimal usage:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    browser_conf = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)  <span class=\"hljs-comment\"># or False to see the browser</span>\n    run_conf = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_conf) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n            config=run_conf\n        )\n        <span class=\"hljs-built_in\">print</span>(result.markdown)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<blockquote>\n<p>IMPORTANT: By default cache mode is set to <code>CacheMode.ENABLED</code>. So to have fresh content, you need to set it to <code>CacheMode.BYPASS</code></p>\n</blockquote>\n<p>We\u2019ll explore more advanced config in later tutorials (like enabling proxies, PDF output, multi-tab sessions, etc.). For now, just note how you pass these objects to manage crawling.</p>\n<hr>\n<h2 id=\"4-generating-markdown-output\">4. Generating Markdown Output</h2>\n<p>By default, Crawl4AI automatically generates Markdown from each crawled page. However, the exact output depends on whether you specify a <strong>markdown generator</strong> or <strong>content filter</strong>.</p>\n<ul>\n<li><strong><code>result.markdown</code></strong>:<br>\n  The direct HTML-to-Markdown conversion.  </li>\n<li><strong><code>result.markdown.fit_markdown</code></strong>:<br>\n  The same content after applying any configured <strong>content filter</strong> (e.g., <code>PruningContentFilter</code>).</li>\n</ul>\n<h3 id=\"example-using-a-filter-with-defaultmarkdowngenerator\">Example: Using a Filter with <code>DefaultMarkdownGenerator</code></h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.content_filter_strategy <span class=\"hljs-keyword\">import</span> PruningContentFilter\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\nmd_generator = DefaultMarkdownGenerator(\n    content_filter=PruningContentFilter(threshold=<span class=\"hljs-number\">0.4</span>, threshold_type=<span class=\"hljs-string\">\"fixed\"</span>)\n)\n\nconfig = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    markdown_generator=md_generator\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>, config=config)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Raw Markdown length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.markdown.raw_markdown))\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fit Markdown length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.markdown.fit_markdown))\n</code></pre></div>\n<p><strong>Note</strong>: If you do <strong>not</strong> specify a content filter or markdown generator, you\u2019ll typically see only the raw Markdown. <code>PruningContentFilter</code> may adds around <code>50ms</code> in processing time. We\u2019ll dive deeper into these strategies in a dedicated <strong>Markdown Generation</strong> tutorial.</p>\n<hr>\n<h2 id=\"5-simple-data-extraction-css-based\">5. Simple Data Extraction (CSS-based)</h2>\n<p>Crawl4AI can also extract structured data (JSON) using CSS or XPath selectors. Below is a minimal CSS-based example:</p>\n<blockquote>\n<p><strong>New!</strong> Crawl4AI now provides a powerful utility to automatically generate extraction schemas using LLM. This is a one-time cost that gives you a reusable schema for fast, LLM-free extractions:</p>\n</blockquote>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n\n<span class=\"hljs-comment\"># Generate a schema (one-time cost)</span>\nhtml = <span class=\"hljs-string\">\"&lt;div class='product'&gt;&lt;h2&gt;Gaming Laptop&lt;/h2&gt;&lt;span class='price'&gt;$999.99&lt;/span&gt;&lt;/div&gt;\"</span>\n\n<span class=\"hljs-comment\"># Using OpenAI (requires API token)</span>\nschema = JsonCssExtractionStrategy.generate_schema(\n    html,\n    llm_provider=<span class=\"hljs-string\">\"openai/gpt-4o\"</span>,  <span class=\"hljs-comment\"># Default provider</span>\n    api_token=<span class=\"hljs-string\">\"your-openai-token\"</span>  <span class=\"hljs-comment\"># Required for OpenAI</span>\n)\n\n<span class=\"hljs-comment\"># Or using Ollama (open source, no token needed)</span>\nschema = JsonCssExtractionStrategy.generate_schema(\n    html,\n    llm_provider=<span class=\"hljs-string\">\"ollama/llama3.3\"</span>,  <span class=\"hljs-comment\"># Open source alternative</span>\n    api_token=None  <span class=\"hljs-comment\"># Not needed for Ollama</span>\n)\n\n<span class=\"hljs-comment\"># Use the schema for fast, repeated extractions</span>\nstrategy = JsonCssExtractionStrategy(schema)\n</code></pre></div>\n<p>For a complete guide on schema generation and advanced usage, see <a href=\"../../extraction/no-llm-strategies/\">No-LLM Extraction Strategies</a>.</p>\n<p>Here's a basic extraction example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Example Items\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.item\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n\n    raw_html = <span class=\"hljs-string\">\"&lt;div class='item'&gt;&lt;h2&gt;Item 1&lt;/h2&gt;&lt;a href='https://example.com/item1'&gt;Link 1&lt;/a&gt;&lt;/div&gt;\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"raw://\"</span> + raw_html,\n            config=CrawlerRunConfig(\n                cache_mode=CacheMode.BYPASS,\n                extraction_strategy=JsonCssExtractionStrategy(schema)\n            )\n        )\n        <span class=\"hljs-comment\"># The JSON output is stored in 'extracted_content'</span>\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(data)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Why is this helpful?</strong>\n- Great for repetitive page structures (e.g., item listings, articles).\n- No AI usage or costs.\n- The crawler returns a JSON string you can parse or store.</p>\n<blockquote>\n<p>Tips: You can pass raw HTML to the crawler instead of a URL. To do so, prefix the HTML with <code>raw://</code>.</p>\n</blockquote>\n<hr>\n<h2 id=\"6-simple-data-extraction-llm-based\">6. Simple Data Extraction (LLM-based)</h2>\n<p>For more complex or irregular pages, a language model can parse text intelligently into a structure you define. Crawl4AI supports <strong>open-source</strong> or <strong>closed-source</strong> providers:</p>\n<ul>\n<li><strong>Open-Source Models</strong> (e.g., <code>ollama/llama3.3</code>, <code>no_token</code>)  </li>\n<li><strong>OpenAI Models</strong> (e.g., <code>openai/gpt-4</code>, requires <code>api_token</code>)  </li>\n<li>Or any provider supported by the underlying library</li>\n</ul>\n<p>Below is an example using <strong>open-source</strong> style (no token) and closed-source:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> pydantic <span class=\"hljs-keyword\">import</span> BaseModel, Field\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> LLMExtractionStrategy\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">OpenAIModelFee</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    model_name: <span class=\"hljs-built_in\">str</span> = Field(..., description=<span class=\"hljs-string\">\"Name of the OpenAI model.\"</span>)\n    input_fee: <span class=\"hljs-built_in\">str</span> = Field(..., description=<span class=\"hljs-string\">\"Fee for input token for the OpenAI model.\"</span>)\n    output_fee: <span class=\"hljs-built_in\">str</span> = Field(\n        ..., description=<span class=\"hljs-string\">\"Fee for output token for the OpenAI model.\"</span>\n    )\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_structured_data_using_llm</span>(<span class=\"hljs-params\">\n    provider: <span class=\"hljs-built_in\">str</span>, api_token: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-literal\">None</span>, extra_headers: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n</span>):\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"\\n--- Extracting Structured Data with <span class=\"hljs-subst\">{provider}</span> ---\"</span>)\n\n    <span class=\"hljs-keyword\">if</span> api_token <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">and</span> provider != <span class=\"hljs-string\">\"ollama\"</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"API token is required for <span class=\"hljs-subst\">{provider}</span>. Skipping this example.\"</span>)\n        <span class=\"hljs-keyword\">return</span>\n\n    browser_config = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>)\n\n    extra_args = {<span class=\"hljs-string\">\"temperature\"</span>: <span class=\"hljs-number\">0</span>, <span class=\"hljs-string\">\"top_p\"</span>: <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-string\">\"max_tokens\"</span>: <span class=\"hljs-number\">2000</span>}\n    <span class=\"hljs-keyword\">if</span> extra_headers:\n        extra_args[<span class=\"hljs-string\">\"extra_headers\"</span>] = extra_headers\n\n    crawler_config = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        word_count_threshold=<span class=\"hljs-number\">1</span>,\n        page_timeout=<span class=\"hljs-number\">80000</span>,\n        extraction_strategy=LLMExtractionStrategy(\n            provider=provider,\n            api_token=api_token,\n            schema=OpenAIModelFee.model_json_schema(),\n            extraction_type=<span class=\"hljs-string\">\"schema\"</span>,\n            instruction=<span class=\"hljs-string\">\"\"\"From the crawled content, extract all mentioned model names along with their fees for input and output tokens. \n            Do not miss any models in the entire content.\"\"\"</span>,\n            extra_args=extra_args,\n        ),\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://openai.com/api/pricing/\"</span>, config=crawler_config\n        )\n        <span class=\"hljs-built_in\">print</span>(result.extracted_content)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    <span class=\"hljs-comment\"># Use ollama with llama3.3</span>\n    <span class=\"hljs-comment\"># asyncio.run(</span>\n    <span class=\"hljs-comment\">#     extract_structured_data_using_llm(</span>\n    <span class=\"hljs-comment\">#         provider=\"ollama/llama3.3\", api_token=\"no-token\"</span>\n    <span class=\"hljs-comment\">#     )</span>\n    <span class=\"hljs-comment\"># )</span>\n\n    asyncio.run(\n        extract_structured_data_using_llm(\n            provider=<span class=\"hljs-string\">\"openai/gpt-4o\"</span>, api_token=os.getenv(<span class=\"hljs-string\">\"OPENAI_API_KEY\"</span>)\n        )\n    )\n</code></pre></div>\n<p><strong>What\u2019s happening?</strong>\n- We define a Pydantic schema (<code>PricingInfo</code>) describing the fields we want.\n- The LLM extraction strategy uses that schema and your instructions to transform raw text into structured JSON.\n- Depending on the <strong>provider</strong> and <strong>api_token</strong>, you can use local models or a remote API.</p>\n<hr>\n<h2 id=\"7-multi-url-concurrency-preview\">7. Multi-URL Concurrency (Preview)</h2>\n<p>If you need to crawl multiple URLs in <strong>parallel</strong>, you can use <code>arun_many()</code>. By default, Crawl4AI employs a <strong>MemoryAdaptiveDispatcher</strong>, automatically adjusting concurrency based on system resources. Here\u2019s a quick glimpse:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">quick_parallel_example</span>():\n    urls = [\n        <span class=\"hljs-string\">\"https://example.com/page1\"</span>,\n        <span class=\"hljs-string\">\"https://example.com/page2\"</span>,\n        <span class=\"hljs-string\">\"https://example.com/page3\"</span>\n    ]\n\n    run_conf = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        stream=<span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Enable streaming mode</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Stream results as they complete</span>\n        <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">await</span> crawler.arun_many(urls, config=run_conf):\n            <span class=\"hljs-keyword\">if</span> result.success:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[OK] <span class=\"hljs-subst\">{result.url}</span>, length: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.markdown_v2.raw_markdown)}</span>\"</span>)\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[ERROR] <span class=\"hljs-subst\">{result.url}</span> =&gt; <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\n        <span class=\"hljs-comment\"># Or get all results at once (default behavior)</span>\n        run_conf = run_conf.clone(stream=<span class=\"hljs-literal\">False</span>)\n        results = <span class=\"hljs-keyword\">await</span> crawler.arun_many(urls, config=run_conf)\n        <span class=\"hljs-keyword\">for</span> res <span class=\"hljs-keyword\">in</span> results:\n            <span class=\"hljs-keyword\">if</span> res.success:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[OK] <span class=\"hljs-subst\">{res.url}</span>, length: <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(res.markdown_v2.raw_markdown)}</span>\"</span>)\n            <span class=\"hljs-keyword\">else</span>:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[ERROR] <span class=\"hljs-subst\">{res.url}</span> =&gt; <span class=\"hljs-subst\">{res.error_message}</span>\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(quick_parallel_example())\n</code></pre></div>\n<p>The example above shows two ways to handle multiple URLs:\n1. <strong>Streaming mode</strong> (<code>stream=True</code>): Process results as they become available using <code>async for</code>\n2. <strong>Batch mode</strong> (<code>stream=False</code>): Wait for all results to complete</p>\n<p>For more advanced concurrency (e.g., a <strong>semaphore-based</strong> approach, <strong>adaptive memory usage throttling</strong>, or customized rate limiting), see <a href=\"../../advanced/multi-url-crawling/\">Advanced Multi-URL Crawling</a>.</p>\n<hr>\n<h2 id=\"8-dynamic-content-example\">8. Dynamic Content Example</h2>\n<p>Some sites require multiple \u201cpage clicks\u201d or dynamic JavaScript updates. Below is an example showing how to <strong>click</strong> a \u201cNext Page\u201d button and wait for new commits to load on GitHub, using <strong><code>BrowserConfig</code></strong> and <strong><code>CrawlerRunConfig</code></strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">extract_structured_data_using_css_extractor</span>():\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n--- Using JsonCssExtractionStrategy for Fast Structured Output ---\"</span>)\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"KidoCode Courses\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"section.charge-methodology .w-tab-content &gt; div\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"section_title\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h3.heading-50\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>,\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"section_description\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".charge-content\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>,\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"course_name\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".text-block-93\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>,\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"course_description\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".course-content-text\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>,\n            },\n            {\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"course_icon\"</span>,\n                <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".image-92\"</span>,\n                <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>,\n                <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"src\"</span>,\n            },\n        ],\n    }\n\n    browser_config = BrowserConfig(headless=<span class=\"hljs-literal\">True</span>, java_script_enabled=<span class=\"hljs-literal\">True</span>)\n\n    js_click_tabs = <span class=\"hljs-string\">\"\"\"\n    (async () =&gt; {\n        const tabs = document.querySelectorAll(\"section.charge-methodology .tabs-menu-3 &gt; div\");\n        for(let tab of tabs) {\n            tab.scrollIntoView();\n            tab.click();\n            await new Promise(r =&gt; setTimeout(r, 500));\n        }\n    })();\n    \"\"\"</span>\n\n    crawler_config = CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        extraction_strategy=JsonCssExtractionStrategy(schema),\n        js_code=[js_click_tabs],\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://www.kidocode.com/degrees/technology\"</span>, config=crawler_config\n        )\n\n        companies = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Successfully extracted <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(companies)}</span> companies\"</span>)\n        <span class=\"hljs-built_in\">print</span>(json.dumps(companies[<span class=\"hljs-number\">0</span>], indent=<span class=\"hljs-number\">2</span>))\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">await</span> extract_structured_data_using_css_extractor()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key Points</strong>:</p>\n<ul>\n<li><strong><code>BrowserConfig(headless=False)</code></strong>: We want to watch it click \u201cNext Page.\u201d  </li>\n<li><strong><code>CrawlerRunConfig(...)</code></strong>: We specify the extraction strategy, pass <code>session_id</code> to reuse the same page.  </li>\n<li><strong><code>js_code</code></strong> and <strong><code>wait_for</code></strong> are used for subsequent pages (<code>page &gt; 0</code>) to click the \u201cNext\u201d button and wait for new commits to load.  </li>\n<li><strong><code>js_only=True</code></strong> indicates we\u2019re not re-navigating but continuing the existing session.  </li>\n<li>Finally, we call <code>kill_session()</code> to clean up the page and browser session.</li>\n</ul>\n<hr>\n<h2 id=\"9-next-steps\">9. Next Steps</h2>\n<p>Congratulations! You have:</p>\n<ol>\n<li>Performed a basic crawl and printed Markdown.  </li>\n<li>Used <strong>content filters</strong> with a markdown generator.  </li>\n<li>Extracted JSON via <strong>CSS</strong> or <strong>LLM</strong> strategies.  </li>\n<li>Handled <strong>dynamic</strong> pages with JavaScript triggers.</li>\n</ol>\n<p>If you\u2019re ready for more, check out:</p>\n<ul>\n<li><strong>Installation</strong>: A deeper dive into advanced installs, Docker usage (experimental), or optional dependencies.  </li>\n<li><strong>Hooks &amp; Auth</strong>: Learn how to run custom JavaScript or handle logins with cookies, local storage, etc.  </li>\n<li><strong>Deployment</strong>: Explore ephemeral testing in Docker or plan for the upcoming stable Docker release.  </li>\n<li><strong>Browser Management</strong>: Delve into user simulation, stealth modes, and concurrency best practices.  </li>\n</ul>\n<p>Crawl4AI is a powerful, flexible tool. Enjoy building out your scrapers, data pipelines, or AI-driven extraction flows. Happy crawling!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Getting Started with Crawl4AI\nWelcome to **Crawl4AI** , an open-source LLM-friendly Web Crawler & Scraper. In this tutorial, you\u2019ll:\n  1. Run your **first crawl** using minimal configuration. \n  2. Generate **Markdown** output (and learn how it\u2019s influenced by content filters). \n  3. Experiment with a simple **CSS-based extraction** strategy. \n  4. See a glimpse of **LLM-based extraction** (including open-source and closed-source model options). \n  5. Crawl a **dynamic** page that loads content via JavaScript.\n\n\n## 1. Introduction\nCrawl4AI provides:\n  * An asynchronous crawler, **`AsyncWebCrawler`**.\n  * Configurable browser and run settings via **`BrowserConfig`**and**`CrawlerRunConfig`**.\n  * Automatic HTML-to-Markdown conversion via **`DefaultMarkdownGenerator`**(supports optional filters).\n  * Multiple extraction strategies (LLM-based or \u201ctraditional\u201d CSS/XPath-based).\n\n\nBy the end of this guide, you\u2019ll have performed a basic crawl, generated Markdown, tried out two extraction strategies, and crawled a dynamic page that uses \u201cLoad More\u201d buttons or JavaScript updates.\n## 2. Your First Crawl\nHere\u2019s a minimal Python script that creates an **`AsyncWebCrawler`**, fetches a webpage, and prints the first 300 characters of its Markdown output:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nasync def main():\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\")\n    print(result.markdown[:300]) # Print first 300 chars\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**What\u2019s happening?** - **`AsyncWebCrawler`**launches a headless browser (Chromium by default). - It fetches`https://example.com`. - Crawl4AI automatically converts the HTML into Markdown.\nYou now have a simple, working crawl!\n## 3. Basic Configuration (Light Introduction)\nCrawl4AI\u2019s crawler can be heavily customized using two main classes:\n1. **`BrowserConfig`**: Controls browser behavior (headless or full UI, user agent, JavaScript toggles, etc.). 2.**`CrawlerRunConfig`**: Controls how each crawl runs (caching, extraction, timeouts, hooking, etc.).\nBelow is an example with minimal usage:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nasync def main():\n  browser_conf = BrowserConfig(headless=True) # or False to see the browser\n  run_conf = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS\n  )\n  async with AsyncWebCrawler(config=browser_conf) as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com\",\n      config=run_conf\n    )\n    print(result.markdown)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n> IMPORTANT: By default cache mode is set to `CacheMode.ENABLED`. So to have fresh content, you need to set it to `CacheMode.BYPASS`\nWe\u2019ll explore more advanced config in later tutorials (like enabling proxies, PDF output, multi-tab sessions, etc.). For now, just note how you pass these objects to manage crawling.\n## 4. Generating Markdown Output\nBy default, Crawl4AI automatically generates Markdown from each crawled page. However, the exact output depends on whether you specify a **markdown generator** or **content filter**.\n  * **`result.markdown`**: The direct HTML-to-Markdown conversion.\n  * **`result.markdown.fit_markdown`**: The same content after applying any configured**content filter** (e.g., `PruningContentFilter`).\n\n\n### Example: Using a Filter with `DefaultMarkdownGenerator`\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.content_filter_strategy import PruningContentFilter\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nmd_generator = DefaultMarkdownGenerator(\n  content_filter=PruningContentFilter(threshold=0.4, threshold_type=\"fixed\")\n)\nconfig = CrawlerRunConfig(\n  cache_mode=CacheMode.BYPASS,\n  markdown_generator=md_generator\n)\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(\"https://news.ycombinator.com\", config=config)\n  print(\"Raw Markdown length:\", len(result.markdown.raw_markdown))\n  print(\"Fit Markdown length:\", len(result.markdown.fit_markdown))\n\n```\n\n**Note** : If you do **not** specify a content filter or markdown generator, you\u2019ll typically see only the raw Markdown. `PruningContentFilter` may adds around `50ms` in processing time. We\u2019ll dive deeper into these strategies in a dedicated **Markdown Generation** tutorial.\n## 5. Simple Data Extraction (CSS-based)\nCrawl4AI can also extract structured data (JSON) using CSS or XPath selectors. Below is a minimal CSS-based example:\n> **New!** Crawl4AI now provides a powerful utility to automatically generate extraction schemas using LLM. This is a one-time cost that gives you a reusable schema for fast, LLM-free extractions:\n```\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n# Generate a schema (one-time cost)\nhtml = \"<div class='product'><h2>Gaming Laptop</h2><span class='price'>$999.99</span></div>\"\n# Using OpenAI (requires API token)\nschema = JsonCssExtractionStrategy.generate_schema(\n  html,\n  llm_provider=\"openai/gpt-4o\", # Default provider\n  api_token=\"your-openai-token\" # Required for OpenAI\n)\n# Or using Ollama (open source, no token needed)\nschema = JsonCssExtractionStrategy.generate_schema(\n  html,\n  llm_provider=\"ollama/llama3.3\", # Open source alternative\n  api_token=None # Not needed for Ollama\n)\n# Use the schema for fast, repeated extractions\nstrategy = JsonCssExtractionStrategy(schema)\n\n```\n\nFor a complete guide on schema generation and advanced usage, see [No-LLM Extraction Strategies](https://docs.crawl4ai.com/core/extraction/no-llm-strategies/>).\nHere's a basic extraction example:\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  schema = {\n    \"name\": \"Example Items\",\n    \"baseSelector\": \"div.item\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  raw_html = \"<div class='item'><h2>Item 1</h2><a href='https://example.com/item1'>Link 1</a></div>\"\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"raw://\" + raw_html,\n      config=CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        extraction_strategy=JsonCssExtractionStrategy(schema)\n      )\n    )\n    # The JSON output is stored in 'extracted_content'\n    data = json.loads(result.extracted_content)\n    print(data)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Why is this helpful?** - Great for repetitive page structures (e.g., item listings, articles). - No AI usage or costs. - The crawler returns a JSON string you can parse or store.\n> Tips: You can pass raw HTML to the crawler instead of a URL. To do so, prefix the HTML with `raw://`.\n## 6. Simple Data Extraction (LLM-based)\nFor more complex or irregular pages, a language model can parse text intelligently into a structure you define. Crawl4AI supports **open-source** or **closed-source** providers:\n  * **Open-Source Models** (e.g., `ollama/llama3.3`, `no_token`) \n  * **OpenAI Models** (e.g., `openai/gpt-4`, requires `api_token`) \n  * Or any provider supported by the underlying library\n\n\nBelow is an example using **open-source** style (no token) and closed-source:\n```\nimport os\nimport json\nimport asyncio\nfrom pydantic import BaseModel, Field\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\nclass OpenAIModelFee(BaseModel):\n  model_name: str = Field(..., description=\"Name of the OpenAI model.\")\n  input_fee: str = Field(..., description=\"Fee for input token for the OpenAI model.\")\n  output_fee: str = Field(\n    ..., description=\"Fee for output token for the OpenAI model.\"\n  )\nasync def extract_structured_data_using_llm(\n  provider: str, api_token: str = None, extra_headers: Dict[str, str] = None\n):\n  print(f\"\\n--- Extracting Structured Data with {provider} ---\")\n  if api_token is None and provider != \"ollama\":\n    print(f\"API token is required for {provider}. Skipping this example.\")\n    return\n  browser_config = BrowserConfig(headless=True)\n  extra_args = {\"temperature\": 0, \"top_p\": 0.9, \"max_tokens\": 2000}\n  if extra_headers:\n    extra_args[\"extra_headers\"] = extra_headers\n  crawler_config = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    word_count_threshold=1,\n    page_timeout=80000,\n    extraction_strategy=LLMExtractionStrategy(\n      provider=provider,\n      api_token=api_token,\n      schema=OpenAIModelFee.model_json_schema(),\n      extraction_type=\"schema\",\n      instruction=\"\"\"From the crawled content, extract all mentioned model names along with their fees for input and output tokens. \n      Do not miss any models in the entire content.\"\"\",\n      extra_args=extra_args,\n    ),\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    result = await crawler.arun(\n      url=\"https://openai.com/api/pricing/\", config=crawler_config\n    )\n    print(result.extracted_content)\nif __name__ == \"__main__\":\n  # Use ollama with llama3.3\n  # asyncio.run(\n  #   extract_structured_data_using_llm(\n  #     provider=\"ollama/llama3.3\", api_token=\"no-token\"\n  #   )\n  # )\n  asyncio.run(\n    extract_structured_data_using_llm(\n      provider=\"openai/gpt-4o\", api_token=os.getenv(\"OPENAI_API_KEY\")\n    )\n  )\n\n```\n\n**What\u2019s happening?** - We define a Pydantic schema (`PricingInfo`) describing the fields we want. - The LLM extraction strategy uses that schema and your instructions to transform raw text into structured JSON. - Depending on the **provider** and **api_token** , you can use local models or a remote API.\n## 7. Multi-URL Concurrency (Preview)\nIf you need to crawl multiple URLs in **parallel** , you can use `arun_many()`. By default, Crawl4AI employs a **MemoryAdaptiveDispatcher** , automatically adjusting concurrency based on system resources. Here\u2019s a quick glimpse:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nasync def quick_parallel_example():\n  urls = [\n    \"https://example.com/page1\",\n    \"https://example.com/page2\",\n    \"https://example.com/page3\"\n  ]\n  run_conf = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    stream=True # Enable streaming mode\n  )\n  async with AsyncWebCrawler() as crawler:\n    # Stream results as they complete\n    async for result in await crawler.arun_many(urls, config=run_conf):\n      if result.success:\n        print(f\"[OK] {result.url}, length: {len(result.markdown_v2.raw_markdown)}\")\n      else:\n        print(f\"[ERROR] {result.url} => {result.error_message}\")\n    # Or get all results at once (default behavior)\n    run_conf = run_conf.clone(stream=False)\n    results = await crawler.arun_many(urls, config=run_conf)\n    for res in results:\n      if res.success:\n        print(f\"[OK] {res.url}, length: {len(res.markdown_v2.raw_markdown)}\")\n      else:\n        print(f\"[ERROR] {res.url} => {res.error_message}\")\nif __name__ == \"__main__\":\n  asyncio.run(quick_parallel_example())\n\n```\n\nThe example above shows two ways to handle multiple URLs: 1. **Streaming mode** (`stream=True`): Process results as they become available using `async for` 2. **Batch mode** (`stream=False`): Wait for all results to complete\nFor more advanced concurrency (e.g., a **semaphore-based** approach, **adaptive memory usage throttling** , or customized rate limiting), see [Advanced Multi-URL Crawling](https://docs.crawl4ai.com/core/advanced/multi-url-crawling/>).\n## 8. Dynamic Content Example\nSome sites require multiple \u201cpage clicks\u201d or dynamic JavaScript updates. Below is an example showing how to **click** a \u201cNext Page\u201d button and wait for new commits to load on GitHub, using **`BrowserConfig`**and**`CrawlerRunConfig`**:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def extract_structured_data_using_css_extractor():\n  print(\"\\n--- Using JsonCssExtractionStrategy for Fast Structured Output ---\")\n  schema = {\n    \"name\": \"KidoCode Courses\",\n    \"baseSelector\": \"section.charge-methodology .w-tab-content > div\",\n    \"fields\": [\n      {\n        \"name\": \"section_title\",\n        \"selector\": \"h3.heading-50\",\n        \"type\": \"text\",\n      },\n      {\n        \"name\": \"section_description\",\n        \"selector\": \".charge-content\",\n        \"type\": \"text\",\n      },\n      {\n        \"name\": \"course_name\",\n        \"selector\": \".text-block-93\",\n        \"type\": \"text\",\n      },\n      {\n        \"name\": \"course_description\",\n        \"selector\": \".course-content-text\",\n        \"type\": \"text\",\n      },\n      {\n        \"name\": \"course_icon\",\n        \"selector\": \".image-92\",\n        \"type\": \"attribute\",\n        \"attribute\": \"src\",\n      },\n    ],\n  }\n  browser_config = BrowserConfig(headless=True, java_script_enabled=True)\n  js_click_tabs = \"\"\"\n  (async () => {\n    const tabs = document.querySelectorAll(\"section.charge-methodology .tabs-menu-3 > div\");\n    for(let tab of tabs) {\n      tab.scrollIntoView();\n      tab.click();\n      await new Promise(r => setTimeout(r, 500));\n    }\n  })();\n  \"\"\"\n  crawler_config = CrawlerRunConfig(\n    cache_mode=CacheMode.BYPASS,\n    extraction_strategy=JsonCssExtractionStrategy(schema),\n    js_code=[js_click_tabs],\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    result = await crawler.arun(\n      url=\"https://www.kidocode.com/degrees/technology\", config=crawler_config\n    )\n    companies = json.loads(result.extracted_content)\n    print(f\"Successfully extracted {len(companies)} companies\")\n    print(json.dumps(companies[0], indent=2))\nasync def main():\n  await extract_structured_data_using_css_extractor()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key Points** :\n  * **`BrowserConfig(headless=False)`**: We want to watch it click \u201cNext Page.\u201d\n  * **`CrawlerRunConfig(...)`**: We specify the extraction strategy, pass`session_id` to reuse the same page. \n  * **`js_code`**and**`wait_for`**are used for subsequent pages (`page > 0`) to click the \u201cNext\u201d button and wait for new commits to load. \n  * **`js_only=True`**indicates we\u2019re not re-navigating but continuing the existing session.\n  * Finally, we call `kill_session()` to clean up the page and browser session.\n\n\n## 9. Next Steps\nCongratulations! You have:\n  1. Performed a basic crawl and printed Markdown. \n  2. Used **content filters** with a markdown generator. \n  3. Extracted JSON via **CSS** or **LLM** strategies. \n  4. Handled **dynamic** pages with JavaScript triggers.\n\n\nIf you\u2019re ready for more, check out:\n  * **Installation** : A deeper dive into advanced installs, Docker usage (experimental), or optional dependencies. \n  * **Hooks & Auth**: Learn how to run custom JavaScript or handle logins with cookies, local storage, etc. \n  * **Deployment** : Explore ephemeral testing in Docker or plan for the upcoming stable Docker release. \n  * **Browser Management** : Delve into user simulation, stealth modes, and concurrency best practices. \n\n\nCrawl4AI is a powerful, flexible tool. Enjoy building out your scrapers, data pipelines, or AI-driven extraction flows. Happy crawling!\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/core",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/simple-crawling"
      ],
      "depth": 1,
      "stats": {
        "processed": 25,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:31",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "session-management.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/session-management",
      "timestamp": "2025-02-06T13:23:23.486502",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/session-management/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Session Management - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Session Management</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#session-management\">Session Management</a></li>\n        <li><a href=\"#basic-session-usage\">Basic Session Usage</a></li><li><a href=\"#dynamic-content-with-sessions\">Dynamic Content with Sessions</a></li><li><a href=\"#example-1-basic-session-based-crawling\">Example 1: Basic Session-Based Crawling</a></li><li><a href=\"#advanced-technique-1-custom-execution-hooks\">Advanced Technique 1: Custom Execution Hooks</a></li><li><a href=\"#advanced-technique-2-integrated-javascript-execution-and-waiting\">Advanced Technique 2: Integrated JavaScript Execution and Waiting</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"session-management\">Session Management</h1>\n<p>Session management in Crawl4AI is a powerful feature that allows you to maintain state across multiple requests, making it particularly suitable for handling complex multi-step crawling tasks. It enables you to reuse the same browser tab (or page object) across sequential actions and crawls, which is beneficial for:</p>\n<ul>\n<li><strong>Performing JavaScript actions before and after crawling.</strong></li>\n<li><strong>Executing multiple sequential crawls faster</strong> without needing to reopen tabs or allocate memory repeatedly.</li>\n</ul>\n<p><strong>Note:</strong> This feature is designed for sequential workflows and is not suitable for parallel operations.</p>\n<hr>\n<h4 id=\"basic-session-usage\">Basic Session Usage</h4>\n<p>Use <code>BrowserConfig</code> and <code>CrawlerRunConfig</code> to maintain state with a <code>session_id</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs import BrowserConfig, <span class=\"hljs-function\">CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>() <span class=\"hljs-keyword\">as</span> crawler:\n    session_id</span> = <span class=\"hljs-string\">\"my_session\"</span>\n\n    <span class=\"hljs-meta\"># Define configurations</span>\n    config1 = CrawlerRunConfig(\n        url=<span class=\"hljs-string\">\"https://example.com/page1\"</span>, session_id=session_id\n    )\n    config2 = CrawlerRunConfig(\n        url=<span class=\"hljs-string\">\"https://example.com/page2\"</span>, session_id=session_id\n    )\n\n    <span class=\"hljs-meta\"># First request</span>\n    result1 = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config1)\n\n    <span class=\"hljs-meta\"># Subsequent request using the same session</span>\n    result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config2)\n\n    <span class=\"hljs-meta\"># Clean up when done</span>\n    <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n</code></pre></div>\n<hr>\n<h4 id=\"dynamic-content-with-sessions\">Dynamic Content with Sessions</h4>\n<p>Here's an example of crawling GitHub commits across multiple pages while preserving session state:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n<span class=\"hljs-keyword\">from</span> crawl4ai.cache_context <span class=\"hljs-keyword\">import</span> CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_dynamic_content</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"github_commits_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>\n        all_commits = []\n\n        <span class=\"hljs-comment\"># Define extraction schema</span>\n        schema = {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Commit Extractor\"</span>,\n            <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"li.Box-sc-g0xbh4-0\"</span>,\n            <span class=\"hljs-string\">\"fields\"</span>: [{\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h4.markdown-title\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            }],\n        }\n        extraction_strategy = JsonCssExtractionStrategy(schema)\n\n        <span class=\"hljs-comment\"># JavaScript and wait configurations</span>\n        js_next_page = <span class=\"hljs-string\">\"\"\"document.querySelector('a[data-testid=\"pagination-next-button\"]').click();\"\"\"</span>\n        wait_for = <span class=\"hljs-string\">\"\"\"() =&gt; document.querySelectorAll('li.Box-sc-g0xbh4-0').length &gt; 0\"\"\"</span>\n\n        <span class=\"hljs-comment\"># Crawl multiple pages</span>\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                extraction_strategy=extraction_strategy,\n                js_code=js_next_page <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                wait_for=wait_for <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-keyword\">if</span> result.success:\n                commits = json.loads(result.extracted_content)\n                all_commits.extend(commits)\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(commits)}</span> commits\"</span>)\n\n        <span class=\"hljs-comment\"># Clean up session</span>\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n        <span class=\"hljs-keyword\">return</span> all_commits\n</code></pre></div>\n<hr>\n<h2 id=\"example-1-basic-session-based-crawling\">Example 1: Basic Session-Based Crawling</h2>\n<p>A simple example using session-based crawling:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> BrowserConfig, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.cache_context <span class=\"hljs-keyword\">import</span> CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">basic_session_crawl</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"dynamic_content_session\"</span>\n        url = <span class=\"hljs-string\">\"https://example.com/dynamic-content\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=<span class=\"hljs-string\">\"document.querySelector('.load-more-button').click();\"</span> <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\".content-item\"</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{result.extracted_content.count(<span class=\"hljs-string\">'.content-item'</span>)}</span> items\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(basic_session_crawl())\n</code></pre></div>\n<p>This example shows:\n1. Reusing the same <code>session_id</code> across multiple requests.\n2. Executing JavaScript to load more content dynamically.\n3. Properly closing the session to free resources.</p>\n<hr>\n<h2 id=\"advanced-technique-1-custom-execution-hooks\">Advanced Technique 1: Custom Execution Hooks</h2>\n<blockquote>\n<p>Warning: You might feel confused by the end of the next few examples \ud83d\ude05, so make sure you are comfortable with the order of the parts before you start this.</p>\n</blockquote>\n<p>Use custom hooks to handle complex scenarios, such as waiting for content to load dynamically:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">advanced_session_crawl_with_hooks</span>():\n    first_commit = <span class=\"hljs-string\">\"\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_execution_started</span>(<span class=\"hljs-params\">page</span>):\n        <span class=\"hljs-keyword\">nonlocal</span> first_commit\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n                <span class=\"hljs-keyword\">await</span> page.wait_for_selector(<span class=\"hljs-string\">\"li.commit-item h4\"</span>)\n                commit = <span class=\"hljs-keyword\">await</span> page.query_selector(<span class=\"hljs-string\">\"li.commit-item h4\"</span>)\n                commit = <span class=\"hljs-keyword\">await</span> commit.evaluate(<span class=\"hljs-string\">\"(element) =&gt; element.textContent\"</span>).strip()\n                <span class=\"hljs-keyword\">if</span> commit <span class=\"hljs-keyword\">and</span> commit != first_commit:\n                    first_commit = commit\n                    <span class=\"hljs-keyword\">break</span>\n                <span class=\"hljs-keyword\">await</span> asyncio.sleep(<span class=\"hljs-number\">0.5</span>)\n        <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Warning: New content didn't appear: <span class=\"hljs-subst\">{e}</span>\"</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"commit_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/example/repo/commits/main\"</span>\n        crawler.crawler_strategy.set_hook(<span class=\"hljs-string\">\"on_execution_started\"</span>, on_execution_started)\n\n        js_next_page = <span class=\"hljs-string\">\"\"\"document.querySelector('a.pagination-next').click();\"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=js_next_page <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\"li.commit-item\"</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.extracted_content)}</span> commits\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(advanced_session_crawl_with_hooks())\n</code></pre></div>\n<p>This technique ensures new content loads before the next action.</p>\n<hr>\n<h2 id=\"advanced-technique-2-integrated-javascript-execution-and-waiting\">Advanced Technique 2: Integrated JavaScript Execution and Waiting</h2>\n<p>Combine JavaScript execution and waiting logic for concise handling of dynamic content:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">integrated_js_and_wait_crawl</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"integrated_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/example/repo/commits/main\"</span>\n\n        js_next_page_and_wait = <span class=\"hljs-string\">\"\"\"\n        (async () =&gt; {\n            const getCurrentCommit = () =&gt; document.querySelector('li.commit-item h4').textContent.trim();\n            const initialCommit = getCurrentCommit();\n            document.querySelector('a.pagination-next').click();\n            while (getCurrentCommit() === initialCommit) {\n                await new Promise(resolve =&gt; setTimeout(resolve, 100));\n            }\n        })();\n        \"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=js_next_page_and_wait <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\"li.commit-item\"</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.extracted_content)}</span> commits\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(integrated_js_and_wait_crawl())\n</code></pre></div>\n<hr>\n<h4 id=\"common-use-cases-for-sessions\">Common Use Cases for Sessions</h4>\n<p>1.\u2000<strong>Authentication Flows</strong>: Login and interact with secured pages.</p>\n<p>2.\u2000<strong>Pagination Handling</strong>: Navigate through multiple pages.</p>\n<p>3.\u2000<strong>Form Submissions</strong>: Fill forms, submit, and process results.</p>\n<p>4.\u2000<strong>Multi-step Processes</strong>: Complete workflows that span multiple actions.</p>\n<p>5.\u2000<strong>Dynamic Content Navigation</strong>: Handle JavaScript-rendered or event-triggered content.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Session Management\nSession management in Crawl4AI is a powerful feature that allows you to maintain state across multiple requests, making it particularly suitable for handling complex multi-step crawling tasks. It enables you to reuse the same browser tab (or page object) across sequential actions and crawls, which is beneficial for:\n  * **Performing JavaScript actions before and after crawling.**\n  * **Executing multiple sequential crawls faster** without needing to reopen tabs or allocate memory repeatedly.\n\n\n**Note:** This feature is designed for sequential workflows and is not suitable for parallel operations.\n#### Basic Session Usage\nUse `BrowserConfig` and `CrawlerRunConfig` to maintain state with a `session_id`:\n```\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\nasync with AsyncWebCrawler() as crawler:\n  session_id = \"my_session\"\n  # Define configurations\n  config1 = CrawlerRunConfig(\n    url=\"https://example.com/page1\", session_id=session_id\n  )\n  config2 = CrawlerRunConfig(\n    url=\"https://example.com/page2\", session_id=session_id\n  )\n  # First request\n  result1 = await crawler.arun(config=config1)\n  # Subsequent request using the same session\n  result2 = await crawler.arun(config=config2)\n  # Clean up when done\n  await crawler.crawler_strategy.kill_session(session_id)\n\n```\n\n#### Dynamic Content with Sessions\nHere's an example of crawling GitHub commits across multiple pages while preserving session state:\n```\nfrom crawl4ai.async_configs import CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nfrom crawl4ai.cache_context import CacheMode\nasync def crawl_dynamic_content():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"github_commits_session\"\n    url = \"https://github.com/microsoft/TypeScript/commits/main\"\n    all_commits = []\n    # Define extraction schema\n    schema = {\n      \"name\": \"Commit Extractor\",\n      \"baseSelector\": \"li.Box-sc-g0xbh4-0\",\n      \"fields\": [{\n        \"name\": \"title\", \"selector\": \"h4.markdown-title\", \"type\": \"text\"\n      }],\n    }\n    extraction_strategy = JsonCssExtractionStrategy(schema)\n    # JavaScript and wait configurations\n    js_next_page = \"\"\"document.querySelector('a[data-testid=\"pagination-next-button\"]').click();\"\"\"\n    wait_for = \"\"\"() => document.querySelectorAll('li.Box-sc-g0xbh4-0').length > 0\"\"\"\n    # Crawl multiple pages\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        extraction_strategy=extraction_strategy,\n        js_code=js_next_page if page > 0 else None,\n        wait_for=wait_for if page > 0 else None,\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      if result.success:\n        commits = json.loads(result.extracted_content)\n        all_commits.extend(commits)\n        print(f\"Page {page + 1}: Found {len(commits)} commits\")\n    # Clean up session\n    await crawler.crawler_strategy.kill_session(session_id)\n    return all_commits\n\n```\n\n## Example 1: Basic Session-Based Crawling\nA simple example using session-based crawling:\n```\nimport asyncio\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\nfrom crawl4ai.cache_context import CacheMode\nasync def basic_session_crawl():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"dynamic_content_session\"\n    url = \"https://example.com/dynamic-content\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=\"document.querySelector('.load-more-button').click();\" if page > 0 else None,\n        css_selector=\".content-item\",\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {result.extracted_content.count('.content-item')} items\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(basic_session_crawl())\n\n```\n\nThis example shows: 1. Reusing the same `session_id` across multiple requests. 2. Executing JavaScript to load more content dynamically. 3. Properly closing the session to free resources.\n## Advanced Technique 1: Custom Execution Hooks\n> Warning: You might feel confused by the end of the next few examples \ud83d\ude05, so make sure you are comfortable with the order of the parts before you start this.\nUse custom hooks to handle complex scenarios, such as waiting for content to load dynamically:\n```\nasync def advanced_session_crawl_with_hooks():\n  first_commit = \"\"\n  async def on_execution_started(page):\n    nonlocal first_commit\n    try:\n      while True:\n        await page.wait_for_selector(\"li.commit-item h4\")\n        commit = await page.query_selector(\"li.commit-item h4\")\n        commit = await commit.evaluate(\"(element) => element.textContent\").strip()\n        if commit and commit != first_commit:\n          first_commit = commit\n          break\n        await asyncio.sleep(0.5)\n    except Exception as e:\n      print(f\"Warning: New content didn't appear: {e}\")\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"commit_session\"\n    url = \"https://github.com/example/repo/commits/main\"\n    crawler.crawler_strategy.set_hook(\"on_execution_started\", on_execution_started)\n    js_next_page = \"\"\"document.querySelector('a.pagination-next').click();\"\"\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=js_next_page if page > 0 else None,\n        css_selector=\"li.commit-item\",\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {len(result.extracted_content)} commits\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(advanced_session_crawl_with_hooks())\n\n```\n\nThis technique ensures new content loads before the next action.\n## Advanced Technique 2: Integrated JavaScript Execution and Waiting\nCombine JavaScript execution and waiting logic for concise handling of dynamic content:\n```\nasync def integrated_js_and_wait_crawl():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"integrated_session\"\n    url = \"https://github.com/example/repo/commits/main\"\n    js_next_page_and_wait = \"\"\"\n    (async () => {\n      const getCurrentCommit = () => document.querySelector('li.commit-item h4').textContent.trim();\n      const initialCommit = getCurrentCommit();\n      document.querySelector('a.pagination-next').click();\n      while (getCurrentCommit() === initialCommit) {\n        await new Promise(resolve => setTimeout(resolve, 100));\n      }\n    })();\n    \"\"\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=js_next_page_and_wait if page > 0 else None,\n        css_selector=\"li.commit-item\",\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {len(result.extracted_content)} commits\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(integrated_js_and_wait_crawl())\n\n```\n\n#### Common Use Cases for Sessions\n1. **Authentication Flows** : Login and interact with secured pages.\n2. **Pagination Handling** : Navigate through multiple pages.\n3. **Form Submissions** : Fill forms, submit, and process results.\n4. **Multi-step Processes** : Complete workflows that span multiple actions.\n5. **Dynamic Content Navigation** : Handle JavaScript-rendered or event-triggered content.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/ssl-certificate"
      ],
      "depth": 1,
      "stats": {
        "processed": 5,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:07",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "simple-crawling.json",
    "content": {
      "url": "https://docs.crawl4ai.com/core/simple-crawling",
      "timestamp": "2025-02-06T13:23:48.954906",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/simple-crawling/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Simple Crawling - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Simple Crawling</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#simple-crawling\">Simple Crawling</a></li>\n        <li><a href=\"#basic-usage\">Basic Usage</a></li><li><a href=\"#understanding-the-response\">Understanding the Response</a></li><li><a href=\"#adding-basic-options\">Adding Basic Options</a></li><li><a href=\"#handling-errors\">Handling Errors</a></li><li><a href=\"#logging-and-debugging\">Logging and Debugging</a></li><li><a href=\"#complete-example\">Complete Example</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"simple-crawling\">Simple Crawling</h1>\n<p>This guide covers the basics of web crawling with Crawl4AI. You'll learn how to set up a crawler, make your first request, and understand the response.</p>\n<h2 id=\"basic-usage\">Basic Usage</h2>\n<p>Set up a simple crawl using <code>BrowserConfig</code> and <code>CrawlerRunConfig</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    browser_config = BrowserConfig()  <span class=\"hljs-comment\"># Default browser configuration</span>\n    run_config = CrawlerRunConfig()   <span class=\"hljs-comment\"># Default crawl run configuration</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n            config=run_config\n        )\n        <span class=\"hljs-built_in\">print</span>(result.markdown)  <span class=\"hljs-comment\"># Print clean markdown content</span>\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h2 id=\"understanding-the-response\">Understanding the Response</h2>\n<p>The <code>arun()</code> method returns a <code>CrawlResult</code> object with several useful properties. Here's a quick overview (see <a href=\"../../api/crawl-result/\">CrawlResult</a> for complete details):</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n    config=CrawlerRunConfig(fit_markdown=<span class=\"hljs-literal\">True</span>)\n)\n\n<span class=\"hljs-comment\"># Different content formats</span>\n<span class=\"hljs-built_in\">print</span>(result.html)         <span class=\"hljs-comment\"># Raw HTML</span>\n<span class=\"hljs-built_in\">print</span>(result.cleaned_html) <span class=\"hljs-comment\"># Cleaned HTML</span>\n<span class=\"hljs-built_in\">print</span>(result.markdown)     <span class=\"hljs-comment\"># Markdown version</span>\n<span class=\"hljs-built_in\">print</span>(result.fit_markdown) <span class=\"hljs-comment\"># Most relevant content in markdown</span>\n\n<span class=\"hljs-comment\"># Check success status</span>\n<span class=\"hljs-built_in\">print</span>(result.success)      <span class=\"hljs-comment\"># True if crawl succeeded</span>\n<span class=\"hljs-built_in\">print</span>(result.status_code)  <span class=\"hljs-comment\"># HTTP status code (e.g., 200, 404)</span>\n\n<span class=\"hljs-comment\"># Access extracted media and links</span>\n<span class=\"hljs-built_in\">print</span>(result.media)        <span class=\"hljs-comment\"># Dictionary of found media (images, videos, audio)</span>\n<span class=\"hljs-built_in\">print</span>(result.links)        <span class=\"hljs-comment\"># Dictionary of internal and external links</span>\n</code></pre></div>\n<h2 id=\"adding-basic-options\">Adding Basic Options</h2>\n<p>Customize your crawl using <code>CrawlerRunConfig</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">run_config = CrawlerRunConfig(\n    word_count_threshold=<span class=\"hljs-number\">10</span>,        <span class=\"hljs-comment\"># Minimum words per content block</span>\n    exclude_external_links=<span class=\"hljs-literal\">True</span>,    <span class=\"hljs-comment\"># Remove external links</span>\n    remove_overlay_elements=<span class=\"hljs-literal\">True</span>,   <span class=\"hljs-comment\"># Remove popups/modals</span>\n    process_iframes=<span class=\"hljs-literal\">True</span>           <span class=\"hljs-comment\"># Process iframe content</span>\n)\n\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n    config=run_config\n)\n</code></pre></div>\n<h2 id=\"handling-errors\">Handling Errors</h2>\n<p>Always check if the crawl was successful:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">run_config = CrawlerRunConfig()\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=run_config)\n\n<span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Crawl failed: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Status code: <span class=\"hljs-subst\">{result.status_code}</span>\"</span>)\n</code></pre></div>\n<h2 id=\"logging-and-debugging\">Logging and Debugging</h2>\n<p>Enable verbose logging in <code>BrowserConfig</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\">browser_config = BrowserConfig(verbose=True)\n\n<span class=\"hljs-function\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>(<span class=\"hljs-params\">config=browser_config</span>) <span class=\"hljs-keyword\">as</span> crawler:\n    run_config</span> = CrawlerRunConfig()\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=run_config)\n</code></pre></div>\n<h2 id=\"complete-example\">Complete Example</h2>\n<p>Here's a more comprehensive example demonstrating common usage patterns:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> BrowserConfig, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    browser_config = BrowserConfig(verbose=<span class=\"hljs-literal\">True</span>)\n    run_config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Content filtering</span>\n        word_count_threshold=<span class=\"hljs-number\">10</span>,\n        excluded_tags=[<span class=\"hljs-string\">'form'</span>, <span class=\"hljs-string\">'header'</span>],\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Content processing</span>\n        process_iframes=<span class=\"hljs-literal\">True</span>,\n        remove_overlay_elements=<span class=\"hljs-literal\">True</span>,\n\n        <span class=\"hljs-comment\"># Cache control</span>\n        cache_mode=CacheMode.ENABLED  <span class=\"hljs-comment\"># Use cache if available</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_config) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n            config=run_config\n        )\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-comment\"># Print clean content</span>\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Content:\"</span>, result.markdown[:<span class=\"hljs-number\">500</span>])  <span class=\"hljs-comment\"># First 500 chars</span>\n\n            <span class=\"hljs-comment\"># Process images</span>\n            <span class=\"hljs-keyword\">for</span> image <span class=\"hljs-keyword\">in</span> result.media[<span class=\"hljs-string\">\"images\"</span>]:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found image: <span class=\"hljs-subst\">{image[<span class=\"hljs-string\">'src'</span>]}</span>\"</span>)\n\n            <span class=\"hljs-comment\"># Process links</span>\n            <span class=\"hljs-keyword\">for</span> link <span class=\"hljs-keyword\">in</span> result.links[<span class=\"hljs-string\">\"internal\"</span>]:\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Internal link: <span class=\"hljs-subst\">{link[<span class=\"hljs-string\">'href'</span>]}</span>\"</span>)\n\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Crawl failed: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Simple Crawling\nThis guide covers the basics of web crawling with Crawl4AI. You'll learn how to set up a crawler, make your first request, and understand the response.\n## Basic Usage\nSet up a simple crawl using `BrowserConfig` and `CrawlerRunConfig`:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\nasync def main():\n  browser_config = BrowserConfig() # Default browser configuration\n  run_config = CrawlerRunConfig()  # Default crawl run configuration\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com\",\n      config=run_config\n    )\n    print(result.markdown) # Print clean markdown content\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## Understanding the Response\nThe `arun()` method returns a `CrawlResult` object with several useful properties. Here's a quick overview (see [CrawlResult](https://docs.crawl4ai.com/core/api/crawl-result/>) for complete details):\n```\nresult = await crawler.arun(\n  url=\"https://example.com\",\n  config=CrawlerRunConfig(fit_markdown=True)\n)\n# Different content formats\nprint(result.html)     # Raw HTML\nprint(result.cleaned_html) # Cleaned HTML\nprint(result.markdown)   # Markdown version\nprint(result.fit_markdown) # Most relevant content in markdown\n# Check success status\nprint(result.success)   # True if crawl succeeded\nprint(result.status_code) # HTTP status code (e.g., 200, 404)\n# Access extracted media and links\nprint(result.media)    # Dictionary of found media (images, videos, audio)\nprint(result.links)    # Dictionary of internal and external links\n\n```\n\n## Adding Basic Options\nCustomize your crawl using `CrawlerRunConfig`:\n```\nrun_config = CrawlerRunConfig(\n  word_count_threshold=10,    # Minimum words per content block\n  exclude_external_links=True,  # Remove external links\n  remove_overlay_elements=True,  # Remove popups/modals\n  process_iframes=True      # Process iframe content\n)\nresult = await crawler.arun(\n  url=\"https://example.com\",\n  config=run_config\n)\n\n```\n\n## Handling Errors\nAlways check if the crawl was successful:\n```\nrun_config = CrawlerRunConfig()\nresult = await crawler.arun(url=\"https://example.com\", config=run_config)\nif not result.success:\n  print(f\"Crawl failed: {result.error_message}\")\n  print(f\"Status code: {result.status_code}\")\n\n```\n\n## Logging and Debugging\nEnable verbose logging in `BrowserConfig`:\n```\nbrowser_config = BrowserConfig(verbose=True)\nasync with AsyncWebCrawler(config=browser_config) as crawler:\n  run_config = CrawlerRunConfig()\n  result = await crawler.arun(url=\"https://example.com\", config=run_config)\n\n```\n\n## Complete Example\nHere's a more comprehensive example demonstrating common usage patterns:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig, CacheMode\nasync def main():\n  browser_config = BrowserConfig(verbose=True)\n  run_config = CrawlerRunConfig(\n    # Content filtering\n    word_count_threshold=10,\n    excluded_tags=['form', 'header'],\n    exclude_external_links=True,\n    # Content processing\n    process_iframes=True,\n    remove_overlay_elements=True,\n    # Cache control\n    cache_mode=CacheMode.ENABLED # Use cache if available\n  )\n  async with AsyncWebCrawler(config=browser_config) as crawler:\n    result = await crawler.arun(\n      url=\"https://example.com\",\n      config=run_config\n    )\n    if result.success:\n      # Print clean content\n      print(\"Content:\", result.markdown[:500]) # First 500 chars\n      # Process images\n      for image in result.media[\"images\"]:\n        print(f\"Found image: {image['src']}\")\n      # Process links\n      for link in result.links[\"internal\"]:\n        print(f\"Internal link: {link['href']}\")\n    else:\n      print(f\"Crawl failed: {result.error_message}\")\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/browser-crawler-config",
        "https://docs.crawl4ai.com/cache-modes",
        "https://docs.crawl4ai.com/content-selection",
        "https://docs.crawl4ai.com/crawler-result",
        "https://docs.crawl4ai.com/docker-deploymeny",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/fit-markdown",
        "https://docs.crawl4ai.com/installation",
        "https://docs.crawl4ai.com/link-media",
        "https://docs.crawl4ai.com/local-files",
        "https://docs.crawl4ai.com/markdown-generation",
        "https://docs.crawl4ai.com/page-interaction",
        "https://docs.crawl4ai.com/quickstart"
      ],
      "depth": 1,
      "stats": {
        "processed": 26,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:32",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "ssl-certificate.json",
    "content": {
      "url": "https://docs.crawl4ai.com/advanced/ssl-certificate",
      "timestamp": "2025-02-06T13:23:24.667600",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/ssl-certificate/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>SSL Certificate - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">SSL Certificate</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#sslcertificate-reference\">SSLCertificate Reference</a></li>\n        <li><a href=\"#1-overview\">1. Overview</a></li><li><a href=\"#2-construction-fetching\">2. Construction &amp; Fetching</a></li><li><a href=\"#3-common-properties\">3. Common Properties</a></li><li><a href=\"#4-export-methods\">4. Export Methods</a></li><li><a href=\"#5-example-usage-in-crawl4ai\">5. Example Usage in Crawl4AI</a></li><li><a href=\"#6-notes-best-practices\">6. Notes &amp; Best Practices</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"sslcertificate-reference\"><code>SSLCertificate</code> Reference</h1>\n<p>The <strong><code>SSLCertificate</code></strong> class encapsulates an SSL certificate\u2019s data and allows exporting it in various formats (PEM, DER, JSON, or text). It\u2019s used within <strong>Crawl4AI</strong> whenever you set <strong><code>fetch_ssl_certificate=True</code></strong> in your <strong><code>CrawlerRunConfig</code></strong>.  </p>\n<h2 id=\"1-overview\">1. Overview</h2>\n<p><strong>Location</strong>: <code>crawl4ai/ssl_certificate.py</code></p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SSLCertificate</span>:\n    <span class=\"hljs-string\">\"\"\"\n    Represents an SSL certificate with methods to export in various formats.\n\n    Main Methods:\n    - from_url(url, timeout=10)\n    - from_file(file_path)\n    - from_binary(binary_data)\n    - to_json(filepath=None)\n    - to_pem(filepath=None)\n    - to_der(filepath=None)\n    ...\n\n    Common Properties:\n    - issuer\n    - subject\n    - valid_from\n    - valid_until\n    - fingerprint\n    \"\"\"</span>\n</code></pre></div>\n<h3 id=\"typical-use-case\">Typical Use Case</h3>\n<ol>\n<li>You <strong>enable</strong> certificate fetching in your crawl by:\n   <div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-scss\"><span class=\"hljs-built_in\">CrawlerRunConfig</span>(fetch_ssl_certificate=True, ...)\n</code></pre></div></li>\n<li>After <code>arun()</code>, if <code>result.ssl_certificate</code> is present, it\u2019s an instance of <strong><code>SSLCertificate</code></strong>.  </li>\n<li>You can <strong>read</strong> basic properties (issuer, subject, validity) or <strong>export</strong> them in multiple formats.</li>\n</ol>\n<hr>\n<h2 id=\"2-construction-fetching\">2. Construction &amp; Fetching</h2>\n<h3 id=\"21-from_urlurl-timeout10\">2.1 <strong><code>from_url(url, timeout=10)</code></strong></h3>\n<p>Manually load an SSL certificate from a given URL (port 443). Typically used internally, but you can call it directly if you want:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">cert = SSLCertificate.from_url(<span class=\"hljs-string\">\"https://example.com\"</span>)\n<span class=\"hljs-keyword\">if</span> cert:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fingerprint:\"</span>, cert.fingerprint)\n</code></pre></div>\n<h3 id=\"22-from_filefile_path\">2.2 <strong><code>from_file(file_path)</code></strong></h3>\n<p>Load from a file containing certificate data in ASN.1 or DER. Rarely needed unless you have local cert files:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">cert</span> = SSLCertificate.from_file(<span class=\"hljs-string\">\"/path/to/cert.der\"</span>)\n</code></pre></div>\n<h3 id=\"23-from_binarybinary_data\">2.3 <strong><code>from_binary(binary_data)</code></strong></h3>\n<p>Initialize from raw binary. E.g., if you captured it from a socket or another source:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">cert</span> = SSLCertificate.from_binary(raw_bytes)\n</code></pre></div>\n<hr>\n<h2 id=\"3-common-properties\">3. Common Properties</h2>\n<p>After obtaining a <strong><code>SSLCertificate</code></strong> instance (e.g. <code>result.ssl_certificate</code> from a crawl), you can read:</p>\n<p>1.\u2000<strong><code>issuer</code></strong> <em>(dict)</em><br>\n   - E.g. <code>{\"CN\": \"My Root CA\", \"O\": \"...\"}</code>\n2.\u2000<strong><code>subject</code></strong> <em>(dict)</em><br>\n   - E.g. <code>{\"CN\": \"example.com\", \"O\": \"ExampleOrg\"}</code>\n3.\u2000<strong><code>valid_from</code></strong> <em>(str)</em><br>\n   - NotBefore date/time. Often in ASN.1/UTC format.\n4.\u2000<strong><code>valid_until</code></strong> <em>(str)</em><br>\n   - NotAfter date/time.\n5.\u2000<strong><code>fingerprint</code></strong> <em>(str)</em><br>\n   - The SHA-256 digest (lowercase hex).<br>\n   - E.g. <code>\"d14d2e...\"</code></p>\n<hr>\n<h2 id=\"4-export-methods\">4. Export Methods</h2>\n<p>Once you have a <strong><code>SSLCertificate</code></strong> object, you can <strong>export</strong> or <strong>inspect</strong> it:</p>\n<h3 id=\"41-to_jsonfilepathnone-optionalstr\">4.1 <strong><code>to_json(filepath=None)</code> \u2192 <code>Optional[str]</code></strong></h3>\n<ul>\n<li>Returns a JSON string containing the parsed certificate fields.  </li>\n<li>If <code>filepath</code> is provided, saves it to disk instead, returning <code>None</code>.</li>\n</ul>\n<p><strong>Usage</strong>:\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">json_data = cert.to_json()  <span class=\"hljs-comment\"># returns JSON string</span>\ncert.to_json(<span class=\"hljs-string\">\"certificate.json\"</span>)  <span class=\"hljs-comment\"># writes file, returns None</span>\n</code></pre></div><p></p>\n<h3 id=\"42-to_pemfilepathnone-optionalstr\">4.2 <strong><code>to_pem(filepath=None)</code> \u2192 <code>Optional[str]</code></strong></h3>\n<ul>\n<li>Returns a PEM-encoded string (common for web servers).  </li>\n<li>If <code>filepath</code> is provided, saves it to disk instead.</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">pem_str = cert.to_pem()              <span class=\"hljs-comment\"># in-memory PEM string</span>\ncert.to_pem(<span class=\"hljs-string\">\"/path/to/cert.pem\"</span>)     <span class=\"hljs-comment\"># saved to file</span>\n</code></pre></div>\n<h3 id=\"43-to_derfilepathnone-optionalbytes\">4.3 <strong><code>to_der(filepath=None)</code> \u2192 <code>Optional[bytes]</code></strong></h3>\n<ul>\n<li>Returns the original DER (binary ASN.1) bytes.  </li>\n<li>If <code>filepath</code> is specified, writes the bytes there instead.</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">der_bytes = cert.to_der()\ncert.to_der(<span class=\"hljs-string\">\"certificate.der\"</span>)\n</code></pre></div>\n<h3 id=\"44-optional-export_as_text\">4.4 (Optional) <strong><code>export_as_text()</code></strong></h3>\n<ul>\n<li>If you see a method like <code>export_as_text()</code>, it typically returns an OpenSSL-style textual representation.  </li>\n<li>Not always needed, but can help for debugging or manual inspection.</li>\n</ul>\n<hr>\n<h2 id=\"5-example-usage-in-crawl4ai\">5. Example Usage in Crawl4AI</h2>\n<p>Below is a minimal sample showing how the crawler obtains an SSL cert from a site, then reads or exports it. The code snippet:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">import asyncio\nimport os\n<span class=\"hljs-selector-tag\">from</span> crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\n\nasync def <span class=\"hljs-selector-tag\">main</span>():\n    tmp_dir = <span class=\"hljs-string\">\"tmp\"</span>\n    os.<span class=\"hljs-built_in\">makedirs</span>(tmp_dir, exist_ok=True)\n\n    config = <span class=\"hljs-built_in\">CrawlerRunConfig</span>(\n        fetch_ssl_certificate=True,\n        cache_mode=CacheMode.BYPASS\n    )\n\n    async with <span class=\"hljs-built_in\">AsyncWebCrawler</span>() as crawler:\n        result = await crawler.<span class=\"hljs-built_in\">arun</span>(<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n        if result.success and result.ssl_certificate:\n            cert = result.ssl_certificate\n            # <span class=\"hljs-number\">1</span>. Basic Info\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Issuer CN:\"</span>, cert.issuer.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"CN\"</span>, <span class=\"hljs-string\">\"\"</span>))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Valid until:\"</span>, cert.valid_until)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Fingerprint:\"</span>, cert.fingerprint)\n\n            # <span class=\"hljs-number\">2</span>. Export\n            cert.<span class=\"hljs-built_in\">to_json</span>(os.path.<span class=\"hljs-built_in\">join</span>(tmp_dir, <span class=\"hljs-string\">\"certificate.json\"</span>))\n            cert.<span class=\"hljs-built_in\">to_pem</span>(os.path.<span class=\"hljs-built_in\">join</span>(tmp_dir, <span class=\"hljs-string\">\"certificate.pem\"</span>))\n            cert.<span class=\"hljs-built_in\">to_der</span>(os.path.<span class=\"hljs-built_in\">join</span>(tmp_dir, <span class=\"hljs-string\">\"certificate.der\"</span>))\n\nif __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.<span class=\"hljs-built_in\">run</span>(<span class=\"hljs-built_in\">main</span>())\n</code></pre></div>\n<hr>\n<h2 id=\"6-notes-best-practices\">6. Notes &amp; Best Practices</h2>\n<p>1.\u2000<strong>Timeout</strong>: <code>SSLCertificate.from_url</code> internally uses a default <strong>10s</strong> socket connect and wraps SSL.<br>\n2.\u2000<strong>Binary Form</strong>: The certificate is loaded in ASN.1 (DER) form, then re-parsed by <code>OpenSSL.crypto</code>.<br>\n3.\u2000<strong>Validation</strong>: This does <strong>not</strong> validate the certificate chain or trust store. It only fetches and parses.<br>\n4.\u2000<strong>Integration</strong>: Within Crawl4AI, you typically just set <code>fetch_ssl_certificate=True</code> in <code>CrawlerRunConfig</code>; the final result\u2019s <code>ssl_certificate</code> is automatically built.<br>\n5.\u2000<strong>Export</strong>: If you need to store or analyze a cert, the <code>to_json</code> and <code>to_pem</code> are quite universal.</p>\n<hr>\n<h3 id=\"summary\">Summary</h3>\n<ul>\n<li><strong><code>SSLCertificate</code></strong> is a convenience class for capturing and exporting the <strong>TLS certificate</strong> from your crawled site(s).  </li>\n<li>Common usage is in the <strong><code>CrawlResult.ssl_certificate</code></strong> field, accessible after setting <code>fetch_ssl_certificate=True</code>.  </li>\n<li>Offers quick access to essential certificate details (<code>issuer</code>, <code>subject</code>, <code>fingerprint</code>) and is easy to export (PEM, DER, JSON) for further analysis or server usage.</li>\n</ul>\n<p>Use it whenever you need <strong>insight</strong> into a site\u2019s certificate or require some form of cryptographic or compliance check.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# `SSLCertificate` Reference\nThe **`SSLCertificate`**class encapsulates an SSL certificate\u2019s data and allows exporting it in various formats (PEM, DER, JSON, or text). It\u2019s used within**Crawl4AI** whenever you set **`fetch_ssl_certificate=True`**in your**`CrawlerRunConfig`**.\n## 1. Overview\n**Location** : `crawl4ai/ssl_certificate.py`\n```\nclass SSLCertificate:\n  \"\"\"\n  Represents an SSL certificate with methods to export in various formats.\n  Main Methods:\n  - from_url(url, timeout=10)\n  - from_file(file_path)\n  - from_binary(binary_data)\n  - to_json(filepath=None)\n  - to_pem(filepath=None)\n  - to_der(filepath=None)\n  ...\n  Common Properties:\n  - issuer\n  - subject\n  - valid_from\n  - valid_until\n  - fingerprint\n  \"\"\"\n\n```\n\n### Typical Use Case\n  1. You **enable** certificate fetching in your crawl by: \n```\nCrawlerRunConfig(fetch_ssl_certificate=True, ...)\n\n```\n\n  2. After `arun()`, if `result.ssl_certificate` is present, it\u2019s an instance of **`SSLCertificate`**.\n  3. You can **read** basic properties (issuer, subject, validity) or **export** them in multiple formats.\n\n\n## 2. Construction & Fetching\n### 2.1 **`from_url(url, timeout=10)`**\nManually load an SSL certificate from a given URL (port 443). Typically used internally, but you can call it directly if you want:\n```\ncert = SSLCertificate.from_url(\"https://example.com\")\nif cert:\n  print(\"Fingerprint:\", cert.fingerprint)\n\n```\n\n### 2.2 **`from_file(file_path)`**\nLoad from a file containing certificate data in ASN.1 or DER. Rarely needed unless you have local cert files:\n```\ncert = SSLCertificate.from_file(\"/path/to/cert.der\")\n\n```\n\n### 2.3 **`from_binary(binary_data)`**\nInitialize from raw binary. E.g., if you captured it from a socket or another source:\n```\ncert = SSLCertificate.from_binary(raw_bytes)\n\n```\n\n## 3. Common Properties\nAfter obtaining a **`SSLCertificate`**instance (e.g.`result.ssl_certificate` from a crawl), you can read:\n1. **`issuer`**_(dict)_ - E.g. `{\"CN\": \"My Root CA\", \"O\": \"...\"}` 2. **`subject`**_(dict)_ - E.g. `{\"CN\": \"example.com\", \"O\": \"ExampleOrg\"}` 3. **`valid_from`**_(str)_ - NotBefore date/time. Often in ASN.1/UTC format. 4. **`valid_until`**_(str)_ - NotAfter date/time. 5. **`fingerprint`**_(str)_ - The SHA-256 digest (lowercase hex). - E.g. `\"d14d2e...\"`\n## 4. Export Methods\nOnce you have a **`SSLCertificate`**object, you can**export** or **inspect** it:\n### 4.1 **`to_json(filepath=None)`\u2192`Optional[str]`**\n  * Returns a JSON string containing the parsed certificate fields. \n  * If `filepath` is provided, saves it to disk instead, returning `None`.\n\n\n**Usage** : \n```\njson_data = cert.to_json() # returns JSON string\ncert.to_json(\"certificate.json\") # writes file, returns None\n\n```\n\n### 4.2 **`to_pem(filepath=None)`\u2192`Optional[str]`**\n  * Returns a PEM-encoded string (common for web servers). \n  * If `filepath` is provided, saves it to disk instead.\n\n\n```\npem_str = cert.to_pem()       # in-memory PEM string\ncert.to_pem(\"/path/to/cert.pem\")   # saved to file\n\n```\n\n### 4.3 **`to_der(filepath=None)`\u2192`Optional[bytes]`**\n  * Returns the original DER (binary ASN.1) bytes. \n  * If `filepath` is specified, writes the bytes there instead.\n\n\n```\nder_bytes = cert.to_der()\ncert.to_der(\"certificate.der\")\n\n```\n\n### 4.4 (Optional) **`export_as_text()`**\n  * If you see a method like `export_as_text()`, it typically returns an OpenSSL-style textual representation. \n  * Not always needed, but can help for debugging or manual inspection.\n\n\n## 5. Example Usage in Crawl4AI\nBelow is a minimal sample showing how the crawler obtains an SSL cert from a site, then reads or exports it. The code snippet:\n```\nimport asyncio\nimport os\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nasync def main():\n  tmp_dir = \"tmp\"\n  os.makedirs(tmp_dir, exist_ok=True)\n  config = CrawlerRunConfig(\n    fetch_ssl_certificate=True,\n    cache_mode=CacheMode.BYPASS\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://example.com\", config=config)\n    if result.success and result.ssl_certificate:\n      cert = result.ssl_certificate\n      # 1. Basic Info\n      print(\"Issuer CN:\", cert.issuer.get(\"CN\", \"\"))\n      print(\"Valid until:\", cert.valid_until)\n      print(\"Fingerprint:\", cert.fingerprint)\n      # 2. Export\n      cert.to_json(os.path.join(tmp_dir, \"certificate.json\"))\n      cert.to_pem(os.path.join(tmp_dir, \"certificate.pem\"))\n      cert.to_der(os.path.join(tmp_dir, \"certificate.der\"))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 6. Notes & Best Practices\n1. **Timeout** : `SSLCertificate.from_url` internally uses a default **10s** socket connect and wraps SSL. 2. **Binary Form** : The certificate is loaded in ASN.1 (DER) form, then re-parsed by `OpenSSL.crypto`. 3. **Validation** : This does **not** validate the certificate chain or trust store. It only fetches and parses. 4. **Integration** : Within Crawl4AI, you typically just set `fetch_ssl_certificate=True` in `CrawlerRunConfig`; the final result\u2019s `ssl_certificate` is automatically built. 5. **Export** : If you need to store or analyze a cert, the `to_json` and `to_pem` are quite universal.\n### Summary\n  * **`SSLCertificate`**is a convenience class for capturing and exporting the**TLS certificate** from your crawled site(s). \n  * Common usage is in the **`CrawlResult.ssl_certificate`**field, accessible after setting`fetch_ssl_certificate=True`. \n  * Offers quick access to essential certificate details (`issuer`, `subject`, `fingerprint`) and is easy to export (PEM, DER, JSON) for further analysis or server usage.\n\n\nUse it whenever you need **insight** into a site\u2019s certificate or require some form of cryptographic or compliance check.\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced-features",
        "https://docs.crawl4ai.com/api/arun",
        "https://docs.crawl4ai.com/api/arun_many",
        "https://docs.crawl4ai.com/api/async-webcrawler",
        "https://docs.crawl4ai.com/api/crawl-result",
        "https://docs.crawl4ai.com/api/parameters",
        "https://docs.crawl4ai.com/api/strategies",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-dispatcher",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/file-downloading",
        "https://docs.crawl4ai.com/hooks-auth",
        "https://docs.crawl4ai.com/identity-based-crawling",
        "https://docs.crawl4ai.com/lazy-loading",
        "https://docs.crawl4ai.com/multi-url-crawling",
        "https://docs.crawl4ai.com/proxy-security",
        "https://docs.crawl4ai.com/session-management"
      ],
      "depth": 1,
      "stats": {
        "processed": 6,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:08",
        "page_limit": 34
      }
    }
  },
  {
    "source_file": "strategies.json",
    "content": {
      "url": "https://docs.crawl4ai.com/api/strategies",
      "timestamp": "2025-02-06T13:23:31.933022",
      "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"\ud83d\ude80\ud83e\udd16 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/api/strategies/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Strategies - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Strategies</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#extraction-chunking-strategies-api\">Extraction &amp; Chunking Strategies API</a></li>\n        <li><a href=\"#extraction-strategies\">Extraction Strategies</a></li><li><a href=\"#chunking-strategies\">Chunking Strategies</a></li><li><a href=\"#usage-examples\">Usage Examples</a></li><li><a href=\"#best-practices\">Best Practices</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"extraction-chunking-strategies-api\">Extraction &amp; Chunking Strategies API</h1>\n<p>This documentation covers the API reference for extraction and chunking strategies in Crawl4AI.</p>\n<h2 id=\"extraction-strategies\">Extraction Strategies</h2>\n<p>All extraction strategies inherit from the base <code>ExtractionStrategy</code> class and implement two key methods:\n- <code>extract(url: str, html: str) -&gt; List[Dict[str, Any]]</code>\n- <code>run(url: str, sections: List[str]) -&gt; List[Dict[str, Any]]</code></p>\n<h3 id=\"llmextractionstrategy\">LLMExtractionStrategy</h3>\n<p>Used for extracting structured data using Language Models.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">LLMExtractionStrategy(\n    <span class=\"hljs-comment\"># Required Parameters</span>\n    provider: <span class=\"hljs-built_in\">str</span> = DEFAULT_PROVIDER,     <span class=\"hljs-comment\"># LLM provider (e.g., \"ollama/llama2\")</span>\n    api_token: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>,      <span class=\"hljs-comment\"># API token</span>\n\n    <span class=\"hljs-comment\"># Extraction Configuration</span>\n    instruction: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-literal\">None</span>,              <span class=\"hljs-comment\"># Custom extraction instruction</span>\n    schema: <span class=\"hljs-type\">Dict</span> = <span class=\"hljs-literal\">None</span>,                  <span class=\"hljs-comment\"># Pydantic model schema for structured data</span>\n    extraction_type: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">\"block\"</span>,       <span class=\"hljs-comment\"># \"block\" or \"schema\"</span>\n\n    <span class=\"hljs-comment\"># Chunking Parameters</span>\n    chunk_token_threshold: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">4000</span>,    <span class=\"hljs-comment\"># Maximum tokens per chunk</span>\n    overlap_rate: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.1</span>,           <span class=\"hljs-comment\"># Overlap between chunks</span>\n    word_token_rate: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.75</span>,       <span class=\"hljs-comment\"># Word to token conversion rate</span>\n    apply_chunking: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">True</span>,         <span class=\"hljs-comment\"># Enable/disable chunking</span>\n\n    <span class=\"hljs-comment\"># API Configuration</span>\n    base_url: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-literal\">None</span>,                <span class=\"hljs-comment\"># Base URL for API</span>\n    extra_args: <span class=\"hljs-type\">Dict</span> = {},               <span class=\"hljs-comment\"># Additional provider arguments</span>\n    verbose: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>                <span class=\"hljs-comment\"># Enable verbose logging</span>\n)\n</code></pre></div>\n<h3 id=\"cosinestrategy\">CosineStrategy</h3>\n<p>Used for content similarity-based extraction and clustering.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">CosineStrategy(\n    <span class=\"hljs-comment\"># Content Filtering</span>\n    semantic_filter: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-literal\">None</span>,        <span class=\"hljs-comment\"># Topic/keyword filter</span>\n    word_count_threshold: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">10</span>,     <span class=\"hljs-comment\"># Minimum words per cluster</span>\n    sim_threshold: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.3</span>,         <span class=\"hljs-comment\"># Similarity threshold</span>\n\n    <span class=\"hljs-comment\"># Clustering Parameters</span>\n    max_dist: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.2</span>,             <span class=\"hljs-comment\"># Maximum cluster distance</span>\n    linkage_method: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">'ward'</span>,       <span class=\"hljs-comment\"># Clustering method</span>\n    top_k: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">3</span>,                    <span class=\"hljs-comment\"># Top clusters to return</span>\n\n    <span class=\"hljs-comment\"># Model Configuration</span>\n    model_name: <span class=\"hljs-built_in\">str</span> = <span class=\"hljs-string\">'sentence-transformers/all-MiniLM-L6-v2'</span>,  <span class=\"hljs-comment\"># Embedding model</span>\n\n    verbose: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>              <span class=\"hljs-comment\"># Enable verbose logging</span>\n)\n</code></pre></div>\n<h3 id=\"jsoncssextractionstrategy\">JsonCssExtractionStrategy</h3>\n<p>Used for CSS selector-based structured data extraction.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">JsonCssExtractionStrategy(\n    schema: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">Any</span>],    <span class=\"hljs-comment\"># Extraction schema</span>\n    verbose: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>      <span class=\"hljs-comment\"># Enable verbose logging</span>\n)\n\n<span class=\"hljs-comment\"># Schema Structure</span>\nschema = {\n    <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-built_in\">str</span>,              <span class=\"hljs-comment\"># Schema name</span>\n    <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-built_in\">str</span>,      <span class=\"hljs-comment\"># Base CSS selector</span>\n    <span class=\"hljs-string\">\"fields\"</span>: [               <span class=\"hljs-comment\"># List of fields to extract</span>\n        {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-built_in\">str</span>,      <span class=\"hljs-comment\"># Field name</span>\n            <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-built_in\">str</span>,  <span class=\"hljs-comment\"># CSS selector</span>\n            <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-built_in\">str</span>,     <span class=\"hljs-comment\"># Field type: \"text\", \"attribute\", \"html\", \"regex\"</span>\n            <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-built_in\">str</span>, <span class=\"hljs-comment\"># For type=\"attribute\"</span>\n            <span class=\"hljs-string\">\"pattern\"</span>: <span class=\"hljs-built_in\">str</span>,  <span class=\"hljs-comment\"># For type=\"regex\"</span>\n            <span class=\"hljs-string\">\"transform\"</span>: <span class=\"hljs-built_in\">str</span>, <span class=\"hljs-comment\"># Optional: \"lowercase\", \"uppercase\", \"strip\"</span>\n            <span class=\"hljs-string\">\"default\"</span>: <span class=\"hljs-type\">Any</span>    <span class=\"hljs-comment\"># Default value if extraction fails</span>\n        }\n    ]\n}\n</code></pre></div>\n<h2 id=\"chunking-strategies\">Chunking Strategies</h2>\n<p>All chunking strategies inherit from <code>ChunkingStrategy</code> and implement the <code>chunk(text: str) -&gt; list</code> method.</p>\n<h3 id=\"regexchunking\">RegexChunking</h3>\n<p>Splits text based on regex patterns.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">RegexChunking(\n    patterns: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># Regex patterns for splitting</span>\n                               <span class=\"hljs-comment\"># Default: [r'\\n\\n']</span>\n)\n</code></pre></div>\n<h3 id=\"slidingwindowchunking\">SlidingWindowChunking</h3>\n<p>Creates overlapping chunks with a sliding window approach.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-perl\">SlidingWindowChunking(\n    window_size: <span class=\"hljs-keyword\">int</span> = <span class=\"hljs-number\">100</span>,    <span class=\"hljs-comment\"># Window size in words</span>\n    step: <span class=\"hljs-keyword\">int</span> = <span class=\"hljs-number\">50</span>             <span class=\"hljs-comment\"># Step size between windows</span>\n)\n</code></pre></div>\n<h3 id=\"overlappingwindowchunking\">OverlappingWindowChunking</h3>\n<p>Creates chunks with specified overlap.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-yaml\"><span class=\"hljs-string\">OverlappingWindowChunking(</span>\n    <span class=\"hljs-attr\">window_size:</span> <span class=\"hljs-string\">int</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-number\">1000</span><span class=\"hljs-string\">,</span>   <span class=\"hljs-comment\"># Chunk size in words</span>\n    <span class=\"hljs-attr\">overlap:</span> <span class=\"hljs-string\">int</span> <span class=\"hljs-string\">=</span> <span class=\"hljs-number\">100</span>         <span class=\"hljs-comment\"># Overlap size in words</span>\n<span class=\"hljs-string\">)</span>\n</code></pre></div>\n<h2 id=\"usage-examples\">Usage Examples</h2>\n<h3 id=\"llm-extraction\">LLM Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> pydantic <span class=\"hljs-keyword\">import</span> BaseModel\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> LLMExtractionStrategy\n\n<span class=\"hljs-comment\"># Define schema</span>\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Article</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    title: <span class=\"hljs-built_in\">str</span>\n    content: <span class=\"hljs-built_in\">str</span>\n    author: <span class=\"hljs-built_in\">str</span>\n\n<span class=\"hljs-comment\"># Create strategy</span>\nstrategy = LLMExtractionStrategy(\n    provider=<span class=\"hljs-string\">\"ollama/llama2\"</span>,\n    schema=Article.schema(),\n    instruction=<span class=\"hljs-string\">\"Extract article details\"</span>\n)\n\n<span class=\"hljs-comment\"># Use with crawler</span>\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com/article\"</span>,\n    extraction_strategy=strategy\n)\n\n<span class=\"hljs-comment\"># Access extracted data</span>\ndata = json.loads(result.extracted_content)\n</code></pre></div>\n<h3 id=\"css-extraction\">CSS Extraction</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n\n<span class=\"hljs-comment\"># Define schema</span>\nschema = {\n    <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Product List\"</span>,\n    <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\".product-card\"</span>,\n    <span class=\"hljs-string\">\"fields\"</span>: [\n        {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2.title\"</span>,\n            <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n        },\n        {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"price\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\".price\"</span>,\n            <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>,\n            <span class=\"hljs-string\">\"transform\"</span>: <span class=\"hljs-string\">\"strip\"</span>\n        },\n        {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"image\"</span>,\n            <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"img\"</span>,\n            <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>,\n            <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"src\"</span>\n        }\n    ]\n}\n\n<span class=\"hljs-comment\"># Create and use strategy</span>\nstrategy = JsonCssExtractionStrategy(schema)\nresult = await crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com/products\"</span>,\n    extraction_strategy=strategy\n)\n</code></pre></div>\n<h3 id=\"content-chunking\">Content Chunking</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">from crawl4ai.chunking_strategy import OverlappingWindowChunking\n\n<span class=\"hljs-comment\"># Create chunking strategy</span>\nchunker = OverlappingWindowChunking(\n    window_size=500,  <span class=\"hljs-comment\"># 500 words per chunk</span>\n    overlap=50        <span class=\"hljs-comment\"># 50 words overlap</span>\n)\n\n<span class=\"hljs-comment\"># Use with extraction strategy</span>\nstrategy = LLMExtractionStrategy(\n    provider=<span class=\"hljs-string\">\"ollama/llama2\"</span>,\n    chunking_strategy=chunker\n)\n\nresult = await crawler.arun(\n    url=<span class=\"hljs-string\">\"https://example.com/long-article\"</span>,\n    extraction_strategy=strategy\n)\n</code></pre></div>\n<h2 id=\"best-practices\">Best Practices</h2>\n<p>1.\u2000<strong>Choose the Right Strategy</strong>\n   - Use <code>LLMExtractionStrategy</code> for complex, unstructured content\n   - Use <code>JsonCssExtractionStrategy</code> for well-structured HTML\n   - Use <code>CosineStrategy</code> for content similarity and clustering</p>\n<p>2.\u2000<strong>Optimize Chunking</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\"><span class=\"hljs-comment\"># For long documents</span>\nstrategy = LLMExtractionStrategy(\n    chunk_token_threshold=2000,  <span class=\"hljs-comment\"># Smaller chunks</span>\n    overlap_rate=0.1           <span class=\"hljs-comment\"># 10% overlap</span>\n)\n</code></pre></div><p></p>\n<p>3.\u2000<strong>Handle Errors</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">try</span>:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n        url=<span class=\"hljs-string\">\"https://example.com\"</span>,\n        extraction_strategy=strategy\n    )\n    <span class=\"hljs-keyword\">if</span> result.success:\n        content = json.loads(result.extracted_content)\n<span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Extraction failed: <span class=\"hljs-subst\">{e}</span>\"</span>)\n</code></pre></div><p></p>\n<p>4.\u2000<strong>Monitor Performance</strong>\n   </p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">strategy <span class=\"hljs-punctuation\">=</span> CosineStrategy<span class=\"hljs-punctuation\">(</span>\n    verbose<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,  <span class=\"hljs-comment\"># Enable logging</span>\n    word_count_threshold<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">20</span>,  <span class=\"hljs-comment\"># Filter short content</span>\n    top_k<span class=\"hljs-punctuation\">=</span><span class=\"hljs-number\">5</span>  <span class=\"hljs-comment\"># Limit results</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div><p></p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
      "markdown": "# Extraction & Chunking Strategies API\nThis documentation covers the API reference for extraction and chunking strategies in Crawl4AI.\n## Extraction Strategies\nAll extraction strategies inherit from the base `ExtractionStrategy` class and implement two key methods: - `extract(url: str, html: str) -> List[Dict[str, Any]]` - `run(url: str, sections: List[str]) -> List[Dict[str, Any]]`\n### LLMExtractionStrategy\nUsed for extracting structured data using Language Models.\n```\nLLMExtractionStrategy(\n  # Required Parameters\n  provider: str = DEFAULT_PROVIDER,   # LLM provider (e.g., \"ollama/llama2\")\n  api_token: Optional[str] = None,   # API token\n  # Extraction Configuration\n  instruction: str = None,       # Custom extraction instruction\n  schema: Dict = None,         # Pydantic model schema for structured data\n  extraction_type: str = \"block\",    # \"block\" or \"schema\"\n  # Chunking Parameters\n  chunk_token_threshold: int = 4000,  # Maximum tokens per chunk\n  overlap_rate: float = 0.1,      # Overlap between chunks\n  word_token_rate: float = 0.75,    # Word to token conversion rate\n  apply_chunking: bool = True,     # Enable/disable chunking\n  # API Configuration\n  base_url: str = None,        # Base URL for API\n  extra_args: Dict = {},        # Additional provider arguments\n  verbose: bool = False        # Enable verbose logging\n)\n\n```\n\n### CosineStrategy\nUsed for content similarity-based extraction and clustering.\n```\nCosineStrategy(\n  # Content Filtering\n  semantic_filter: str = None,    # Topic/keyword filter\n  word_count_threshold: int = 10,   # Minimum words per cluster\n  sim_threshold: float = 0.3,     # Similarity threshold\n  # Clustering Parameters\n  max_dist: float = 0.2,       # Maximum cluster distance\n  linkage_method: str = 'ward',    # Clustering method\n  top_k: int = 3,          # Top clusters to return\n  # Model Configuration\n  model_name: str = 'sentence-transformers/all-MiniLM-L6-v2', # Embedding model\n  verbose: bool = False       # Enable verbose logging\n)\n\n```\n\n### JsonCssExtractionStrategy\nUsed for CSS selector-based structured data extraction.\n```\nJsonCssExtractionStrategy(\n  schema: Dict[str, Any],  # Extraction schema\n  verbose: bool = False   # Enable verbose logging\n)\n# Schema Structure\nschema = {\n  \"name\": str,       # Schema name\n  \"baseSelector\": str,   # Base CSS selector\n  \"fields\": [        # List of fields to extract\n    {\n      \"name\": str,   # Field name\n      \"selector\": str, # CSS selector\n      \"type\": str,   # Field type: \"text\", \"attribute\", \"html\", \"regex\"\n      \"attribute\": str, # For type=\"attribute\"\n      \"pattern\": str, # For type=\"regex\"\n      \"transform\": str, # Optional: \"lowercase\", \"uppercase\", \"strip\"\n      \"default\": Any  # Default value if extraction fails\n    }\n  ]\n}\n\n```\n\n## Chunking Strategies\nAll chunking strategies inherit from `ChunkingStrategy` and implement the `chunk(text: str) -> list` method.\n### RegexChunking\nSplits text based on regex patterns.\n```\nRegexChunking(\n  patterns: List[str] = None # Regex patterns for splitting\n                # Default: [r'\\n\\n']\n)\n\n```\n\n### SlidingWindowChunking\nCreates overlapping chunks with a sliding window approach.\n```\nSlidingWindowChunking(\n  window_size: int = 100,  # Window size in words\n  step: int = 50       # Step size between windows\n)\n\n```\n\n### OverlappingWindowChunking\nCreates chunks with specified overlap.\n```\nOverlappingWindowChunking(\n  window_size: int = 1000,  # Chunk size in words\n  overlap: int = 100     # Overlap size in words\n)\n\n```\n\n## Usage Examples\n### LLM Extraction\n```\nfrom pydantic import BaseModel\nfrom crawl4ai.extraction_strategy import LLMExtractionStrategy\n# Define schema\nclass Article(BaseModel):\n  title: str\n  content: str\n  author: str\n# Create strategy\nstrategy = LLMExtractionStrategy(\n  provider=\"ollama/llama2\",\n  schema=Article.schema(),\n  instruction=\"Extract article details\"\n)\n# Use with crawler\nresult = await crawler.arun(\n  url=\"https://example.com/article\",\n  extraction_strategy=strategy\n)\n# Access extracted data\ndata = json.loads(result.extracted_content)\n\n```\n\n### CSS Extraction\n```\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n# Define schema\nschema = {\n  \"name\": \"Product List\",\n  \"baseSelector\": \".product-card\",\n  \"fields\": [\n    {\n      \"name\": \"title\",\n      \"selector\": \"h2.title\",\n      \"type\": \"text\"\n    },\n    {\n      \"name\": \"price\",\n      \"selector\": \".price\",\n      \"type\": \"text\",\n      \"transform\": \"strip\"\n    },\n    {\n      \"name\": \"image\",\n      \"selector\": \"img\",\n      \"type\": \"attribute\",\n      \"attribute\": \"src\"\n    }\n  ]\n}\n# Create and use strategy\nstrategy = JsonCssExtractionStrategy(schema)\nresult = await crawler.arun(\n  url=\"https://example.com/products\",\n  extraction_strategy=strategy\n)\n\n```\n\n### Content Chunking\n```\nfrom crawl4ai.chunking_strategy import OverlappingWindowChunking\n# Create chunking strategy\nchunker = OverlappingWindowChunking(\n  window_size=500, # 500 words per chunk\n  overlap=50    # 50 words overlap\n)\n# Use with extraction strategy\nstrategy = LLMExtractionStrategy(\n  provider=\"ollama/llama2\",\n  chunking_strategy=chunker\n)\nresult = await crawler.arun(\n  url=\"https://example.com/long-article\",\n  extraction_strategy=strategy\n)\n\n```\n\n## Best Practices\n1. **Choose the Right Strategy** - Use `LLMExtractionStrategy` for complex, unstructured content - Use `JsonCssExtractionStrategy` for well-structured HTML - Use `CosineStrategy` for content similarity and clustering\n2. **Optimize Chunking**\n```\n# For long documents\nstrategy = LLMExtractionStrategy(\n  chunk_token_threshold=2000, # Smaller chunks\n  overlap_rate=0.1      # 10% overlap\n)\n\n```\n\n3. **Handle Errors**\n```\ntry:\n  result = await crawler.arun(\n    url=\"https://example.com\",\n    extraction_strategy=strategy\n  )\n  if result.success:\n    content = json.loads(result.extracted_content)\nexcept Exception as e:\n  print(f\"Extraction failed: {e}\")\n\n```\n\n4. **Monitor Performance**\n```\nstrategy = CosineStrategy(\n  verbose=True, # Enable logging\n  word_count_threshold=20, # Filter short content\n  top_k=5 # Limit results\n)\n\n```\n\n##### Search\nxClose\nType to start searching\n",
      "links": [
        "https://docs.crawl4ai.com",
        "https://docs.crawl4ai.com/advanced/advanced-features",
        "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
        "https://docs.crawl4ai.com/advanced/file-downloading",
        "https://docs.crawl4ai.com/advanced/hooks-auth",
        "https://docs.crawl4ai.com/advanced/identity-based-crawling",
        "https://docs.crawl4ai.com/advanced/lazy-loading",
        "https://docs.crawl4ai.com/advanced/multi-url-crawling",
        "https://docs.crawl4ai.com/advanced/proxy-security",
        "https://docs.crawl4ai.com/advanced/session-management",
        "https://docs.crawl4ai.com/advanced/ssl-certificate",
        "https://docs.crawl4ai.com/arun",
        "https://docs.crawl4ai.com/arun_many",
        "https://docs.crawl4ai.com/async-webcrawler",
        "https://docs.crawl4ai.com/blog",
        "https://docs.crawl4ai.com/core/browser-crawler-config",
        "https://docs.crawl4ai.com/core/cache-modes",
        "https://docs.crawl4ai.com/core/content-selection",
        "https://docs.crawl4ai.com/core/crawler-result",
        "https://docs.crawl4ai.com/core/docker-deploymeny",
        "https://docs.crawl4ai.com/core/fit-markdown",
        "https://docs.crawl4ai.com/core/installation",
        "https://docs.crawl4ai.com/core/link-media",
        "https://docs.crawl4ai.com/core/local-files",
        "https://docs.crawl4ai.com/core/markdown-generation",
        "https://docs.crawl4ai.com/core/page-interaction",
        "https://docs.crawl4ai.com/core/quickstart",
        "https://docs.crawl4ai.com/core/simple-crawling",
        "https://docs.crawl4ai.com/crawl-result",
        "https://docs.crawl4ai.com/extraction/chunking",
        "https://docs.crawl4ai.com/extraction/clustring-strategies",
        "https://docs.crawl4ai.com/extraction/llm-strategies",
        "https://docs.crawl4ai.com/extraction/no-llm-strategies",
        "https://docs.crawl4ai.com/parameters"
      ],
      "depth": 1,
      "stats": {
        "processed": 12,
        "total": 0,
        "depth": 1,
        "elapsed": "0:00:15",
        "page_limit": 34
      }
    }
  }
]