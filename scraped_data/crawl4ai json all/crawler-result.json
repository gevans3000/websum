{
  "url": "https://docs.crawl4ai.com/core/crawler-result",
  "timestamp": "2025-02-06T13:23:37.802018",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"üöÄü§ñ Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/crawler-result/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Crawler Result - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Crawler Result</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#crawl-result-and-output\">Crawl Result and Output</a></li>\n        <li><a href=\"#1-the-crawlresult-model\">1. The CrawlResult Model</a></li><li><a href=\"#2-html-variants\">2. HTML Variants</a></li><li><a href=\"#3-markdown-generation\">3. Markdown Generation</a></li><li><a href=\"#4-structured-extraction-extracted_content\">4. Structured Extraction: extracted_content</a></li><li><a href=\"#5-more-fields-links-media-and-more\">5. More Fields: Links, Media, and More</a></li><li><a href=\"#6-accessing-these-fields\">6. Accessing These Fields</a></li><li><a href=\"#7-next-steps\">7. Next Steps</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"crawl-result-and-output\">Crawl Result and Output</h1>\n<p>When you call <code>arun()</code> on a page, Crawl4AI returns a <strong><code>CrawlResult</code></strong> object containing everything you might need‚Äîraw HTML, a cleaned version, optional screenshots or PDFs, structured extraction results, and more. This document explains those fields and how they map to different output types.  </p>\n<hr>\n<h2 id=\"1-the-crawlresult-model\">1. The <code>CrawlResult</code> Model</h2>\n<p>Below is the core schema. Each field captures a different aspect of the crawl‚Äôs result:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MarkdownGenerationResult</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    raw_markdown: <span class=\"hljs-built_in\">str</span>\n    markdown_with_citations: <span class=\"hljs-built_in\">str</span>\n    references_markdown: <span class=\"hljs-built_in\">str</span>\n    fit_markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    fit_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n\n<span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CrawlResult</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):\n    url: <span class=\"hljs-built_in\">str</span>\n    html: <span class=\"hljs-built_in\">str</span>\n    success: <span class=\"hljs-built_in\">bool</span>\n    cleaned_html: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    media: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    links: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">Dict</span>]] = {}\n    downloaded_files: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">str</span>]] = <span class=\"hljs-literal\">None</span>\n    screenshot: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    pdf : <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">bytes</span>] = <span class=\"hljs-literal\">None</span>\n    markdown: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">Union</span>[<span class=\"hljs-built_in\">str</span>, MarkdownGenerationResult]] = <span class=\"hljs-literal\">None</span>\n    markdown_v2: <span class=\"hljs-type\">Optional</span>[MarkdownGenerationResult] = <span class=\"hljs-literal\">None</span>\n    extracted_content: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    metadata: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    error_message: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    session_id: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">str</span>] = <span class=\"hljs-literal\">None</span>\n    response_headers: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">dict</span>] = <span class=\"hljs-literal\">None</span>\n    status_code: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>\n    ssl_certificate: <span class=\"hljs-type\">Optional</span>[SSLCertificate] = <span class=\"hljs-literal\">None</span>\n    <span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Config</span>:\n        arbitrary_types_allowed = <span class=\"hljs-literal\">True</span>\n</code></pre></div>\n<h3 id=\"table-key-fields-in-crawlresult\">Table: Key Fields in <code>CrawlResult</code></h3>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Field (Name &amp; Type)</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>url (<code>str</code>)</strong></td>\n<td>The final or actual URL crawled (in case of redirects).</td>\n</tr>\n<tr>\n<td><strong>html (<code>str</code>)</strong></td>\n<td>Original, unmodified page HTML. Good for debugging or custom processing.</td>\n</tr>\n<tr>\n<td><strong>success (<code>bool</code>)</strong></td>\n<td><code>True</code> if the crawl completed without major errors, else <code>False</code>.</td>\n</tr>\n<tr>\n<td><strong>cleaned_html (<code>Optional[str]</code>)</strong></td>\n<td>Sanitized HTML with scripts/styles removed; can exclude tags if configured via <code>excluded_tags</code> etc.</td>\n</tr>\n<tr>\n<td><strong>media (<code>Dict[str, List[Dict]]</code>)</strong></td>\n<td>Extracted media info (images, audio, etc.), each with attributes like <code>src</code>, <code>alt</code>, <code>score</code>, etc.</td>\n</tr>\n<tr>\n<td><strong>links (<code>Dict[str, List[Dict]]</code>)</strong></td>\n<td>Extracted link data, split by <code>internal</code> and <code>external</code>. Each link usually has <code>href</code>, <code>text</code>, etc.</td>\n</tr>\n<tr>\n<td><strong>downloaded_files (<code>Optional[List[str]]</code>)</strong></td>\n<td>If <code>accept_downloads=True</code> in <code>BrowserConfig</code>, this lists the filepaths of saved downloads.</td>\n</tr>\n<tr>\n<td><strong>screenshot (<code>Optional[str]</code>)</strong></td>\n<td>Screenshot of the page (base64-encoded) if <code>screenshot=True</code>.</td>\n</tr>\n<tr>\n<td><strong>pdf (<code>Optional[bytes]</code>)</strong></td>\n<td>PDF of the page if <code>pdf=True</code>.</td>\n</tr>\n<tr>\n<td><strong>markdown (<code>Optional[str or MarkdownGenerationResult]</code>)</strong></td>\n<td>For now, <code>markdown_v2</code> holds a <code>MarkdownGenerationResult</code>. Over time, this will be consolidated into <code>markdown</code>. The generator can provide raw markdown, citations, references, and optionally <code>fit_markdown</code>.</td>\n</tr>\n<tr>\n<td><strong>markdown_v2 (<code>Optional[MarkdownGenerationResult]</code>)</strong></td>\n<td>Legacy field for detailed markdown output. This will be replaced by <code>markdown</code> soon.</td>\n</tr>\n<tr>\n<td><strong>extracted_content (<code>Optional[str]</code>)</strong></td>\n<td>The output of a structured extraction (CSS/LLM-based) stored as JSON string or other text.</td>\n</tr>\n<tr>\n<td><strong>metadata (<code>Optional[dict]</code>)</strong></td>\n<td>Additional info about the crawl or extracted data.</td>\n</tr>\n<tr>\n<td><strong>error_message (<code>Optional[str]</code>)</strong></td>\n<td>If <code>success=False</code>, contains a short description of what went wrong.</td>\n</tr>\n<tr>\n<td><strong>session_id (<code>Optional[str]</code>)</strong></td>\n<td>The ID of the session used for multi-page or persistent crawling.</td>\n</tr>\n<tr>\n<td><strong>response_headers (<code>Optional[dict]</code>)</strong></td>\n<td>HTTP response headers, if captured.</td>\n</tr>\n<tr>\n<td><strong>status_code (<code>Optional[int]</code>)</strong></td>\n<td>HTTP status code (e.g., 200 for OK).</td>\n</tr>\n<tr>\n<td><strong>ssl_certificate (<code>Optional[SSLCertificate]</code>)</strong></td>\n<td>SSL certificate info if <code>fetch_ssl_certificate=True</code>.</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"2-html-variants\">2. HTML Variants</h2>\n<h3 id=\"html-raw-html\"><code>html</code>: Raw HTML</h3>\n<p>Crawl4AI preserves the exact HTML as <code>result.html</code>. Useful for:</p>\n<ul>\n<li>Debugging page issues or checking the original content.</li>\n<li>Performing your own specialized parse if needed.</li>\n</ul>\n<h3 id=\"cleaned_html-sanitized\"><code>cleaned_html</code>: Sanitized</h3>\n<p>If you specify any cleanup or exclusion parameters in <code>CrawlerRunConfig</code> (like <code>excluded_tags</code>, <code>remove_forms</code>, etc.), you‚Äôll see the result here:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-lua\"><span class=\"hljs-built_in\">config</span> = CrawlerRunConfig(\n    excluded_tags=[<span class=\"hljs-string\">\"form\"</span>, <span class=\"hljs-string\">\"header\"</span>, <span class=\"hljs-string\">\"footer\"</span>],\n    keep_data_attributes=False\n)\nresult = await crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>, <span class=\"hljs-built_in\">config</span>=<span class=\"hljs-built_in\">config</span>)\n<span class=\"hljs-built_in\">print</span>(result.cleaned_html)  # Freed of forms, header, footer, data-* attributes\n</code></pre></div>\n<hr>\n<h2 id=\"3-markdown-generation\">3. Markdown Generation</h2>\n<h3 id=\"31-markdown_v2-legacy-vs-markdown\">3.1 <code>markdown_v2</code> (Legacy) vs <code>markdown</code></h3>\n<ul>\n<li><strong><code>markdown_v2</code></strong>: The current location for detailed markdown output, returning a <strong><code>MarkdownGenerationResult</code></strong> object.  </li>\n<li><strong><code>markdown</code></strong>: Eventually, we‚Äôre merging these fields. For now, you might see <code>result.markdown_v2</code> used widely in code examples.</li>\n</ul>\n<p><strong><code>MarkdownGenerationResult</code></strong> Fields:</p>\n<table class=\"table table-striped table-hover\">\n<thead>\n<tr>\n<th>Field</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>raw_markdown</strong></td>\n<td>The basic HTML‚ÜíMarkdown conversion.</td>\n</tr>\n<tr>\n<td><strong>markdown_with_citations</strong></td>\n<td>Markdown including inline citations that reference links at the end.</td>\n</tr>\n<tr>\n<td><strong>references_markdown</strong></td>\n<td>The references/citations themselves (if <code>citations=True</code>).</td>\n</tr>\n<tr>\n<td><strong>fit_markdown</strong></td>\n<td>The filtered/‚Äúfit‚Äù markdown if a content filter was used.</td>\n</tr>\n<tr>\n<td><strong>fit_html</strong></td>\n<td>The filtered HTML that generated <code>fit_markdown</code>.</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"32-basic-example-with-a-markdown-generator\">3.2 Basic Example with a Markdown Generator</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.markdown_generation_strategy <span class=\"hljs-keyword\">import</span> DefaultMarkdownGenerator\n\nconfig = CrawlerRunConfig(\n    markdown_generator=DefaultMarkdownGenerator(\n        options={<span class=\"hljs-string\">\"citations\"</span>: <span class=\"hljs-literal\">True</span>, <span class=\"hljs-string\">\"body_width\"</span>: <span class=\"hljs-number\">80</span>}  <span class=\"hljs-comment\"># e.g. pass html2text style options</span>\n    )\n)\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=config)\n\nmd_res = result.markdown_v2  <span class=\"hljs-comment\"># or eventually 'result.markdown'</span>\n<span class=\"hljs-built_in\">print</span>(md_res.raw_markdown[:<span class=\"hljs-number\">500</span>])\n<span class=\"hljs-built_in\">print</span>(md_res.markdown_with_citations)\n<span class=\"hljs-built_in\">print</span>(md_res.references_markdown)\n</code></pre></div>\n<p><strong>Note</strong>: If you use a filter like <code>PruningContentFilter</code>, you‚Äôll get <code>fit_markdown</code> and <code>fit_html</code> as well.</p>\n<hr>\n<h2 id=\"4-structured-extraction-extracted_content\">4. Structured Extraction: <code>extracted_content</code></h2>\n<p>If you run a JSON-based extraction strategy (CSS, XPath, LLM, etc.), the structured data is <strong>not</strong> stored in <code>markdown</code>‚Äîit‚Äôs placed in <strong><code>result.extracted_content</code></strong> as a JSON string (or sometimes plain text).</p>\n<h3 id=\"example-css-extraction-with-raw-html\">Example: CSS Extraction with <code>raw://</code> HTML</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">import</span> json\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Example Items\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.item\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n    raw_html = <span class=\"hljs-string\">\"&lt;div class='item'&gt;&lt;h2&gt;Item 1&lt;/h2&gt;&lt;a href='https://example.com/item1'&gt;Link 1&lt;/a&gt;&lt;/div&gt;\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"raw://\"</span> + raw_html,\n            config=CrawlerRunConfig(\n                cache_mode=CacheMode.BYPASS,\n                extraction_strategy=JsonCssExtractionStrategy(schema)\n            )\n        )\n        data = json.loads(result.extracted_content)\n        <span class=\"hljs-built_in\">print</span>(data)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p>Here:\n- <code>url=\"raw://...\"</code> passes the HTML content directly, no network requests.<br>\n- The <strong>CSS</strong> extraction strategy populates <code>result.extracted_content</code> with the JSON array <code>[{\"title\": \"...\", \"link\": \"...\"}]</code>.</p>\n<hr>\n<h2 id=\"5-more-fields-links-media-and-more\">5. More Fields: Links, Media, and More</h2>\n<h3 id=\"51-links\">5.1 <code>links</code></h3>\n<p>A dictionary, typically with <code>\"internal\"</code> and <code>\"external\"</code> lists. Each entry might have <code>href</code>, <code>text</code>, <code>title</code>, etc. This is automatically captured if you haven‚Äôt disabled link extraction.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\"><span class=\"hljs-built_in\">print</span>(result.links[<span class=\"hljs-string\">\"internal\"</span>][:3])  <span class=\"hljs-comment\"># Show first 3 internal links</span>\n</code></pre></div>\n<h3 id=\"52-media\">5.2 <code>media</code></h3>\n<p>Similarly, a dictionary with <code>\"images\"</code>, <code>\"audio\"</code>, <code>\"video\"</code>, etc. Each item could include <code>src</code>, <code>alt</code>, <code>score</code>, and more, if your crawler is set to gather them.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\">images = result.media.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"images\"</span>, [])\n<span class=\"hljs-keyword\">for</span> img <span class=\"hljs-keyword\">in</span> images:\n    print(<span class=\"hljs-string\">\"Image URL:\"</span>, img[<span class=\"hljs-string\">\"src\"</span>], <span class=\"hljs-string\">\"Alt:\"</span>, img.<span class=\"hljs-keyword\">get</span>(<span class=\"hljs-string\">\"alt\"</span>))\n</code></pre></div>\n<h3 id=\"53-screenshot-and-pdf\">5.3 <code>screenshot</code> and <code>pdf</code></h3>\n<p>If you set <code>screenshot=True</code> or <code>pdf=True</code> in <strong><code>CrawlerRunConfig</code></strong>, then:</p>\n<ul>\n<li><code>result.screenshot</code> contains a base64-encoded PNG string.  </li>\n<li><code>result.pdf</code> contains raw PDF bytes (you can write them to a file).</li>\n</ul>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">\"page.pdf\"</span>, <span class=\"hljs-string\">\"wb\"</span>) <span class=\"hljs-keyword\">as</span> f:\n    f.write(result.pdf)\n</code></pre></div>\n<h3 id=\"54-ssl_certificate\">5.4 <code>ssl_certificate</code></h3>\n<p>If <code>fetch_ssl_certificate=True</code>, <code>result.ssl_certificate</code> holds details about the site‚Äôs SSL cert, such as issuer, validity dates, etc.</p>\n<hr>\n<h2 id=\"6-accessing-these-fields\">6. Accessing These Fields</h2>\n<p>After you run:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">result</span> = await crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=some_config)\n</code></pre></div>\n<p>Check any field:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-css\">if result<span class=\"hljs-selector-class\">.success</span>:\n    <span class=\"hljs-built_in\">print</span>(result.status_code, result.response_headers)\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Links found:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.<span class=\"hljs-built_in\">get</span>(<span class=\"hljs-string\">\"internal\"</span>, [])))\n    if result.markdown_v2:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown snippet:\"</span>, result.markdown_v2.raw_markdown[:<span class=\"hljs-number\">200</span>])\n    if result.extracted_content:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Structured JSON:\"</span>, result.extracted_content)\nelse:\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n</code></pre></div>\n<p><strong>Remember</strong>: Use <code>result.markdown_v2</code> for now. It will eventually become <code>result.markdown</code>.</p>\n<hr>\n<h2 id=\"7-next-steps\">7. Next Steps</h2>\n<ul>\n<li><strong>Markdown Generation</strong>: Dive deeper into how to configure <code>DefaultMarkdownGenerator</code> and various filters.  </li>\n<li><strong>Content Filtering</strong>: Learn how to use <code>BM25ContentFilter</code> and <code>PruningContentFilter</code>.</li>\n<li><strong>Session &amp; Hooks</strong>: If you want to manipulate the page or preserve state across multiple <code>arun()</code> calls, see the hooking or session docs.  </li>\n<li><strong>LLM Extraction</strong>: For complex or unstructured content requiring AI-driven parsing, check the LLM-based strategies doc.</li>\n</ul>\n<p><strong>Enjoy</strong> exploring all that <code>CrawlResult</code> offers‚Äîwhether you need raw HTML, sanitized output, markdown, or fully structured data, Crawl4AI has you covered!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Crawl Result and Output\nWhen you call `arun()` on a page, Crawl4AI returns a **`CrawlResult`**object containing everything you might need‚Äîraw HTML, a cleaned version, optional screenshots or PDFs, structured extraction results, and more. This document explains those fields and how they map to different output types.\n## 1. The `CrawlResult` Model\nBelow is the core schema. Each field captures a different aspect of the crawl‚Äôs result:\n```\nclass MarkdownGenerationResult(BaseModel):\n  raw_markdown: str\n  markdown_with_citations: str\n  references_markdown: str\n  fit_markdown: Optional[str] = None\n  fit_html: Optional[str] = None\nclass CrawlResult(BaseModel):\n  url: str\n  html: str\n  success: bool\n  cleaned_html: Optional[str] = None\n  media: Dict[str, List[Dict]] = {}\n  links: Dict[str, List[Dict]] = {}\n  downloaded_files: Optional[List[str]] = None\n  screenshot: Optional[str] = None\n  pdf : Optional[bytes] = None\n  markdown: Optional[Union[str, MarkdownGenerationResult]] = None\n  markdown_v2: Optional[MarkdownGenerationResult] = None\n  extracted_content: Optional[str] = None\n  metadata: Optional[dict] = None\n  error_message: Optional[str] = None\n  session_id: Optional[str] = None\n  response_headers: Optional[dict] = None\n  status_code: Optional[int] = None\n  ssl_certificate: Optional[SSLCertificate] = None\n  class Config:\n    arbitrary_types_allowed = True\n\n```\n\n### Table: Key Fields in `CrawlResult`\nField (Name & Type) | Description  \n---|---  \n**url (`str`)** | The final or actual URL crawled (in case of redirects).  \n**html (`str`)** | Original, unmodified page HTML. Good for debugging or custom processing.  \n**success (`bool`)** | `True` if the crawl completed without major errors, else `False`.  \n**cleaned_html (`Optional[str]`)** | Sanitized HTML with scripts/styles removed; can exclude tags if configured via `excluded_tags` etc.  \n**media (`Dict[str, List[Dict]]`)** | Extracted media info (images, audio, etc.), each with attributes like `src`, `alt`, `score`, etc.  \n**links (`Dict[str, List[Dict]]`)** | Extracted link data, split by `internal` and `external`. Each link usually has `href`, `text`, etc.  \n**downloaded_files (`Optional[List[str]]`)** | If `accept_downloads=True` in `BrowserConfig`, this lists the filepaths of saved downloads.  \n**screenshot (`Optional[str]`)** | Screenshot of the page (base64-encoded) if `screenshot=True`.  \n**pdf (`Optional[bytes]`)** | PDF of the page if `pdf=True`.  \n**markdown (`Optional[str or MarkdownGenerationResult]`)** | For now, `markdown_v2` holds a `MarkdownGenerationResult`. Over time, this will be consolidated into `markdown`. The generator can provide raw markdown, citations, references, and optionally `fit_markdown`.  \n**markdown_v2 (`Optional[MarkdownGenerationResult]`)** | Legacy field for detailed markdown output. This will be replaced by `markdown` soon.  \n**extracted_content (`Optional[str]`)** | The output of a structured extraction (CSS/LLM-based) stored as JSON string or other text.  \n**metadata (`Optional[dict]`)** | Additional info about the crawl or extracted data.  \n**error_message (`Optional[str]`)** | If `success=False`, contains a short description of what went wrong.  \n**session_id (`Optional[str]`)** | The ID of the session used for multi-page or persistent crawling.  \n**response_headers (`Optional[dict]`)** | HTTP response headers, if captured.  \n**status_code (`Optional[int]`)** | HTTP status code (e.g., 200 for OK).  \n**ssl_certificate (`Optional[SSLCertificate]`)** | SSL certificate info if `fetch_ssl_certificate=True`.  \n## 2. HTML Variants\n### `html`: Raw HTML\nCrawl4AI preserves the exact HTML as `result.html`. Useful for:\n  * Debugging page issues or checking the original content.\n  * Performing your own specialized parse if needed.\n\n\n### `cleaned_html`: Sanitized\nIf you specify any cleanup or exclusion parameters in `CrawlerRunConfig` (like `excluded_tags`, `remove_forms`, etc.), you‚Äôll see the result here:\n```\nconfig = CrawlerRunConfig(\n  excluded_tags=[\"form\", \"header\", \"footer\"],\n  keep_data_attributes=False\n)\nresult = await crawler.arun(\"https://example.com\", config=config)\nprint(result.cleaned_html) # Freed of forms, header, footer, data-* attributes\n\n```\n\n## 3. Markdown Generation\n### 3.1 `markdown_v2` (Legacy) vs `markdown`\n  * **`markdown_v2`**: The current location for detailed markdown output, returning a**`MarkdownGenerationResult`**object.\n  * **`markdown`**: Eventually, we‚Äôre merging these fields. For now, you might see`result.markdown_v2` used widely in code examples.\n\n\n**`MarkdownGenerationResult`**Fields:\nField | Description  \n---|---  \n**raw_markdown** | The basic HTML‚ÜíMarkdown conversion.  \n**markdown_with_citations** | Markdown including inline citations that reference links at the end.  \n**references_markdown** | The references/citations themselves (if `citations=True`).  \n**fit_markdown** | The filtered/‚Äúfit‚Äù markdown if a content filter was used.  \n**fit_html** | The filtered HTML that generated `fit_markdown`.  \n### 3.2 Basic Example with a Markdown Generator\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nfrom crawl4ai.markdown_generation_strategy import DefaultMarkdownGenerator\nconfig = CrawlerRunConfig(\n  markdown_generator=DefaultMarkdownGenerator(\n    options={\"citations\": True, \"body_width\": 80} # e.g. pass html2text style options\n  )\n)\nresult = await crawler.arun(url=\"https://example.com\", config=config)\nmd_res = result.markdown_v2 # or eventually 'result.markdown'\nprint(md_res.raw_markdown[:500])\nprint(md_res.markdown_with_citations)\nprint(md_res.references_markdown)\n\n```\n\n**Note** : If you use a filter like `PruningContentFilter`, you‚Äôll get `fit_markdown` and `fit_html` as well.\n## 4. Structured Extraction: `extracted_content`\nIf you run a JSON-based extraction strategy (CSS, XPath, LLM, etc.), the structured data is **not** stored in `markdown`‚Äîit‚Äôs placed in **`result.extracted_content`**as a JSON string (or sometimes plain text).\n### Example: CSS Extraction with `raw://` HTML\n```\nimport asyncio\nimport json\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  schema = {\n    \"name\": \"Example Items\",\n    \"baseSelector\": \"div.item\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  raw_html = \"<div class='item'><h2>Item 1</h2><a href='https://example.com/item1'>Link 1</a></div>\"\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"raw://\" + raw_html,\n      config=CrawlerRunConfig(\n        cache_mode=CacheMode.BYPASS,\n        extraction_strategy=JsonCssExtractionStrategy(schema)\n      )\n    )\n    data = json.loads(result.extracted_content)\n    print(data)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\nHere: - `url=\"raw://...\"` passes the HTML content directly, no network requests. - The **CSS** extraction strategy populates `result.extracted_content` with the JSON array `[{\"title\": \"...\", \"link\": \"...\"}]`.\n## 5. More Fields: Links, Media, and More\n### 5.1 `links`\nA dictionary, typically with `\"internal\"` and `\"external\"` lists. Each entry might have `href`, `text`, `title`, etc. This is automatically captured if you haven‚Äôt disabled link extraction.\n```\nprint(result.links[\"internal\"][:3]) # Show first 3 internal links\n\n```\n\n### 5.2 `media`\nSimilarly, a dictionary with `\"images\"`, `\"audio\"`, `\"video\"`, etc. Each item could include `src`, `alt`, `score`, and more, if your crawler is set to gather them.\n```\nimages = result.media.get(\"images\", [])\nfor img in images:\n  print(\"Image URL:\", img[\"src\"], \"Alt:\", img.get(\"alt\"))\n\n```\n\n### 5.3 `screenshot` and `pdf`\nIf you set `screenshot=True` or `pdf=True` in **`CrawlerRunConfig`**, then:\n  * `result.screenshot` contains a base64-encoded PNG string. \n  * `result.pdf` contains raw PDF bytes (you can write them to a file).\n\n\n```\nwith open(\"page.pdf\", \"wb\") as f:\n  f.write(result.pdf)\n\n```\n\n### 5.4 `ssl_certificate`\nIf `fetch_ssl_certificate=True`, `result.ssl_certificate` holds details about the site‚Äôs SSL cert, such as issuer, validity dates, etc.\n## 6. Accessing These Fields\nAfter you run:\n```\nresult = await crawler.arun(url=\"https://example.com\", config=some_config)\n\n```\n\nCheck any field:\n```\nif result.success:\n  print(result.status_code, result.response_headers)\n  print(\"Links found:\", len(result.links.get(\"internal\", [])))\n  if result.markdown_v2:\n    print(\"Markdown snippet:\", result.markdown_v2.raw_markdown[:200])\n  if result.extracted_content:\n    print(\"Structured JSON:\", result.extracted_content)\nelse:\n  print(\"Error:\", result.error_message)\n\n```\n\n**Remember** : Use `result.markdown_v2` for now. It will eventually become `result.markdown`.\n## 7. Next Steps\n  * **Markdown Generation** : Dive deeper into how to configure `DefaultMarkdownGenerator` and various filters. \n  * **Content Filtering** : Learn how to use `BM25ContentFilter` and `PruningContentFilter`.\n  * **Session & Hooks**: If you want to manipulate the page or preserve state across multiple `arun()` calls, see the hooking or session docs. \n  * **LLM Extraction** : For complex or unstructured content requiring AI-driven parsing, check the LLM-based strategies doc.\n\n\n**Enjoy** exploring all that `CrawlResult` offers‚Äîwhether you need raw HTML, sanitized output, markdown, or fully structured data, Crawl4AI has you covered!\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/browser-crawler-config",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/link-media",
    "https://docs.crawl4ai.com/local-files",
    "https://docs.crawl4ai.com/markdown-generation",
    "https://docs.crawl4ai.com/page-interaction",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 17,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:21",
    "page_limit": 34
  }
}