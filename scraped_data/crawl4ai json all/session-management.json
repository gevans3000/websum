{
  "url": "https://docs.crawl4ai.com/advanced/session-management",
  "timestamp": "2025-02-06T13:23:23.486502",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"ðŸš€ðŸ¤– Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/advanced/session-management/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Session Management - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../../core/quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Core</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../core/link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Session Management</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#session-management\">Session Management</a></li>\n        <li><a href=\"#basic-session-usage\">Basic Session Usage</a></li><li><a href=\"#dynamic-content-with-sessions\">Dynamic Content with Sessions</a></li><li><a href=\"#example-1-basic-session-based-crawling\">Example 1: Basic Session-Based Crawling</a></li><li><a href=\"#advanced-technique-1-custom-execution-hooks\">Advanced Technique 1: Custom Execution Hooks</a></li><li><a href=\"#advanced-technique-2-integrated-javascript-execution-and-waiting\">Advanced Technique 2: Integrated JavaScript Execution and Waiting</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"session-management\">Session Management</h1>\n<p>Session management in Crawl4AI is a powerful feature that allows you to maintain state across multiple requests, making it particularly suitable for handling complex multi-step crawling tasks. It enables you to reuse the same browser tab (or page object) across sequential actions and crawls, which is beneficial for:</p>\n<ul>\n<li><strong>Performing JavaScript actions before and after crawling.</strong></li>\n<li><strong>Executing multiple sequential crawls faster</strong> without needing to reopen tabs or allocate memory repeatedly.</li>\n</ul>\n<p><strong>Note:</strong> This feature is designed for sequential workflows and is not suitable for parallel operations.</p>\n<hr>\n<h4 id=\"basic-session-usage\">Basic Session Usage</h4>\n<p>Use <code>BrowserConfig</code> and <code>CrawlerRunConfig</code> to maintain state with a <code>session_id</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-csharp\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs import BrowserConfig, <span class=\"hljs-function\">CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title\">AsyncWebCrawler</span>() <span class=\"hljs-keyword\">as</span> crawler:\n    session_id</span> = <span class=\"hljs-string\">\"my_session\"</span>\n\n    <span class=\"hljs-meta\"># Define configurations</span>\n    config1 = CrawlerRunConfig(\n        url=<span class=\"hljs-string\">\"https://example.com/page1\"</span>, session_id=session_id\n    )\n    config2 = CrawlerRunConfig(\n        url=<span class=\"hljs-string\">\"https://example.com/page2\"</span>, session_id=session_id\n    )\n\n    <span class=\"hljs-meta\"># First request</span>\n    result1 = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config1)\n\n    <span class=\"hljs-meta\"># Subsequent request using the same session</span>\n    result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config2)\n\n    <span class=\"hljs-meta\"># Clean up when done</span>\n    <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n</code></pre></div>\n<hr>\n<h4 id=\"dynamic-content-with-sessions\">Dynamic Content with Sessions</h4>\n<p>Here's an example of crawling GitHub commits across multiple pages while preserving session state:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n<span class=\"hljs-keyword\">from</span> crawl4ai.cache_context <span class=\"hljs-keyword\">import</span> CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_dynamic_content</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"github_commits_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>\n        all_commits = []\n\n        <span class=\"hljs-comment\"># Define extraction schema</span>\n        schema = {\n            <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Commit Extractor\"</span>,\n            <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"li.Box-sc-g0xbh4-0\"</span>,\n            <span class=\"hljs-string\">\"fields\"</span>: [{\n                <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h4.markdown-title\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>\n            }],\n        }\n        extraction_strategy = JsonCssExtractionStrategy(schema)\n\n        <span class=\"hljs-comment\"># JavaScript and wait configurations</span>\n        js_next_page = <span class=\"hljs-string\">\"\"\"document.querySelector('a[data-testid=\"pagination-next-button\"]').click();\"\"\"</span>\n        wait_for = <span class=\"hljs-string\">\"\"\"() =&gt; document.querySelectorAll('li.Box-sc-g0xbh4-0').length &gt; 0\"\"\"</span>\n\n        <span class=\"hljs-comment\"># Crawl multiple pages</span>\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                extraction_strategy=extraction_strategy,\n                js_code=js_next_page <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                wait_for=wait_for <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-keyword\">if</span> result.success:\n                commits = json.loads(result.extracted_content)\n                all_commits.extend(commits)\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(commits)}</span> commits\"</span>)\n\n        <span class=\"hljs-comment\"># Clean up session</span>\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n        <span class=\"hljs-keyword\">return</span> all_commits\n</code></pre></div>\n<hr>\n<h2 id=\"example-1-basic-session-based-crawling\">Example 1: Basic Session-Based Crawling</h2>\n<p>A simple example using session-based crawling:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> BrowserConfig, CrawlerRunConfig\n<span class=\"hljs-keyword\">from</span> crawl4ai.cache_context <span class=\"hljs-keyword\">import</span> CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">basic_session_crawl</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"dynamic_content_session\"</span>\n        url = <span class=\"hljs-string\">\"https://example.com/dynamic-content\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=<span class=\"hljs-string\">\"document.querySelector('.load-more-button').click();\"</span> <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\".content-item\"</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{result.extracted_content.count(<span class=\"hljs-string\">'.content-item'</span>)}</span> items\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(basic_session_crawl())\n</code></pre></div>\n<p>This example shows:\n1. Reusing the same <code>session_id</code> across multiple requests.\n2. Executing JavaScript to load more content dynamically.\n3. Properly closing the session to free resources.</p>\n<hr>\n<h2 id=\"advanced-technique-1-custom-execution-hooks\">Advanced Technique 1: Custom Execution Hooks</h2>\n<blockquote>\n<p>Warning: You might feel confused by the end of the next few examples ðŸ˜…, so make sure you are comfortable with the order of the parts before you start this.</p>\n</blockquote>\n<p>Use custom hooks to handle complex scenarios, such as waiting for content to load dynamically:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">advanced_session_crawl_with_hooks</span>():\n    first_commit = <span class=\"hljs-string\">\"\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">on_execution_started</span>(<span class=\"hljs-params\">page</span>):\n        <span class=\"hljs-keyword\">nonlocal</span> first_commit\n        <span class=\"hljs-keyword\">try</span>:\n            <span class=\"hljs-keyword\">while</span> <span class=\"hljs-literal\">True</span>:\n                <span class=\"hljs-keyword\">await</span> page.wait_for_selector(<span class=\"hljs-string\">\"li.commit-item h4\"</span>)\n                commit = <span class=\"hljs-keyword\">await</span> page.query_selector(<span class=\"hljs-string\">\"li.commit-item h4\"</span>)\n                commit = <span class=\"hljs-keyword\">await</span> commit.evaluate(<span class=\"hljs-string\">\"(element) =&gt; element.textContent\"</span>).strip()\n                <span class=\"hljs-keyword\">if</span> commit <span class=\"hljs-keyword\">and</span> commit != first_commit:\n                    first_commit = commit\n                    <span class=\"hljs-keyword\">break</span>\n                <span class=\"hljs-keyword\">await</span> asyncio.sleep(<span class=\"hljs-number\">0.5</span>)\n        <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Warning: New content didn't appear: <span class=\"hljs-subst\">{e}</span>\"</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"commit_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/example/repo/commits/main\"</span>\n        crawler.crawler_strategy.set_hook(<span class=\"hljs-string\">\"on_execution_started\"</span>, on_execution_started)\n\n        js_next_page = <span class=\"hljs-string\">\"\"\"document.querySelector('a.pagination-next').click();\"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=js_next_page <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\"li.commit-item\"</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.extracted_content)}</span> commits\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(advanced_session_crawl_with_hooks())\n</code></pre></div>\n<p>This technique ensures new content loads before the next action.</p>\n<hr>\n<h2 id=\"advanced-technique-2-integrated-javascript-execution-and-waiting\">Advanced Technique 2: Integrated JavaScript Execution and Waiting</h2>\n<p>Combine JavaScript execution and waiting logic for concise handling of dynamic content:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">integrated_js_and_wait_crawl</span>():\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        session_id = <span class=\"hljs-string\">\"integrated_session\"</span>\n        url = <span class=\"hljs-string\">\"https://github.com/example/repo/commits/main\"</span>\n\n        js_next_page_and_wait = <span class=\"hljs-string\">\"\"\"\n        (async () =&gt; {\n            const getCurrentCommit = () =&gt; document.querySelector('li.commit-item h4').textContent.trim();\n            const initialCommit = getCurrentCommit();\n            document.querySelector('a.pagination-next').click();\n            while (getCurrentCommit() === initialCommit) {\n                await new Promise(resolve =&gt; setTimeout(resolve, 100));\n            }\n        })();\n        \"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">3</span>):\n            config = CrawlerRunConfig(\n                url=url,\n                session_id=session_id,\n                js_code=js_next_page_and_wait <span class=\"hljs-keyword\">if</span> page &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>,\n                css_selector=<span class=\"hljs-string\">\"li.commit-item\"</span>,\n                js_only=page &gt; <span class=\"hljs-number\">0</span>,\n                cache_mode=CacheMode.BYPASS\n            )\n\n            result = <span class=\"hljs-keyword\">await</span> crawler.arun(config=config)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page + <span class=\"hljs-number\">1</span>}</span>: Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.extracted_content)}</span> commits\"</span>)\n\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\nasyncio.run(integrated_js_and_wait_crawl())\n</code></pre></div>\n<hr>\n<h4 id=\"common-use-cases-for-sessions\">Common Use Cases for Sessions</h4>\n<p>1.â€€<strong>Authentication Flows</strong>: Login and interact with secured pages.</p>\n<p>2.â€€<strong>Pagination Handling</strong>: Navigate through multiple pages.</p>\n<p>3.â€€<strong>Form Submissions</strong>: Fill forms, submit, and process results.</p>\n<p>4.â€€<strong>Multi-step Processes</strong>: Complete workflows that span multiple actions.</p>\n<p>5.â€€<strong>Dynamic Content Navigation</strong>: Handle JavaScript-rendered or event-triggered content.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Session Management\nSession management in Crawl4AI is a powerful feature that allows you to maintain state across multiple requests, making it particularly suitable for handling complex multi-step crawling tasks. It enables you to reuse the same browser tab (or page object) across sequential actions and crawls, which is beneficial for:\n  * **Performing JavaScript actions before and after crawling.**\n  * **Executing multiple sequential crawls faster** without needing to reopen tabs or allocate memory repeatedly.\n\n\n**Note:** This feature is designed for sequential workflows and is not suitable for parallel operations.\n#### Basic Session Usage\nUse `BrowserConfig` and `CrawlerRunConfig` to maintain state with a `session_id`:\n```\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\nasync with AsyncWebCrawler() as crawler:\n  session_id = \"my_session\"\n  # Define configurations\n  config1 = CrawlerRunConfig(\n    url=\"https://example.com/page1\", session_id=session_id\n  )\n  config2 = CrawlerRunConfig(\n    url=\"https://example.com/page2\", session_id=session_id\n  )\n  # First request\n  result1 = await crawler.arun(config=config1)\n  # Subsequent request using the same session\n  result2 = await crawler.arun(config=config2)\n  # Clean up when done\n  await crawler.crawler_strategy.kill_session(session_id)\n\n```\n\n#### Dynamic Content with Sessions\nHere's an example of crawling GitHub commits across multiple pages while preserving session state:\n```\nfrom crawl4ai.async_configs import CrawlerRunConfig\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nfrom crawl4ai.cache_context import CacheMode\nasync def crawl_dynamic_content():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"github_commits_session\"\n    url = \"https://github.com/microsoft/TypeScript/commits/main\"\n    all_commits = []\n    # Define extraction schema\n    schema = {\n      \"name\": \"Commit Extractor\",\n      \"baseSelector\": \"li.Box-sc-g0xbh4-0\",\n      \"fields\": [{\n        \"name\": \"title\", \"selector\": \"h4.markdown-title\", \"type\": \"text\"\n      }],\n    }\n    extraction_strategy = JsonCssExtractionStrategy(schema)\n    # JavaScript and wait configurations\n    js_next_page = \"\"\"document.querySelector('a[data-testid=\"pagination-next-button\"]').click();\"\"\"\n    wait_for = \"\"\"() => document.querySelectorAll('li.Box-sc-g0xbh4-0').length > 0\"\"\"\n    # Crawl multiple pages\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        extraction_strategy=extraction_strategy,\n        js_code=js_next_page if page > 0 else None,\n        wait_for=wait_for if page > 0 else None,\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      if result.success:\n        commits = json.loads(result.extracted_content)\n        all_commits.extend(commits)\n        print(f\"Page {page + 1}: Found {len(commits)} commits\")\n    # Clean up session\n    await crawler.crawler_strategy.kill_session(session_id)\n    return all_commits\n\n```\n\n## Example 1: Basic Session-Based Crawling\nA simple example using session-based crawling:\n```\nimport asyncio\nfrom crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\nfrom crawl4ai.cache_context import CacheMode\nasync def basic_session_crawl():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"dynamic_content_session\"\n    url = \"https://example.com/dynamic-content\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=\"document.querySelector('.load-more-button').click();\" if page > 0 else None,\n        css_selector=\".content-item\",\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {result.extracted_content.count('.content-item')} items\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(basic_session_crawl())\n\n```\n\nThis example shows: 1. Reusing the same `session_id` across multiple requests. 2. Executing JavaScript to load more content dynamically. 3. Properly closing the session to free resources.\n## Advanced Technique 1: Custom Execution Hooks\n> Warning: You might feel confused by the end of the next few examples ðŸ˜…, so make sure you are comfortable with the order of the parts before you start this.\nUse custom hooks to handle complex scenarios, such as waiting for content to load dynamically:\n```\nasync def advanced_session_crawl_with_hooks():\n  first_commit = \"\"\n  async def on_execution_started(page):\n    nonlocal first_commit\n    try:\n      while True:\n        await page.wait_for_selector(\"li.commit-item h4\")\n        commit = await page.query_selector(\"li.commit-item h4\")\n        commit = await commit.evaluate(\"(element) => element.textContent\").strip()\n        if commit and commit != first_commit:\n          first_commit = commit\n          break\n        await asyncio.sleep(0.5)\n    except Exception as e:\n      print(f\"Warning: New content didn't appear: {e}\")\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"commit_session\"\n    url = \"https://github.com/example/repo/commits/main\"\n    crawler.crawler_strategy.set_hook(\"on_execution_started\", on_execution_started)\n    js_next_page = \"\"\"document.querySelector('a.pagination-next').click();\"\"\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=js_next_page if page > 0 else None,\n        css_selector=\"li.commit-item\",\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {len(result.extracted_content)} commits\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(advanced_session_crawl_with_hooks())\n\n```\n\nThis technique ensures new content loads before the next action.\n## Advanced Technique 2: Integrated JavaScript Execution and Waiting\nCombine JavaScript execution and waiting logic for concise handling of dynamic content:\n```\nasync def integrated_js_and_wait_crawl():\n  async with AsyncWebCrawler() as crawler:\n    session_id = \"integrated_session\"\n    url = \"https://github.com/example/repo/commits/main\"\n    js_next_page_and_wait = \"\"\"\n    (async () => {\n      const getCurrentCommit = () => document.querySelector('li.commit-item h4').textContent.trim();\n      const initialCommit = getCurrentCommit();\n      document.querySelector('a.pagination-next').click();\n      while (getCurrentCommit() === initialCommit) {\n        await new Promise(resolve => setTimeout(resolve, 100));\n      }\n    })();\n    \"\"\"\n    for page in range(3):\n      config = CrawlerRunConfig(\n        url=url,\n        session_id=session_id,\n        js_code=js_next_page_and_wait if page > 0 else None,\n        css_selector=\"li.commit-item\",\n        js_only=page > 0,\n        cache_mode=CacheMode.BYPASS\n      )\n      result = await crawler.arun(config=config)\n      print(f\"Page {page + 1}: Found {len(result.extracted_content)} commits\")\n    await crawler.crawler_strategy.kill_session(session_id)\nasyncio.run(integrated_js_and_wait_crawl())\n\n```\n\n#### Common Use Cases for Sessions\n1. **Authentication Flows** : Login and interact with secured pages.\n2. **Pagination Handling** : Navigate through multiple pages.\n3. **Form Submissions** : Fill forms, submit, and process results.\n4. **Multi-step Processes** : Complete workflows that span multiple actions.\n5. **Dynamic Content Navigation** : Handle JavaScript-rendered or event-triggered content.\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced-features",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/core/browser-crawler-config",
    "https://docs.crawl4ai.com/core/cache-modes",
    "https://docs.crawl4ai.com/core/content-selection",
    "https://docs.crawl4ai.com/core/crawler-result",
    "https://docs.crawl4ai.com/core/docker-deploymeny",
    "https://docs.crawl4ai.com/core/fit-markdown",
    "https://docs.crawl4ai.com/core/installation",
    "https://docs.crawl4ai.com/core/link-media",
    "https://docs.crawl4ai.com/core/local-files",
    "https://docs.crawl4ai.com/core/markdown-generation",
    "https://docs.crawl4ai.com/core/page-interaction",
    "https://docs.crawl4ai.com/core/quickstart",
    "https://docs.crawl4ai.com/core/simple-crawling",
    "https://docs.crawl4ai.com/crawl-dispatcher",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/file-downloading",
    "https://docs.crawl4ai.com/hooks-auth",
    "https://docs.crawl4ai.com/identity-based-crawling",
    "https://docs.crawl4ai.com/lazy-loading",
    "https://docs.crawl4ai.com/multi-url-crawling",
    "https://docs.crawl4ai.com/proxy-security",
    "https://docs.crawl4ai.com/ssl-certificate"
  ],
  "depth": 1,
  "stats": {
    "processed": 5,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:07",
    "page_limit": 34
  }
}