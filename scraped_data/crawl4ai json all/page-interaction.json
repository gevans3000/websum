{
  "url": "https://docs.crawl4ai.com/core/page-interaction",
  "timestamp": "2025-02-06T13:23:46.458402",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"üöÄü§ñ Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/page-interaction/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Page Interaction - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Page Interaction</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#page-interaction\">Page Interaction</a></li>\n        <li><a href=\"#1-javascript-execution\">1. JavaScript Execution</a></li><li><a href=\"#2-wait-conditions\">2. Wait Conditions</a></li><li><a href=\"#3-handling-dynamic-content\">3. Handling Dynamic Content</a></li><li><a href=\"#4-timing-control\">4. Timing Control</a></li><li><a href=\"#5-multi-step-interaction-example\">5. Multi-Step Interaction Example</a></li><li><a href=\"#6-combine-interaction-with-extraction\">6. Combine Interaction with Extraction</a></li><li><a href=\"#7-relevant-crawlerrunconfig-parameters\">7. Relevant CrawlerRunConfig Parameters</a></li><li><a href=\"#8-conclusion\">8. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"page-interaction\">Page Interaction</h1>\n<p>Crawl4AI provides powerful features for interacting with <strong>dynamic</strong> webpages, handling JavaScript execution, waiting for conditions, and managing multi-step flows. By combining <strong>js_code</strong>, <strong>wait_for</strong>, and certain <strong>CrawlerRunConfig</strong> parameters, you can:</p>\n<ol>\n<li>Click ‚ÄúLoad More‚Äù buttons  </li>\n<li>Fill forms and submit them  </li>\n<li>Wait for elements or data to appear  </li>\n<li>Reuse sessions across multiple steps  </li>\n</ol>\n<p>Below is a quick overview of how to do it.</p>\n<hr>\n<h2 id=\"1-javascript-execution\">1. JavaScript Execution</h2>\n<h3 id=\"basic-execution\">Basic Execution</h3>\n<p><strong><code>js_code</code></strong> in <strong><code>CrawlerRunConfig</code></strong> accepts either a single JS string or a list of JS snippets.<br>\n<strong>Example</strong>: We‚Äôll scroll to the bottom of the page, then optionally click a ‚ÄúLoad More‚Äù button.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Single JS command</span>\n    config = CrawlerRunConfig(\n        js_code=<span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># Example site</span>\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawled length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n    <span class=\"hljs-comment\"># Multiple commands</span>\n    js_commands = [\n        <span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n        <span class=\"hljs-comment\"># 'More' link on Hacker News</span>\n        <span class=\"hljs-string\">\"document.querySelector('a.morelink')?.click();\"</span>,  \n    ]\n    config = CrawlerRunConfig(js_code=js_commands)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># Another pass</span>\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"After scroll+click, length:\"</span>, <span class=\"hljs-built_in\">len</span>(result.cleaned_html))\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Relevant <code>CrawlerRunConfig</code> params</strong>:\n- <strong><code>js_code</code></strong>: A string or list of strings with JavaScript to run after the page loads.\n- <strong><code>js_only</code></strong>: If set to <code>True</code> on subsequent calls, indicates we‚Äôre continuing an existing session without a new full navigation.<br>\n- <strong><code>session_id</code></strong>: If you want to keep the same page across multiple calls, specify an ID.</p>\n<hr>\n<h2 id=\"2-wait-conditions\">2. Wait Conditions</h2>\n<h3 id=\"21-css-based-waiting\">2.1 CSS-Based Waiting</h3>\n<p>Sometimes, you just want to wait for a specific element to appear. For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    config = CrawlerRunConfig(\n        <span class=\"hljs-comment\"># Wait for at least 30 items on Hacker News</span>\n        wait_for=<span class=\"hljs-string\">\"css:.athing:nth-child(30)\"</span>  \n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"We have at least 30 items loaded!\"</span>)\n        <span class=\"hljs-comment\"># Rough check</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Total items in HTML:\"</span>, result.cleaned_html.count(<span class=\"hljs-string\">\"athing\"</span>))  \n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key param</strong>:\n- <strong><code>wait_for=\"css:...\"</code></strong>: Tells the crawler to wait until that CSS selector is present.</p>\n<h3 id=\"22-javascript-based-waiting\">2.2 JavaScript-Based Waiting</h3>\n<p>For more complex conditions (e.g., waiting for content length to exceed a threshold), prefix <code>js:</code>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-ini\"><span class=\"hljs-attr\">wait_condition</span> = <span class=\"hljs-string\">\"\"\"() =&gt; {\n    const items = document.querySelectorAll('.athing');\n    return items.length &gt; 50;  // Wait for at least 51 items\n}\"\"\"</span>\n\n<span class=\"hljs-attr\">config</span> = CrawlerRunConfig(wait_for=f<span class=\"hljs-string\">\"js:{wait_condition}\"</span>)\n</code></pre></div>\n<p><strong>Behind the Scenes</strong>: Crawl4AI keeps polling the JS function until it returns <code>true</code> or a timeout occurs.</p>\n<hr>\n<h2 id=\"3-handling-dynamic-content\">3. Handling Dynamic Content</h2>\n<p>Many modern sites require <strong>multiple steps</strong>: scrolling, clicking ‚ÄúLoad More,‚Äù or updating via JavaScript. Below are typical patterns.</p>\n<h3 id=\"31-load-more-example-hacker-news-more-link\">3.1 Load More Example (Hacker News ‚ÄúMore‚Äù Link)</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Step 1: Load initial Hacker News page</span>\n    config = CrawlerRunConfig(\n        wait_for=<span class=\"hljs-string\">\"css:.athing:nth-child(30)\"</span>  <span class=\"hljs-comment\"># Wait for 30 items</span>\n    )\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,\n            config=config\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Initial items loaded.\"</span>)\n\n        <span class=\"hljs-comment\"># Step 2: Let's scroll and click the \"More\" link</span>\n        load_more_js = [\n            <span class=\"hljs-string\">\"window.scrollTo(0, document.body.scrollHeight);\"</span>,\n            <span class=\"hljs-comment\"># The \"More\" link at page bottom</span>\n            <span class=\"hljs-string\">\"document.querySelector('a.morelink')?.click();\"</span>  \n        ]\n\n        next_page_conf = CrawlerRunConfig(\n            js_code=load_more_js,\n            wait_for=<span class=\"hljs-string\">\"\"\"js:() =&gt; {\n                return document.querySelectorAll('.athing').length &gt; 30;\n            }\"\"\"</span>,\n            <span class=\"hljs-comment\"># Mark that we do not re-navigate, but run JS in the same session:</span>\n            js_only=<span class=\"hljs-literal\">True</span>,\n            session_id=<span class=\"hljs-string\">\"hn_session\"</span>\n        )\n\n        <span class=\"hljs-comment\"># Re-use the same crawler session</span>\n        result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://news.ycombinator.com\"</span>,  <span class=\"hljs-comment\"># same URL but continuing session</span>\n            config=next_page_conf\n        )\n        total_items = result2.cleaned_html.count(<span class=\"hljs-string\">\"athing\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Items after load-more:\"</span>, total_items)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key params</strong>:\n- <strong><code>session_id=\"hn_session\"</code></strong>: Keep the same page across multiple calls to <code>arun()</code>.\n- <strong><code>js_only=True</code></strong>: We‚Äôre not performing a full reload, just applying JS in the existing page.\n- <strong><code>wait_for</code></strong> with <code>js:</code>: Wait for item count to grow beyond 30.</p>\n<hr>\n<h3 id=\"32-form-interaction\">3.2 Form Interaction</h3>\n<p>If the site has a search or login form, you can fill fields and submit them with <strong><code>js_code</code></strong>. For instance, if GitHub had a local search form:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">js_form_interaction = <span class=\"hljs-string\">\"\"\"\ndocument.querySelector('#your-search').value = 'TypeScript commits';\ndocument.querySelector('form').submit();\n\"\"\"</span>\n\nconfig = CrawlerRunConfig(\n    js_code=js_form_interaction,\n    wait_for=<span class=\"hljs-string\">\"css:.commit\"</span>\n)\nresult = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://github.com/search\"</span>, config=config)\n</code></pre></div>\n<p><strong>In reality</strong>: Replace IDs or classes with the real site‚Äôs form selectors.</p>\n<hr>\n<h2 id=\"4-timing-control\">4. Timing Control</h2>\n<p>1.‚ÄÄ<strong><code>page_timeout</code></strong> (ms): Overall page load or script execution time limit.<br>\n2.‚ÄÄ<strong><code>delay_before_return_html</code></strong> (seconds): Wait an extra moment before capturing the final HTML.<br>\n3.‚ÄÄ<strong><code>mean_delay</code></strong> &amp; <strong><code>max_range</code></strong>: If you call <code>arun_many()</code> with multiple URLs, these add a random pause between each request.</p>\n<p><strong>Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">config = CrawlerRunConfig(\n    page_timeout=60000,  <span class=\"hljs-comment\"># 60s limit</span>\n    delay_before_return_html=2.5\n)\n</code></pre></div>\n<hr>\n<h2 id=\"5-multi-step-interaction-example\">5. Multi-Step Interaction Example</h2>\n<p>Below is a simplified script that does multiple ‚ÄúLoad More‚Äù clicks on GitHub‚Äôs TypeScript commits page. It <strong>re-uses</strong> the same session to accumulate new commits each time. The code includes the relevant <strong><code>CrawlerRunConfig</code></strong> parameters you‚Äôd rely on.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">multi_page_commits</span>():\n    browser_cfg = BrowserConfig(\n        headless=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Visible for demonstration</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n    session_id = <span class=\"hljs-string\">\"github_ts_commits\"</span>\n\n    base_wait = <span class=\"hljs-string\">\"\"\"js:() =&gt; {\n        const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n        return commits.length &gt; 0;\n    }\"\"\"</span>\n\n    <span class=\"hljs-comment\"># Step 1: Load initial commits</span>\n    config1 = CrawlerRunConfig(\n        wait_for=base_wait,\n        session_id=session_id,\n        cache_mode=CacheMode.BYPASS,\n        <span class=\"hljs-comment\"># Not using js_only yet since it's our first load</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_cfg) <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>,\n            config=config1\n        )\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Initial commits loaded. Count:\"</span>, result.cleaned_html.count(<span class=\"hljs-string\">\"commit\"</span>))\n\n        <span class=\"hljs-comment\"># Step 2: For subsequent pages, we run JS to click 'Next Page' if it exists</span>\n        js_next_page = <span class=\"hljs-string\">\"\"\"\n        const selector = 'a[data-testid=\"pagination-next-button\"]';\n        const button = document.querySelector(selector);\n        if (button) button.click();\n        \"\"\"</span>\n\n        <span class=\"hljs-comment\"># Wait until new commits appear</span>\n        wait_for_more = <span class=\"hljs-string\">\"\"\"js:() =&gt; {\n            const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n            if (!window.firstCommit &amp;&amp; commits.length&gt;0) {\n                window.firstCommit = commits[0].textContent;\n                return false;\n            }\n            // If top commit changes, we have new commits\n            const topNow = commits[0]?.textContent.trim();\n            return topNow &amp;&amp; topNow !== window.firstCommit;\n        }\"\"\"</span>\n\n        <span class=\"hljs-keyword\">for</span> page <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">2</span>):  <span class=\"hljs-comment\"># let's do 2 more \"Next\" pages</span>\n            config_next = CrawlerRunConfig(\n                session_id=session_id,\n                js_code=js_next_page,\n                wait_for=wait_for_more,\n                js_only=<span class=\"hljs-literal\">True</span>,       <span class=\"hljs-comment\"># We're continuing from the open tab</span>\n                cache_mode=CacheMode.BYPASS\n            )\n            result2 = <span class=\"hljs-keyword\">await</span> crawler.arun(\n                url=<span class=\"hljs-string\">\"https://github.com/microsoft/TypeScript/commits/main\"</span>,\n                config=config_next\n            )\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Page <span class=\"hljs-subst\">{page+<span class=\"hljs-number\">2</span>}</span> commits count:\"</span>, result2.cleaned_html.count(<span class=\"hljs-string\">\"commit\"</span>))\n\n        <span class=\"hljs-comment\"># Optionally kill session</span>\n        <span class=\"hljs-keyword\">await</span> crawler.crawler_strategy.kill_session(session_id)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-keyword\">await</span> multi_page_commits()\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<p><strong>Key Points</strong>:</p>\n<ul>\n<li><strong><code>session_id</code></strong>: Keep the same page open.  </li>\n<li><strong><code>js_code</code></strong> + <strong><code>wait_for</code></strong> + <strong><code>js_only=True</code></strong>: We do partial refreshes, waiting for new commits to appear.  </li>\n<li><strong><code>cache_mode=CacheMode.BYPASS</code></strong> ensures we always see fresh data each step.</li>\n</ul>\n<hr>\n<h2 id=\"6-combine-interaction-with-extraction\">6. Combine Interaction with Extraction</h2>\n<p>Once dynamic content is loaded, you can attach an <strong><code>extraction_strategy</code></strong> (like <code>JsonCssExtractionStrategy</code> or <code>LLMExtractionStrategy</code>). For example:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">schema</span> <span class=\"hljs-punctuation\">=</span> <span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"Commits\"</span>,\n    <span class=\"hljs-string\">\"baseSelector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"li.Box-sc-g0xbh4-0\"</span>,\n    <span class=\"hljs-string\">\"fields\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-punctuation\">[</span>\n        <span class=\"hljs-punctuation\">{</span><span class=\"hljs-string\">\"name\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"h4.markdown-title\"</span>, <span class=\"hljs-string\">\"type\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"text\"</span><span class=\"hljs-punctuation\">}</span>\n    <span class=\"hljs-punctuation\">]</span>\n<span class=\"hljs-punctuation\">}</span>\nconfig <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    session_id<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"ts_commits_session\"</span>,\n    js_code<span class=\"hljs-punctuation\">=</span>js_next_page,\n    wait_for<span class=\"hljs-punctuation\">=</span>wait_for_more,\n    extraction_strategy<span class=\"hljs-punctuation\">=</span>JsonCssExtractionStrategy<span class=\"hljs-punctuation\">(</span><span class=\"hljs-keyword\">schema</span><span class=\"hljs-punctuation\">)</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>When done, check <code>result.extracted_content</code> for the JSON.</p>\n<hr>\n<h2 id=\"7-relevant-crawlerrunconfig-parameters\">7. Relevant <code>CrawlerRunConfig</code> Parameters</h2>\n<p>Below are the key interaction-related parameters in <code>CrawlerRunConfig</code>. For a full list, see <a href=\"../../api/parameters/\">Configuration Parameters</a>.</p>\n<ul>\n<li><strong><code>js_code</code></strong>: JavaScript to run after initial load.  </li>\n<li><strong><code>js_only</code></strong>: If <code>True</code>, no new page navigation‚Äîonly JS in the existing session.  </li>\n<li><strong><code>wait_for</code></strong>: CSS (<code>\"css:...\"</code>) or JS (<code>\"js:...\"</code>) expression to wait for.  </li>\n<li><strong><code>session_id</code></strong>: Reuse the same page across calls.  </li>\n<li><strong><code>cache_mode</code></strong>: Whether to read/write from the cache or bypass.  </li>\n<li><strong><code>remove_overlay_elements</code></strong>: Remove certain popups automatically.  </li>\n<li><strong><code>simulate_user</code>, <code>override_navigator</code>, <code>magic</code></strong>: Anti-bot or ‚Äúhuman-like‚Äù interactions.</li>\n</ul>\n<hr>\n<h2 id=\"8-conclusion\">8. Conclusion</h2>\n<p>Crawl4AI‚Äôs <strong>page interaction</strong> features let you:</p>\n<p>1.‚ÄÄ<strong>Execute JavaScript</strong> for scrolling, clicks, or form filling.<br>\n2.‚ÄÄ<strong>Wait</strong> for CSS or custom JS conditions before capturing data.<br>\n3.‚ÄÄ<strong>Handle</strong> multi-step flows (like ‚ÄúLoad More‚Äù) with partial reloads or persistent sessions.<br>\n4. Combine with <strong>structured extraction</strong> for dynamic sites.</p>\n<p>With these tools, you can scrape modern, interactive webpages confidently. For advanced hooking, user simulation, or in-depth config, check the <a href=\"../../api/parameters/\">API reference</a> or related advanced docs. Happy scripting!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Page Interaction\nCrawl4AI provides powerful features for interacting with **dynamic** webpages, handling JavaScript execution, waiting for conditions, and managing multi-step flows. By combining **js_code** , **wait_for** , and certain **CrawlerRunConfig** parameters, you can:\n  1. Click ‚ÄúLoad More‚Äù buttons \n  2. Fill forms and submit them \n  3. Wait for elements or data to appear \n  4. Reuse sessions across multiple steps \n\n\nBelow is a quick overview of how to do it.\n## 1. JavaScript Execution\n### Basic Execution\n**`js_code`**in**`CrawlerRunConfig`**accepts either a single JS string or a list of JS snippets.**Example** : We‚Äôll scroll to the bottom of the page, then optionally click a ‚ÄúLoad More‚Äù button.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Single JS command\n  config = CrawlerRunConfig(\n    js_code=\"window.scrollTo(0, document.body.scrollHeight);\"\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # Example site\n      config=config\n    )\n    print(\"Crawled length:\", len(result.cleaned_html))\n  # Multiple commands\n  js_commands = [\n    \"window.scrollTo(0, document.body.scrollHeight);\",\n    # 'More' link on Hacker News\n    \"document.querySelector('a.morelink')?.click();\", \n  ]\n  config = CrawlerRunConfig(js_code=js_commands)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # Another pass\n      config=config\n    )\n    print(\"After scroll+click, length:\", len(result.cleaned_html))\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Relevant`CrawlerRunConfig` params**: - **`js_code`**: A string or list of strings with JavaScript to run after the page loads. -**`js_only`**: If set to`True` on subsequent calls, indicates we‚Äôre continuing an existing session without a new full navigation. - **`session_id`**: If you want to keep the same page across multiple calls, specify an ID.\n## 2. Wait Conditions\n### 2.1 CSS-Based Waiting\nSometimes, you just want to wait for a specific element to appear. For example:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  config = CrawlerRunConfig(\n    # Wait for at least 30 items on Hacker News\n    wait_for=\"css:.athing:nth-child(30)\" \n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\",\n      config=config\n    )\n    print(\"We have at least 30 items loaded!\")\n    # Rough check\n    print(\"Total items in HTML:\", result.cleaned_html.count(\"athing\")) \nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key param** : - **`wait_for=\"css:...\"`**: Tells the crawler to wait until that CSS selector is present.\n### 2.2 JavaScript-Based Waiting\nFor more complex conditions (e.g., waiting for content length to exceed a threshold), prefix `js:`:\n```\nwait_condition = \"\"\"() => {\n  const items = document.querySelectorAll('.athing');\n  return items.length > 50; // Wait for at least 51 items\n}\"\"\"\nconfig = CrawlerRunConfig(wait_for=f\"js:{wait_condition}\")\n\n```\n\n**Behind the Scenes** : Crawl4AI keeps polling the JS function until it returns `true` or a timeout occurs.\n## 3. Handling Dynamic Content\nMany modern sites require **multiple steps** : scrolling, clicking ‚ÄúLoad More,‚Äù or updating via JavaScript. Below are typical patterns.\n### 3.1 Load More Example (Hacker News ‚ÄúMore‚Äù Link)\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\nasync def main():\n  # Step 1: Load initial Hacker News page\n  config = CrawlerRunConfig(\n    wait_for=\"css:.athing:nth-child(30)\" # Wait for 30 items\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://news.ycombinator.com\",\n      config=config\n    )\n    print(\"Initial items loaded.\")\n    # Step 2: Let's scroll and click the \"More\" link\n    load_more_js = [\n      \"window.scrollTo(0, document.body.scrollHeight);\",\n      # The \"More\" link at page bottom\n      \"document.querySelector('a.morelink')?.click();\" \n    ]\n    next_page_conf = CrawlerRunConfig(\n      js_code=load_more_js,\n      wait_for=\"\"\"js:() => {\n        return document.querySelectorAll('.athing').length > 30;\n      }\"\"\",\n      # Mark that we do not re-navigate, but run JS in the same session:\n      js_only=True,\n      session_id=\"hn_session\"\n    )\n    # Re-use the same crawler session\n    result2 = await crawler.arun(\n      url=\"https://news.ycombinator.com\", # same URL but continuing session\n      config=next_page_conf\n    )\n    total_items = result2.cleaned_html.count(\"athing\")\n    print(\"Items after load-more:\", total_items)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key params** : - **`session_id=\"hn_session\"`**: Keep the same page across multiple calls to`arun()`. - **`js_only=True`**: We‚Äôre not performing a full reload, just applying JS in the existing page. -**`wait_for`**with`js:` : Wait for item count to grow beyond 30.\n### 3.2 Form Interaction\nIf the site has a search or login form, you can fill fields and submit them with **`js_code`**. For instance, if GitHub had a local search form:\n```\njs_form_interaction = \"\"\"\ndocument.querySelector('#your-search').value = 'TypeScript commits';\ndocument.querySelector('form').submit();\n\"\"\"\nconfig = CrawlerRunConfig(\n  js_code=js_form_interaction,\n  wait_for=\"css:.commit\"\n)\nresult = await crawler.arun(url=\"https://github.com/search\", config=config)\n\n```\n\n**In reality** : Replace IDs or classes with the real site‚Äôs form selectors.\n## 4. Timing Control\n1. **`page_timeout`**(ms): Overall page load or script execution time limit. 2.**`delay_before_return_html`**(seconds): Wait an extra moment before capturing the final HTML. 3.**`mean_delay`** & **`max_range`**: If you call`arun_many()` with multiple URLs, these add a random pause between each request.\n**Example** :\n```\nconfig = CrawlerRunConfig(\n  page_timeout=60000, # 60s limit\n  delay_before_return_html=2.5\n)\n\n```\n\n## 5. Multi-Step Interaction Example\nBelow is a simplified script that does multiple ‚ÄúLoad More‚Äù clicks on GitHub‚Äôs TypeScript commits page. It **re-uses** the same session to accumulate new commits each time. The code includes the relevant **`CrawlerRunConfig`**parameters you‚Äôd rely on.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nasync def multi_page_commits():\n  browser_cfg = BrowserConfig(\n    headless=False, # Visible for demonstration\n    verbose=True\n  )\n  session_id = \"github_ts_commits\"\n  base_wait = \"\"\"js:() => {\n    const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n    return commits.length > 0;\n  }\"\"\"\n  # Step 1: Load initial commits\n  config1 = CrawlerRunConfig(\n    wait_for=base_wait,\n    session_id=session_id,\n    cache_mode=CacheMode.BYPASS,\n    # Not using js_only yet since it's our first load\n  )\n  async with AsyncWebCrawler(config=browser_cfg) as crawler:\n    result = await crawler.arun(\n      url=\"https://github.com/microsoft/TypeScript/commits/main\",\n      config=config1\n    )\n    print(\"Initial commits loaded. Count:\", result.cleaned_html.count(\"commit\"))\n    # Step 2: For subsequent pages, we run JS to click 'Next Page' if it exists\n    js_next_page = \"\"\"\n    const selector = 'a[data-testid=\"pagination-next-button\"]';\n    const button = document.querySelector(selector);\n    if (button) button.click();\n    \"\"\"\n    # Wait until new commits appear\n    wait_for_more = \"\"\"js:() => {\n      const commits = document.querySelectorAll('li.Box-sc-g0xbh4-0 h4');\n      if (!window.firstCommit && commits.length>0) {\n        window.firstCommit = commits[0].textContent;\n        return false;\n      }\n      // If top commit changes, we have new commits\n      const topNow = commits[0]?.textContent.trim();\n      return topNow && topNow !== window.firstCommit;\n    }\"\"\"\n    for page in range(2): # let's do 2 more \"Next\" pages\n      config_next = CrawlerRunConfig(\n        session_id=session_id,\n        js_code=js_next_page,\n        wait_for=wait_for_more,\n        js_only=True,    # We're continuing from the open tab\n        cache_mode=CacheMode.BYPASS\n      )\n      result2 = await crawler.arun(\n        url=\"https://github.com/microsoft/TypeScript/commits/main\",\n        config=config_next\n      )\n      print(f\"Page {page+2} commits count:\", result2.cleaned_html.count(\"commit\"))\n    # Optionally kill session\n    await crawler.crawler_strategy.kill_session(session_id)\nasync def main():\n  await multi_page_commits()\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n**Key Points** :\n  * **`session_id`**: Keep the same page open.\n  * **`js_code`**+**`wait_for`**+**`js_only=True`**: We do partial refreshes, waiting for new commits to appear.\n  * **`cache_mode=CacheMode.BYPASS`**ensures we always see fresh data each step.\n\n\n## 6. Combine Interaction with Extraction\nOnce dynamic content is loaded, you can attach an **`extraction_strategy`**(like`JsonCssExtractionStrategy` or `LLMExtractionStrategy`). For example:\n```\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nschema = {\n  \"name\": \"Commits\",\n  \"baseSelector\": \"li.Box-sc-g0xbh4-0\",\n  \"fields\": [\n    {\"name\": \"title\", \"selector\": \"h4.markdown-title\", \"type\": \"text\"}\n  ]\n}\nconfig = CrawlerRunConfig(\n  session_id=\"ts_commits_session\",\n  js_code=js_next_page,\n  wait_for=wait_for_more,\n  extraction_strategy=JsonCssExtractionStrategy(schema)\n)\n\n```\n\nWhen done, check `result.extracted_content` for the JSON.\n## 7. Relevant `CrawlerRunConfig` Parameters\nBelow are the key interaction-related parameters in `CrawlerRunConfig`. For a full list, see [Configuration Parameters](https://docs.crawl4ai.com/core/api/parameters/>).\n  * **`js_code`**: JavaScript to run after initial load.\n  * **`js_only`**: If`True` , no new page navigation‚Äîonly JS in the existing session. \n  * **`wait_for`**: CSS (`\"css:...\"`) or JS (`\"js:...\"`) expression to wait for. \n  * **`session_id`**: Reuse the same page across calls.\n  * **`cache_mode`**: Whether to read/write from the cache or bypass.\n  * **`remove_overlay_elements`**: Remove certain popups automatically.\n  * **`simulate_user`,`override_navigator` , `magic`**: Anti-bot or ‚Äúhuman-like‚Äù interactions.\n\n\n## 8. Conclusion\nCrawl4AI‚Äôs **page interaction** features let you:\n1. **Execute JavaScript** for scrolling, clicks, or form filling. 2. **Wait** for CSS or custom JS conditions before capturing data. 3. **Handle** multi-step flows (like ‚ÄúLoad More‚Äù) with partial reloads or persistent sessions. 4. Combine with **structured extraction** for dynamic sites.\nWith these tools, you can scrape modern, interactive webpages confidently. For advanced hooking, user simulation, or in-depth config, check the [API reference](https://docs.crawl4ai.com/core/api/parameters/>) or related advanced docs. Happy scripting!\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/browser-crawler-config",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/crawler-result",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/link-media",
    "https://docs.crawl4ai.com/local-files",
    "https://docs.crawl4ai.com/markdown-generation",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 24,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:30",
    "page_limit": 34
  }
}