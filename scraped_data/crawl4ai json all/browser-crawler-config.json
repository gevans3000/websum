{
  "url": "https://docs.crawl4ai.com/core/browser-crawler-config",
  "timestamp": "2025-02-06T13:23:34.161632",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"üöÄü§ñ Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/browser-crawler-config/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Browser &amp; Crawler Config - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Browser &amp; Crawler Config</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#browser-crawler-configuration-quick-overview\">Browser &amp; Crawler Configuration (Quick Overview)</a></li>\n        <li><a href=\"#1-browserconfig-essentials\">1. BrowserConfig Essentials</a></li><li><a href=\"#2-crawlerrunconfig-essentials\">2. CrawlerRunConfig Essentials</a></li><li><a href=\"#3-putting-it-all-together\">3. Putting It All Together</a></li><li><a href=\"#4-next-steps\">4. Next Steps</a></li><li><a href=\"#5-conclusion\">5. Conclusion</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"browser-crawler-configuration-quick-overview\">Browser &amp; Crawler Configuration (Quick Overview)</h1>\n<p>Crawl4AI‚Äôs flexibility stems from two key classes:</p>\n<p>1.‚ÄÄ<strong><code>BrowserConfig</code></strong> ‚Äì Dictates <strong>how</strong> the browser is launched and behaves (e.g., headless or visible, proxy, user agent).<br>\n2.‚ÄÄ<strong><code>CrawlerRunConfig</code></strong> ‚Äì Dictates <strong>how</strong> each <strong>crawl</strong> operates (e.g., caching, extraction, timeouts, JavaScript code to run, etc.).</p>\n<p>In most examples, you create <strong>one</strong> <code>BrowserConfig</code> for the entire crawler session, then pass a <strong>fresh</strong> or re-used <code>CrawlerRunConfig</code> whenever you call <code>arun()</code>. This tutorial shows the most commonly used parameters. If you need advanced or rarely used fields, see the <a href=\"../../api/parameters/\">Configuration Parameters</a>.</p>\n<hr>\n<h2 id=\"1-browserconfig-essentials\">1. BrowserConfig Essentials</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BrowserConfig</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        browser_type=<span class=\"hljs-string\">\"chromium\"</span>,\n        headless=<span class=\"hljs-literal\">True</span>,\n        proxy_config=<span class=\"hljs-literal\">None</span>,\n        viewport_width=<span class=\"hljs-number\">1080</span>,\n        viewport_height=<span class=\"hljs-number\">600</span>,\n        verbose=<span class=\"hljs-literal\">True</span>,\n        use_persistent_context=<span class=\"hljs-literal\">False</span>,\n        user_data_dir=<span class=\"hljs-literal\">None</span>,\n        cookies=<span class=\"hljs-literal\">None</span>,\n        headers=<span class=\"hljs-literal\">None</span>,\n        user_agent=<span class=\"hljs-literal\">None</span>,\n        text_mode=<span class=\"hljs-literal\">False</span>,\n        light_mode=<span class=\"hljs-literal\">False</span>,\n        extra_args=<span class=\"hljs-literal\">None</span>,\n        <span class=\"hljs-comment\"># ... other advanced parameters omitted here</span>\n    </span>):\n        ...\n</code></pre></div>\n<h3 id=\"key-fields-to-note\">Key Fields to Note</h3>\n<p>1.‚ÄÄ<strong><code>browser_type</code></strong><br>\n- Options: <code>\"chromium\"</code>, <code>\"firefox\"</code>, or <code>\"webkit\"</code>.<br>\n- Defaults to <code>\"chromium\"</code>.<br>\n- If you need a different engine, specify it here.</p>\n<p>2.‚ÄÄ<strong><code>headless</code></strong><br>\n   - <code>True</code>: Runs the browser in headless mode (invisible browser).<br>\n   - <code>False</code>: Runs the browser in visible mode, which helps with debugging.</p>\n<p>3.‚ÄÄ<strong><code>proxy_config</code></strong><br>\n   - A dictionary with fields like:<br>\n</p><div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-json\"><span class=\"hljs-punctuation\">{</span>\n    <span class=\"hljs-attr\">\"server\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"http://proxy.example.com:8080\"</span><span class=\"hljs-punctuation\">,</span> \n    <span class=\"hljs-attr\">\"username\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"...\"</span><span class=\"hljs-punctuation\">,</span> \n    <span class=\"hljs-attr\">\"password\"</span><span class=\"hljs-punctuation\">:</span> <span class=\"hljs-string\">\"...\"</span>\n<span class=\"hljs-punctuation\">}</span>\n</code></pre></div>\n   - Leave as <code>None</code> if a proxy is not required.<p></p>\n<p>4.‚ÄÄ<strong><code>viewport_width</code> &amp; <code>viewport_height</code></strong>:<br>\n   - The initial window size.<br>\n   - Some sites behave differently with smaller or bigger viewports.</p>\n<p>5.‚ÄÄ<strong><code>verbose</code></strong>:<br>\n   - If <code>True</code>, prints extra logs.<br>\n   - Handy for debugging.</p>\n<p>6.‚ÄÄ<strong><code>use_persistent_context</code></strong>:<br>\n   - If <code>True</code>, uses a <strong>persistent</strong> browser profile, storing cookies/local storage across runs.<br>\n   - Typically also set <code>user_data_dir</code> to point to a folder.</p>\n<p>7.‚ÄÄ<strong><code>cookies</code></strong> &amp; <strong><code>headers</code></strong>:<br>\n   - If you want to start with specific cookies or add universal HTTP headers, set them here.<br>\n   - E.g. <code>cookies=[{\"name\": \"session\", \"value\": \"abc123\", \"domain\": \"example.com\"}]</code>.</p>\n<p>8.‚ÄÄ<strong><code>user_agent</code></strong>:<br>\n   - Custom User-Agent string. If <code>None</code>, a default is used.<br>\n   - You can also set <code>user_agent_mode=\"random\"</code> for randomization (if you want to fight bot detection).</p>\n<p>9.‚ÄÄ<strong><code>text_mode</code></strong> &amp; <strong><code>light_mode</code></strong>:<br>\n   - <code>text_mode=True</code> disables images, possibly speeding up text-only crawls.<br>\n   - <code>light_mode=True</code> turns off certain background features for performance.  </p>\n<p>10.‚ÄÄ<strong><code>extra_args</code></strong>:<br>\n    - Additional flags for the underlying browser.<br>\n    - E.g. <code>[\"--disable-extensions\"]</code>.</p>\n<h3 id=\"helper-methods\">Helper Methods</h3>\n<p>Both configuration classes provide a <code>clone()</code> method to create modified copies:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\"><span class=\"hljs-comment\"># Create a base browser config</span>\nbase_browser <span class=\"hljs-punctuation\">=</span> BrowserConfig<span class=\"hljs-punctuation\">(</span>\n    browser_type<span class=\"hljs-punctuation\">=</span><span class=\"hljs-string\">\"chromium\"</span>,\n    headless<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>,\n    text_mode<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n\n<span class=\"hljs-comment\"># Create a visible browser config for debugging</span>\ndebug_browser <span class=\"hljs-punctuation\">=</span> base_browser.clone<span class=\"hljs-punctuation\">(</span>\n    headless<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">False</span>,\n    verbose<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p><strong>Minimal Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig\n\nbrowser_conf = BrowserConfig(\n    browser_type=<span class=\"hljs-string\">\"firefox\"</span>,\n    headless=<span class=\"hljs-literal\">False</span>,\n    text_mode=<span class=\"hljs-literal\">True</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_conf) <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://example.com\"</span>)\n    <span class=\"hljs-built_in\">print</span>(result.markdown[:<span class=\"hljs-number\">300</span>])\n</code></pre></div>\n<hr>\n<h2 id=\"2-crawlerrunconfig-essentials\">2. CrawlerRunConfig Essentials</h2>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CrawlerRunConfig</span>:\n    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">\n        word_count_threshold=<span class=\"hljs-number\">200</span>,\n        extraction_strategy=<span class=\"hljs-literal\">None</span>,\n        markdown_generator=<span class=\"hljs-literal\">None</span>,\n        cache_mode=<span class=\"hljs-literal\">None</span>,\n        js_code=<span class=\"hljs-literal\">None</span>,\n        wait_for=<span class=\"hljs-literal\">None</span>,\n        screenshot=<span class=\"hljs-literal\">False</span>,\n        pdf=<span class=\"hljs-literal\">False</span>,\n        enable_rate_limiting=<span class=\"hljs-literal\">False</span>,\n        rate_limit_config=<span class=\"hljs-literal\">None</span>,\n        memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,\n        check_interval=<span class=\"hljs-number\">1.0</span>,\n        max_session_permit=<span class=\"hljs-number\">20</span>,\n        display_mode=<span class=\"hljs-literal\">None</span>,\n        verbose=<span class=\"hljs-literal\">True</span>,\n        stream=<span class=\"hljs-literal\">False</span>,  <span class=\"hljs-comment\"># Enable streaming for arun_many()</span>\n        <span class=\"hljs-comment\"># ... other advanced parameters omitted</span>\n    </span>):\n        ...\n</code></pre></div>\n<h3 id=\"key-fields-to-note_1\">Key Fields to Note</h3>\n<p>1.‚ÄÄ<strong><code>word_count_threshold</code></strong>:<br>\n   - The minimum word count before a block is considered.<br>\n   - If your site has lots of short paragraphs or items, you can lower it.</p>\n<p>2.‚ÄÄ<strong><code>extraction_strategy</code></strong>:<br>\n   - Where you plug in JSON-based extraction (CSS, LLM, etc.).<br>\n   - If <code>None</code>, no structured extraction is done (only raw/cleaned HTML + markdown).</p>\n<p>3.‚ÄÄ<strong><code>markdown_generator</code></strong>:<br>\n   - E.g., <code>DefaultMarkdownGenerator(...)</code>, controlling how HTML‚ÜíMarkdown conversion is done.<br>\n   - If <code>None</code>, a default approach is used.</p>\n<p>4.‚ÄÄ<strong><code>cache_mode</code></strong>:<br>\n   - Controls caching behavior (<code>ENABLED</code>, <code>BYPASS</code>, <code>DISABLED</code>, etc.).<br>\n   - If <code>None</code>, defaults to some level of caching or you can specify <code>CacheMode.ENABLED</code>.</p>\n<p>5.‚ÄÄ<strong><code>js_code</code></strong>:<br>\n   - A string or list of JS strings to execute.<br>\n   - Great for ‚ÄúLoad More‚Äù buttons or user interactions.  </p>\n<p>6.‚ÄÄ<strong><code>wait_for</code></strong>:<br>\n   - A CSS or JS expression to wait for before extracting content.<br>\n   - Common usage: <code>wait_for=\"css:.main-loaded\"</code> or <code>wait_for=\"js:() =&gt; window.loaded === true\"</code>.</p>\n<p>7.‚ÄÄ<strong><code>screenshot</code></strong> &amp; <strong><code>pdf</code></strong>:<br>\n   - If <code>True</code>, captures a screenshot or PDF after the page is fully loaded.<br>\n   - The results go to <code>result.screenshot</code> (base64) or <code>result.pdf</code> (bytes).</p>\n<p>8.‚ÄÄ<strong><code>verbose</code></strong>:<br>\n   - Logs additional runtime details.<br>\n   - Overlaps with the browser‚Äôs verbosity if also set to <code>True</code> in <code>BrowserConfig</code>.</p>\n<p>9.‚ÄÄ<strong><code>enable_rate_limiting</code></strong>:<br>\n   - If <code>True</code>, enables rate limiting for batch processing.<br>\n   - Requires <code>rate_limit_config</code> to be set.</p>\n<p>10.‚ÄÄ<strong><code>rate_limit_config</code></strong>:<br>\n    - A <code>RateLimitConfig</code> object controlling rate limiting behavior.<br>\n    - See below for details.</p>\n<p>11.‚ÄÄ<strong><code>memory_threshold_percent</code></strong>:<br>\n    - The memory threshold (as a percentage) to monitor.<br>\n    - If exceeded, the crawler will pause or slow down.</p>\n<p>12.‚ÄÄ<strong><code>check_interval</code></strong>:<br>\n    - The interval (in seconds) to check system resources.<br>\n    - Affects how often memory and CPU usage are monitored.</p>\n<p>13.‚ÄÄ<strong><code>max_session_permit</code></strong>:<br>\n    - The maximum number of concurrent crawl sessions.<br>\n    - Helps prevent overwhelming the system.</p>\n<p>14.‚ÄÄ<strong><code>display_mode</code></strong>:<br>\n    - The display mode for progress information (<code>DETAILED</code>, <code>BRIEF</code>, etc.).<br>\n    - Affects how much information is printed during the crawl.</p>\n<h3 id=\"helper-methods_1\">Helper Methods</h3>\n<p>The <code>clone()</code> method is particularly useful for creating variations of your crawler configuration:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\"><span class=\"hljs-comment\"># Create a base configuration</span>\nbase_config = CrawlerRunConfig(\n    cache_mode=CacheMode.ENABLED,\n    word_count_threshold=200,\n    wait_until=<span class=\"hljs-string\">\"networkidle\"</span>\n)\n\n<span class=\"hljs-comment\"># Create variations for different use cases</span>\nstream_config = base_config.clone(\n    stream=True,  <span class=\"hljs-comment\"># Enable streaming mode</span>\n    cache_mode=CacheMode.BYPASS\n)\n\ndebug_config = base_config.clone(\n    page_timeout=120000,  <span class=\"hljs-comment\"># Longer timeout for debugging</span>\n    verbose=True\n)\n</code></pre></div>\n<p>The <code>clone()</code> method:\n- Creates a new instance with all the same settings\n- Updates only the specified parameters\n- Leaves the original configuration unchanged\n- Perfect for creating variations without repeating all parameters</p>\n<h3 id=\"rate-limiting-resource-management\">Rate Limiting &amp; Resource Management</h3>\n<p>For batch processing with <code>arun_many()</code>, you can enable intelligent rate limiting:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> RateLimitConfig\n\nconfig = CrawlerRunConfig(\n    enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n    rate_limit_config=RateLimitConfig(\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),    <span class=\"hljs-comment\"># Random delay range</span>\n        max_delay=<span class=\"hljs-number\">60.0</span>,           <span class=\"hljs-comment\"># Max delay after rate limits</span>\n        max_retries=<span class=\"hljs-number\">3</span>,            <span class=\"hljs-comment\"># Retries before giving up</span>\n        rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]  <span class=\"hljs-comment\"># Status codes to watch</span>\n    ),\n    memory_threshold_percent=<span class=\"hljs-number\">70.0</span>,  <span class=\"hljs-comment\"># Memory threshold</span>\n    check_interval=<span class=\"hljs-number\">1.0</span>,            <span class=\"hljs-comment\"># Resource check interval</span>\n    max_session_permit=<span class=\"hljs-number\">20</span>,         <span class=\"hljs-comment\"># Max concurrent crawls</span>\n    display_mode=<span class=\"hljs-string\">\"DETAILED\"</span>        <span class=\"hljs-comment\"># Progress display mode</span>\n)\n</code></pre></div>\n<p>This configuration:\n- Implements intelligent rate limiting per domain\n- Monitors system resources\n- Provides detailed progress information\n- Manages concurrent crawls efficiently</p>\n<p><strong>Minimal Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, CrawlerRunConfig\n\ncrawl_conf = CrawlerRunConfig(\n    js_code=<span class=\"hljs-string\">\"document.querySelector('button#loadMore')?.click()\"</span>,\n    wait_for=<span class=\"hljs-string\">\"css:.loaded-content\"</span>,\n    screenshot=<span class=\"hljs-literal\">True</span>,\n    enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n    rate_limit_config=RateLimitConfig(\n        base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),\n        max_delay=<span class=\"hljs-number\">60.0</span>,\n        max_retries=<span class=\"hljs-number\">3</span>,\n        rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]\n    ),\n    stream=<span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># Enable streaming</span>\n)\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com\"</span>, config=crawl_conf)\n    <span class=\"hljs-built_in\">print</span>(result.screenshot[:<span class=\"hljs-number\">100</span>])  <span class=\"hljs-comment\"># Base64-encoded PNG snippet</span>\n</code></pre></div>\n<hr>\n<h2 id=\"3-putting-it-all-together\">3. Putting It All Together</h2>\n<p>In a typical scenario, you define <strong>one</strong> <code>BrowserConfig</code> for your crawler session, then create <strong>one or more</strong> <code>CrawlerRunConfig</code> depending on each call‚Äôs needs:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n<span class=\"hljs-keyword\">from</span> crawl4ai.extraction_strategy <span class=\"hljs-keyword\">import</span> JsonCssExtractionStrategy\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># 1) Browser config: headless, bigger viewport, no proxy</span>\n    browser_conf = BrowserConfig(\n        headless=<span class=\"hljs-literal\">True</span>,\n        viewport_width=<span class=\"hljs-number\">1280</span>,\n        viewport_height=<span class=\"hljs-number\">720</span>\n    )\n\n    <span class=\"hljs-comment\"># 2) Example extraction strategy</span>\n    schema = {\n        <span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"Articles\"</span>,\n        <span class=\"hljs-string\">\"baseSelector\"</span>: <span class=\"hljs-string\">\"div.article\"</span>,\n        <span class=\"hljs-string\">\"fields\"</span>: [\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"title\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"h2\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"text\"</span>},\n            {<span class=\"hljs-string\">\"name\"</span>: <span class=\"hljs-string\">\"link\"</span>, <span class=\"hljs-string\">\"selector\"</span>: <span class=\"hljs-string\">\"a\"</span>, <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"attribute\"</span>, <span class=\"hljs-string\">\"attribute\"</span>: <span class=\"hljs-string\">\"href\"</span>}\n        ]\n    }\n    extraction = JsonCssExtractionStrategy(schema)\n\n    <span class=\"hljs-comment\"># 3) Crawler run config: skip cache, use extraction</span>\n    run_conf = CrawlerRunConfig(\n        extraction_strategy=extraction,\n        cache_mode=CacheMode.BYPASS,\n        enable_rate_limiting=<span class=\"hljs-literal\">True</span>,\n        rate_limit_config=RateLimitConfig(\n            base_delay=(<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">3.0</span>),\n            max_delay=<span class=\"hljs-number\">60.0</span>,\n            max_retries=<span class=\"hljs-number\">3</span>,\n            rate_limit_codes=[<span class=\"hljs-number\">429</span>, <span class=\"hljs-number\">503</span>]\n        )\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler(config=browser_conf) <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># 4) Execute the crawl</span>\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=<span class=\"hljs-string\">\"https://example.com/news\"</span>, config=run_conf)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Extracted content:\"</span>, result.extracted_content)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Error:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"4-next-steps\">4. Next Steps</h2>\n<p>For a <strong>detailed list</strong> of available parameters (including advanced ones), see:</p>\n<ul>\n<li><a href=\"../../api/parameters/\">BrowserConfig and CrawlerRunConfig Reference</a>  </li>\n</ul>\n<p>You can explore topics like:</p>\n<ul>\n<li><strong>Custom Hooks &amp; Auth</strong> (Inject JavaScript or handle login forms).  </li>\n<li><strong>Session Management</strong> (Re-use pages, preserve state across multiple calls).  </li>\n<li><strong>Magic Mode</strong> or <strong>Identity-based Crawling</strong> (Fight bot detection by simulating user behavior).  </li>\n<li><strong>Advanced Caching</strong> (Fine-tune read/write cache modes).  </li>\n</ul>\n<hr>\n<h2 id=\"5-conclusion\">5. Conclusion</h2>\n<p><strong>BrowserConfig</strong> and <strong>CrawlerRunConfig</strong> give you straightforward ways to define:</p>\n<ul>\n<li><strong>Which</strong> browser to launch, how it should run, and any proxy or user agent needs.  </li>\n<li><strong>How</strong> each crawl should behave‚Äîcaching, timeouts, JavaScript code, extraction strategies, etc.</li>\n</ul>\n<p>Use them together for <strong>clear, maintainable</strong> code, and when you need more specialized behavior, check out the advanced parameters in the <a href=\"../../api/parameters/\">reference docs</a>. Happy crawling!</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Browser & Crawler Configuration (Quick Overview)\nCrawl4AI‚Äôs flexibility stems from two key classes:\n1. **`BrowserConfig`**‚Äì Dictates**how** the browser is launched and behaves (e.g., headless or visible, proxy, user agent). 2. **`CrawlerRunConfig`**‚Äì Dictates**how** each **crawl** operates (e.g., caching, extraction, timeouts, JavaScript code to run, etc.).\nIn most examples, you create **one** `BrowserConfig` for the entire crawler session, then pass a **fresh** or re-used `CrawlerRunConfig` whenever you call `arun()`. This tutorial shows the most commonly used parameters. If you need advanced or rarely used fields, see the [Configuration Parameters](https://docs.crawl4ai.com/core/api/parameters/>).\n## 1. BrowserConfig Essentials\n```\nclass BrowserConfig:\n  def __init__(\n    browser_type=\"chromium\",\n    headless=True,\n    proxy_config=None,\n    viewport_width=1080,\n    viewport_height=600,\n    verbose=True,\n    use_persistent_context=False,\n    user_data_dir=None,\n    cookies=None,\n    headers=None,\n    user_agent=None,\n    text_mode=False,\n    light_mode=False,\n    extra_args=None,\n    # ... other advanced parameters omitted here\n  ):\n    ...\n\n```\n\n### Key Fields to Note\n1. **`browser_type`**- Options:`\"chromium\"` , `\"firefox\"`, or `\"webkit\"`. - Defaults to `\"chromium\"`. - If you need a different engine, specify it here.\n2. **`headless`**-`True` : Runs the browser in headless mode (invisible browser). - `False`: Runs the browser in visible mode, which helps with debugging.\n3. **`proxy_config`**- A dictionary with fields like:\n```\n{\n  \"server\": \"http://proxy.example.com:8080\", \n  \"username\": \"...\", \n  \"password\": \"...\"\n}\n\n```\n\n- Leave as `None` if a proxy is not required. \n4. **`viewport_width` & `viewport_height`**: - The initial window size. - Some sites behave differently with smaller or bigger viewports.\n5. **`verbose`**: - If`True` , prints extra logs. - Handy for debugging.\n6. **`use_persistent_context`**: - If`True` , uses a **persistent** browser profile, storing cookies/local storage across runs. - Typically also set `user_data_dir` to point to a folder.\n7. **`cookies`** & **`headers`**: - If you want to start with specific cookies or add universal HTTP headers, set them here. - E.g.`cookies=[{\"name\": \"session\", \"value\": \"abc123\", \"domain\": \"example.com\"}]`.\n8. **`user_agent`**: - Custom User-Agent string. If`None` , a default is used. - You can also set `user_agent_mode=\"random\"` for randomization (if you want to fight bot detection).\n9. **`text_mode`** & **`light_mode`**: -`text_mode=True` disables images, possibly speeding up text-only crawls. - `light_mode=True` turns off certain background features for performance. \n10. **`extra_args`**: - Additional flags for the underlying browser. - E.g.`[\"--disable-extensions\"]`.\n### Helper Methods\nBoth configuration classes provide a `clone()` method to create modified copies:\n```\n# Create a base browser config\nbase_browser = BrowserConfig(\n  browser_type=\"chromium\",\n  headless=True,\n  text_mode=True\n)\n# Create a visible browser config for debugging\ndebug_browser = base_browser.clone(\n  headless=False,\n  verbose=True\n)\n\n```\n\n**Minimal Example** :\n```\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig\nbrowser_conf = BrowserConfig(\n  browser_type=\"firefox\",\n  headless=False,\n  text_mode=True\n)\nasync with AsyncWebCrawler(config=browser_conf) as crawler:\n  result = await crawler.arun(\"https://example.com\")\n  print(result.markdown[:300])\n\n```\n\n## 2. CrawlerRunConfig Essentials\n```\nclass CrawlerRunConfig:\n  def __init__(\n    word_count_threshold=200,\n    extraction_strategy=None,\n    markdown_generator=None,\n    cache_mode=None,\n    js_code=None,\n    wait_for=None,\n    screenshot=False,\n    pdf=False,\n    enable_rate_limiting=False,\n    rate_limit_config=None,\n    memory_threshold_percent=70.0,\n    check_interval=1.0,\n    max_session_permit=20,\n    display_mode=None,\n    verbose=True,\n    stream=False, # Enable streaming for arun_many()\n    # ... other advanced parameters omitted\n  ):\n    ...\n\n```\n\n### Key Fields to Note\n1. **`word_count_threshold`**: - The minimum word count before a block is considered. - If your site has lots of short paragraphs or items, you can lower it.\n2. **`extraction_strategy`**: - Where you plug in JSON-based extraction (CSS, LLM, etc.). - If`None` , no structured extraction is done (only raw/cleaned HTML + markdown).\n3. **`markdown_generator`**: - E.g.,`DefaultMarkdownGenerator(...)` , controlling how HTML‚ÜíMarkdown conversion is done. - If `None`, a default approach is used.\n4. **`cache_mode`**: - Controls caching behavior (`ENABLED` , `BYPASS`, `DISABLED`, etc.). - If `None`, defaults to some level of caching or you can specify `CacheMode.ENABLED`.\n5. **`js_code`**: - A string or list of JS strings to execute. - Great for ‚ÄúLoad More‚Äù buttons or user interactions.\n6. **`wait_for`**: - A CSS or JS expression to wait for before extracting content. - Common usage:`wait_for=\"css:.main-loaded\"` or `wait_for=\"js:() => window.loaded === true\"`.\n7. **`screenshot`** & **`pdf`**: - If`True` , captures a screenshot or PDF after the page is fully loaded. - The results go to `result.screenshot` (base64) or `result.pdf` (bytes).\n8. **`verbose`**: - Logs additional runtime details. - Overlaps with the browser‚Äôs verbosity if also set to`True` in `BrowserConfig`.\n9. **`enable_rate_limiting`**: - If`True` , enables rate limiting for batch processing. - Requires `rate_limit_config` to be set.\n10. **`rate_limit_config`**: - A`RateLimitConfig` object controlling rate limiting behavior. - See below for details.\n11. **`memory_threshold_percent`**: - The memory threshold (as a percentage) to monitor. - If exceeded, the crawler will pause or slow down.\n12. **`check_interval`**: - The interval (in seconds) to check system resources. - Affects how often memory and CPU usage are monitored.\n13. **`max_session_permit`**: - The maximum number of concurrent crawl sessions. - Helps prevent overwhelming the system.\n14. **`display_mode`**: - The display mode for progress information (`DETAILED` , `BRIEF`, etc.). - Affects how much information is printed during the crawl.\n### Helper Methods\nThe `clone()` method is particularly useful for creating variations of your crawler configuration:\n```\n# Create a base configuration\nbase_config = CrawlerRunConfig(\n  cache_mode=CacheMode.ENABLED,\n  word_count_threshold=200,\n  wait_until=\"networkidle\"\n)\n# Create variations for different use cases\nstream_config = base_config.clone(\n  stream=True, # Enable streaming mode\n  cache_mode=CacheMode.BYPASS\n)\ndebug_config = base_config.clone(\n  page_timeout=120000, # Longer timeout for debugging\n  verbose=True\n)\n\n```\n\nThe `clone()` method: - Creates a new instance with all the same settings - Updates only the specified parameters - Leaves the original configuration unchanged - Perfect for creating variations without repeating all parameters\n### Rate Limiting & Resource Management\nFor batch processing with `arun_many()`, you can enable intelligent rate limiting:\n```\nfrom crawl4ai import RateLimitConfig\nconfig = CrawlerRunConfig(\n  enable_rate_limiting=True,\n  rate_limit_config=RateLimitConfig(\n    base_delay=(1.0, 3.0),  # Random delay range\n    max_delay=60.0,      # Max delay after rate limits\n    max_retries=3,      # Retries before giving up\n    rate_limit_codes=[429, 503] # Status codes to watch\n  ),\n  memory_threshold_percent=70.0, # Memory threshold\n  check_interval=1.0,      # Resource check interval\n  max_session_permit=20,     # Max concurrent crawls\n  display_mode=\"DETAILED\"    # Progress display mode\n)\n\n```\n\nThis configuration: - Implements intelligent rate limiting per domain - Monitors system resources - Provides detailed progress information - Manages concurrent crawls efficiently\n**Minimal Example** :\n```\nfrom crawl4ai import AsyncWebCrawler, CrawlerRunConfig\ncrawl_conf = CrawlerRunConfig(\n  js_code=\"document.querySelector('button#loadMore')?.click()\",\n  wait_for=\"css:.loaded-content\",\n  screenshot=True,\n  enable_rate_limiting=True,\n  rate_limit_config=RateLimitConfig(\n    base_delay=(1.0, 3.0),\n    max_delay=60.0,\n    max_retries=3,\n    rate_limit_codes=[429, 503]\n  ),\n  stream=True # Enable streaming\n)\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(url=\"https://example.com\", config=crawl_conf)\n  print(result.screenshot[:100]) # Base64-encoded PNG snippet\n\n```\n\n## 3. Putting It All Together\nIn a typical scenario, you define **one** `BrowserConfig` for your crawler session, then create **one or more** `CrawlerRunConfig` depending on each call‚Äôs needs:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\nfrom crawl4ai.extraction_strategy import JsonCssExtractionStrategy\nasync def main():\n  # 1) Browser config: headless, bigger viewport, no proxy\n  browser_conf = BrowserConfig(\n    headless=True,\n    viewport_width=1280,\n    viewport_height=720\n  )\n  # 2) Example extraction strategy\n  schema = {\n    \"name\": \"Articles\",\n    \"baseSelector\": \"div.article\",\n    \"fields\": [\n      {\"name\": \"title\", \"selector\": \"h2\", \"type\": \"text\"},\n      {\"name\": \"link\", \"selector\": \"a\", \"type\": \"attribute\", \"attribute\": \"href\"}\n    ]\n  }\n  extraction = JsonCssExtractionStrategy(schema)\n  # 3) Crawler run config: skip cache, use extraction\n  run_conf = CrawlerRunConfig(\n    extraction_strategy=extraction,\n    cache_mode=CacheMode.BYPASS,\n    enable_rate_limiting=True,\n    rate_limit_config=RateLimitConfig(\n      base_delay=(1.0, 3.0),\n      max_delay=60.0,\n      max_retries=3,\n      rate_limit_codes=[429, 503]\n    )\n  )\n  async with AsyncWebCrawler(config=browser_conf) as crawler:\n    # 4) Execute the crawl\n    result = await crawler.arun(url=\"https://example.com/news\", config=run_conf)\n    if result.success:\n      print(\"Extracted content:\", result.extracted_content)\n    else:\n      print(\"Error:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 4. Next Steps\nFor a **detailed list** of available parameters (including advanced ones), see:\n  * [BrowserConfig and CrawlerRunConfig Reference](https://docs.crawl4ai.com/core/api/parameters/>)\n\n\nYou can explore topics like:\n  * **Custom Hooks & Auth** (Inject JavaScript or handle login forms). \n  * **Session Management** (Re-use pages, preserve state across multiple calls). \n  * **Magic Mode** or **Identity-based Crawling** (Fight bot detection by simulating user behavior). \n  * **Advanced Caching** (Fine-tune read/write cache modes). \n\n\n## 5. Conclusion\n**BrowserConfig** and **CrawlerRunConfig** give you straightforward ways to define:\n  * **Which** browser to launch, how it should run, and any proxy or user agent needs. \n  * **How** each crawl should behave‚Äîcaching, timeouts, JavaScript code, extraction strategies, etc.\n\n\nUse them together for **clear, maintainable** code, and when you need more specialized behavior, check out the advanced parameters in the [reference docs](https://docs.crawl4ai.com/core/api/parameters/>). Happy crawling!\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/crawler-result",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/link-media",
    "https://docs.crawl4ai.com/local-files",
    "https://docs.crawl4ai.com/markdown-generation",
    "https://docs.crawl4ai.com/page-interaction",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 14,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:17",
    "page_limit": 34
  }
}