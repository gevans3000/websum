{
  "url": "https://docs.crawl4ai.com/core/local-files",
  "timestamp": "2025-02-06T13:23:43.952252",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"ðŸš€ðŸ¤– Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/local-files/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Local Files &amp; Raw HTML - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Local Files &amp; Raw HTML</span>\n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../link-media/\">Link &amp; Media</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#prefix-based-input-handling-in-crawl4ai\">Prefix-Based Input Handling in Crawl4AI</a></li>\n        <li><a href=\"#crawling-a-web-url\">Crawling a Web URL</a></li><li><a href=\"#crawling-a-local-html-file\">Crawling a Local HTML File</a></li><li><a href=\"#crawling-raw-html-content\">Crawling Raw HTML Content</a></li><li><a href=\"#complete-example\">Complete Example</a></li>\n        <li><a href=\"#conclusion\">Conclusion</a></li>\n        \n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"prefix-based-input-handling-in-crawl4ai\">Prefix-Based Input Handling in Crawl4AI</h1>\n<p>This guide will walk you through using the Crawl4AI library to crawl web pages, local HTML files, and raw HTML strings. We'll demonstrate these capabilities using a Wikipedia page as an example.</p>\n<h2 id=\"crawling-a-web-url\">Crawling a Web URL</h2>\n<p>To crawl a live web page, provide the URL starting with <code>http://</code> or <code>https://</code>, using a <code>CrawlerRunConfig</code> object:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_web</span>():\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            url=<span class=\"hljs-string\">\"https://en.wikipedia.org/wiki/apple\"</span>, \n            config=config\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_web())\n</code></pre></div>\n<h2 id=\"crawling-a-local-html-file\">Crawling a Local HTML File</h2>\n<p>To crawl a local HTML file, prefix the file path with <code>file://</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_local_file</span>():\n    local_file_path = <span class=\"hljs-string\">\"/path/to/apple.html\"</span>  <span class=\"hljs-comment\"># Replace with your file path</span>\n    file_url = <span class=\"hljs-string\">f\"file://<span class=\"hljs-subst\">{local_file_path}</span>\"</span>\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=file_url, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content from Local File:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl local file: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_local_file())\n</code></pre></div>\n<h2 id=\"crawling-raw-html-content\">Crawling Raw HTML Content</h2>\n<p>To crawl raw HTML content, prefix the HTML string with <code>raw:</code>.</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">crawl_raw_html</span>():\n    raw_html = <span class=\"hljs-string\">\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello, World!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\"</span>\n    raw_html_url = <span class=\"hljs-string\">f\"raw:<span class=\"hljs-subst\">{raw_html}</span>\"</span>\n    config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=raw_html_url, config=config)\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Markdown Content from Raw HTML:\"</span>)\n            <span class=\"hljs-built_in\">print</span>(result.markdown)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl raw HTML: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n\nasyncio.run(crawl_raw_html())\n</code></pre></div>\n<hr>\n<h1 id=\"complete-example\">Complete Example</h1>\n<p>Below is a comprehensive script that:</p>\n<ol>\n<li>Crawls the Wikipedia page for \"Apple.\"</li>\n<li>Saves the HTML content to a local file (<code>apple.html</code>).</li>\n<li>Crawls the local HTML file and verifies the markdown length matches the original crawl.</li>\n<li>Crawls the raw HTML content from the saved file and verifies consistency.</li>\n</ol>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> sys\n<span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> pathlib <span class=\"hljs-keyword\">import</span> Path\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n<span class=\"hljs-keyword\">from</span> crawl4ai.async_configs <span class=\"hljs-keyword\">import</span> CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    wikipedia_url = <span class=\"hljs-string\">\"https://en.wikipedia.org/wiki/apple\"</span>\n    script_dir = Path(__file__).parent\n    html_file_path = script_dir / <span class=\"hljs-string\">\"apple.html\"</span>\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        <span class=\"hljs-comment\"># Step 1: Crawl the Web URL</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n=== Step 1: Crawling the Wikipedia URL ===\"</span>)\n        web_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=wikipedia_url, config=web_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl <span class=\"hljs-subst\">{wikipedia_url}</span>: <span class=\"hljs-subst\">{result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(html_file_path, <span class=\"hljs-string\">'w'</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>) <span class=\"hljs-keyword\">as</span> f:\n            f.write(result.html)\n        web_crawl_length = <span class=\"hljs-built_in\">len</span>(result.markdown)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Length of markdown from web crawl: <span class=\"hljs-subst\">{web_crawl_length}</span>\\n\"</span>)\n\n        <span class=\"hljs-comment\"># Step 2: Crawl from the Local HTML File</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"=== Step 2: Crawling from the Local HTML File ===\"</span>)\n        file_url = <span class=\"hljs-string\">f\"file://<span class=\"hljs-subst\">{html_file_path.resolve()}</span>\"</span>\n        file_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        local_result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=file_url, config=file_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> local_result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl local file <span class=\"hljs-subst\">{file_url}</span>: <span class=\"hljs-subst\">{local_result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        local_crawl_length = <span class=\"hljs-built_in\">len</span>(local_result.markdown)\n        <span class=\"hljs-keyword\">assert</span> web_crawl_length == local_crawl_length, <span class=\"hljs-string\">\"Markdown length mismatch\"</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"âœ… Markdown length matches between web and local file crawl.\\n\"</span>)\n\n        <span class=\"hljs-comment\"># Step 3: Crawl Using Raw HTML Content</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"=== Step 3: Crawling Using Raw HTML Content ===\"</span>)\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(html_file_path, <span class=\"hljs-string\">'r'</span>, encoding=<span class=\"hljs-string\">'utf-8'</span>) <span class=\"hljs-keyword\">as</span> f:\n            raw_html_content = f.read()\n        raw_html_url = <span class=\"hljs-string\">f\"raw:<span class=\"hljs-subst\">{raw_html_content}</span>\"</span>\n        raw_config = CrawlerRunConfig(bypass_cache=<span class=\"hljs-literal\">True</span>)\n        raw_result = <span class=\"hljs-keyword\">await</span> crawler.arun(url=raw_html_url, config=raw_config)\n\n        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> raw_result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Failed to crawl raw HTML content: <span class=\"hljs-subst\">{raw_result.error_message}</span>\"</span>)\n            <span class=\"hljs-keyword\">return</span>\n\n        raw_crawl_length = <span class=\"hljs-built_in\">len</span>(raw_result.markdown)\n        <span class=\"hljs-keyword\">assert</span> web_crawl_length == raw_crawl_length, <span class=\"hljs-string\">\"Markdown length mismatch\"</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"âœ… Markdown length matches between web and raw HTML crawl.\\n\"</span>)\n\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"All tests passed successfully!\"</span>)\n    <span class=\"hljs-keyword\">if</span> html_file_path.exists():\n        os.remove(html_file_path)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h1 id=\"conclusion\">Conclusion</h1>\n<p>With the unified <code>url</code> parameter and prefix-based handling in <strong>Crawl4AI</strong>, you can seamlessly handle web URLs, local HTML files, and raw HTML content. Use <code>CrawlerRunConfig</code> for flexible and consistent configuration in all scenarios.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Prefix-Based Input Handling in Crawl4AI\nThis guide will walk you through using the Crawl4AI library to crawl web pages, local HTML files, and raw HTML strings. We'll demonstrate these capabilities using a Wikipedia page as an example.\n## Crawling a Web URL\nTo crawl a live web page, provide the URL starting with `http://` or `https://`, using a `CrawlerRunConfig` object:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_web():\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      url=\"https://en.wikipedia.org/wiki/apple\", \n      config=config\n    )\n    if result.success:\n      print(\"Markdown Content:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl: {result.error_message}\")\nasyncio.run(crawl_web())\n\n```\n\n## Crawling a Local HTML File\nTo crawl a local HTML file, prefix the file path with `file://`.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_local_file():\n  local_file_path = \"/path/to/apple.html\" # Replace with your file path\n  file_url = f\"file://{local_file_path}\"\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=file_url, config=config)\n    if result.success:\n      print(\"Markdown Content from Local File:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl local file: {result.error_message}\")\nasyncio.run(crawl_local_file())\n\n```\n\n## Crawling Raw HTML Content\nTo crawl raw HTML content, prefix the HTML string with `raw:`.\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def crawl_raw_html():\n  raw_html = \"<html><body><h1>Hello, World!</h1></body></html>\"\n  raw_html_url = f\"raw:{raw_html}\"\n  config = CrawlerRunConfig(bypass_cache=True)\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(url=raw_html_url, config=config)\n    if result.success:\n      print(\"Markdown Content from Raw HTML:\")\n      print(result.markdown)\n    else:\n      print(f\"Failed to crawl raw HTML: {result.error_message}\")\nasyncio.run(crawl_raw_html())\n\n```\n\n# Complete Example\nBelow is a comprehensive script that:\n  1. Crawls the Wikipedia page for \"Apple.\"\n  2. Saves the HTML content to a local file (`apple.html`).\n  3. Crawls the local HTML file and verifies the markdown length matches the original crawl.\n  4. Crawls the raw HTML content from the saved file and verifies consistency.\n\n\n```\nimport os\nimport sys\nimport asyncio\nfrom pathlib import Path\nfrom crawl4ai import AsyncWebCrawler\nfrom crawl4ai.async_configs import CrawlerRunConfig\nasync def main():\n  wikipedia_url = \"https://en.wikipedia.org/wiki/apple\"\n  script_dir = Path(__file__).parent\n  html_file_path = script_dir / \"apple.html\"\n  async with AsyncWebCrawler() as crawler:\n    # Step 1: Crawl the Web URL\n    print(\"\\n=== Step 1: Crawling the Wikipedia URL ===\")\n    web_config = CrawlerRunConfig(bypass_cache=True)\n    result = await crawler.arun(url=wikipedia_url, config=web_config)\n    if not result.success:\n      print(f\"Failed to crawl {wikipedia_url}: {result.error_message}\")\n      return\n    with open(html_file_path, 'w', encoding='utf-8') as f:\n      f.write(result.html)\n    web_crawl_length = len(result.markdown)\n    print(f\"Length of markdown from web crawl: {web_crawl_length}\\n\")\n    # Step 2: Crawl from the Local HTML File\n    print(\"=== Step 2: Crawling from the Local HTML File ===\")\n    file_url = f\"file://{html_file_path.resolve()}\"\n    file_config = CrawlerRunConfig(bypass_cache=True)\n    local_result = await crawler.arun(url=file_url, config=file_config)\n    if not local_result.success:\n      print(f\"Failed to crawl local file {file_url}: {local_result.error_message}\")\n      return\n    local_crawl_length = len(local_result.markdown)\n    assert web_crawl_length == local_crawl_length, \"Markdown length mismatch\"\n    print(\"âœ… Markdown length matches between web and local file crawl.\\n\")\n    # Step 3: Crawl Using Raw HTML Content\n    print(\"=== Step 3: Crawling Using Raw HTML Content ===\")\n    with open(html_file_path, 'r', encoding='utf-8') as f:\n      raw_html_content = f.read()\n    raw_html_url = f\"raw:{raw_html_content}\"\n    raw_config = CrawlerRunConfig(bypass_cache=True)\n    raw_result = await crawler.arun(url=raw_html_url, config=raw_config)\n    if not raw_result.success:\n      print(f\"Failed to crawl raw HTML content: {raw_result.error_message}\")\n      return\n    raw_crawl_length = len(raw_result.markdown)\n    assert web_crawl_length == raw_crawl_length, \"Markdown length mismatch\"\n    print(\"âœ… Markdown length matches between web and raw HTML crawl.\\n\")\n    print(\"All tests passed successfully!\")\n  if html_file_path.exists():\n    os.remove(html_file_path)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n# Conclusion\nWith the unified `url` parameter and prefix-based handling in **Crawl4AI** , you can seamlessly handle web URLs, local HTML files, and raw HTML content. Use `CrawlerRunConfig` for flexible and consistent configuration in all scenarios.\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/browser-crawler-config",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/crawler-result",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/link-media",
    "https://docs.crawl4ai.com/markdown-generation",
    "https://docs.crawl4ai.com/page-interaction",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 22,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:27",
    "page_limit": 34
  }
}