{
  "url": "https://docs.crawl4ai.com/core/link-media",
  "timestamp": "2025-02-06T13:23:42.782400",
  "html": "<!DOCTYPE html><html lang=\"en\" style=\"scroll-padding-top: 50px;\"><head>\n    \n    <meta charset=\"UTF-8\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\">\n    <meta name=\"generator\" content=\"mkdocs-1.6.0, mkdocs-terminal-4.4.0\">\n    \n    <meta name=\"description\" content=\"🚀🤖 Crawl4AI, Open-source LLM-Friendly Web Crawler &amp; Scraper\"> \n     \n    \n    <link rel=\"canonical\" href=\"https://docs.crawl4ai.com/core/link-media/\"><link rel=\"icon\" type=\"image/png\" sizes=\"192x192\" href=\"../../img/android-chrome-192x192.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"512x512\" href=\"../../img/android-chrome-512x512.png\">\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"../../img/apple-touch-icon.png\">\n<link rel=\"shortcut icon\" type=\"image/png\" sizes=\"48x48\" href=\"../../img/favicon.ico\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"../../img/favicon-16x16.png\">\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"../../img/favicon-32x32.png\">\n\n\n    \n \n<title>Link &amp; Media - Crawl4AI Documentation (v0.4.3bx)</title>\n\n\n<link href=\"../../css/fontawesome/css/fontawesome.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/fontawesome/css/solid.min.css\" rel=\"stylesheet\">\n<link href=\"../../css/normalize.css\" rel=\"stylesheet\">\n<link href=\"../../css/terminal.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.tile_grid.css\" rel=\"stylesheet\">\n<link href=\"../../css/theme.footer.css\" rel=\"stylesheet\">\n<!-- dark color palette -->\n<link href=\"../../css/palettes/dark.css\" rel=\"stylesheet\">\n\n<!-- page layout -->\n<style>\n/* initially set page layout to a one column grid */\n.terminal-mkdocs-main-grid {\n    display: grid;\n    grid-column-gap: 1.4em;\n    grid-template-columns: auto;\n    grid-template-rows: auto;\n}\n\n/*  \n*   when side navigation is not hidden, use a two column grid.  \n*   if the screen is too narrow, fall back to the initial one column grid layout.\n*   in this case the main content will be placed under the navigation panel. \n*/\n@media only screen and (min-width: 70em) {\n    .terminal-mkdocs-main-grid {\n        grid-template-columns: 4fr 9fr;\n    }\n}</style>\n\n\n\n    \n    <link href=\"../../assets/styles.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/highlight.css\" rel=\"stylesheet\"> \n    <link href=\"../../assets/dmvendor.css\" rel=\"stylesheet\">  \n    \n    \n\n    \n    <!-- search css support -->\n<link href=\"../../css/search/bootstrap-modal.css\" rel=\"stylesheet\">\n<!-- search scripts -->\n<script>\n    var base_url = \"../..\",\n    shortcuts = \"{}\";\n</script>\n<script src=\"../../js/jquery/jquery-1.10.1.min.js\" defer=\"\"></script>\n<script src=\"../../js/bootstrap/bootstrap.min.js\" defer=\"\"></script>\n<script src=\"../../js/mkdocs/base.js\" defer=\"\"></script>\n    \n    \n    \n    \n    <script src=\"../../assets/highlight.min.js\"></script>\n    \n    <script src=\"../../assets/highlight_init.js\"></script>\n    \n    <script src=\"https://buttons.github.io/buttons.js\"></script>\n    \n    <script src=\"../../search/main.js\"></script>\n    \n\n    \n</head>\n\n<body class=\"terminal\" style=\"\"><div class=\"container\">\n    <div class=\"terminal-nav\">\n        <header class=\"terminal-logo\">\n            <div id=\"mkdocs-terminal-site-name\" class=\"logo terminal-prompt\"><a href=\"https://docs.crawl4ai.com/\" class=\"no-style\">Crawl4AI Documentation (v0.4.3bx)</a></div>\n        </header>\n        \n        <nav class=\"terminal-menu\">\n            \n            <ul vocab=\"https://schema.org/\" typeof=\"BreadcrumbList\">\n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../..\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Home</span>\n                    </a>\n                    <meta property=\"position\" content=\"0\">\n                </li>\n                \n                \n                \n                \n                <li property=\"itemListElement\" typeof=\"ListItem\">\n                    <a href=\"../quickstart/\" class=\"menu-item \" property=\"item\" typeof=\"WebPage\">\n                        <span property=\"name\">Quick Start</span>\n                    </a>\n                    <meta property=\"position\" content=\"1\">\n                </li>\n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                \n                    \n                    \n\n\n<li property=\"itemListElement\" typeof=\"ListItem\">\n    <a href=\"#\" class=\"menu-item\" data-toggle=\"modal\" data-target=\"#mkdocs_search_modal\" property=\"item\" typeof=\"SearchAction\">\n        <i aria-hidden=\"true\" class=\"fa fa-search\"></i> <span property=\"name\">Search</span>\n    </a>\n    <meta property=\"position\" content=\"2\">\n</li>\n                    \n            </ul>\n            \n        </nav>\n    </div>\n</div>\n        \n    <div class=\"container\">\n        <div class=\"terminal-mkdocs-main-grid\"><aside id=\"terminal-mkdocs-side-panel\"><nav>\n  \n    <ul class=\"terminal-mkdocs-side-nav-items\">\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../..\">Home</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Setup &amp; Installation</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../installation/\">Installation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../docker-deploymeny/\">Docker Deployment</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../quickstart/\">Quick Start</a>\n        \n    \n    \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Blog &amp; Changelog</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../blog/\">Blog Home</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"https://github.com/unclecode/crawl4ai/blob/main/CHANGELOG.md\">Changelog</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item--active terminal-mkdocs-side-nav-section-no-index\">Core</span>\n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../simple-crawling/\">Simple Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../crawler-result/\">Crawler Result</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../browser-crawler-config/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../markdown-generation/\">Markdown Generation</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../fit-markdown/\">Fit Markdown</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../page-interaction/\">Page Interaction</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../content-selection/\">Content Selection</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../cache-modes/\">Cache Modes</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../local-files/\">Local Files &amp; Raw HTML</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        <span class=\"\n\n    terminal-mkdocs-side-nav-item--active\">Link &amp; Media</span>\n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Advanced</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/advanced-features/\">Overview</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/file-downloading/\">File Downloading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/lazy-loading/\">Lazy Loading</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/hooks-auth/\">Hooks &amp; Auth</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/proxy-security/\">Proxy &amp; Security</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/session-management/\">Session Management</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/multi-url-crawling/\">Multi-URL Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/crawl-dispatcher/\">Crawl Dispatcher</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/identity-based-crawling/\">Identity Based Crawling</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../advanced/ssl-certificate/\">SSL Certificate</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">Extraction</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/no-llm-strategies/\">LLM-Free Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/llm-strategies/\">LLM Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/clustring-strategies/\">Clustering Strategies</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../extraction/chunking/\">Chunking</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n          \n\n\n\n<li class=\"terminal-mkdocs-side-nav-li\">\n    \n    \n        \n        \n\n        \n            \n    \n        \n        \n            \n            \n            <span class=\"\n        \n    \n\n    terminal-mkdocs-side-nav-item terminal-mkdocs-side-nav-section-no-index\">API Reference</span>\n        \n    \n    \n        \n      \n        \n            <ul class=\"terminal-mkdocs-side-nav-li-ul\">\n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/async-webcrawler/\">AsyncWebCrawler</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun/\">arun()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/arun_many/\">arun_many()</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/parameters/\">Browser &amp; Crawler Config</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/crawl-result/\">CrawlResult</a>\n        \n    \n    </li>\n            \n        \n            \n            \n\n             \n                <li class=\"terminal-mkdocs-side-nav-li-ul-li\">\n    \n        \n        \n            <a class=\"\n\n    terminal-mkdocs-side-nav-item\" href=\"../../api/strategies/\">Strategies</a>\n        \n    \n    </li>\n            \n            \n    </ul>\n        \n    \n  </li>\n        \n    </ul>\n  \n</nav><hr>\n<nav>\n    <ul>\n        <li><a href=\"#link-media\">Link &amp; Media</a></li>\n        <li><a href=\"#1-link-extraction\">1. Link Extraction</a></li><li><a href=\"#2-domain-filtering\">2. Domain Filtering</a></li><li><a href=\"#3-media-extraction\">3. Media Extraction</a></li><li><a href=\"#4-putting-it-all-together-link-media-filtering\">4. Putting It All Together: Link &amp; Media Filtering</a></li><li><a href=\"#5-common-pitfalls-tips\">5. Common Pitfalls &amp; Tips</a></li>\n    </ul>\n</nav>\n</aside>\n            <main id=\"terminal-mkdocs-main-content\">\n<section id=\"mkdocs-terminal-content\">\n    <h1 id=\"link-media\">Link &amp; Media</h1>\n<p>In this tutorial, you’ll learn how to:</p>\n<ol>\n<li>Extract links (internal, external) from crawled pages  </li>\n<li>Filter or exclude specific domains (e.g., social media or custom domains)  </li>\n<li>Access and manage media data (especially images) in the crawl result  </li>\n<li>Configure your crawler to exclude or prioritize certain images</li>\n</ol>\n<blockquote>\n<p><strong>Prerequisites</strong><br>\n- You have completed or are familiar with the <a href=\"../simple-crawling/\">AsyncWebCrawler Basics</a> tutorial.<br>\n- You can run Crawl4AI in your environment (Playwright, Python, etc.).</p>\n</blockquote>\n<hr>\n<p>Below is a revised version of the <strong>Link Extraction</strong> and <strong>Media Extraction</strong> sections that includes example data structures showing how links and media items are stored in <code>CrawlResult</code>. Feel free to adjust any field names or descriptions to match your actual output.</p>\n<hr>\n<h2 id=\"1-link-extraction\">1. Link Extraction</h2>\n<h3 id=\"11-resultlinks\">1.1 <code>result.links</code></h3>\n<p>When you call <code>arun()</code> or <code>arun_many()</code> on a URL, Crawl4AI automatically extracts links and stores them in the <code>links</code> field of <code>CrawlResult</code>. By default, the crawler tries to distinguish <strong>internal</strong> links (same domain) from <strong>external</strong> links (different domains).</p>\n<p><strong>Basic Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n    result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://www.example.com\"</span>)\n    <span class=\"hljs-keyword\">if</span> result.success:\n        internal_links = result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])\n        external_links = result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(internal_links)}</span> internal links.\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(internal_links)}</span> external links.\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(result.media)}</span> media items.\"</span>)\n\n        <span class=\"hljs-comment\"># Each link is typically a dictionary with fields like:</span>\n        <span class=\"hljs-comment\"># { \"href\": \"...\", \"text\": \"...\", \"title\": \"...\", \"base_domain\": \"...\" }</span>\n        <span class=\"hljs-keyword\">if</span> internal_links:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Sample Internal Link:\"</span>, internal_links[<span class=\"hljs-number\">0</span>])\n    <span class=\"hljs-keyword\">else</span>:\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Crawl failed:\"</span>, result.error_message)\n</code></pre></div>\n<p><strong>Structure Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-bash\">result.links = {\n  <span class=\"hljs-string\">\"internal\"</span>: [\n    {\n      <span class=\"hljs-string\">\"href\"</span>: <span class=\"hljs-string\">\"https://kidocode.com/\"</span>,\n      <span class=\"hljs-string\">\"text\"</span>: <span class=\"hljs-string\">\"\"</span>,\n      <span class=\"hljs-string\">\"title\"</span>: <span class=\"hljs-string\">\"\"</span>,\n      <span class=\"hljs-string\">\"base_domain\"</span>: <span class=\"hljs-string\">\"kidocode.com\"</span>\n    },\n    {\n      <span class=\"hljs-string\">\"href\"</span>: <span class=\"hljs-string\">\"https://kidocode.com/degrees/technology\"</span>,\n      <span class=\"hljs-string\">\"text\"</span>: <span class=\"hljs-string\">\"Technology Degree\"</span>,\n      <span class=\"hljs-string\">\"title\"</span>: <span class=\"hljs-string\">\"KidoCode Tech Program\"</span>,\n      <span class=\"hljs-string\">\"base_domain\"</span>: <span class=\"hljs-string\">\"kidocode.com\"</span>\n    },\n    <span class=\"hljs-comment\"># ...</span>\n  ],\n  <span class=\"hljs-string\">\"external\"</span>: [\n    <span class=\"hljs-comment\"># possibly other links leading to third-party sites</span>\n  ]\n}\n</code></pre></div>\n<ul>\n<li><strong><code>href</code></strong>: The raw hyperlink URL.  </li>\n<li><strong><code>text</code></strong>: The link text (if any) within the <code>&lt;a&gt;</code> tag.  </li>\n<li><strong><code>title</code></strong>: The <code>title</code> attribute of the link (if present).  </li>\n<li><strong><code>base_domain</code></strong>: The domain extracted from <code>href</code>. Helpful for filtering or grouping by domain.</li>\n</ul>\n<hr>\n<h2 id=\"2-domain-filtering\">2. Domain Filtering</h2>\n<p>Some websites contain hundreds of third-party or affiliate links. You can filter out certain domains at <strong>crawl time</strong> by configuring the crawler. The most relevant parameters in <code>CrawlerRunConfig</code> are:</p>\n<ul>\n<li><strong><code>exclude_external_links</code></strong>: If <code>True</code>, discard any link pointing outside the root domain.  </li>\n<li><strong><code>exclude_social_media_domains</code></strong>: Provide a list of social media platforms (e.g., <code>[\"facebook.com\", \"twitter.com\"]</code>) to exclude from your crawl.  </li>\n<li><strong><code>exclude_social_media_links</code></strong>: If <code>True</code>, automatically skip known social platforms.  </li>\n<li><strong><code>exclude_domains</code></strong>: Provide a list of custom domains you want to exclude (e.g., <code>[\"spammyads.com\", \"tracker.net\"]</code>).</li>\n</ul>\n<h3 id=\"21-example-excluding-external-social-media-links\">2.1 Example: Excluding External &amp; Social Media Links</h3>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    crawler_cfg = CrawlerRunConfig(\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,          <span class=\"hljs-comment\"># No links outside primary domain</span>\n        exclude_social_media_links=<span class=\"hljs-literal\">True</span>       <span class=\"hljs-comment\"># Skip recognized social media domains</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(\n            <span class=\"hljs-string\">\"https://www.example.com\"</span>,\n            config=crawler_cfg\n        )\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[OK] Crawled:\"</span>, result.url)\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Internal links count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"External links count:\"</span>, <span class=\"hljs-built_in\">len</span>(result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])))  \n            <span class=\"hljs-comment\"># Likely zero external links in this scenario</span>\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[ERROR]\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<h3 id=\"22-example-excluding-specific-domains\">2.2 Example: Excluding Specific Domains</h3>\n<p>If you want to let external links in, but specifically exclude a domain (e.g., <code>suspiciousads.com</code>), do this:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-makefile\">crawler_cfg = CrawlerRunConfig(\n    exclude_domains=[<span class=\"hljs-string\">\"suspiciousads.com\"</span>]\n)\n</code></pre></div>\n<p>This approach is handy when you still want external links but need to block certain sites you consider spammy.</p>\n<hr>\n<h2 id=\"3-media-extraction\">3. Media Extraction</h2>\n<h3 id=\"31-accessing-resultmedia\">3.1 Accessing <code>result.media</code></h3>\n<p>By default, Crawl4AI collects images, audio, and video URLs it finds on the page. These are stored in <code>result.media</code>, a dictionary keyed by media type (e.g., <code>images</code>, <code>videos</code>, <code>audio</code>).</p>\n<p><strong>Basic Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">if</span> result.success:\n    images_info = result.media.get(<span class=\"hljs-string\">\"images\"</span>, [])\n    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"Found <span class=\"hljs-subst\">{<span class=\"hljs-built_in\">len</span>(images_info)}</span> images in total.\"</span>)\n    <span class=\"hljs-keyword\">for</span> i, img <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(images_info[:<span class=\"hljs-number\">5</span>]):  <span class=\"hljs-comment\"># Inspect just the first 5</span>\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"[Image <span class=\"hljs-subst\">{i}</span>] URL: <span class=\"hljs-subst\">{img[<span class=\"hljs-string\">'src'</span>]}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Alt text: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'alt'</span>, <span class=\"hljs-string\">''</span>)}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Score: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'score'</span>)}</span>\"</span>)\n        <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"           Description: <span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'desc'</span>, <span class=\"hljs-string\">''</span>)}</span>\\n\"</span>)\n</code></pre></div>\n<p><strong>Structure Example</strong>:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\">result.media = {\n  <span class=\"hljs-string\">\"images\"</span>: [\n    {\n      <span class=\"hljs-string\">\"src\"</span>: <span class=\"hljs-string\">\"https://cdn.prod.website-files.com/.../Group%2089.svg\"</span>,\n      <span class=\"hljs-string\">\"alt\"</span>: <span class=\"hljs-string\">\"coding school for kids\"</span>,\n      <span class=\"hljs-string\">\"desc\"</span>: <span class=\"hljs-string\">\"Trial Class Degrees degrees All Degrees AI Degree Technology ...\"</span>,\n      <span class=\"hljs-string\">\"score\"</span>: <span class=\"hljs-number\">3</span>,\n      <span class=\"hljs-string\">\"type\"</span>: <span class=\"hljs-string\">\"image\"</span>,\n      <span class=\"hljs-string\">\"group_id\"</span>: <span class=\"hljs-number\">0</span>,\n      <span class=\"hljs-string\">\"format\"</span>: <span class=\"hljs-literal\">None</span>,\n      <span class=\"hljs-string\">\"width\"</span>: <span class=\"hljs-literal\">None</span>,\n      <span class=\"hljs-string\">\"height\"</span>: <span class=\"hljs-literal\">None</span>\n    },\n    <span class=\"hljs-comment\"># ...</span>\n  ],\n  <span class=\"hljs-string\">\"videos\"</span>: [\n    <span class=\"hljs-comment\"># Similar structure but with video-specific fields</span>\n  ],\n  <span class=\"hljs-string\">\"audio\"</span>: [\n    <span class=\"hljs-comment\"># Similar structure but with audio-specific fields</span>\n  ]\n}\n</code></pre></div>\n<p>Depending on your Crawl4AI version or scraping strategy, these dictionaries can include fields like:</p>\n<ul>\n<li><strong><code>src</code></strong>: The media URL (e.g., image source)  </li>\n<li><strong><code>alt</code></strong>: The alt text for images (if present)  </li>\n<li><strong><code>desc</code></strong>: A snippet of nearby text or a short description (optional)  </li>\n<li><strong><code>score</code></strong>: A heuristic relevance score if you’re using content-scoring features  </li>\n<li><strong><code>width</code></strong>, <strong><code>height</code></strong>: If the crawler detects dimensions for the image/video  </li>\n<li><strong><code>type</code></strong>: Usually <code>\"image\"</code>, <code>\"video\"</code>, or <code>\"audio\"</code>  </li>\n<li><strong><code>group_id</code></strong>: If you’re grouping related media items, the crawler might assign an ID  </li>\n</ul>\n<p>With these details, you can easily filter out or focus on certain images (for instance, ignoring images with very low scores or a different domain), or gather metadata for analytics.</p>\n<h3 id=\"32-excluding-external-images\">3.2 Excluding External Images</h3>\n<p>If you’re dealing with heavy pages or want to skip third-party images (advertisements, for example), you can turn on:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-graphql\">crawler_cfg <span class=\"hljs-punctuation\">=</span> CrawlerRunConfig<span class=\"hljs-punctuation\">(</span>\n    exclude_external_images<span class=\"hljs-punctuation\">=</span><span class=\"hljs-literal\">True</span>\n<span class=\"hljs-punctuation\">)</span>\n</code></pre></div>\n<p>This setting attempts to discard images from outside the primary domain, keeping only those from the site you’re crawling.</p>\n<h3 id=\"33-additional-media-config\">3.3 Additional Media Config</h3>\n<ul>\n<li><strong><code>screenshot</code></strong>: Set to <code>True</code> if you want a full-page screenshot stored as <code>base64</code> in <code>result.screenshot</code>.  </li>\n<li><strong><code>pdf</code></strong>: Set to <code>True</code> if you want a PDF version of the page in <code>result.pdf</code>.  </li>\n<li><strong><code>wait_for_images</code></strong>: If <code>True</code>, attempts to wait until images are fully loaded before final extraction.</li>\n</ul>\n<hr>\n<h2 id=\"4-putting-it-all-together-link-media-filtering\">4. Putting It All Together: Link &amp; Media Filtering</h2>\n<p>Here’s a combined example demonstrating how to filter out external links, skip certain domains, and exclude external images:</p>\n<div class=\"highlight\"><pre><span></span><code data-highlighted=\"yes\" class=\"hljs language-python\"><span class=\"hljs-keyword\">import</span> asyncio\n<span class=\"hljs-keyword\">from</span> crawl4ai <span class=\"hljs-keyword\">import</span> AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\n\n<span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():\n    <span class=\"hljs-comment\"># Suppose we want to keep only internal links, remove certain domains, </span>\n    <span class=\"hljs-comment\"># and discard external images from the final crawl data.</span>\n    crawler_cfg = CrawlerRunConfig(\n        exclude_external_links=<span class=\"hljs-literal\">True</span>,\n        exclude_domains=[<span class=\"hljs-string\">\"spammyads.com\"</span>],\n        exclude_social_media_links=<span class=\"hljs-literal\">True</span>,   <span class=\"hljs-comment\"># skip Twitter, Facebook, etc.</span>\n        exclude_external_images=<span class=\"hljs-literal\">True</span>,      <span class=\"hljs-comment\"># keep only images from main domain</span>\n        wait_for_images=<span class=\"hljs-literal\">True</span>,             <span class=\"hljs-comment\"># ensure images are loaded</span>\n        verbose=<span class=\"hljs-literal\">True</span>\n    )\n\n    <span class=\"hljs-keyword\">async</span> <span class=\"hljs-keyword\">with</span> AsyncWebCrawler() <span class=\"hljs-keyword\">as</span> crawler:\n        result = <span class=\"hljs-keyword\">await</span> crawler.arun(<span class=\"hljs-string\">\"https://www.example.com\"</span>, config=crawler_cfg)\n\n        <span class=\"hljs-keyword\">if</span> result.success:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[OK] Crawled:\"</span>, result.url)\n\n            <span class=\"hljs-comment\"># 1. Links</span>\n            in_links = result.links.get(<span class=\"hljs-string\">\"internal\"</span>, [])\n            ext_links = result.links.get(<span class=\"hljs-string\">\"external\"</span>, [])\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Internal link count:\"</span>, <span class=\"hljs-built_in\">len</span>(in_links))\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"External link count:\"</span>, <span class=\"hljs-built_in\">len</span>(ext_links))  <span class=\"hljs-comment\"># should be zero with exclude_external_links=True</span>\n\n            <span class=\"hljs-comment\"># 2. Images</span>\n            images = result.media.get(<span class=\"hljs-string\">\"images\"</span>, [])\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"Images found:\"</span>, <span class=\"hljs-built_in\">len</span>(images))\n\n            <span class=\"hljs-comment\"># Let's see a snippet of these images</span>\n            <span class=\"hljs-keyword\">for</span> i, img <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(images[:<span class=\"hljs-number\">3</span>]):\n                <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f\"  - <span class=\"hljs-subst\">{img[<span class=\"hljs-string\">'src'</span>]}</span> (alt=<span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'alt'</span>,<span class=\"hljs-string\">''</span>)}</span>, score=<span class=\"hljs-subst\">{img.get(<span class=\"hljs-string\">'score'</span>,<span class=\"hljs-string\">'N/A'</span>)}</span>)\"</span>)\n        <span class=\"hljs-keyword\">else</span>:\n            <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"[ERROR] Failed to crawl. Reason:\"</span>, result.error_message)\n\n<span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">\"__main__\"</span>:\n    asyncio.run(main())\n</code></pre></div>\n<hr>\n<h2 id=\"5-common-pitfalls-tips\">5. Common Pitfalls &amp; Tips</h2>\n<p>1. <strong>Conflicting Flags</strong>:<br>\n   - <code>exclude_external_links=True</code> but then also specifying <code>exclude_social_media_links=True</code> is typically fine, but understand that the first setting already discards <em>all</em> external links. The second becomes somewhat redundant.<br>\n   - <code>exclude_external_images=True</code> but want to keep some external images? Currently no partial domain-based setting for images, so you might need a custom approach or hook logic.</p>\n<p>2. <strong>Relevancy Scores</strong>:<br>\n   - If your version of Crawl4AI or your scraping strategy includes an <code>img[\"score\"]</code>, it’s typically a heuristic based on size, position, or content analysis. Evaluate carefully if you rely on it.</p>\n<p>3. <strong>Performance</strong>:<br>\n   - Excluding certain domains or external images can speed up your crawl, especially for large, media-heavy pages.<br>\n   - If you want a “full” link map, do <em>not</em> exclude them. Instead, you can post-filter in your own code.</p>\n<p>4. <strong>Social Media Lists</strong>:<br>\n   - <code>exclude_social_media_links=True</code> typically references an internal list of known social domains like Facebook, Twitter, LinkedIn, etc. If you need to add or remove from that list, look for library settings or a local config file (depending on your version).</p>\n<hr>\n<p><strong>That’s it for Link &amp; Media Analysis!</strong> You’re now equipped to filter out unwanted sites and zero in on the images and videos that matter for your project.</p>\n</section>\n\n            </main>\n        </div>\n        <hr><footer>\n    <div class=\"terminal-mkdocs-footer-grid\">\n        <div id=\"terminal-mkdocs-footer-copyright-info\">\n             Site built with <a href=\"http://www.mkdocs.org\">MkDocs</a> and <a href=\"https://github.com/ntno/mkdocs-terminal\">Terminal for MkDocs</a>.\n        </div>\n    </div>\n</footer>\n    </div>\n\n    \n    <div class=\"modal\" id=\"mkdocs_search_modal\" tabindex=\"-1\" role=\"alertdialog\" aria-modal=\"true\" aria-labelledby=\"searchModalLabel\">\n    <div class=\"modal-dialog modal-lg\" role=\"search\">\n        <div class=\"modal-content\">\n            <div class=\"modal-header\">\n                <h5 class=\"modal-title\" id=\"searchModalLabel\">Search</h5>\n                <button type=\"button\" class=\"close btn btn-default btn-ghost\" data-dismiss=\"modal\"><span aria-hidden=\"true\">x</span><span class=\"sr-only\">Close</span></button>\n            </div>\n            <div class=\"modal-body\">\n                <p id=\"searchInputLabel\">Type to start searching</p>\n                <form>\n                    <div class=\"form-group\">\n                        <input type=\"search\" class=\"form-control\" aria-labelledby=\"searchInputLabel\" placeholder=\"\" id=\"mkdocs-search-query\" title=\"Please enter search terms here\">\n                    </div>\n                </form>\n                <div id=\"mkdocs-search-results\" data-no-results-text=\"No document matches found\"></div>\n            </div>\n            <div class=\"modal-footer\">\n            </div>\n        </div>\n    </div>\n</div>\n    \n    \n\n\n</body></html>",
  "markdown": "# Link & Media\nIn this tutorial, you’ll learn how to:\n  1. Extract links (internal, external) from crawled pages \n  2. Filter or exclude specific domains (e.g., social media or custom domains) \n  3. Access and manage media data (especially images) in the crawl result \n  4. Configure your crawler to exclude or prioritize certain images\n\n\n> **Prerequisites** - You have completed or are familiar with the [AsyncWebCrawler Basics](https://docs.crawl4ai.com/core/<../simple-crawling/>) tutorial. - You can run Crawl4AI in your environment (Playwright, Python, etc.).\nBelow is a revised version of the **Link Extraction** and **Media Extraction** sections that includes example data structures showing how links and media items are stored in `CrawlResult`. Feel free to adjust any field names or descriptions to match your actual output.\n## 1. Link Extraction\n### 1.1 `result.links`\nWhen you call `arun()` or `arun_many()` on a URL, Crawl4AI automatically extracts links and stores them in the `links` field of `CrawlResult`. By default, the crawler tries to distinguish **internal** links (same domain) from **external** links (different domains).\n**Basic Example** :\n```\nfrom crawl4ai import AsyncWebCrawler\nasync with AsyncWebCrawler() as crawler:\n  result = await crawler.arun(\"https://www.example.com\")\n  if result.success:\n    internal_links = result.links.get(\"internal\", [])\n    external_links = result.links.get(\"external\", [])\n    print(f\"Found {len(internal_links)} internal links.\")\n    print(f\"Found {len(internal_links)} external links.\")\n    print(f\"Found {len(result.media)} media items.\")\n    # Each link is typically a dictionary with fields like:\n    # { \"href\": \"...\", \"text\": \"...\", \"title\": \"...\", \"base_domain\": \"...\" }\n    if internal_links:\n      print(\"Sample Internal Link:\", internal_links[0])\n  else:\n    print(\"Crawl failed:\", result.error_message)\n\n```\n\n**Structure Example** :\n```\nresult.links = {\n \"internal\": [\n  {\n   \"href\": \"https://kidocode.com/\",\n   \"text\": \"\",\n   \"title\": \"\",\n   \"base_domain\": \"kidocode.com\"\n  },\n  {\n   \"href\": \"https://kidocode.com/degrees/technology\",\n   \"text\": \"Technology Degree\",\n   \"title\": \"KidoCode Tech Program\",\n   \"base_domain\": \"kidocode.com\"\n  },\n  # ...\n ],\n \"external\": [\n  # possibly other links leading to third-party sites\n ]\n}\n\n```\n\n  * **`href`**: The raw hyperlink URL.\n  * **`text`**: The link text (if any) within the`<a>` tag. \n  * **`title`**: The`title` attribute of the link (if present). \n  * **`base_domain`**: The domain extracted from`href`. Helpful for filtering or grouping by domain.\n\n\n## 2. Domain Filtering\nSome websites contain hundreds of third-party or affiliate links. You can filter out certain domains at **crawl time** by configuring the crawler. The most relevant parameters in `CrawlerRunConfig` are:\n  * **`exclude_external_links`**: If`True` , discard any link pointing outside the root domain. \n  * **`exclude_social_media_domains`**: Provide a list of social media platforms (e.g.,`[\"facebook.com\", \"twitter.com\"]`) to exclude from your crawl. \n  * **`exclude_social_media_links`**: If`True` , automatically skip known social platforms. \n  * **`exclude_domains`**: Provide a list of custom domains you want to exclude (e.g.,`[\"spammyads.com\", \"tracker.net\"]`).\n\n\n### 2.1 Example: Excluding External & Social Media Links\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  crawler_cfg = CrawlerRunConfig(\n    exclude_external_links=True,     # No links outside primary domain\n    exclude_social_media_links=True    # Skip recognized social media domains\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\n      \"https://www.example.com\",\n      config=crawler_cfg\n    )\n    if result.success:\n      print(\"[OK] Crawled:\", result.url)\n      print(\"Internal links count:\", len(result.links.get(\"internal\", [])))\n      print(\"External links count:\", len(result.links.get(\"external\", []))) \n      # Likely zero external links in this scenario\n    else:\n      print(\"[ERROR]\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n### 2.2 Example: Excluding Specific Domains\nIf you want to let external links in, but specifically exclude a domain (e.g., `suspiciousads.com`), do this:\n```\ncrawler_cfg = CrawlerRunConfig(\n  exclude_domains=[\"suspiciousads.com\"]\n)\n\n```\n\nThis approach is handy when you still want external links but need to block certain sites you consider spammy.\n## 3. Media Extraction\n### 3.1 Accessing `result.media`\nBy default, Crawl4AI collects images, audio, and video URLs it finds on the page. These are stored in `result.media`, a dictionary keyed by media type (e.g., `images`, `videos`, `audio`).\n**Basic Example** :\n```\nif result.success:\n  images_info = result.media.get(\"images\", [])\n  print(f\"Found {len(images_info)} images in total.\")\n  for i, img in enumerate(images_info[:5]): # Inspect just the first 5\n    print(f\"[Image {i}] URL: {img['src']}\")\n    print(f\"      Alt text: {img.get('alt', '')}\")\n    print(f\"      Score: {img.get('score')}\")\n    print(f\"      Description: {img.get('desc', '')}\\n\")\n\n```\n\n**Structure Example** :\n```\nresult.media = {\n \"images\": [\n  {\n   \"src\": \"https://cdn.prod.website-files.com/.../Group%2089.svg\",\n   \"alt\": \"coding school for kids\",\n   \"desc\": \"Trial Class Degrees degrees All Degrees AI Degree Technology ...\",\n   \"score\": 3,\n   \"type\": \"image\",\n   \"group_id\": 0,\n   \"format\": None,\n   \"width\": None,\n   \"height\": None\n  },\n  # ...\n ],\n \"videos\": [\n  # Similar structure but with video-specific fields\n ],\n \"audio\": [\n  # Similar structure but with audio-specific fields\n ]\n}\n\n```\n\nDepending on your Crawl4AI version or scraping strategy, these dictionaries can include fields like:\n  * **`src`**: The media URL (e.g., image source)\n  * **`alt`**: The alt text for images (if present)\n  * **`desc`**: A snippet of nearby text or a short description (optional)\n  * **`score`**: A heuristic relevance score if you’re using content-scoring features\n  * **`width`**,**`height`**: If the crawler detects dimensions for the image/video\n  * **`type`**: Usually`\"image\"` , `\"video\"`, or `\"audio\"`\n  * **`group_id`**: If you’re grouping related media items, the crawler might assign an ID\n\n\nWith these details, you can easily filter out or focus on certain images (for instance, ignoring images with very low scores or a different domain), or gather metadata for analytics.\n### 3.2 Excluding External Images\nIf you’re dealing with heavy pages or want to skip third-party images (advertisements, for example), you can turn on:\n```\ncrawler_cfg = CrawlerRunConfig(\n  exclude_external_images=True\n)\n\n```\n\nThis setting attempts to discard images from outside the primary domain, keeping only those from the site you’re crawling.\n### 3.3 Additional Media Config\n  * **`screenshot`**: Set to`True` if you want a full-page screenshot stored as `base64` in `result.screenshot`. \n  * **`pdf`**: Set to`True` if you want a PDF version of the page in `result.pdf`. \n  * **`wait_for_images`**: If`True` , attempts to wait until images are fully loaded before final extraction.\n\n\n## 4. Putting It All Together: Link & Media Filtering\nHere’s a combined example demonstrating how to filter out external links, skip certain domains, and exclude external images:\n```\nimport asyncio\nfrom crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig\nasync def main():\n  # Suppose we want to keep only internal links, remove certain domains, \n  # and discard external images from the final crawl data.\n  crawler_cfg = CrawlerRunConfig(\n    exclude_external_links=True,\n    exclude_domains=[\"spammyads.com\"],\n    exclude_social_media_links=True,  # skip Twitter, Facebook, etc.\n    exclude_external_images=True,   # keep only images from main domain\n    wait_for_images=True,       # ensure images are loaded\n    verbose=True\n  )\n  async with AsyncWebCrawler() as crawler:\n    result = await crawler.arun(\"https://www.example.com\", config=crawler_cfg)\n    if result.success:\n      print(\"[OK] Crawled:\", result.url)\n      # 1. Links\n      in_links = result.links.get(\"internal\", [])\n      ext_links = result.links.get(\"external\", [])\n      print(\"Internal link count:\", len(in_links))\n      print(\"External link count:\", len(ext_links)) # should be zero with exclude_external_links=True\n      # 2. Images\n      images = result.media.get(\"images\", [])\n      print(\"Images found:\", len(images))\n      # Let's see a snippet of these images\n      for i, img in enumerate(images[:3]):\n        print(f\" - {img['src']} (alt={img.get('alt','')}, score={img.get('score','N/A')})\")\n    else:\n      print(\"[ERROR] Failed to crawl. Reason:\", result.error_message)\nif __name__ == \"__main__\":\n  asyncio.run(main())\n\n```\n\n## 5. Common Pitfalls & Tips\n1. **Conflicting Flags** : - `exclude_external_links=True` but then also specifying `exclude_social_media_links=True` is typically fine, but understand that the first setting already discards _all_ external links. The second becomes somewhat redundant. - `exclude_external_images=True` but want to keep some external images? Currently no partial domain-based setting for images, so you might need a custom approach or hook logic.\n2. **Relevancy Scores** : - If your version of Crawl4AI or your scraping strategy includes an `img[\"score\"]`, it’s typically a heuristic based on size, position, or content analysis. Evaluate carefully if you rely on it.\n3. **Performance** : - Excluding certain domains or external images can speed up your crawl, especially for large, media-heavy pages. - If you want a “full” link map, do _not_ exclude them. Instead, you can post-filter in your own code.\n4. **Social Media Lists** : - `exclude_social_media_links=True` typically references an internal list of known social domains like Facebook, Twitter, LinkedIn, etc. If you need to add or remove from that list, look for library settings or a local config file (depending on your version).\n**That’s it for Link & Media Analysis!** You’re now equipped to filter out unwanted sites and zero in on the images and videos that matter for your project.\n##### Search\nxClose\nType to start searching\n",
  "links": [
    "https://docs.crawl4ai.com",
    "https://docs.crawl4ai.com/advanced/advanced-features",
    "https://docs.crawl4ai.com/advanced/crawl-dispatcher",
    "https://docs.crawl4ai.com/advanced/file-downloading",
    "https://docs.crawl4ai.com/advanced/hooks-auth",
    "https://docs.crawl4ai.com/advanced/identity-based-crawling",
    "https://docs.crawl4ai.com/advanced/lazy-loading",
    "https://docs.crawl4ai.com/advanced/multi-url-crawling",
    "https://docs.crawl4ai.com/advanced/proxy-security",
    "https://docs.crawl4ai.com/advanced/session-management",
    "https://docs.crawl4ai.com/advanced/ssl-certificate",
    "https://docs.crawl4ai.com/api/arun",
    "https://docs.crawl4ai.com/api/arun_many",
    "https://docs.crawl4ai.com/api/async-webcrawler",
    "https://docs.crawl4ai.com/api/crawl-result",
    "https://docs.crawl4ai.com/api/parameters",
    "https://docs.crawl4ai.com/api/strategies",
    "https://docs.crawl4ai.com/blog",
    "https://docs.crawl4ai.com/browser-crawler-config",
    "https://docs.crawl4ai.com/cache-modes",
    "https://docs.crawl4ai.com/content-selection",
    "https://docs.crawl4ai.com/crawler-result",
    "https://docs.crawl4ai.com/docker-deploymeny",
    "https://docs.crawl4ai.com/extraction/chunking",
    "https://docs.crawl4ai.com/extraction/clustring-strategies",
    "https://docs.crawl4ai.com/extraction/llm-strategies",
    "https://docs.crawl4ai.com/extraction/no-llm-strategies",
    "https://docs.crawl4ai.com/fit-markdown",
    "https://docs.crawl4ai.com/installation",
    "https://docs.crawl4ai.com/local-files",
    "https://docs.crawl4ai.com/markdown-generation",
    "https://docs.crawl4ai.com/page-interaction",
    "https://docs.crawl4ai.com/quickstart",
    "https://docs.crawl4ai.com/simple-crawling"
  ],
  "depth": 1,
  "stats": {
    "processed": 21,
    "total": 0,
    "depth": 1,
    "elapsed": "0:00:26",
    "page_limit": 34
  }
}